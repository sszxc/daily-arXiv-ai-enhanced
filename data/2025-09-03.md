<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 83]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Robotic Fire Risk Detection based on Dynamic Knowledge Graph Reasoning: An LLM-Driven Approach with Graph Chain-of-Thought](https://arxiv.org/abs/2509.00054)
*Haimei Pan,Jiyun Zhang,Qinxi Wei,Xiongnan Jin,Chen Xinkai,Jie Cheng*

Main category: cs.RO

TL;DR: 本文构建了一个利用大型语言模型整合火灾领域知识的知识图谱，并提出了Insights-on-Graph（IOG）框架，该框架结合知识图谱的结构化火灾信息和大型多模态模型，能从实时场景图像生成感知驱动的风险图，实现早期火灾风险检测并提供可解释的应急响应，经实验验证在火灾风险检测和救援决策中具有良好适用性和实用价值。


<details>
  <summary>Details</summary>
Motivation: 当前火灾场景下的灾前预警和灾时救援研究面临感知不完整、火灾态势感知不足和响应延迟等挑战，需要增强机器人的智能感知和响应规划能力。

Method: 首先利用大型语言模型构建整合火灾预防指南中的火灾领域知识和机器人应急响应文档中的火灾救援任务信息的知识图谱；然后提出Insights-on-Graph（IOG）框架，整合知识图谱的结构化火灾信息和大型多模态模型，从实时场景图像生成感知驱动的风险图。

Result: 广泛的模拟和真实世界实验表明，IOG在火灾风险检测和救援决策中具有良好的适用性和实际应用价值。

Conclusion: IOG框架能够有效解决火灾场景中机器人智能感知和响应规划的问题，在火灾风险检测和救援决策方面具有良好的应用前景和实用价值。

Abstract: Fire is a highly destructive disaster, but effective prevention can
significantly reduce its likelihood of occurrence. When it happens, deploying
emergency robots in fire-risk scenarios can help minimize the danger to human
responders. However, current research on pre-disaster warnings and
disaster-time rescue still faces significant challenges due to incomplete
perception, inadequate fire situational awareness, and delayed response. To
enhance intelligent perception and response planning for robots in fire
scenarios, we first construct a knowledge graph (KG) by leveraging large
language models (LLMs) to integrate fire domain knowledge derived from fire
prevention guidelines and fire rescue task information from robotic emergency
response documents. We then propose a new framework called Insights-on-Graph
(IOG), which integrates the structured fire information of KG and Large
Multimodal Models (LMMs). The framework generates perception-driven risk graphs
from real-time scene imagery to enable early fire risk detection and provide
interpretable emergency responses for task module and robot component
configuration based on the evolving risk situation. Extensive simulations and
real-world experiments show that IOG has good applicability and practical
application value in fire risk detection and rescue decision-making.

</details>


### [2] [U2UData-2: A Scalable Swarm UAVs Autonomous Flight Dataset for Long-horizon Tasks](https://arxiv.org/abs/2509.00055)
*Tongtong Feng,Xin Wang,Feilin Han,Leping Zhang,Wenwu Zhu*

Main category: cs.RO

TL;DR: 本文提出U2UData-2，首个用于长时（LH）任务的大规模群体无人机自主飞行数据集及可扩展的数据在线采集与算法闭环验证平台，包含15架无人机在12个场景下的720条轨迹等数据，支持定制化并提供野生动物保护LH任务及9个SOTA模型基准。


<details>
  <summary>Details</summary>
Motivation: 现有方法因数据集限制仅关注特定基础任务，无法在现实世界中部署长时（LH）任务，而LH任务需处理长期依赖、维持持久状态及适应动态目标变化。

Method: 构建U2UData-2数据集，由15架无人机自主协作飞行采集，包含12个场景、720条轨迹等多类型数据；开发可扩展的群体无人机数据在线采集与算法闭环验证平台，支持模拟器、无人机等多方面定制，通过可视化控制窗口实现一键部署在线采集定制化数据集及闭环仿真验证算法。

Result: 提供了首个用于LH任务的大规模群体无人机自主飞行数据集U2UData-2，并开发了相应的可扩展平台，还引入野生动物保护LH任务及9个SOTA模型的综合基准。

Conclusion: U2UData-2为群体无人机长时任务研究提供了重要的数据支持和验证平台，有助于推动低空经济发展。

Abstract: Swarm UAV autonomous flight for Long-Horizon (LH) tasks is crucial for
advancing the low-altitude economy. However, existing methods focus only on
specific basic tasks due to dataset limitations, failing in real-world
deployment for LH tasks. LH tasks are not mere concatenations of basic tasks,
requiring handling long-term dependencies, maintaining persistent states, and
adapting to dynamic goal shifts. This paper presents U2UData-2, the first
large-scale swarm UAV autonomous flight dataset for LH tasks and the first
scalable swarm UAV data online collection and algorithm closed-loop
verification platform. The dataset is captured by 15 UAVs in autonomous
collaborative flights for LH tasks, comprising 12 scenes, 720 traces, 120
hours, 600 seconds per trajectory, 4.32M LiDAR frames, and 12.96M RGB frames.
This dataset also includes brightness, temperature, humidity, smoke, and
airflow values covering all flight routes. The platform supports the
customization of simulators, UAVs, sensors, flight algorithms, formation modes,
and LH tasks. Through a visual control window, this platform allows users to
collect customized datasets through one-click deployment online and to verify
algorithms by closed-loop simulation. U2UData-2 also introduces an LH task for
wildlife conservation and provides comprehensive benchmarks with 9 SOTA models.
U2UData-2 can be found at https://fengtt42.github.io/U2UData-2/.

</details>


### [3] [Correspondence-Free, Function-Based Sim-to-Real Learning for Deformable Surface Control](https://arxiv.org/abs/2509.00060)
*Yingjun Tian,Guoxin Fang,Renbo Su,Aoran Lyu,Neelotpal Dutta,Simeon Gill,Andrew Weightman,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 本文提出一种无对应、基于函数的仿真到现实学习方法，用于控制可变形自由曲面，无需依赖全对应标记点，能整合到逆运动学和形状控制的神经网络计算流程中，并在四种气动驱动软体机器人上验证了其通用性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统仿真到现实迁移方法强烈依赖带全对应标记点，存在局限性，需一种不依赖此类标记点的方法以适应不同输入（如无对应点云或容忍缺失标记点的运动捕捉数据）。

Method: 同时学习一个由神经网络参数化的变形函数空间和置信度图，将模拟形状映射到现实对应物，支持3D扫描仪的点云输入（无对应）或运动捕捉系统的标记点输入（容忍缺失标记）。

Result: 该仿真到现实迁移可无缝整合到基于神经网络的逆运动学和形状控制计算流程中，在视觉设备和四种气动驱动软体机器人（可变形膜、机器人模特、两个软体操纵器）上展示了通用性和适应性。

Conclusion: 所提无对应、基于函数的仿真到现实学习方法有效解决了传统方法依赖标记点的问题，具有良好的通用性和适应性，适用于多种软体机器人控制。

Abstract: This paper presents a correspondence-free, function-based sim-to-real
learning method for controlling deformable freeform surfaces. Unlike
traditional sim-to-real transfer methods that strongly rely on marker points
with full correspondences, our approach simultaneously learns a deformation
function space and a confidence map -- both parameterized by a neural network
-- to map simulated shapes to their real-world counterparts. As a result, the
sim-to-real learning can be conducted by input from either a 3D scanner as
point clouds (without correspondences) or a motion capture system as marker
points (tolerating missed markers). The resultant sim-to-real transfer can be
seamlessly integrated into a neural network-based computational pipeline for
inverse kinematics and shape control. We demonstrate the versatility and
adaptability of our method on both vision devices and across four pneumatically
actuated soft robots: a deformable membrane, a robotic mannequin, and two soft
manipulators.

</details>


### [4] [OpenTie: Open-vocabulary Sequential Rebar Tying System](https://arxiv.org/abs/2509.00064)
*Mingze Liu,Sai Fan,Haozhen Li,Haobo Liang,Yixing Yuan,Yanke Wang*

Main category: cs.RO

TL;DR: 本文提出OpenTie，一种无训练的3D钢筋绑扎框架，结合RGB转点云生成和开放词汇检测，通过机械臂和双目相机实现，适用于水平和垂直钢筋绑扎任务，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有产品和研究主要集中于需要模型训练的平面钢筋设置，存在空白，故提出OpenTie以满足3D无训练钢筋绑扎需求。

Method: 利用RGB到点云生成和开放词汇检测，通过带双目相机的机械臂实现OpenTie；应用基于提示的目标检测方法于经提出的基于图像到点云生成框架的后处理程序过滤后的图像，以保证高精度。

Result: 系统对水平和垂直钢筋绑扎任务具有灵活性，在真实钢筋设置场景的实验验证了该系统在实践中的有效性。

Conclusion: OpenTie框架有效解决了现有钢筋绑扎研究中对训练的依赖和平面限制问题，适用于复杂3D场景，具有实践应用价值。

Abstract: Robotic practices on the construction site emerge as an attention-attracting
manner owing to their capability of tackle complex challenges, especially in
the rebar-involved scenarios. Most of existing products and research are mainly
focused on flat rebar setting with model training demands. To fulfill this gap,
we propose OpenTie, a 3D training-free rebar tying framework utilizing a
RGB-to-point-cloud generation and an open-vocabulary detection. We implements
the OpenTie via a robotic arm with a binocular camera and guarantees a high
accuracy by applying the prompt-based object detection method on the image
filtered by our propose post-processing procedure based a image to point cloud
generation framework. The system is flexible for horizontal and vertical rebar
tying tasks and the experiments on the real-world rebar setting verifies that
the effectiveness of the system in practice.

</details>


### [5] [Hybrid Perception and Equivariant Diffusion for Robust Multi-Node Rebar Tying](https://arxiv.org/abs/2509.00065)
*Zhitao Wang,Yirong Xiong,Roberto Horowitz,Yanke Wang,Yuxing Han*

Main category: cs.RO

TL;DR: 本文提出一种混合感知与运动规划方法，整合基于几何的感知与SE(3)上的等变去噪扩散（Diffusion-EDFs），实现少样本训练下的鲁棒多节点钢筋绑扎。


<details>
  <summary>Details</summary>
Motivation: 钢筋绑扎是混凝土施工中重复且关键的任务，人工操作存在人体工程学风险，现有机器人技术在密集钢筋节点中准确估计绑扎位姿面临挑战。

Method: 感知模块采用DBSCAN聚类、基于几何的节点特征提取和PCA，用于分割钢筋、识别节点并估计方向向量；运动规划器基于Diffusion-EDFs，仅需5-10次演示训练，生成优化避碰和绑扎效率的末端执行器位姿。

Result: 在单层、多层及杂乱配置的钢筋网格上验证，节点检测成功率高，绑扎顺序准确，相比依赖大数据集或大量手动参数调优的传统方法，减少数据需求且实现鲁棒、高效、自适应的多节点绑扎。

Conclusion: 混合感知与扩散驱动规划方法能增强现场施工任务自动化，提升安全性和劳动效率。

Abstract: Rebar tying is a repetitive but critical task in reinforced concrete
construction, typically performed manually at considerable ergonomic risk.
Recent advances in robotic manipulation hold the potential to automate the
tying process, yet face challenges in accurately estimating tying poses in
congested rebar nodes. In this paper, we introduce a hybrid perception and
motion planning approach that integrates geometry-based perception with
Equivariant Denoising Diffusion on SE(3) (Diffusion-EDFs) to enable robust
multi-node rebar tying with minimal training data. Our perception module
utilizes density-based clustering (DBSCAN), geometry-based node feature
extraction, and principal component analysis (PCA) to segment rebar bars,
identify rebar nodes, and estimate orientation vectors for sequential ranking,
even in complex, unstructured environments. The motion planner, based on
Diffusion-EDFs, is trained on as few as 5-10 demonstrations to generate
sequential end-effector poses that optimize collision avoidance and tying
efficiency. The proposed system is validated on various rebar meshes, including
single-layer, multi-layer, and cluttered configurations, demonstrating high
success rates in node detection and accurate sequential tying. Compared with
conventional approaches that rely on large datasets or extensive manual
parameter tuning, our method achieves robust, efficient, and adaptable
multi-node tying while significantly reducing data requirements. This result
underscores the potential of hybrid perception and diffusion-driven planning to
enhance automation in on-site construction tasks, improving both safety and
labor efficiency.

</details>


### [6] [A Comparative Study of Spline-Based Trajectory Reconstruction Methods Across Varying Automatic Vehicle Location Data Densities](https://arxiv.org/abs/2509.00119)
*Jake Robbennolt,Sirajum Munira,Stephen D. Boyles*

Main category: cs.RO

TL;DR: 本研究评估了13种轨迹重建方法（含新方法），使用德克萨斯州奥斯汀的高分辨率AVL数据，分析速度、位置、平滑度和数据密度四因素对性能的影响，发现速度感知方法优于仅位置方法，VCHIP-ME在准确性和计算效率间平衡最佳，为相关系统实施提供指导并强调高频AVL数据收集的重要性。


<details>
  <summary>Details</summary>
Motivation: AVL数据能洞察交通动态，但因更新频率不一致需轨迹重建，现有方法缺乏在稀疏和密集数据集上的综合评估及对实际应用的指导。

Method: 评估13种轨迹重建方法（含新方法），结合传统数学误差指标（位置和速度）与实际考量（如物理真实性：速度、加速度与停止状态、减速率、速度变化的一致性），分析速度、位置、平滑度和数据密度四因素影响，在稀疏和密集数据集上进行评估。

Result: 速度感知方法持续优于仅位置方法；平滑方法在复杂拥堵城市环境中会降低整体性能，但单调性约束仍关键；速度约束Hermite插值（VCHIP-ME）效果最优，兼具高精度和计算效率，最小开销使其适用于历史分析和实时应用，结合密集数据集时预测能力显著。

Conclusion: 研究结果为轨迹重建系统的研究人员和从业者提供实用指导，强调投资更高频率AVL数据收集以改善分析的重要性。

Abstract: Automatic vehicle location (AVL) data offers insights into transit dynamics,
but its effectiveness is often hampered by inconsistent update frequencies,
necessitating trajectory reconstruction. This research evaluates 13 trajectory
reconstruction methods, including several novel approaches, using
high-resolution AVL data from Austin, Texas. We examine the interplay of four
critical factors -- velocity, position, smoothing, and data density -- on
reconstruction performance. A key contribution of this study is evaluation of
these methods across sparse and dense datasets, providing insights into the
trade-off between accuracy and resource allocation. Our evaluation framework
combines traditional mathematical error metrics for positional and velocity
with practical considerations, such as physical realism (e.g., aligning
velocity and acceleration with stopped states, deceleration rates, and speed
variability). In addition, we provide insight into the relative value of each
method in calculating realistic metrics for infrastructure evaluations. Our
findings indicate that velocity-aware methods consistently outperform
position-only approaches. Interestingly, we discovered that smoothing-based
methods can degrade overall performance in complex, congested urban
environments, although enforcing monotonicity remains critical. The velocity
constrained Hermite interpolation with monotonicity enforcement (VCHIP-ME)
yields optimal results, offering a balance between high accuracy and
computational efficiency. Its minimal overhead makes it suitable for both
historical analysis and real-time applications, providing significant
predictive power when combined with dense datasets. These findings offer
practical guidance for researchers and practitioners implementing trajectory
reconstruction systems and emphasize the importance of investing in
higher-frequency AVL data collection for improved analysis.

</details>


### [7] [Poke and Strike: Learning Task-Informed Exploration Policies](https://arxiv.org/abs/2509.00178)
*Marina Y. Aoyama,Joao Moura,Juan Del Aguila Ferrandis,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 本文提出一种基于强化学习的任务感知探索方法，通过任务策略对属性估计误差的敏感度自动生成奖励来训练探索策略，并引入不确定性机制决定从探索到任务执行的过渡时机。该方法在击球任务上成功率达90%，平均探索时间不足1.2秒，显著优于基线，且在物理实验中验证有效。


<details>
  <summary>Details</summary>
Motivation: 动态机器人任务中，如将 puck 击打到可达工作空间外的目标，机器人必须先识别物体相关物理属性才能成功执行任务，且无法从失败中恢复或重试（无人工干预）。

Method: 1. 基于强化学习的任务感知探索方法，利用特权任务策略对属性估计误差的敏感度自动生成奖励训练探索策略；2. 引入基于不确定性的机制决定从探索到任务执行的过渡时机，确保足够的属性估计精度和最小的探索时间。

Result: 1. 在击球任务上成功率达90%，平均探索时间不足1.2秒；2. 显著优于基线（基线成功率最高40%或需在测试时低效查询和在模拟器中重新训练）；3. 任务感知奖励能捕捉击球任务和经典 CartPole 示例中物理属性的相对重要性；4. 在 KUKA iiwa 机械臂物理设置中验证了识别物体属性和调整任务执行的能力。

Conclusion: 所提任务感知探索方法能有效识别物体物理属性，确保机器人在动态任务中成功执行，且探索时间短、性能优于基线，在物理实验中得到验证。

Abstract: In many dynamic robotic tasks, such as striking pucks into a goal outside the
reachable workspace, the robot must first identify the relevant physical
properties of the object for successful task execution, as it is unable to
recover from failure or retry without human intervention. To address this
challenge, we propose a task-informed exploration approach, based on
reinforcement learning, that trains an exploration policy using rewards
automatically generated from the sensitivity of a privileged task policy to
errors in estimated properties. We also introduce an uncertainty-based
mechanism to determine when to transition from exploration to task execution,
ensuring sufficient property estimation accuracy with minimal exploration time.
Our method achieves a 90% success rate on the striking task with an average
exploration time under 1.2 seconds, significantly outperforming baselines that
achieve at most 40% success or require inefficient querying and retraining in a
simulator at test time. Additionally, we demonstrate that our task-informed
rewards capture the relative importance of physical properties in both the
striking task and the classical CartPole example. Finally, we validate our
approach by demonstrating its ability to identify object properties and adjust
task execution in a physical setup using the KUKA iiwa robot arm.

</details>


### [8] [First Order Model-Based RL through Decoupled Backpropagation](https://arxiv.org/abs/2509.00215)
*Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti*

Main category: cs.RO

TL;DR: 本文提出一种混合方法，通过模拟器生成轨迹并利用学习的可微模型计算梯度，以解决强化学习中模拟器梯度不可用或模型预测误差累积的问题，在基准控制任务和真实机器人上验证了其样本效率、速度和通用性。


<details>
  <summary>Details</summary>
Motivation: 强化学习中利用模拟器导数的方法虽性能优越，但获取模拟器梯度常因实现成本高或不可用而不切实际；基于模型的强化学习通过学习动态模型近似梯度，却因训练过程中预测误差累积导致求解器效率和策略性能下降。

Method: 提出轨迹生成与梯度计算解耦的混合设计：使用模拟器展开轨迹，同时通过学习的可微模拟器模型反向传播计算梯度；并从模拟轨迹中学习更准确的评论家（critic）。

Result: 该方法实现了与SHAC等专用优化器相当的样本效率和速度，同时保持了PPO等标准方法的通用性，避免了其他一阶基于模型的强化学习方法中观察到的不良行为；在基准控制任务和真实Go2四足机器人的四足及双足 locomotion 任务上经验性地验证了其有效性。

Conclusion: 所提混合方法在模拟器梯度不可用时，能实现高效且一致的一阶策略优化，兼具样本效率、速度和通用性，在基准任务和真实机器人上均表现出有效性。

Abstract: There is growing interest in reinforcement learning (RL) methods that
leverage the simulator's derivatives to improve learning efficiency. While
early gradient-based approaches have demonstrated superior performance compared
to derivative-free methods, accessing simulator gradients is often impractical
due to their implementation cost or unavailability. Model-based RL (MBRL) can
approximate these gradients via learned dynamics models, but the solver
efficiency suffers from compounding prediction errors during training rollouts,
which can degrade policy performance. We propose an approach that decouples
trajectory generation from gradient computation: trajectories are unrolled
using a simulator, while gradients are computed via backpropagation through a
learned differentiable model of the simulator. This hybrid design enables
efficient and consistent first-order policy optimization, even when simulator
gradients are unavailable, as well as learning a critic from simulation
rollouts, which is more accurate. Our method achieves the sample efficiency and
speed of specialized optimizers such as SHAC, while maintaining the generality
of standard approaches like PPO and avoiding ill behaviors observed in other
first-order MBRL methods. We empirically validate our algorithm on benchmark
control tasks and demonstrate its effectiveness on a real Go2 quadruped robot,
across both quadrupedal and bipedal locomotion tasks.

</details>


### [9] [Embodied AI in Social Spaces: Responsible and Adaptive Robots in Complex Setting - UKAIRS 2025 (Copy)](https://arxiv.org/abs/2509.00218)
*Aleksandra Landowska,Aislinn D Gomez Bergin,Ayodeji O. Abioye,Jayati Deshmukh,Andriana Bouadouki,Maria Wheadon,Athina Georgara,Dominic Price,Tuyen Nguyen,Shuang Ao,Lokesh Singh,Yi Long,Raffaele Miele,Joel E. Fischer,Sarvapali D. Ramchurn*

Main category: cs.RO

TL;DR: 本文概述了一个旨在为复杂动态环境开发负责任且自适应的多人多机器人（MHMR）系统的多学科项目，该项目整合了协同设计、伦理框架和多模态传感，以创建情感响应、情境感知且符合不同用户需求的AI驱动机器人，并展示了具身AI如何支持可持续、伦理和以人为中心的未来。


<details>
  <summary>Details</summary>
Motivation: 开发适用于复杂动态环境的负责任且自适应的多人多机器人（MHMR）系统，以支持可持续、伦理和以人为中心的未来。

Method: 整合协同设计、伦理框架和多模态传感，创建AI驱动的机器人。

Result: 概述了项目的愿景、方法论和早期成果。

Conclusion: 具身AI能够支持可持续、伦理和以人为中心的未来。

Abstract: This paper introduces and overviews a multidisciplinary project aimed at
developing responsible and adaptive multi-human multi-robot (MHMR) systems for
complex, dynamic settings. The project integrates co-design, ethical
frameworks, and multimodal sensing to create AI-driven robots that are
emotionally responsive, context-aware, and aligned with the needs of diverse
users. We outline the project's vision, methodology, and early outcomes,
demonstrating how embodied AI can support sustainable, ethical, and
human-centred futures.

</details>


### [10] [Learn from What We HAVE: History-Aware VErifier that Reasons about Past Interactions Online](https://arxiv.org/abs/2509.00271)
*Yishu Li,Xinyi Mao,Ying Yuan,Kyutae Sim,Ben Eisner,David Held*

Main category: cs.RO

TL;DR: 本文提出一种新的History-Aware VErifier (HAVE)，通过利用过去的交互来在线消除不确定场景的歧义，解决机器人在处理视觉模糊物体时生成模型性能不佳的问题，经验证在多个环境中有效。


<details>
  <summary>Details</summary>
Motivation: 机器人经常遇到视觉模糊的物体，其操作结果在物理交互前不确定，而生成模型即使在动作历史条件下，在模糊情况下也只能获得次优性能。

Method: 明确将动作生成与验证分离：使用基于无条件扩散的生成器提出多个候选动作，并采用历史感知验证器通过推理过去的交互来选择最有前景的动作。

Result: 通过理论分析证明使用验证器显著提高了预期动作质量，在包括铰接物体、多模态门和不平坦物体拾取在内的多个模拟和现实环境中的实证评估和分析证实了该方法的有效性以及相对于基线的改进。

Conclusion: HAVE方法通过解耦动作生成与验证并利用历史交互，有效解决了机器人在不确定场景中的动作选择问题，在多种环境中表现优于基线。

Abstract: We introduce a novel History-Aware VErifier (HAVE) to disambiguate uncertain
scenarios online by leveraging past interactions. Robots frequently encounter
visually ambiguous objects whose manipulation outcomes remain uncertain until
physically interacted with. While generative models alone could theoretically
adapt to such ambiguity, in practice they obtain suboptimal performance in
ambiguous cases, even when conditioned on action history. To address this, we
propose explicitly decoupling action generation from verification: we use an
unconditional diffusion-based generator to propose multiple candidate actions
and employ our history-aware verifier to select the most promising action by
reasoning about past interactions. Through theoretical analysis, we demonstrate
that employing a verifier significantly improves expected action quality.
Empirical evaluations and analysis across multiple simulated and real-world
environments including articulated objects, multi-modal doors, and uneven
object pick-up confirm the effectiveness of our method and improvements over
baselines. Our project website is available at:
https://liy1shu.github.io/HAVE_CoRL25/

</details>


### [11] [TReF-6: Inferring Task-Relevant Frames from a Single Demonstration for One-Shot Skill Generalization](https://arxiv.org/abs/2509.00310)
*Yuxuan Ding,Shuangge Wang,Tesca Fitzgerald*

Main category: cs.RO

TL;DR: TReF-6方法通过从单条轨迹推断6DoF任务相关参考系，解决机器人单示范泛化难题，利用视觉语言模型和Grounded-SAM实现技能跨场景一致泛化，在仿真和真实操作任务中验证有效。


<details>
  <summary>Details</summary>
Motivation: 机器人因缺乏可迁移、可解释的空间表示，难以从单示范中泛化。

Method: TReF-6从轨迹几何中识别影响点定义局部坐标系原点，作为动态运动基元（DMP）参数化参考；通过视觉语言模型实现参考系语义接地，利用Grounded-SAM在新场景中定位。

Result: 在仿真中验证了TReF-6对轨迹噪声的鲁棒性；在真实世界操作任务上部署端到端 pipeline，支持单样本模仿学习，能在不同物体配置下保持任务意图。

Conclusion: TReF-6有效解决了单示范泛化问题，实现了功能一致的技能泛化。

Abstract: Robots often struggle to generalize from a single demonstration due to the
lack of a transferable and interpretable spatial representation. In this work,
we introduce TReF-6, a method that infers a simplified, abstracted 6DoF
Task-Relevant Frame from a single trajectory. Our approach identifies an
influence point purely from the trajectory geometry to define the origin for a
local frame, which serves as a reference for parameterizing a Dynamic Movement
Primitive (DMP). This influence point captures the task's spatial structure,
extending the standard DMP formulation beyond start-goal imitation. The
inferred frame is semantically grounded via a vision-language model and
localized in novel scenes by Grounded-SAM, enabling functionally consistent
skill generalization. We validate TReF-6 in simulation and demonstrate
robustness to trajectory noise. We further deploy an end-to-end pipeline on
real-world manipulation tasks, showing that TReF-6 supports one-shot imitation
learning that preserves task intent across diverse object configurations.

</details>


### [12] [A Framework for Task and Motion Planning based on Expanding AND/OR Graphs](https://arxiv.org/abs/2509.00317)
*Fulvio Mastrogiovanni,Antony Thomas*

Main category: cs.RO

TL;DR: 本文介绍了一种基于扩展AND/OR图的任务与运动规划（TMP）框架TMP-EAOG，通过迭代扩展AND/OR图并结合运动规划可行性评估，具备对不确定性的鲁棒性、可控自主性和有限灵活性，在模拟移动机械臂的基准测试中表现良好。


<details>
  <summary>Details</summary>
Motivation: 空间环境中机器人自主性面临高感知和运动不确定性、严格运动学约束及有限人工干预等挑战，任务与运动规划（TMP）对自主服务、表面操作和在轨任务等至关重要。

Method: 提出TMP-EAOG框架，在AND/OR图中编码任务级抽象，迭代扩展图并执行闭环运动规划评估以确定可行性。

Result: 在两个基准域上使用模拟移动机械臂（作为空间级自主机器人的代理）进行评估，结果表明TMP-EAOG能应对基准测试中的多种挑战。

Conclusion: TMP-EAOG具有一定的不确定性鲁棒性、可控自主性和有限灵活性，适用于空间环境机器人任务规划。

Abstract: Robot autonomy in space environments presents unique challenges, including
high perception and motion uncertainty, strict kinematic constraints, and
limited opportunities for human intervention. Therefore, Task and Motion
Planning (TMP) may be critical for autonomous servicing, surface operations, or
even in-orbit missions, just to name a few, as it models tasks as discrete
action sequencing integrated with continuous motion feasibility assessments. In
this paper, we introduce a TMP framework based on expanding AND/OR graphs,
referred to as TMP-EAOG, and demonstrate its adaptability to different
scenarios. TMP-EAOG encodes task-level abstractions within an AND/OR graph,
which expands iteratively as the plan is executed, and performs in-the-loop
motion planning assessments to ascertain their feasibility. As a consequence,
TMP-EAOG is characterised by the desirable properties of (i) robustness to a
certain degree of uncertainty, because AND/OR graph expansion can accommodate
for unpredictable information about the robot environment, (ii) controlled
autonomy, since an AND/OR graph can be validated by human experts, and (iii)
bounded flexibility, in that unexpected events, including the assessment of
unfeasible motions, can lead to different courses of action as alternative
paths in the AND/OR graph. We evaluate TMP-EAOG on two benchmark domains. We
use a simulated mobile manipulator as a proxy for space-grade autonomous
robots. Our evaluation shows that TMP-EAOG can deal with a wide range of
challenges in the benchmarks.

</details>


### [13] [Contact-Aided Navigation of Flexible Robotic Endoscope Using Deep Reinforcement Learning in Dynamic Stomach](https://arxiv.org/abs/2509.00319)
*Chi Kit Ng,Huxin Gao,Tian-Ao Ren,Jiewen Lai,Hongliang Ren*

Main category: cs.RO

TL;DR: 本文提出一种基于深度强化学习（DRL）的接触辅助导航（CAN）策略，用于柔性机器人内窥镜（FRE）在胃肠道尤其是动态胃环境中的导航，通过接触力反馈和PPO算法训练，在模拟中实现高成功率和低误差，优于基线策略。


<details>
  <summary>Details</summary>
Motivation: 柔性机器人内窥镜（FRE）在动态胃环境中导航面临挑战，需有效利用与可变形胃壁的接触来到达目标位置。

Method: 提出基于深度强化学习（DRL）的接触辅助导航（CAN）策略，利用接触力反馈；在基于物理的有限元法（FEM）模拟的可变形胃训练环境中，使用近端策略优化（PPO）算法训练。

Result: 在静态和动态胃环境中，CAN智能体成功率达100%，平均误差1.6mm；在有更强外部干扰的未知复杂场景中，成功率保持85%，显著优于基线策略。

Conclusion: 基于DRL的CAN策略大幅提升了FRE的导航性能，验证了其有效性。

Abstract: Navigating a flexible robotic endoscope (FRE) through the gastrointestinal
tract is critical for surgical diagnosis and treatment. However, navigation in
the dynamic stomach is particularly challenging because the FRE must learn to
effectively use contact with the deformable stomach walls to reach target
locations. To address this, we introduce a deep reinforcement learning (DRL)
based Contact-Aided Navigation (CAN) strategy for FREs, leveraging contact
force feedback to enhance motion stability and navigation precision. The
training environment is established using a physics-based finite element method
(FEM) simulation of a deformable stomach. Trained with the Proximal Policy
Optimization (PPO) algorithm, our approach achieves high navigation success
rates (within 3 mm error between the FRE's end-effector and target) and
significantly outperforms baseline policies. In both static and dynamic stomach
environments, the CAN agent achieved a 100% success rate with 1.6 mm average
error, and it maintained an 85% success rate in challenging unseen scenarios
with stronger external disturbances. These results validate that the DRL-based
CAN strategy substantially enhances FRE navigation performance over prior
methods.

</details>


### [14] [Mechanistic interpretability for steering vision-language-action models](https://arxiv.org/abs/2509.00328)
*Bear Häon,Kaylene Stocking,Ian Chuang,Claire Tomlin*

Main category: cs.RO

TL;DR: 本文介绍了首个通过内部表征解释和引导视觉-语言-动作（VLA）模型的框架，通过将Transformer层前馈激活投影到token嵌入基上识别稀疏语义方向，并提出通用激活引导方法，在Pi0和OpenVLA模型上实现了模拟和物理机器人的零样本行为控制。


<details>
  <summary>Details</summary>
Motivation: VLA模型在部署到现实世界机器人时缺乏机械洞察力，而经典机器人管道基于明确的运动学、动力学和控制模型，本文受大型语言模型机械可解释性进展的启发，旨在解决VLA模型的解释性和引导问题。

Method: 将Transformer层内的前馈激活投影到token嵌入基上，识别与动作选择有因果关系的稀疏语义方向（如速度和方向），并引入通用激活引导方法，无需微调、奖励信号或环境交互即可实时调节行为。

Result: 在Pi0和OpenVLA两个开源VLA模型上进行了评估，在模拟（LIBERO）和物理机器人（UR5）上展示了零样本行为控制。

Conclusion: 该工作表明，可解释的具身VLA组件可以被系统地用于控制，为机器人领域透明且可引导的基础模型建立了新范式。

Abstract: Vision-Language-Action (VLA) models are a promising path to realizing
generalist embodied agents that can quickly adapt to new tasks, modalities, and
environments. However, methods for interpreting and steering VLAs fall far
short of classical robotics pipelines, which are grounded in explicit models of
kinematics, dynamics, and control. This lack of mechanistic insight is a
central challenge for deploying learned policies in real-world robotics, where
robustness and explainability are critical. Motivated by advances in
mechanistic interpretability for large language models, we introduce the first
framework for interpreting and steering VLAs via their internal
representations, enabling direct intervention in model behavior at inference
time. We project feedforward activations within transformer layers onto the
token embedding basis, identifying sparse semantic directions - such as speed
and direction - that are causally linked to action selection. Leveraging these
findings, we introduce a general-purpose activation steering method that
modulates behavior in real time, without fine-tuning, reward signals, or
environment interaction. We evaluate this method on two recent open-source
VLAs, Pi0 and OpenVLA, and demonstrate zero-shot behavioral control in
simulation (LIBERO) and on a physical robot (UR5). This work demonstrates that
interpretable components of embodied VLAs can be systematically harnessed for
control - establishing a new paradigm for transparent and steerable foundation
models in robotics.

</details>


### [15] [Jacobian Exploratory Dual-Phase Reinforcement Learning for Dynamic Endoluminal Navigation of Deformable Continuum Robots](https://arxiv.org/abs/2509.00329)
*Yu Tian,Chi Kit Ng,Hongliang Ren*

Main category: cs.RO

TL;DR: 本文提出Jacobian探索双阶段强化学习（JEDP-RL）框架，解决可变形连续体机器人（DCRs）因非线性变形力学和部分状态可观测性导致的传统强化学习（RL）马尔可夫假设失效问题，通过分解规划为Jacobian估计和策略执行阶段，在SOFA手术动态仿真中表现出比PPO基线更快的收敛速度、更高的导航效率和更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 可变形连续体机器人（DCRs）存在非线性变形力学和部分状态可观测性，违反传统强化学习（RL）方法的马尔可夫假设，而基于雅可比矩阵的方法对刚性机械臂虽有理论基础，但直接应用于DCRs受时变运动学和欠驱动变形动力学限制。

Method: 提出Jacobian探索双阶段强化学习（JEDP-RL）框架，将规划分解为阶段性雅可比矩阵估计和策略执行；训练中先执行小规模局部探索动作估计变形雅可比矩阵，再用雅可比特征增强状态表示以恢复近似马尔可夫性。

Result: 在SOFA手术动态仿真中，JEDP-RL相比PPO基线：1）收敛速度快3.2倍；2）导航效率高，到达目标所需步骤少25%；3）泛化能力强，材料特性变化下成功率92%，未知组织环境中成功率83%（比PPO高33%）。

Conclusion: JEDP-RL框架通过分解规划为雅可比矩阵估计和策略执行阶段，并增强状态表示，有效解决了DCRs的强化学习规划挑战，在收敛速度、导航效率和泛化能力上优于PPO基线。

Abstract: Deformable continuum robots (DCRs) present unique planning challenges due to
nonlinear deformation mechanics and partial state observability, violating the
Markov assumptions of conventional reinforcement learning (RL) methods. While
Jacobian-based approaches offer theoretical foundations for rigid manipulators,
their direct application to DCRs remains limited by time-varying kinematics and
underactuated deformation dynamics. This paper proposes Jacobian Exploratory
Dual-Phase RL (JEDP-RL), a framework that decomposes planning into phased
Jacobian estimation and policy execution. During each training step, we first
perform small-scale local exploratory actions to estimate the deformation
Jacobian matrix, then augment the state representation with Jacobian features
to restore approximate Markovianity. Extensive SOFA surgical dynamic
simulations demonstrate JEDP-RL's three key advantages over proximal policy
optimization (PPO) baselines: 1) Convergence speed: 3.2x faster policy
convergence, 2) Navigation efficiency: requires 25% fewer steps to reach the
target, and 3) Generalization ability: achieve 92% success rate under material
property variations and achieve 83% (33% higher than PPO) success rate in the
unseen tissue environment.

</details>


### [16] [Autonomous Aggregate Sorting in Construction and Mining via Computer Vision-Aided Robotic Arm Systems](https://arxiv.org/abs/2509.00339)
*Md. Taherul Islam Shawon,Yuan Li,Yincai Cai,Junjie Niu,Ting Peng*

Main category: cs.RO

TL;DR: 本文提出了一种计算机视觉辅助机械臂系统，用于建筑和采矿应用中的骨料自主分拣，该系统集成了六自由度机械臂、双目立体相机和基于ROS的控制框架，实验验证了四种骨料类型的平均抓取和分拣成功率达97.5%，显示出在提高生产率、降低运营成本和改善骨料处理安全性方面的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 传统骨料分拣方法（无论是人工还是机械）通常存在精度低、灵活性有限以及对不同材料特性（如尺寸、形状和岩性）的适应性差等问题。

Method: 该系统集成了六自由度机械臂、用于3D感知的双目立体相机和基于ROS的控制框架。核心技术包括用于骨料检测的注意力增强YOLOv8模型、用于3D定位的立体匹配、用于臂运动控制的Denavit-Hartenberg运动学建模、用于尺寸估计的最小外接矩形分析以及用于精确坐标对齐的手眼校准。

Result: 对四种骨料类型的实验验证实现了97.5%的平均抓取和分拣成功率，分类精度相当。剩余挑战包括小骨料的可靠处理和基于纹理的错误分类。

Conclusion: 所提出的系统在提高骨料处理的生产率、降低运营成本和改善安全性方面显示出巨大潜力，同时为推进建筑、采矿和回收行业的智能自动化提供了可扩展的框架。

Abstract: Traditional aggregate sorting methods, whether manual or mechanical, often
suffer from low precision, limited flexibility, and poor adaptability to
diverse material properties such as size, shape, and lithology. To address
these limitations, this study presents a computer vision-aided robotic arm
system designed for autonomous aggregate sorting in construction and mining
applications. The system integrates a six-degree-of-freedom robotic arm, a
binocular stereo camera for 3D perception, and a ROS-based control framework.
Core techniques include an attention-augmented YOLOv8 model for aggregate
detection, stereo matching for 3D localization, Denavit-Hartenberg kinematic
modeling for arm motion control, minimum enclosing rectangle analysis for size
estimation, and hand-eye calibration for precise coordinate alignment.
Experimental validation with four aggregate types achieved an average grasping
and sorting success rate of 97.5%, with comparable classification accuracy.
Remaining challenges include the reliable handling of small aggregates and
texture-based misclassification. Overall, the proposed system demonstrates
significant potential to enhance productivity, reduce operational costs, and
improve safety in aggregate handling, while providing a scalable framework for
advancing smart automation in construction, mining, and recycling industries.

</details>


### [17] [Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-Top Manipulation](https://arxiv.org/abs/2509.00361)
*Chuye Zhang,Xiaoxiong Zhang,Wei Pan,Linfang Zheng,Wei Zhang*

Main category: cs.RO

TL;DR: GVF-TAPE是一个结合生成式视觉预见性和任务无关姿态估计的闭环框架，用于非结构化环境中的机器人操作，通过生成视频模型预测未来RGB-D帧和姿态估计模型提取末端执行器姿态，实现跨多种任务的实时自适应操作。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的机器人操作需要系统能跨多种任务泛化并保持鲁棒可靠性能。

Method: 使用生成视频模型从单一侧视RGB图像和任务描述预测未来RGB-D帧，解耦的姿态估计模型从预测帧中提取末端执行器姿态，通过闭环迭代整合视频预见性和姿态估计。

Result: 在仿真和现实环境中的大量实验表明，该方法减少了对特定任务动作数据的依赖，并能有效泛化。

Conclusion: GVF-TAPE为智能机器人系统提供了一种实用且可扩展的解决方案。

Abstract: Robotic manipulation in unstructured environments requires systems that can
generalize across diverse tasks while maintaining robust and reliable
performance. We introduce {GVF-TAPE}, a closed-loop framework that combines
generative visual foresight with task-agnostic pose estimation to enable
scalable robotic manipulation. GVF-TAPE employs a generative video model to
predict future RGB-D frames from a single side-view RGB image and a task
description, offering visual plans that guide robot actions. A decoupled pose
estimation model then extracts end-effector poses from the predicted frames,
translating them into executable commands via low-level controllers. By
iteratively integrating video foresight and pose estimation in a closed loop,
GVF-TAPE achieves real-time, adaptive manipulation across a broad range of
tasks. Extensive experiments in both simulation and real-world settings
demonstrate that our approach reduces reliance on task-specific action data and
generalizes effectively, providing a practical and scalable solution for
intelligent robotic systems.

</details>


### [18] [Embodied Spatial Intelligence: from Implicit Scene Modeling to Spatial Reasoning](https://arxiv.org/abs/2509.00465)
*Jiading Fang*

Main category: cs.RO

TL;DR: 本文提出“具身空间智能”以解决机器人基于自然语言指令感知和作用于现实世界的挑战，通过场景表示和空间推理两方面的贡献奠定基础


<details>
  <summary>Details</summary>
Motivation: 创建能基于自然语言指令在现实世界中感知和行动的机器人

Method: 在感知方面，使用隐式神经模型开发稳健、可扩展且准确的场景表示，包括自监督相机校准、高保真深度场生成和大规模重建；在空间推理方面，通过引入新的导航基准、将语言锚定在3D中的方法以及状态反馈机制来增强LLMs的空间能力，以改善长程决策

Result: 为能稳健感知周围环境并智能执行复杂语言指令的机器人奠定了基础

Conclusion: 本研究通过场景表示和空间推理的创新，为具身空间智能机器人的发展提供了关键基础

Abstract: This thesis introduces "Embodied Spatial Intelligence" to address the
challenge of creating robots that can perceive and act in the real world based
on natural language instructions. To bridge the gap between Large Language
Models (LLMs) and physical embodiment, we present contributions on two fronts:
scene representation and spatial reasoning. For perception, we develop robust,
scalable, and accurate scene representations using implicit neural models, with
contributions in self-supervised camera calibration, high-fidelity depth field
generation, and large-scale reconstruction. For spatial reasoning, we enhance
the spatial capabilities of LLMs by introducing a novel navigation benchmark, a
method for grounding language in 3D, and a state-feedback mechanism to improve
long-horizon decision-making. This work lays a foundation for robots that can
robustly perceive their surroundings and intelligently act upon complex,
language-based commands.

</details>


### [19] [Extended Diffeomorphism for Real-Time Motion Replication in Workspaces with Different Spatial Arrangements](https://arxiv.org/abs/2509.00491)
*Masaki Saito,Shunki Itadera,Toshiyuki Murakami*

Main category: cs.RO

TL;DR: 本文提出两种扩展微分同胚设计以补偿机器人工作空间的空间放置差异，通过双臂UR5机器人的拾取任务实验证明该映射生成方法能平衡精确操作所需的低映射误差与平滑复制运动所需的低映射梯度。


<details>
  <summary>Details</summary>
Motivation: 多机器人遥操作可扩展机器人实体的利用率，实时再现机器人运动有助于多机器人高效执行相似任务，但运动再现中需解决机器人工作空间目标关键点的空间排列误差补偿问题。

Method: 基于每个工作空间中的预定义关键点，提出将主机器人位姿转换为从机器人位姿的平滑映射方法。

Result: 通过双臂UR5机器人的拾取任务实验，证明所提映射生成方法能平衡低映射误差（用于精确操作）和低映射梯度（用于平滑复制运动）。

Conclusion: 所提出的扩展微分同胚设计及其映射生成方法有效解决了机器人工作空间空间放置差异的补偿问题，可在多机器人运动再现中兼顾操作精度与运动平滑性。

Abstract: This paper presents two types of extended diffeomorphism designs to
compensate for spatial placement differences between robot workspaces.
Teleoperation of multiple robots is attracting attention to expand the
utilization of the robot embodiment. Real-time reproduction of robot motion
would facilitate the efficient execution of similar tasks by multiple robots. A
challenge in the motion reproduction is compensating for the spatial
arrangement errors of target keypoints in robot workspaces. This paper proposes
a methodology for smooth mappings that transform primary robot poses into
follower robot poses based on the predefined key points in each workspace.
Through a picking task experiment using a dual-arm UR5 robot, this study
demonstrates that the proposed mapping generation method can balance lower
mapping errors for precise operation and lower mapping gradients for smooth
replicated movement.

</details>


### [20] [FLUID: A Fine-Grained Lightweight Urban Signalized-Intersection Dataset of Dense Conflict Trajectories](https://arxiv.org/abs/2509.00497)
*Yiyang Chen,Zhigang Wu,Guohong Zheng,Xuesong Wu,Liwen Xu,Haoyuan Tang,Zhaocheng He,Haipeng Zeng*

Main category: cs.RO

TL;DR: 本文介绍了FLUID，一个包含精细轨迹数据集和无人机轨迹处理框架的研究，旨在解决现有无人机交通数据在场景代表性、信息丰富度和数据保真度方面的局限，数据集涵盖三种交叉口类型，约5小时记录，20000多个交通参与者，具有高时空精度，可用于交通行为建模等研究。


<details>
  <summary>Details</summary>
Motivation: 现有无人机交通数据集在场景代表性、信息丰富度和数据保真度方面存在局限，无法满足评估交通状况和优化政策的需求，尤其是在城市交叉口。

Method: 引入FLUID，包括一个捕捉典型城市信号交叉口密集冲突的细粒度轨迹数据集，以及一个轻量级、全流程的无人机轨迹处理框架。

Result: FLUID涵盖三种不同交叉口类型，约5小时记录时间，8类20000多个交通参与者，平均每分钟两次车辆冲突（涉及约25%的机动车），提供轨迹、交通信号、地图和原始视频等综合数据，经与DataFromSky平台和地面实测对比验证，具有高时空精度，揭示了多样的机动车冲突和违规交互行为。

Conclusion: FLUID对人类偏好挖掘、交通行为建模和自动驾驶研究具有价值。

Abstract: The trajectory data of traffic participants (TPs) is a fundamental resource
for evaluating traffic conditions and optimizing policies, especially at urban
intersections. Although data acquisition using drones is efficient, existing
datasets still have limitations in scene representativeness, information
richness, and data fidelity. This study introduces FLUID, comprising a
fine-grained trajectory dataset that captures dense conflicts at typical urban
signalized intersections, and a lightweight, full-pipeline framework for
drone-based trajectory processing. FLUID covers three distinct intersection
types, with approximately 5 hours of recording time and featuring over 20,000
TPs across 8 categories. Notably, the dataset averages two vehicle conflicts
per minute, involving roughly 25% of all motor vehicles. FLUID provides
comprehensive data, including trajectories, traffic signals, maps, and raw
videos. Comparison with the DataFromSky platform and ground-truth measurements
validates its high spatio-temporal accuracy. Through a detailed classification
of motor vehicle conflicts and violations, FLUID reveals a diversity of
interactive behaviors, demonstrating its value for human preference mining,
traffic behavior modeling, and autonomous driving research.

</details>


### [21] [NeuralSVCD for Efficient Swept Volume Collision Detection](https://arxiv.org/abs/2509.00499)
*Dongwon Son,Hojin Jung,Beomjoon Kim*

Main category: cs.RO

TL;DR: 本文提出NeuralSVCD，一种新型神经编码器-解码器架构，通过分布式几何表示和时间优化利用形状局部性和时间局部性，在不牺牲准确性的前提下提高计算效率，解决现有SVCD方法在效率和准确性之间的权衡问题，实验表明其在碰撞检测准确性和计算效率上均优于现有最先进的SVCD方法，适用于多种机器人操作场景。


<details>
  <summary>Details</summary>
Motivation: 机器人在非结构化环境中操作需要高效可靠的扫描体积碰撞检测（SVCD）以进行安全运动规划。传统离散方法可能会遗漏这些点之间的碰撞，而SVCD会沿整个轨迹持续检查碰撞。现有SVCD方法通常面临效率和准确性之间的权衡，限制了实际应用。

Method: 引入NeuralSVCD，一种新型神经编码器-解码器架构。该方法通过分布式几何表示和时间优化利用形状局部性和时间局部性，以在不牺牲准确性的前提下增强计算效率。

Result: 综合实验表明，NeuralSVCD在碰撞检测准确性和计算效率方面始终优于现有的最先进SVCD方法。

Conclusion: NeuralSVCD展示了其在各种机器人操作场景中的强大适用性。

Abstract: Robot manipulation in unstructured environments requires efficient and
reliable Swept Volume Collision Detection (SVCD) for safe motion planning.
Traditional discrete methods potentially miss collisions between these points,
whereas SVCD continuously checks for collisions along the entire trajectory.
Existing SVCD methods typically face a trade-off between efficiency and
accuracy, limiting practical use. In this paper, we introduce NeuralSVCD, a
novel neural encoder-decoder architecture tailored to overcome this trade-off.
Our approach leverages shape locality and temporal locality through distributed
geometric representations and temporal optimization. This enhances
computational efficiency without sacrificing accuracy. Comprehensive
experiments show that NeuralSVCD consistently outperforms existing
state-of-the-art SVCD methods in terms of both collision detection accuracy and
computational efficiency, demonstrating its robust applicability across diverse
robotic manipulation scenarios. Code and videos are available at
https://neuralsvcd.github.io/.

</details>


### [22] [Needle Biopsy And Fiber-Optic Compatible Robotic Insertion Platform](https://arxiv.org/abs/2509.00530)
*Fanxin Wang,Yikun Cheng,Chuyuan Tao,Rohit Bhargava,Thenkurussi Kesavadas*

Main category: cs.RO

TL;DR: 本文提出一种紧凑、准确且可操纵的机器人插入平台，以解决传统组织活检中手动采样不准确和病理测试耗时的问题，该平台能引导多种不同尺寸工具，辅助外科医生导航至活检目标区域进行多模态诊断，并通过定位精度、导纳性能和工具插入效率等测试验证了系统有效性。


<details>
  <summary>Details</summary>
Motivation: 传统组织活检存在手动采样易不准确和病理测试耗时的局限性，为解决这些问题，提出该机器人插入平台。

Method: 设计了紧凑、准确且可操纵的机器人插入平台，包括概述设备总体概念、详细描述其机械设计和控制方案，该平台能引导多种不同尺寸工具（如用于组织提取的针和用于振动光谱学应用的光纤），辅助外科医生导航至活检目标区域进行多模态诊断。

Result: 通过一系列测试验证了系统有效性，包括定位精度、导纳性能和工具插入效率等方面的测试。

Conclusion: 所提出的机器人插入平台能够克服传统组织病理学的局限性，为组织活检提供了一种更优的解决方案。

Abstract: Tissue biopsy is the gold standard for diagnosing many diseases, involving
the extraction of diseased tissue for histopathology analysis by expert
pathologists. However, this procedure has two main limitations: 1) Manual
sampling through tissue biopsy is prone to inaccuracies; 2) The extraction
process is followed by a time-consuming pathology test. To address these
limitations, we present a compact, accurate, and maneuverable robotic insertion
platform to overcome the limitations in traditional histopathology. Our
platform is capable of steering a variety of tools with different sizes,
including needle for tissue extraction and optical fibers for vibrational
spectroscopy applications. This system facilitates the guidance of end-effector
to the tissue and assists surgeons in navigating to the biopsy target area for
multi-modal diagnosis. In this paper, we outline the general concept of our
device, followed by a detailed description of its mechanical design and control
scheme. We conclude with the validation of the system through a series of
tests, including positioning accuracy, admittance performance, and tool
insertion efficacy.

</details>


### [23] [Reinforcement Learning of Dolly-In Filming Using a Ground-Based Robot](https://arxiv.org/abs/2509.00564)
*Philip Lorimer,Jack Saunders,Alan Hunter,Wenbin Li*

Main category: cs.RO

TL;DR: 本文将强化学习应用于自由漫游地面拍摄机器人，以实现自动推进镜头拍摄，通过结合控制策略克服传统控制障碍，在仿真和实际测试中均优于传统PD控制器，验证了其在电影拍摄中的实用性并为复杂场景研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 解决自由漫游移动摄影车在自动相机控制方面存在的挑战，推动技术与电影创意的融合。

Method: 应用强化学习（RL）实现自由漫游地面拍摄机器人的自动推进镜头拍摄，并将组合控制策略与独立控制策略进行比较，在修改后的ROSBot 2.0平台（配备相机转塔）上进行仿真和实际测试。

Result: 所提出的强化学习管道在仿真中超越了传统的比例-微分（PD）控制器性能，并在实际测试中证明了其有效性。

Conclusion: 该方法在电影拍摄中具有实用性，为复杂拍摄场景的进一步研究奠定了基础，是该领域的一大进步，有效弥合了技术进步与创意电影制作之间的差距。

Abstract: Free-roaming dollies enhance filmmaking with dynamic movement, but challenges
in automated camera control remain unresolved. Our study advances this field by
applying Reinforcement Learning (RL) to automate dolly-in shots using
free-roaming ground-based filming robots, overcoming traditional control
hurdles. We demonstrate the effectiveness of combined control for precise film
tasks by comparing it to independent control strategies. Our robust RL pipeline
surpasses traditional Proportional-Derivative controller performance in
simulation and proves its efficacy in real-world tests on a modified ROSBot 2.0
platform equipped with a camera turret. This validates our approach's
practicality and sets the stage for further research in complex filming
scenarios, contributing significantly to the fusion of technology with
cinematic creativity. This work presents a leap forward in the field and opens
new avenues for research and development, effectively bridging the gap between
technological advancement and creative filmmaking.

</details>


### [24] [ConceptBot: Enhancing Robot's Autonomy through Task Decomposition with Large Language Models and Knowledge Graph](https://arxiv.org/abs/2509.00570)
*Alessandro Leanza,Angelo Moroncelli,Giuseppe Vizzari,Francesco Braghin,Loris Roveda,Blerina Spahiu*

Main category: cs.RO

TL;DR: ConceptBot是一个模块化机器人规划框架，结合大语言模型和知识图谱，解决自然语言指令模糊及环境物体分析问题，在多项任务中表现优于Google SayCan等基线，验证了其泛化能力和可靠性。


<details>
  <summary>Details</summary>
Motivation: 应对自然语言指令中的模糊性以及环境中物体分析的挑战，这些挑战通常源于缺乏常识推理。

Method: 集成三个模块：(i)对象属性提取（OPE）模块，利用ConceptNet丰富场景理解的语义概念；(ii)用户请求处理（URP）模块，消除指令歧义并结构化；(iii)规划器，生成上下文感知、可行的拾取放置策略。

Result: 与Google SayCan相比，显式任务成功率100%，隐式任务准确率87%（SayCan为31%），风险感知任务76%（SayCan为15%）；在材料分类（70% vs 20%）和毒性检测（86% vs 36%）等场景中表现更优；在SafeAgentBench上总体得分80%（次优基线46%），模拟和实验室实验均验证了结果。

Conclusion: ConceptBot无需领域特定训练即可泛化，并显著提高了非结构化环境中机器人策略的可靠性。

Abstract: ConceptBot is a modular robotic planning framework that combines Large
Language Models and Knowledge Graphs to generate feasible and risk-aware plans
despite ambiguities in natural language instructions and correctly analyzing
the objects present in the environment - challenges that typically arise from a
lack of commonsense reasoning. To do that, ConceptBot integrates (i) an Object
Property Extraction (OPE) module that enriches scene understanding with
semantic concepts from ConceptNet, (ii) a User Request Processing (URP) module
that disambiguates and structures instructions, and (iii) a Planner that
generates context-aware, feasible pick-and-place policies. In comparative
evaluations against Google SayCan, ConceptBot achieved 100% success on explicit
tasks, maintained 87% accuracy on implicit tasks (versus 31% for SayCan),
reached 76% on risk-aware tasks (versus 15%), and outperformed SayCan in
application-specific scenarios, including material classification (70% vs. 20%)
and toxicity detection (86% vs. 36%). On SafeAgentBench, ConceptBot achieved an
overall score of 80% (versus 46% for the next-best baseline). These results,
validated in both simulation and laboratory experiments, demonstrate
ConceptBot's ability to generalize without domain-specific training and to
significantly improve the reliability of robotic policies in unstructured
environments. Website: https://sites.google.com/view/conceptbot

</details>


### [25] [Gray-Box Computed Torque Control for Differential-Drive Mobile Robot Tracking](https://arxiv.org/abs/2509.00571)
*Arman Javan Sekhavat Pishkhani*

Main category: cs.RO

TL;DR: 本研究提出一种基于学习的非线性算法用于差速驱动移动机器人的跟踪控制，通过将DRL智能体的黑盒策略网络替换为灰盒计算扭矩控制器(CTC)，结合TD3算法优化参数，提升样本效率并确保闭环稳定性，同时约束参数范围和应用临界阻尼技术，在MuJoCo仿真中与原始CTC和传统运动学控制器对比验证性能。


<details>
  <summary>Details</summary>
Motivation: CTM受系统参数知识不准确影响，DRL算法存在样本效率低和稳定性保证弱的问题。

Method: 用灰盒CTC替代DRL智能体的黑盒策略网络，使用TD3算法寻找任意奖励函数的最优控制器参数，约束部分控制器参数在已知范围内以确保物理合理性，并应用技术强制闭环时间响应为临界阻尼。

Result: 在MuJoCo物理引擎中仿真的差速驱动移动机器人上评估了控制器性能，并与原始CTC和传统运动学控制器进行了对比。

Conclusion: 该方法能仅用少量短学习 episode 找到最优控制器参数，提升了样本效率并确保了闭环稳定性。

Abstract: This study presents a learning-based nonlinear algorithm for tracking control
of differential-drive mobile robots. The Computed Torque Method (CTM) suffers
from inaccurate knowledge of system parameters, while Deep Reinforcement
Learning (DRL) algorithms are known for sample inefficiency and weak stability
guarantees. The proposed method replaces the black-box policy network of a DRL
agent with a gray-box Computed Torque Controller (CTC) to improve sample
efficiency and ensure closed-loop stability. This approach enables finding an
optimal set of controller parameters for an arbitrary reward function using
only a few short learning episodes. The Twin-Delayed Deep Deterministic Policy
Gradient (TD3) algorithm is used for this purpose. Additionally, some
controller parameters are constrained to lie within known value ranges,
ensuring the RL agent learns physically plausible values. A technique is also
applied to enforce a critically damped closed-loop time response. The
controller's performance is evaluated on a differential-drive mobile robot
simulated in the MuJoCo physics engine and compared against the raw CTC and a
conventional kinematic controller.

</details>


### [26] [Learning Dolly-In Filming From Demonstration Using a Ground-Based Robot](https://arxiv.org/abs/2509.00574)
*Philip Lorimer,Alan Hunter,Wenbin Li*

Main category: cs.RO

TL;DR: 本文提出一种基于生成对抗模仿学习（GAIL）的从演示中学习（LfD）方法，用于自由漫游地面拍摄机器人的推镜镜头自动化，解决了强化学习（RL）在电影摄影中依赖定制奖励和大量调优的问题，在模拟中优于PPO基线，无需微调即可直接迁移到现实世界机器人，实现更一致的构图和主体对齐。


<details>
  <summary>Details</summary>
Motivation: 电影摄影相机控制需要平衡精度和艺术性，而通过手工制作的奖励函数难以编码这些品质；强化学习（RL）应用于机器人电影制作时，对定制奖励和大量调优的依赖限制了创造性可用性。

Method: 提出基于生成对抗模仿学习（GAIL）的从演示中学习（LfD）方法，通过模拟中的操纵杆遥操作收集专家轨迹，仅基于这些演示训练GAIL策略。

Result: 在模拟中，GAIL策略优于PPO基线，获得更高奖励、更快收敛和更低方差；无需微调即可直接迁移到现实世界机器人，比先前基于TD3的方法实现更一致的构图和主体对齐。

Conclusion: LfD为电影领域提供了一种强大的、无奖励的RL替代方案，支持实时部署且技术工作量最小；该流程使创意专业人士能够实现直观、风格化的相机控制，弥合艺术意图与机器人自主性之间的差距。

Abstract: Cinematic camera control demands a balance of precision and artistry -
qualities that are difficult to encode through handcrafted reward functions.
While reinforcement learning (RL) has been applied to robotic filmmaking, its
reliance on bespoke rewards and extensive tuning limits creative usability. We
propose a Learning from Demonstration (LfD) approach using Generative
Adversarial Imitation Learning (GAIL) to automate dolly-in shots with a
free-roaming, ground-based filming robot. Expert trajectories are collected via
joystick teleoperation in simulation, capturing smooth, expressive motion
without explicit objective design.
  Trained exclusively on these demonstrations, our GAIL policy outperforms a
PPO baseline in simulation, achieving higher rewards, faster convergence, and
lower variance. Crucially, it transfers directly to a real-world robot without
fine-tuning, achieving more consistent framing and subject alignment than a
prior TD3-based method. These results show that LfD offers a robust,
reward-free alternative to RL in cinematic domains, enabling real-time
deployment with minimal technical effort. Our pipeline brings intuitive,
stylized camera control within reach of creative professionals, bridging the
gap between artistic intent and robotic autonomy.

</details>


### [27] [Galaxea Open-World Dataset and G0 Dual-System VLA Model](https://arxiv.org/abs/2509.00576)
*Tao Jiang,Tianyuan Yuan,Yicheng Liu,Chenhao Lu,Jianning Cui,Xiao Liu,Shuiqi Cheng,Jiyang Gao,Huazhe Xu,Hang Zhao*

Main category: cs.RO

TL;DR: 提出了Galaxea Open-World Dataset大型多样化机器人行为数据集，以及G0双系统框架，通过三阶段课程训练，在桌面操作、少样本学习和长程移动操作等基准测试中证明了有效性，单具身预训练阶段和该数据集对性能提升关键


<details>
  <summary>Details</summary>
Motivation: 为机器人在真实人类生活和工作环境中的行为学习提供大规模、多样化的数据集及有效的训练框架

Method: 构建Galaxea Open-World Dataset，包含一致机器人具身的行为演示和精确子任务级语言标注；提出G0双系统框架，结合VLM进行多模态规划和VLA模型进行细粒度执行，并采用三阶段课程训练（跨具身预训练、单具身预训练、任务特定后训练）

Result: 在桌面操作、少样本学习和长程移动操作的综合基准测试中表现出有效性，单具身预训练阶段与Galaxea Open-World Dataset共同对实现强性能起关键作用

Conclusion: Galaxea Open-World Dataset和G0框架的三阶段训练方法能有效提升机器人在开放世界环境中的任务执行能力

Abstract: We present Galaxea Open-World Dataset, a large-scale, diverse collection of
robot behaviors recorded in authentic human living and working environments.
All demonstrations are gathered using a consistent robotic embodiment, paired
with precise subtask-level language annotations to facilitate both training and
evaluation. Building on this dataset, we introduce G0, a dual-system framework
that couples a Vision-Language Model (VLM) for multimodal planning with a
Vision-Language-Action (VLA) model for fine-grained execution. G0 is trained
using a three-stage curriculum: cross-embodiment pre-training,
single-embodiment pre-training, and task-specific post-training. A
comprehensive benchmark spanning tabletop manipulation, few-shot learning, and
long-horizon mobile manipulation, demonstrates the effectiveness of our
approach. In particular, we find that the single-embodiment pre-training stage,
together with the Galaxea Open-World Dataset, plays a critical role in
achieving strong performance.

</details>


### [28] [Safe and Efficient Lane-Changing for Autonomous Vehicles: An Improved Double Quintic Polynomial Approach with Time-to-Collision Evaluation](https://arxiv.org/abs/2509.00582)
*Rui Bai,Rui Xu,Teng Rui,Jiale Liu,Qi Wei Oung,Hoi Leong Lee,Zhen Tian,Fujiang Yuan*

Main category: cs.RO

TL;DR: 本文提出一种改进的双五次多项式方法，用于混合交通环境下安全高效的换道，将基于碰撞时间（TTC）的评估机制直接融入轨迹优化过程，实现无需事后验证的实时安全感知轨迹生成，模拟结果表明其在安全性、效率和舒适性上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术在与人类驾驶车辆（HDVs）的安全舒适交互方面仍存在挑战，尤其是换道 maneuver 期间。

Method: 该方法包括自动驾驶车辆（AV）和 HDVs 的状态估计、使用双五次多项式的轨迹生成、实时 TTC 计算和自适应轨迹评估，首次将解析 TTC 惩罚直接嵌入闭式双五次多项式求解器中。

Result: 在不同交通场景下的广泛模拟表明，所提出的方法与五次多项式、贝塞尔曲线和 B 样条等传统方法相比，具有更好的安全性、效率和舒适性，不仅能避免碰撞，还能在动态环境中确保平稳过渡和自适应决策。

Conclusion: 这项工作弥合了基于模型和自适应轨迹规划方法之间的差距，为现实世界的自动驾驶应用提供了稳定的解决方案。

Abstract: Autonomous driving technology has made significant advancements in recent
years, yet challenges remain in ensuring safe and comfortable interactions with
human-driven vehicles (HDVs), particularly during lane-changing maneuvers. This
paper proposes an improved double quintic polynomial approach for safe and
efficient lane-changing in mixed traffic environments. The proposed method
integrates a time-to-collision (TTC) based evaluation mechanism directly into
the trajectory optimization process, ensuring that the ego vehicle proactively
maintains a safe gap from surrounding HDVs throughout the maneuver. The
framework comprises state estimation for both the autonomous vehicle (AV) and
HDVs, trajectory generation using double quintic polynomials, real-time TTC
computation, and adaptive trajectory evaluation. To the best of our knowledge,
this is the first work to embed an analytic TTC penalty directly into the
closed-form double-quintic polynomial solver, enabling real-time safety-aware
trajectory generation without post-hoc validation. Extensive simulations
conducted under diverse traffic scenarios demonstrate the safety, efficiency,
and comfort of the proposed approach compared to conventional methods such as
quintic polynomials, Bezier curves, and B-splines. The results highlight that
the improved method not only avoids collisions but also ensures smooth
transitions and adaptive decision-making in dynamic environments. This work
bridges the gap between model-based and adaptive trajectory planning
approaches, offering a stable solution for real-world autonomous driving
applications.

</details>


### [29] [Vehicle-in-Virtual-Environment (VVE) Method for Developing and Evaluating VRU Safety of Connected and Autonomous Driving with Focus on Bicyclist Safety](https://arxiv.org/abs/2509.00624)
*Haochong Chen,Xincheng Cao,Bilin Aksun-Guvenc,Levent Guvenc*

Main category: cs.RO

TL;DR: 该论文聚焦于自动驾驶领域弱势道路使用者（VRU）安全，指出当前研究存在统一规划与避撞系统缺失、延迟容忍控制策略研究有限及标准化测试方法缺乏等问题，项目通过车辆虚拟环境（VVE）方法，在第二年报告中重点提升前一年成果并纳入骑行者安全，开发、评估和演示基于ADS自动转向与制动的VRU安全功能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶中弱势道路使用者（VRU）安全研究存在统一规划与避撞系统缺失、延迟容忍控制策略研究有限及标准化测试方法缺乏等问题，确保VRU安全是动态不可预测环境下的紧迫挑战。

Method: 应用车辆虚拟环境（VVE）方法，利用ADS的自动转向和制动来开发、评估和演示弱势道路使用者（VRU）的安全功能，并在第二年重点提升前一年成果，同时考虑骑行者安全。

Result: 在两年项目中，通过VVE方法开展了VRU安全功能的相关工作，当前第二年项目报告主要聚焦于提升前一年结果，并将骑行者安全纳入研究范围，但具体成果数据未在摘要中提及。

Conclusion: 项目通过车辆虚拟环境（VVE）方法对弱势道路使用者（VRU）安全功能进行了研究，在第二年报告中重点提升了前一年成果并考虑了骑行者安全，为解决自动驾驶中VRU安全的相关问题提供了方向，但具体结论需结合完整研究内容。

Abstract: Extensive research has already been conducted in the autonomous driving field
to help vehicles navigate safely and efficiently. At the same time, plenty of
current research on vulnerable road user (VRU) safety is performed which
largely concentrates on perception, localization, or trajectory prediction of
VRUs. However, existing research still exhibits several gaps, including the
lack of a unified planning and collision avoidance system for autonomous
vehicles, limited investigation into delay tolerant control strategies, and the
absence of an efficient and standardized testing methodology. Ensuring VRU
safety remains one of the most pressing challenges in autonomous driving,
particularly in dynamic and unpredictable environments. In this two year
project, we focused on applying the Vehicle in Virtual Environment (VVE) method
to develop, evaluate, and demonstrate safety functions for Vulnerable Road
Users (VRUs) using automated steering and braking of ADS. In this current
second year project report, our primary focus was on enhancing the previous
year results while also considering bicyclist safety.

</details>


### [30] [A Risk-aware Spatial-temporal Trajectory Planning Framework for Autonomous Vehicles Using QP-MPC and Dynamic Hazard Fields](https://arxiv.org/abs/2509.00643)
*Zhen Tian,Zhihao Lin,Dezong Zhao,Christos Anagnostopoulos,Qiyuan Wang,Wenjing Zhao,Xiaodan Wang,Chongfeng Wei*

Main category: cs.RO

TL;DR: 提出了一种增强的QP-MPC框架，通过动态危险场（DHF）设计新成本函数、整合到QP-MPC中并进行广泛验证，以解决现有轨迹规划方法计算成本高、动态环境性能不稳定和场景验证有限的问题，在多种场景下效率、稳定性和舒适性优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹规划方法存在计算成本高、动态环境中性能不稳定以及在不同场景中验证有限的问题，为克服这些挑战而提出新框架。

Method: 提出增强的QP-MPC框架，包含三个关键创新：（i）设计具有动态危险场的新型成本函数，明确平衡安全、效率和舒适性；（ii）将该成本函数无缝集成到QP-MPC公式中，实现对期望驾驶行为的直接优化；（iii）在复杂任务中对所提框架进行广泛验证。此外，空间安全规划由动态危险场（DHF）指导进行风险评估，时间安全规划基于时空图，还使用五次多项式采样和舒适性子奖励确保换道时的舒适性，效率子奖励维持驾驶效率，所提DHF增强的目标函数整合多个目标，为QP-MPC提供适当的优化任务。

Result: 广泛的仿真表明，所提出的框架在换道、超车和交叉口穿越等多种场景下，在效率、稳定性和舒适性方面优于基准优化方法。

Conclusion: 所提出的DHF增强的QP-MPC框架有效解决了现有轨迹规划方法的问题，在多种复杂场景中表现出更优的性能。

Abstract: Trajectory planning is a critical component in ensuring the safety,
stability, and efficiency of autonomous vehicles. While existing trajectory
planning methods have achieved progress, they often suffer from high
computational costs, unstable performance in dynamic environments, and limited
validation across diverse scenarios. To overcome these challenges, we propose
an enhanced QP-MPC-based framework that incorporates three key innovations: (i)
a novel cost function designed with a dynamic hazard field, which explicitly
balances safety, efficiency, and comfort; (ii) seamless integration of this
cost function into the QP-MPC formulation, enabling direct optimization of
desired driving behaviors; and (iii) extensive validation of the proposed
framework across complex tasks. The spatial safe planning is guided by a
dynamic hazard field (DHF) for risk assessment, while temporal safe planning is
based on a space-time graph. Besides, the quintic polynomial sampling and
sub-reward of comforts are used to ensure comforts during lane-changing. The
sub-reward of efficiency is used to maintain driving efficiency. Finally, the
proposed DHF-enhanced objective function integrates multiple objectives,
providing a proper optimization tasks for QP-MPC. Extensive simulations
demonstrate that the proposed framework outperforms benchmark optimization
methods in terms of efficiency, stability, and comfort across a variety of
scenarios likes lane-changing, overtaking, and crossing intersections.

</details>


### [31] [CARIS: A Context-Adaptable Robot Interface System for Personalized and Scalable Human-Robot Interaction](https://arxiv.org/abs/2509.00660)
*Felipe Arias-Russi,Yuanchen Bai,Angelique Taylor*

Main category: cs.RO

TL;DR: 传统WoZ工具在HRI领域适应性有限，本文介绍了结合多种能力的Context-Adaptable Robot Interface System (CARIS)，通过试点研究展示其在心理健康陪伴和导游两种场景下的WoZ控制潜力，并指出了改进方向，为HRI社区提供了公开可用的工具。


<details>
  <summary>Details</summary>
Motivation: 现有WoZ工具常局限于单一情境，在不同设置、用户和机器人平台间适应性较差，需要解决此问题。

Method: 引入结合远程操作、人类感知、人机对话和多模态数据记录等高级机器人能力的Context-Adaptable Robot Interface System (CARIS)，并通过试点研究在心理健康陪伴和导游两种情境下对其进行WoZ控制演示。

Result: 试点研究表明CARIS具备在心理健康陪伴和导游两种情境下进行WoZ控制机器人的潜力，同时发现了包括运动与通信的更平滑集成、更清晰的功能分离、推荐提示以及一键通信选项等方面的改进空间。

Conclusion: 本项目为HRI社区提供了一个公开可用、可适应不同情境的工具，使研究人员能够简化数据驱动的智能机器人行为研究方法。

Abstract: The human-robot interaction (HRI) field has traditionally used Wizard-of-Oz
(WoZ) controlled robots to explore navigation, conversational dynamics,
human-in-the-loop interactions, and more to explore appropriate robot behaviors
in everyday settings. However, existing WoZ tools are often limited to one
context, making them less adaptable across different settings, users, and
robotic platforms. To mitigate these issues, we introduce a Context-Adaptable
Robot Interface System (CARIS) that combines advanced robotic capabilities such
teleoperation, human perception, human-robot dialogue, and multimodal data
recording. Through pilot studies, we demonstrate the potential of CARIS to WoZ
control a robot in two contexts: 1) mental health companion and as a 2) tour
guide. Furthermore, we identified areas of improvement for CARIS, including
smoother integration between movement and communication, clearer functionality
separation, recommended prompts, and one-click communication options to enhance
the usability wizard control of CARIS. This project offers a publicly
available, context-adaptable tool for the HRI community, enabling researchers
to streamline data-driven approaches to intelligent robot behavior.

</details>


### [32] [DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments](https://arxiv.org/abs/2509.00741)
*Yi Liu,Keyu Fan,Bin Lan,Houde Liu*

Main category: cs.RO

TL;DR: 本文提出DyPho-SLAM，一种实时、资源高效的视觉SLAM系统，旨在解决动态环境中的定位和逼真建图挑战，通过整合先前图像信息生成精确掩码并设计自适应特征提取策略，在动态RGB-D数据集上实现了相机位姿估计和稠密地图重建的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯Splatting表示的视觉SLAM方法在静态环境中表现可靠，但在处理移动物体干扰时经常遇到相机跟踪漂移和模糊建图问题。

Method: 1. 整合先前图像信息生成精确掩码，有效减少掩码误判带来的噪声；2. 设计自适应特征提取策略，在移除动态障碍物后增强优化约束，显著提高系统的鲁棒性。

Result: 在公开的动态RGB-D数据集上，所提出的系统在相机位姿估计和稠密地图重建方面实现了最先进的性能，同时在动态场景中实时运行。

Conclusion: DyPho-SLAM通过优化掩码生成和特征提取策略，有效解决了动态环境中视觉SLAM的跟踪漂移和建图模糊问题，实现了实时且高精度的定位与建图。

Abstract: Visual SLAM algorithms have been enhanced through the exploration of Gaussian
Splatting representations, particularly in generating high-fidelity dense maps.
While existing methods perform reliably in static environments, they often
encounter camera tracking drift and fuzzy mapping when dealing with the
disturbances caused by moving objects. This paper presents DyPho-SLAM, a
real-time, resource-efficient visual SLAM system designed to address the
challenges of localization and photorealistic mapping in environments with
dynamic objects. Specifically, the proposed system integrates prior image
information to generate refined masks, effectively minimizing noise from mask
misjudgment. Additionally, to enhance constraints for optimization after
removing dynamic obstacles, we devise adaptive feature extraction strategies
significantly improving the system's resilience. Experiments conducted on
publicly dynamic RGB-D datasets demonstrate that the proposed system achieves
state-of-the-art performance in camera pose estimation and dense map
reconstruction, while operating in real-time in dynamic scenes.

</details>


### [33] [Inverse Kinematics for a 6-Degree-of-Freedom Robot Manipulator Using Comprehensive Gröbner Systems](https://arxiv.org/abs/2509.00823)
*Takumu Okazaki,Akira Terui,Masahiko Mikawa*

Main category: cs.RO

TL;DR: 本文提出一种利用计算机代数解决特定6自由度机器人逆运动学问题的有效方法，将传统方法扩展到两连续关节旋转轴相交的更通用机械臂，使用综合Gröbner系统（CGS）以关节参数为系数参数求解，通过实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 已知当机械臂三个连续旋转关节的旋转轴相交于一点时，逆运动学问题可分解为位置和姿态确定，本文旨在将此方法扩展到两连续关节旋转轴相交的更通用机械臂，以拓宽可求解逆运动学问题的6自由度机械臂类别并实现更高效的解决方案。

Method: 利用综合Gröbner系统（CGS），将机器人关节参数作为系数中的参数，以避免Gröbner基的重复计算，从而求解逆运动学问题。

Result: 通过实验证明了所提方法的有效性。

Conclusion: 所提方法扩展了可求解逆运动学问题的6自由度机械臂类别，有望实现更高效的解决方案，且实验验证了其有效性。

Abstract: We propose an effective method for solving the inverse kinematic problem of a
specific model of 6-degree-of-freedom (6-DOF) robot manipulator using computer
algebra. It is known that when the rotation axes of three consecutive
rotational joints of a manipulator intersect at a single point, the inverse
kinematics problem can be divided into determining position and orientation. We
extend this method to more general manipulators in which the rotational axes of
two consecutive joints intersect. This extension broadens the class of 6-DOF
manipulators for which the inverse kinematics problem can be solved, and is
expected to enable more efficient solutions. The inverse kinematic problem is
solved using the Comprehensive Gr\"obner System (CGS) with joint parameters of
the robot appearing as parameters in the coefficients to prevent repetitive
calculations of the Gr\"obner bases. The effectiveness of the proposed method
is shown by experiments.

</details>


### [34] [An Effective Trajectory Planning and an Optimized Path Planning for a 6-Degree-of-Freedom Robot Manipulator](https://arxiv.org/abs/2509.00828)
*Takumu Okazaki,Akira Terui,Masahiko Mikawa*

Main category: cs.RO

TL;DR: 提出一种利用计算机代数优化6自由度机器人操纵器路径规划的有效方法，包括计算可行区域、寻找轨迹和关节配置序列，以及通过图最短路径问题和Dijkstra算法优化逆运动学问题解的组合，并通过实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 优化特定模型6自由度机器人操纵器的路径规划，以解决在给定末端执行器轨迹（线段集）和各途经点逆运动学求解方法的情况下，如何获得最优关节配置序列的问题。

Method: 该方法分为三步：首先计算末端执行器特定配置下的机器人可行区域；其次在这些线段上寻找末端执行器应遵循的轨迹以及机器人应遵循的关节配置序列；最后通过将问题转化为图的最短路径问题并应用Dijkstra算法，找到轨迹上各途经点逆运动学问题解的最优组合。

Result: 通过实验证明了所提出方法的有效性。

Conclusion: 所提出的利用计算机代数的路径规划优化方法对于6自由度机器人操纵器是有效的，能够通过上述三步流程及Dijkstra算法得到最优关节配置序列。

Abstract: An effective method for optimizing path planning for a specific model of a
6-degree-of-freedom (6-DOF) robot manipulator is presented as part of the
motion planning of the manipulator using computer algebra. We assume that we
are given a path in the form of a set of line segments that the end-effector
should follow. We also assume that we have a method to solve the inverse
kinematic problem of the manipulator at each via-point of the trajectory. The
proposed method consists of three steps. First, we calculate the feasible
region of the manipulator under a specific configuration of the end-effector.
Next, we aim to find a trajectory on the line segments and a sequence of joint
configurations the manipulator should follow to move the end-effector along the
specified trajectory. Finally, we find the optimal combination of solutions to
the inverse kinematic problem at each via-point along the trajectory by
reducing the problem to a shortest-path problem of the graph and applying
Dijkstra's algorithm. We show the effectiveness of the proposed method by
experiments.

</details>


### [35] [One-Step Model Predictive Path Integral for Manipulator Motion Planning Using Configuration Space Distance Fields](https://arxiv.org/abs/2509.00836)
*Yulin Li,Tetsuro Miyazaki,Kenji Kawashima*

Main category: cs.RO

TL;DR: 本文提出CDF-MPPI框架，将配置空间距离场(CDFs)与模型预测路径积分(MPPI)控制结合，在机器人配置空间直接导航，通过利用CDF梯度统一关节空间MPPI成本并缩短至单步视野，大幅降低计算量同时保持避障能力，在2D环境和7自由度Franka机械臂仿真中实现近100%和高成功率，控制频率超750Hz，优于优化基和标准MPPI基线。


<details>
  <summary>Details</summary>
Motivation: 经典基于优化的机器人运动规划方法依赖有符号距离场(SDF)梯度实现避障，但易陷入局部极小值且在SDF梯度消失时失效；梯度-free方法如MPPI虽有效但因大量轨迹采样、重复碰撞检查及异构物理单位成本函数设计困难而计算昂贵。

Method: 提出整合CDFs与MPPI的框架，在配置空间直接导航，利用CDF梯度统一关节空间MPPI成本，将视野缩短至一步。

Result: 在2D环境中成功率接近100%，在复杂障碍物的7自由度Franka机械臂仿真中成功率持续较高，控制频率超过750Hz，显著优于基于优化和标准MPPI基线。

Conclusion: CDF-MPPI框架对高维运动规划有效且高效。

Abstract: Motion planning for robotic manipulators is a fundamental problem in
robotics. Classical optimization-based methods typically rely on the gradients
of signed distance fields (SDFs) to impose collision-avoidance constraints.
However, these methods are susceptible to local minima and may fail when the
SDF gradients vanish. Recently, Configuration Space Distance Fields (CDFs) have
been introduced, which directly model distances in the robot's configuration
space. Unlike workspace SDFs, CDFs are differentiable almost everywhere and
thus provide reliable gradient information. On the other hand, gradient-free
approaches such as Model Predictive Path Integral (MPPI) control leverage
long-horizon rollouts to achieve collision avoidance. While effective, these
methods are computationally expensive due to the large number of trajectory
samples, repeated collision checks, and the difficulty of designing cost
functions with heterogeneous physical units. In this paper, we propose a
framework that integrates CDFs with MPPI to enable direct navigation in the
robot's configuration space. Leveraging CDF gradients, we unify the MPPI cost
in joint-space and reduce the horizon to one step, substantially cutting
computation while preserving collision avoidance in practice. We demonstrate
that our approach achieves nearly 100% success rates in 2D environments and
consistently high success rates in challenging 7-DOF Franka manipulator
simulations with complex obstacles. Furthermore, our method attains control
frequencies exceeding 750 Hz, substantially outperforming both
optimization-based and standard MPPI baselines. These results highlight the
effectiveness and efficiency of the proposed CDF-MPPI framework for
high-dimensional motion planning.

</details>


### [36] [Enhanced Mean Field Game for Interactive Decision-Making with Varied Stylish Multi-Vehicles](https://arxiv.org/abs/2509.00981)
*Liancheng Zheng,Zhen Tian,Yangfan He,Shuo Liu,Ke Gong,Huilin Chen,Zhihao Lin*

Main category: cs.RO

TL;DR: 本文提出了一种基于MFG的异构交通自动驾驶决策框架，通过量化驾驶风格表示和安全关键换道算法，在实验中实现零碰撞并优于传统博弈论基线


<details>
  <summary>Details</summary>
Motivation: 为了捕捉多样化的人类驾驶行为并确保自动驾驶在密集交通中的安全运行

Method: 提出量化驾驶风格表示，将抽象特征映射到速度、安全系数和反应时间等参数，并通过空间影响场模型嵌入MFG；引入利用动态安全边际、碰撞时间分析和多层约束的安全关键换道算法；使用真实世界NGSIM数据进行风格校准和实证验证

Result: 在六种风格组合、两个15车辆场景和基于NGSIM的试验中实现零碰撞，且性能持续优于传统博弈论基线

Conclusion: 该方法为现实世界自动驾驶应用提供了可扩展、可解释且行为感知的规划框架

Abstract: This paper presents an MFG-based decision-making framework for autonomous
driving in heterogeneous traffic. To capture diverse human behaviors, we
propose a quantitative driving style representation that maps abstract traits
to parameters such as speed, safety factors, and reaction time. These
parameters are embedded into the MFG through a spatial influence field model.
To ensure safe operation in dense traffic, we introduce a safety-critical
lane-changing algorithm that leverages dynamic safety margins,
time-to-collision analysis, and multi-layered constraints. Real-world NGSIM
data is employed for style calibration and empirical validation. Experimental
results demonstrate zero collisions across six style combinations, two
15-vehicle scenarios, and NGSIM-based trials, consistently outperforming
conventional game-theoretic baselines. Overall, our approach provides a
scalable, interpretable, and behavior-aware planning framework for real-world
autonomous driving applications.

</details>


### [37] [A Robust Numerical Method for Solving Trigonometric Equations in Robotic Kinematics](https://arxiv.org/abs/2509.01010)
*Hai-Jun Su*

Main category: cs.RO

TL;DR: 本文提出一种用于解决机器人运动学中常见三角方程组的稳健数值方法，该方法结合多项式替换技术与特征值分解，在数值稳定性上优于传统方法，并作为开源Python包实现，在测试案例中实现机器精度误差（<10^-15）和100%成功率，对机器人逆运动学等应用特别有价值。


<details>
  <summary>Details</summary>
Motivation: 解决机器人运动学中常见三角方程组的求解问题，应对奇异矩阵和边缘情况，提升数值稳定性。

Method: 对于非奇异矩阵，采用Weierstrass替换将系统转化为四次多项式以找到所有解析解；对于奇异矩阵，使用SVD分析开发专门的几何约束方法，整体结合多项式替换技术与特征值分解。

Result: 该求解器在大量测试案例中展示出机器精度准确性（误差<10^-15）和100%成功率。

Conclusion: 此方法数值稳定性优于传统方法，作为开源Python包实现，对机器人应用（如逆运动学问题）特别有价值。

Abstract: This paper presents a robust numerical method for solving systems of
trigonometric equations commonly encountered in robotic kinematics. Our
approach employs polynomial substitution techniques combined with eigenvalue
decomposition to handle singular matrices and edge cases effectively. The
method demonstrates superior numerical stability compared to traditional
approaches and has been implemented as an open-source Python package. For
non-singular matrices, we employ Weierstrass substitution to transform the
system into a quartic polynomial, ensuring all analytical solutions are found.
For singular matrices, we develop specialized geometric constraint methods
using SVD analysis. The solver demonstrates machine precision accuracy ($<
10^{-15}$ error) with 100\% success rate on extensive test cases, making it
particularly valuable for robotics applications such as inverse kinematics
problems.

</details>


### [38] [TARA: A Low-Cost 3D-Printed Robotic Arm for Accessible Robotics Education](https://arxiv.org/abs/2509.01043)
*Thays Leach Mitre*

Main category: cs.RO

TL;DR: 本文提出低成本3D打印机械臂TARA用于可及的机器人教育，含开源资源，成本约200美元，实验验证其基本操作任务性能准确，优先考虑教育可重复性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人平台高成本限制学生获取实际技能的问题。

Method: 设计低成本3D打印机械臂TARA，提供含设计文件、组装说明和基线代码的开源仓库。

Result: TARA成本约200美元，远低于数千美元的工业系统，实验验证其在基本操作任务中性能准确。

Conclusion: 本工作不关注性能基准测试，而是优先考虑教育可重复性，为学生和教育工作者提供可可靠复制和扩展的平台。

Abstract: The high cost of robotic platforms limits students' ability to gain practical
skills directly applicable in real-world scenarios. To address this challenge,
this paper presents TARA, a low-cost, 3D-printed robotic arm designed for
accessible robotics education. TARA includes an open-source repository with
design files, assembly instructions, and baseline code, enabling users to build
and customize the platform. The system balances affordability and
functionality, offering a highly capable robotic arm for approximately 200 USD,
significantly lower than industrial systems that often cost thousands of
dollars. Experimental validation confirmed accurate performance in basic
manipulation tasks. Rather than focusing on performance benchmarking, this work
prioritizes educational reproducibility, providing a platform that students and
educators can reliably replicate and extend.

</details>


### [39] [A Reactive Grasping Framework for Multi-DoF Grippers via Task Space Velocity Fields and Joint Space QP](https://arxiv.org/abs/2509.01044)
*Yonghyeon Lee,Tzu-Yuan Lin,Alexander Alexiev,Sangbae Kim*

Main category: cs.RO

TL;DR: 本文提出一种快速反应的多自由度抓取框架，结合任务空间速度场与关节空间二次规划（QP）的层次结构，解决高自由度系统实时规划难题，通过仿真和真实世界测试验证其能使高自由度臂手系统在动态环境和外部干扰下实现实时无碰撞到达运动。


<details>
  <summary>Details</summary>
Motivation: 高自由度系统的反应式无碰撞全局运动规划面临挑战，状态维度和规划范围的同时增加导致搜索空间组合爆炸，使实时规划难以实现。

Method: 在低维任务空间（如指尖位置）进行全局规划，在全关节空间本地跟踪并强制执行所有约束；通过构建多个任务空间坐标（或部分关节坐标）的速度场，并求解加权关节空间QP以计算关节速度，按适当优先级跟踪这些速度场。

Result: 通过具有特权知识的仿真实验和使用最新位姿跟踪算法FoundationPose的真实世界测试，验证了该方法能使高自由度臂手系统执行实时、无碰撞的到达运动，同时适应动态环境和外部干扰。

Conclusion: 该框架有效解决了高自由度系统的实时规划问题，实现了在动态环境和外部干扰下的实时无碰撞到达运动。

Abstract: We present a fast and reactive grasping framework for multi-DoF grippers that
combines task-space velocity fields with a joint-space Quadratic Program (QP)
in a hierarchical structure. Reactive, collision-free global motion planning is
particularly challenging for high-DoF systems, since simultaneous increases in
state dimensionality and planning horizon trigger a combinatorial explosion of
the search space, making real-time planning intractable. To address this, we
plan globally in a lower-dimensional task space, such as fingertip positions,
and track locally in the full joint space while enforcing all constraints. This
approach is realized by constructing velocity fields in multiple task-space
coordinates (or in some cases a subset of joint coordinates) and solving a
weighted joint-space QP to compute joint velocities that track these fields
with appropriately assigned priorities. Through simulation experiments with
privileged knowledge and real-world tests using the recent pose-tracking
algorithm FoundationPose, we verify that our method enables high-DoF arm-hand
systems to perform real-time, collision-free reaching motions while adapting to
dynamic environments and external disturbances.

</details>


### [40] [Model Predictive Control for a Soft Robotic Finger with Stochastic Behavior based on Fokker-Planck Equation](https://arxiv.org/abs/2509.01065)
*Sumitaka Honji,Takahiro Wada*

Main category: cs.RO

TL;DR: 该研究针对软体机器人运动的高不确定性和非线性问题，提出基于Fokker-Planck方程（FPE）的随机模型预测控制策略（FPE-MPC），通过控制概率分布而非状态来应对不确定性，并在软体机器手指的数值模拟中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 软体机器人虽具有适应性和安全性等优势，但灵活性导致运动存在高度不确定性和非线性，开环控制因缺乏反馈难以应对，而传统确定性模型控制也受不确定性困扰，因此需要新的控制方法。

Method: 提出并实现基于Fokker-Planck方程（FPE）的随机模型预测控制（FPE-MPC），通过FPE控制软体机器人的概率分布而非状态，并进行两个数值模拟案例研究。

Result: 数值模拟案例研究表明，FPE-MPC控制策略能有效管理软体机器人系统固有的不确定性。

Conclusion: 基于Fokker-Planck方程的模型预测控制（FPE-MPC）是一种有效的软体机器人控制方法，可应对其运动中的不确定性问题。

Abstract: The inherent flexibility of soft robots offers numerous advantages, such as
enhanced adaptability and improved safety. However, this flexibility can also
introduce challenges regarding highly uncertain and nonlinear motion. These
challenges become particularly problematic when using open-loop control
methods, which lack a feedback mechanism and are commonly employed in soft
robot control. Though one potential solution is model-based control, typical
deterministic models struggle with uncertainty as mentioned above. The idea is
to use the Fokker-Planck Equation (FPE), a master equation of a stochastic
process, to control not the state of soft robots but the probabilistic
distribution. In this study, we propose and implement a stochastic-based
control strategy, termed FPE-based Model Predictive Control (FPE-MPC), for a
soft robotic finger. Two numerical simulation case studies examine the
performance and characteristics of this control method, revealing its efficacy
in managing the uncertainty inherent in soft robotic systems.

</details>


### [41] [SR-SLAM: Scene-reliability Based RGB-D SLAM in Diverse Environments](https://arxiv.org/abs/2509.01111)
*Haolan Zhang,Chenghao Li,Thanh Nguyen Canh,Lijun Wang,Nak Young Chong*

Main category: cs.RO

TL;DR: 本文提出SRR-SLAM框架，通过基于场景可靠性的环境感知处理增强特征SLAM，在公开数据集和现实场景中优于最先进动态SLAM方法，精度和鲁棒性提升达90%


<details>
  <summary>Details</summary>
Motivation: 当前基于特征的SLAM方法面临两大挑战：动态特征剔除和位姿估计适应性有限，评估和优化策略环境感知不足

Method: 提出统一场景可靠性评估机制，融合多指标和历史观测指导系统行为；开发自适应动态区域选择、深度辅助自调整聚类、可靠性感知位姿优化，以及基于可靠性的关键帧选择和加权优化方案

Result: 在公开数据集和现实场景中，SRR-SLAM优于最先进动态SLAM方法，在不同环境下精度和鲁棒性提升达90%

Conclusion: SRR-SLAM的改进直接提升自主机器人传感系统的测量精度和可靠性

Abstract: Visual simultaneous localization and mapping (SLAM) plays a critical role in
autonomous robotic systems, especially where accurate and reliable measurements
are essential for navigation and sensing. In feature-based SLAM, the
quantityand quality of extracted features significantly influence system
performance. Due to the variations in feature quantity and quality across
diverse environments, current approaches face two major challenges: (1) limited
adaptability in dynamic feature culling and pose estimation, and (2)
insufficient environmental awareness in assessment and optimization strategies.
To address these issues, we propose SRR-SLAM, a scene-reliability based
framework that enhances feature-based SLAM through environment-aware
processing. Our method introduces a unified scene reliability assessment
mechanism that incorporates multiple metrics and historical observations to
guide system behavior. Based on this assessment, we develop: (i) adaptive
dynamic region selection with flexible geometric constraints, (ii)
depth-assisted self-adjusting clustering for efficient dynamic feature removal
in high-dimensional settings, and (iii) reliability-aware pose refinement that
dynamically integrates direct methods when features are insufficient.
Furthermore, we propose (iv) reliability-based keyframe selection and a
weighted optimization scheme to reduce computational overhead while improving
estimation accuracy. Extensive experiments on public datasets and real world
scenarios show that SRR-SLAM outperforms state-of-the-art dynamic SLAM methods,
achieving up to 90% improvement in accuracy and robustness across diverse
environments. These improvements directly contribute to enhanced measurement
precision and reliability in autonomous robotic sensing systems.

</details>


### [42] [A novel parameter estimation method for pneumatic soft hand control applying logarithmic decrement for pseudo rigid body modeling](https://arxiv.org/abs/2509.01113)
*Haiyun Zhang,Kelvin HoLam Heung,Gabrielle J. Naquila,Ashwin Hingwe,Ashish D. Deshpande*

Main category: cs.RO

TL;DR: 本文提出一种结合伪刚体建模（PRBM）与对数衰减法（LDM）的参数估计范式（PRBM+LDM），用于解决软机器人手抓取控制中模型计算低效和参数识别复杂的问题，经实验验证其在位置和力控制上优于传统方法，可实现稳定灵活的抓取和精确力调节。


<details>
  <summary>Details</summary>
Motivation: 软机器人，尤其是软手抓取，由于其连续变形，控制具有挑战性，现有模型存在计算低效和参数识别复杂的问题，限制了其实时适用性。

Method: 提出一种结合伪刚体建模（PRBM）与对数衰减法（LDM）的参数估计范式（PRBM+LDM），并基于此实现闭环位置和力控制器。

Result: 在位置控制方面，PRBM+LDM控制器平均最大误差为4.37度，优于PID控制器的20.38度；在力控制方面，对易碎物体的捏取任务中，薯片（86 vs 82.5）、螺丝刀（74.42 vs 70）、黄铜硬币（64.75 vs 35）的表现均优于恒压抓取。

Conclusion: PRBM+LDM是一种计算高效且准确的软执行器建模技术，能够实现稳定灵活的抓取和精确的力调节。

Abstract: The rapid advancement in physical human-robot interaction (HRI) has
accelerated the development of soft robot designs and controllers. Controlling
soft robots, especially soft hand grasping, is challenging due to their
continuous deformation, motivating the use of reduced model-based controllers
for real-time dynamic performance. Most existing models, however, suffer from
computational inefficiency and complex parameter identification, limiting their
real-time applicability. To address this, we propose a paradigm coupling
Pseudo-Rigid Body Modeling with the Logarithmic Decrement Method for parameter
estimation (PRBM plus LDM). Using a soft robotic hand test bed, we validate
PRBM plus LDM for predicting position and force output from pressure input and
benchmark its performance. We then implement PRBM plus LDM as the basis for
closed-loop position and force controllers. Compared to a simple PID
controller, the PRBM plus LDM position controller achieves lower error (average
maximum error across all fingers: 4.37 degrees versus 20.38 degrees). For force
control, PRBM plus LDM outperforms constant pressure grasping in pinching tasks
on delicate objects: potato chip 86 versus 82.5, screwdriver 74.42 versus 70,
brass coin 64.75 versus 35. These results demonstrate PRBM plus LDM as a
computationally efficient and accurate modeling technique for soft actuators,
enabling stable and flexible grasping with precise force regulation.

</details>


### [43] [Novel bio-inspired soft actuators for upper-limb exoskeletons: design, fabrication and feasibility study](https://arxiv.org/abs/2509.01145)
*Haiyun Zhang,Gabrielle Naquila,Jung Hyun Bae,Zonghuan Wu,Ashwin Hingwe,Ashish Deshpande*

Main category: cs.RO

TL;DR: 本研究介绍了一种上肢软执行器设计范式，包括用于肘部的龙虾启发式硅胶气动机器人（LISPER）和用于肩部的扇贝形气动机器人（SCASPER），并提出了描述两者压力、弯曲角度和输出力关系的综合分析模型，还在假人手臂上进行了初步测试。


<details>
  <summary>Details</summary>
Motivation: 现有康复用软机器人存在响应速度慢、运动范围受限、输出力低等局限性，且关于可穿戴软执行器的精确位置和力控制研究有限，同时对波纹管结构执行器设计如何定量影响机器人能力的研究也不多。

Method: 提出了一种上肢软执行器设计范式，包含LISPER（肘部）和SCASPER（肩部）两个执行器，并建立了描述两者压力、弯曲角度和输出力关系的综合分析模型，还在假人手臂上进行了初步测试。

Result: LISPER具有更高的带宽、更大的输出力/扭矩和高线性度；SCASPER具有高输出力/扭矩和简化的制造工艺；综合分析模型可通过设置执行器的几何构型来修改运动范围和输出力；在假人手臂上的初步测试验证了执行器的能力。

Conclusion: 本研究提出的上肢软执行器设计范式及分析模型，有助于解决现有康复软机器人的局限性，为上肢康复提供了更有效的软执行器方案。

Abstract: Soft robots have been increasingly utilized as sophisticated tools in
physical rehabilitation, particularly for assisting patients with neuromotor
impairments. However, many soft robotics for rehabilitation applications are
characterized by limitations such as slow response times, restricted range of
motion, and low output force. There are also limited studies on the precise
position and force control of wearable soft actuators. Furthermore, not many
studies articulate how bellow-structured actuator designs quantitatively
contribute to the robots' capability. This study introduces a paradigm of upper
limb soft actuator design. This paradigm comprises two actuators: the
Lobster-Inspired Silicone Pneumatic Robot (LISPER) for the elbow and the
Scallop-Shaped Pneumatic Robot (SCASPER) for the shoulder. LISPER is
characterized by higher bandwidth, increased output force/torque, and high
linearity. SCASPER is characterized by high output force/torque and simplified
fabrication processes. Comprehensive analytical models that describe the
relationship between pressure, bending angles, and output force for both
actuators were presented so the geometric configuration of the actuators can be
set to modify the range of motion and output forces. The preliminary test on a
dummy arm is conducted to test the capability of the actuators.

</details>


### [44] [OpenMulti: Open-Vocabulary Instance-Level Multi-Agent Distributed Implicit Mapping](https://arxiv.org/abs/2509.01228)
*Jianyu Dou,Yinan Deng,Jiahui Wang,Xingsi Tang,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: 提出OpenMulti开放词汇实例级多智能体分布式隐式映射框架，通过跨智能体实例对齐模块和交叉渲染监督提升几何与零样本语义精度，支持实例级检索


<details>
  <summary>Details</summary>
Motivation: 现有多智能体分布式协作映射方法缺乏实例级感知和环境语义理解，限制下游应用效果

Method: 1. 引入跨智能体实例对齐模块构建实例协作图确保多智能体实例理解一致；2. 利用交叉渲染监督缓解盲区优化陷阱导致的映射精度下降

Result: 在细粒度几何精度和零样本语义精度上均优于相关算法，且支持实例级检索任务为下游应用提供语义标注

Conclusion: OpenMulti框架有效解决现有方法语义理解不足问题，提升映射性能并支持下游应用，项目网站已公开

Abstract: Multi-agent distributed collaborative mapping provides comprehensive and
efficient representations for robots. However, existing approaches lack
instance-level awareness and semantic understanding of environments, limiting
their effectiveness for downstream applications. To address this issue, we
propose OpenMulti, an open-vocabulary instance-level multi-agent distributed
implicit mapping framework. Specifically, we introduce a Cross-Agent Instance
Alignment module, which constructs an Instance Collaborative Graph to ensure
consistent instance understanding across agents. To alleviate the degradation
of mapping accuracy due to the blind-zone optimization trap, we leverage Cross
Rendering Supervision to enhance distributed learning of the scene.
Experimental results show that OpenMulti outperforms related algorithms in both
fine-grained geometric accuracy and zero-shot semantic accuracy. In addition,
OpenMulti supports instance-level retrieval tasks, delivering semantic
annotations for downstream applications. The project website of OpenMulti is
publicly available at https://openmulti666.github.io/.

</details>


### [45] [Towards Data-Driven Metrics for Social Robot Navigation Benchmarking](https://arxiv.org/abs/2509.01251)
*Pilar Bachiller-Burgos,Ulysses Bernardet,Luis V. Calderita,Pranup Chhetri,Anthony Francis,Noriaki Hirose,Noé Pérez,Dhruv Shah,Phani T. Singamaneni,Xuesu Xiao,Luis J. Manso*

Main category: cs.RO

TL;DR: 本文致力于开发数据驱动的社交机器人导航指标，以促进基准测试和策略优化，提供了动机、数据集存储方案，编译了含4427条轨迹（182条真实、4245条模拟）的数据集并经人工评分得到4402条有效数据，训练了基于RNN的基线指标并展示结果，所有数据、软件和模型权重公开。


<details>
  <summary>Details</summary>
Motivation: 为社交机器人导航的基准测试和策略优化提供数据驱动的指标。

Method: 提出社交导航轨迹数据集的存储方案，据此编译含4427条轨迹（182条真实、4245条模拟）的数据集，经人工评分和数据质量保证后得到4402条 rated trajectories，在此数据集上训练基于RNN的基线指标。

Result: 成功构建了包含真实和模拟轨迹的数据集并获得人工评分结果，训练了基于RNN的基线指标，且所有数据、软件及模型权重公开可用。

Conclusion: 开发了数据驱动的社交机器人导航指标，提供了相关数据集、基线模型及公开资源，为该领域的基准测试和策略优化奠定了基础。

Abstract: This paper presents a joint effort towards the development of a data-driven
Social Robot Navigation metric to facilitate benchmarking and policy
optimization. We provide our motivations for our approach and describe our
proposal for storing rated social navigation trajectory datasets. Following
these guidelines, we compiled a dataset with 4427 trajectories -- 182 real and
4245 simulated -- and presented it to human raters, yielding a total of 4402
rated trajectories after data quality assurance. We also trained an RNN-based
baseline metric on the dataset and present quantitative and qualitative
results. All data, software, and model weights are publicly available.

</details>


### [46] [Toward a Holistic Multi-Criteria Trajectory Evaluation Framework for Autonomous Driving in Mixed Traffic Environment](https://arxiv.org/abs/2509.01291)
*Nouhed Naidja,Stéphane Font,Marc Revilloud,Guillaume Sandou*

Main category: cs.RO

TL;DR: 本文提出了一个统一框架，用于评估和优化自动驾驶车辆轨迹，整合了正式安全、舒适性和效率标准，并通过实际交通条件下的实验和模拟成功验证。


<details>
  <summary>Details</summary>
Motivation: 为了综合评估和优化自动驾驶车辆轨迹，同时考虑安全、舒适性和效率等多方面标准。

Method: 1. 基于自适应椭圆的安全区域分析，使用鞋带公式计算错位和时变配置下的交叉面积以量化碰撞风险；2. 以纵向和横向加加速度为中心的指标建模舒适性；3. 通过总行驶时间评估效率；4. 将这些标准聚合为综合目标函数，使用基于PSO的算法求解。

Result: 该方法在城市十字路口自动驾驶车辆与人类驾驶车辆交互的实际交通条件下以及使用人类在真实交通中驾驶记录的数据进行的模拟中均成功验证。

Conclusion: 所提出的统一框架能够有效整合安全、舒适性和效率标准，对自动驾驶车辆轨迹进行评估和优化，并在实际和模拟环境中得到验证。

Abstract: This paper presents a unified framework for the evaluation and optimization
of autonomous vehicle trajectories, integrating formal safety, comfort, and
efficiency criteria. An innovative geometric indicator, based on the analysis
of safety zones using adaptive ellipses, is used to accurately quantify
collision risks. Our method applies the Shoelace formula to compute the
intersection area in the case of misaligned and time-varying configurations.
Comfort is modeled using indicators centered on longitudinal and lateral jerk,
while efficiency is assessed by overall travel time. These criteria are
aggregated into a comprehensive objective function solved using a PSO based
algorithm. The approach was successfully validated under real traffic
conditions via experiments conducted in an urban intersection involving an
autonomous vehicle interacting with a human-operated vehicle, and in simulation
using data recorded from human driving in real traffic.

</details>


### [47] [Disentangled Multi-Context Meta-Learning: Unlocking robust and Generalized Task Learning](https://arxiv.org/abs/2509.01297)
*Seonsoo Kim,Jun-Gill Kang,Taehong Kim,Seongil Hong*

Main category: cs.RO

TL;DR: 该研究提出解耦多上下文元学习框架，将任务因素分配到不同上下文向量，以提升鲁棒性和泛化能力，在正弦回归和四足机器人运动任务中均优于基线，实现少样本真实数据的sim-to-real迁移。


<details>
  <summary>Details</summary>
Motivation: 元学习中许多方法依赖隐式适应任务变化，多因素混合在单一纠缠表示中，难以解释影响性能的因素且阻碍泛化。

Method: 引入解耦多上下文元学习框架，显式将每个任务因素分配到不同的上下文向量，通过解耦这些变化，实现跨共享因素任务的上下文向量共享。

Result: 在正弦回归任务中，模型在分布外任务上优于基线，通过共享振幅或相移相关上下文向量泛化到未见正弦函数；在四足机器人运动任务中，解耦机器人特定属性和地形特征，将解耦上下文向量转移到强化学习，分布外条件下鲁棒性提升，仅用20秒平坦地形真实数据实现sim-to-real策略迁移到具有分布外机器人属性的复杂地形，这是单任务适应无法实现的。

Conclusion: 解耦多上下文元学习框架通过显式分配任务因素到不同上下文向量并实现共享，有效提升了元学习的鲁棒性、泛化能力和sim-to-real迁移效果。

Abstract: In meta-learning and its downstream tasks, many methods rely on implicit
adaptation to task variations, where multiple factors are mixed together in a
single entangled representation. This makes it difficult to interpret which
factors drive performance and can hinder generalization. In this work, we
introduce a disentangled multi-context meta-learning framework that explicitly
assigns each task factor to a distinct context vector. By decoupling these
variations, our approach improves robustness through deeper task understanding
and enhances generalization by enabling context vector sharing across tasks
with shared factors. We evaluate our approach in two domains. First, on a
sinusoidal regression task, our model outperforms baselines on
out-of-distribution tasks and generalizes to unseen sine functions by sharing
context vectors associated with shared amplitudes or phase shifts. Second, in a
quadruped robot locomotion task, we disentangle the robot-specific properties
and the characteristics of the terrain in the robot dynamics model. By
transferring disentangled context vectors acquired from the dynamics model into
reinforcement learning, the resulting policy achieves improved robustness under
out-of-distribution conditions, surpassing the baselines that rely on a single
unified context. Furthermore, by effectively sharing context, our model enables
successful sim-to-real policy transfer to challenging terrains with
out-of-distribution robot-specific properties, using just 20 seconds of real
data from flat terrain, a result not achievable with single-task adaptation.

</details>


### [48] [TopoNav: Topological Graphs as a Key Enabler for Advanced Object Navigation](https://arxiv.org/abs/2509.01364)
*Peiran Liu,Qiang Zhang,Daojie Peng,Lingfeng Zhang,Yihao Qin,Hang Zhou,Jun Ma,Renjing Xu,Yiding Ji*

Main category: cs.RO

TL;DR: TopoNav是一种利用拓扑结构作为空间记忆的新框架，旨在解决目标导航（ObjectNav）在长时任务和动态场景中的内存管理挑战，通过构建和更新捕捉场景连接、邻接和语义的拓扑图，帮助智能体积累空间知识、检索关键信息并有效推理远距离目标，在基准ObjectNav数据集上实现了最先进的性能，尤其在多样化和复杂环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 目标导航（ObjectNav）在长时任务和动态场景中面临内存管理挑战。

Method: 提出TopoNav框架，利用拓扑结构作为空间记忆，构建和更新捕捉场景连接、邻接和语义意义的拓扑图。

Result: TopoNav在基准ObjectNav数据集上实现了最先进的性能，具有更高的成功率和更高效的路径，尤其在多样化和复杂环境中表现出色。

Conclusion: TopoNav通过将临时视觉输入与持久的空间理解相结合，有效解决了ObjectNav的内存管理问题，提升了导航性能。

Abstract: Object Navigation (ObjectNav) has made great progress with large language
models (LLMs), but still faces challenges in memory management, especially in
long-horizon tasks and dynamic scenes. To address this, we propose TopoNav, a
new framework that leverages topological structures as spatial memory. By
building and updating a topological graph that captures scene connections,
adjacency, and semantic meaning, TopoNav helps agents accumulate spatial
knowledge over time, retrieve key information, and reason effectively toward
distant goals. Our experiments show that TopoNav achieves state-of-the-art
performance on benchmark ObjectNav datasets, with higher success rates and more
efficient paths. It particularly excels in diverse and complex environments, as
it connects temporary visual inputs with lasting spatial understanding.

</details>


### [49] [Analyzing Reluctance to Ask for Help When Cooperating With Robots: Insights to Integrate Artificial Agents in HRC](https://arxiv.org/abs/2509.01450)
*Ane San Martin,Michael Hagenow,Julie Shah,Johan Kildal,Elena Lazkano*

Main category: cs.RO

TL;DR: 该研究通过用户研究分析了远程人类在人机协作装配任务中按需协助的影响，确定了未来用户辅助代理设计的关键方面，包括协助场景、体验、对非人类代理的看法及协助方式（按需/主动）对情绪、生产力和偏好的影响


<details>
  <summary>Details</summary>
Motivation: 随着机器人技术发展，人机协作在工业任务中愈发普遍，人类遇到问题时可能依赖人工代理或机器人帮助，因此需确定未来用户辅助代理设计的关键方面

Method: 分析用户研究中的定量和定性数据，研究用户需要帮助的场景、请求与接收协助的体验，调查参与者对未来非人类辅助代理的看法及协助应按需还是主动提供，并分析设计决策（人类/人工助手、按需/主动帮助）对情绪反应、生产力和偏好的影响

Result: 未明确提及具体结果数据

Conclusion: 未明确给出结论

Abstract: As robot technology advances, collaboration between humans and robots will
become more prevalent in industrial tasks. When humans run into issues in such
scenarios, a likely future involves relying on artificial agents or robots for
aid. This study identifies key aspects for the design of future user-assisting
agents. We analyze quantitative and qualitative data from a user study
examining the impact of on-demand assistance received from a remote human in a
human-robot collaboration (HRC) assembly task. We study scenarios in which
users require help and we assess their experiences in requesting and receiving
assistance. Additionally, we investigate participants' perceptions of future
non-human assisting agents and whether assistance should be on-demand or
unsolicited. Through a user study, we analyze the impact that such design
decisions (human or artificial assistant, on-demand or unsolicited help) can
have on elicited emotional responses, productivity, and preferences of humans
engaged in HRC tasks.

</details>


### [50] [FGO-SLAM: Enhancing Gaussian SLAM with Globally Consistent Opacity Radiance Field](https://arxiv.org/abs/2509.01547)
*Fan Zhu,Yifan Zhao,Ziyu Chen,Biao Yu,Hui Zhu*

Main category: cs.RO

TL;DR: FGO-SLAM是一种高斯SLAM系统，采用不透明度辐射场作为场景表示以增强几何映射性能，通过全局调整优化相机姿态和稀疏点云，基于3D高斯维持全局一致的不透明度辐射场并引入深度畸变和法向一致性项，构建四面体网格后识别水平集直接从3D高斯提取表面，在各种真实世界和大规模合成数据集上实现了最先进的跟踪精度和映射性能。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法难以满足高质量场景重建需求，高斯SLAM系统虽具备快速渲染和高质量映射能力，但缺乏有效的姿态优化方法且在几何重建方面面临挑战。

Method: 采用不透明度辐射场作为场景表示；初始姿态估计后应用全局调整优化相机姿态和稀疏点云；基于3D高斯维持全局一致的不透明度辐射场，引入深度畸变和法向一致性项以优化场景表示；构建四面体网格后识别水平集直接从3D高斯提取表面。

Result: 在各种真实世界和大规模合成数据集上，该方法实现了最先进的跟踪精度和映射性能。

Conclusion: FGO-SLAM通过引入不透明度辐射场、全局调整、深度畸变和法向一致性项以及水平集表面提取等方法，有效解决了传统SLAM和现有高斯SLAM系统的问题，提升了跟踪精度和映射性能。

Abstract: Visual SLAM has regained attention due to its ability to provide perceptual
capabilities and simulation test data for Embodied AI. However, traditional
SLAM methods struggle to meet the demands of high-quality scene reconstruction,
and Gaussian SLAM systems, despite their rapid rendering and high-quality
mapping capabilities, lack effective pose optimization methods and face
challenges in geometric reconstruction. To address these issues, we introduce
FGO-SLAM, a Gaussian SLAM system that employs an opacity radiance field as the
scene representation to enhance geometric mapping performance. After initial
pose estimation, we apply global adjustment to optimize camera poses and sparse
point cloud, ensuring robust tracking of our approach. Additionally, we
maintain a globally consistent opacity radiance field based on 3D Gaussians and
introduce depth distortion and normal consistency terms to refine the scene
representation. Furthermore, after constructing tetrahedral grids, we identify
level sets to directly extract surfaces from 3D Gaussians. Results across
various real-world and large-scale synthetic datasets demonstrate that our
method achieves state-of-the-art tracking accuracy and mapping performance.

</details>


### [51] [Aleatoric Uncertainty from AI-based 6D Object Pose Predictors for Object-relative State Estimation](https://arxiv.org/abs/2509.01583)
*Thomas Jantos,Stephan Weiss,Jan Steinbrener*

Main category: cs.RO

TL;DR: 本文提出一种方法，通过添加两个与现有深度学习（DL）物体相对位姿预测器的平移和旋转部分分离的多层感知器（MLP），扩展该预测器以进行任意不确定性推断，同时冻结预训练预测器实现高效训练。将推断的6D位姿及其不确定性作为扩展卡尔曼滤波器（EKF）的测量值和噪声协方差矩阵，在边缘设备部署时计算开销小，相比固定协方差方法提升了物体相对状态估计性能，并在合成和真实数据上验证了优势。


<details>
  <summary>Details</summary>
Motivation: 在机器人应用中，基于深度学习的测量（如6D物体位姿预测）的不确定性对于概率状态估计器指导机器人任务至关重要，而现有方法缺乏有效的不确定性推断。

Method: 在现有DL物体相对位姿预测器的平移和旋转部分添加两个分离的MLP以进行任意不确定性推断，冻结预训练预测器以高效训练；将推断的6D位姿及其不确定性作为EKF的测量值和噪声协方差矩阵。

Result: 该方法在边缘设备部署时计算开销小，相比固定协方差方法提升了物体相对状态估计性能。

Conclusion: 任意不确定性推断对物体相对状态估计任务有益，所提方法通过添加分离MLP实现了高效的不确定性推断，并在合成和真实数据上验证了其优势。

Abstract: Deep Learning (DL) has become essential in various robotics applications due
to excelling at processing raw sensory data to extract task specific
information from semantic objects. For example, vision-based object-relative
navigation relies on a DL-based 6D object pose predictor to provide the
relative pose between the object and the robot as measurements to the robot's
state estimator. Accurately knowing the uncertainty inherent in such Deep
Neural Network (DNN) based measurements is essential for probabilistic state
estimators subsequently guiding the robot's tasks. Thus, in this letter, we
show that we can extend any existing DL-based object-relative pose predictor
for aleatoric uncertainty inference simply by including two multi-layer
perceptrons detached from the translational and rotational part of the DL
predictor. This allows for efficient training while freezing the existing
pre-trained predictor. We then use the inferred 6D pose and its uncertainty as
a measurement and corresponding noise covariance matrix in an extended Kalman
filter (EKF). Our approach induces minimal computational overhead such that the
state estimator can be deployed on edge devices while benefiting from the
dynamically inferred measurement uncertainty. This increases the performance of
the object-relative state estimation task compared to a fix-covariance
approach. We conduct evaluations on synthetic data and real-world data to
underline the benefits of aleatoric uncertainty inference for the
object-relative state estimation task.

</details>


### [52] [A Hybrid Input based Deep Reinforcement Learning for Lane Change Decision-Making of Autonomous Vehicle](https://arxiv.org/abs/2509.01611)
*Ziteng Gao,Jiaqi Qu,Chaoyu Chen*

Main category: cs.RO

TL;DR: 本文提出一种基于混合输入的深度强化学习（DRL）算法，用于自动驾驶车辆的换道决策与动作实现，通过周围车辆轨迹预测、多模态信息融合及强化学习与端到端控制的集成，提升换道安全性。


<details>
  <summary>Details</summary>
Motivation: 换道决策对自动驾驶车辆而言是复杂但高回报的行为，需降低周围车辆未来行为对自车的风险，并综合利用环境信息以提高决策合理性。

Method: 1. 提出周围车辆轨迹预测方法，将预测结果作为附加信息输入强化学习模型；2. 同时从高维图像和低维传感器数据中提取特征，融合轨迹预测与多模态信息作为强化学习的状态空间；3. 集成强化学习宏观决策与端到端车辆控制，实现完整换道过程。

Result: 在CARLA模拟器中进行的实验表明，混合状态空间的使用显著增强了车辆换道决策的安全性。

Conclusion: 所提出的基于混合输入的DRL算法有效提升了自动驾驶车辆换道决策的安全性，为复杂交通环境下的换道行为提供了可行方案。

Abstract: Lane change decision-making for autonomous vehicles is a complex but
high-reward behavior. In this paper, we propose a hybrid input based deep
reinforcement learning (DRL) algorithm, which realizes abstract lane change
decisions and lane change actions for autonomous vehicles within traffic flow.
Firstly, a surrounding vehicles trajectory prediction method is proposed to
reduce the risk of future behavior of surrounding vehicles to ego vehicle, and
the prediction results are input into the reinforcement learning model as
additional information. Secondly, to comprehensively leverage environmental
information, the model extracts feature from high-dimensional images and
low-dimensional sensor data simultaneously. The fusion of surrounding vehicle
trajectory prediction and multi-modal information are used as state space of
reinforcement learning to improve the rationality of lane change decision.
Finally, we integrate reinforcement learning macro decisions with end-to-end
vehicle control to achieve a holistic lane change process. Experiments were
conducted within the CARLA simulator, and the results demonstrated that the
utilization of a hybrid state space significantly enhances the safety of
vehicle lane change decisions.

</details>


### [53] [Speculative Design of Equitable Robotics: Queer Fictions and Futures](https://arxiv.org/abs/2509.01643)
*Minja Axelsson*

Main category: cs.RO

TL;DR: 本文以探索性论文形式研究公平机器人这一推测性主题，聚焦于LGBTQ+群体的机器人，旨在引发关于艺术和科学领域中理想的酷儿机器人未来的思考与对话，包括回顾现状、提出三种推测性设计方案、探讨伦理问题及给出未来建议。


<details>
  <summary>Details</summary>
Motivation: 旨在引发该领域关于艺术和科学中理想的酷儿机器人未来可能形态的思考与对话。

Method: 首先简要回顾酷儿机器人在小说和科学中的最新发展，整合两者线索；然后通过三种酷儿机器人角色的推测性设计方案进行讨论，包括反映群体酷儿性、进行新型酷儿行动主义、构建酷儿拥有的机器人网络；接着质疑是否应使机器人酷儿化及相关伦理影响；最后提出理想酷儿机器人未来的建议及所需条件。

Result: 提出了三种酷儿机器人角色的推测性设计方案，并对机器人酷儿化的伦理问题进行了探讨，同时给出了关于理想酷儿机器人未来的建议。

Conclusion: 本文对公平机器人中LGBTQ+群体相关主题进行了探索，通过回顾、设计方案、伦理探讨和建议，为理想的酷儿机器人未来提供了思路。

Abstract: This paper examines the speculative topic of equitable robots through an
exploratory essay format. It focuses specifically on robots by and for LGBTQ+
populations. It aims to provoke thought and conversations in the field about
what aspirational queer robotics futures may look like, both in the arts and
sciences. First, it briefly reviews the state-of-the-art of queer robotics in
fiction and science, drawing together threads from each. Then, it discusses
queering robots through three speculative design proposals for queer robot
roles: 1) reflecting the queerness of their ''in-group'' queer users, building
and celebrating ''in-group'' identity, 2) a new kind of queer activism by
implementing queer robot identity performance to interact with ''out-group''
users, with a goal of reducing bigotry through familiarisation, and 3) a
network of queer-owned robots, through which the community could reach each
other, and distribute and access important resources. The paper then questions
whether robots should be queered, and what ethical implications this raises.
Finally, the paper makes suggestions for what aspirational queer robotics
futures may look like, and what would be required to get there.

</details>


### [54] [Data Retrieval with Importance Weights for Few-Shot Imitation Learning](https://arxiv.org/abs/2509.01657)
*Amber Xie,Rahul Chand,Dorsa Sadigh,Joey Hejna*

Main category: cs.RO

TL;DR: 本文提出重要性加权检索（IWR）方法，通过高斯核密度估计（KDE）目标与先验数据分布的比率，解决现有检索式模仿学习中基于最小距离的方法存在的高方差和未考虑先验数据分布的问题，在模拟和真实世界评估中一致提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有检索式模仿学习依赖潜空间中目标数据集点的最小距离来选择先验数据，但该方法等价于目标数据分布的高斯核密度估计（KDE）极限，存在高方差近邻估计易受噪声影响以及未考虑先验数据分布的缺点。

Method: 提出重要性加权检索（IWR），使用高斯KDE估计目标与先验数据分布的比率（重要性权重），通过考虑概率比减轻先前选择规则的偏差，并利用合理建模参数平滑所有数据点的估计。

Result: 在模拟环境和Bridge数据集的真实世界评估中，IWR方法尽管只需微小修改，但一致提升了现有检索式方法的性能。

Conclusion: IWR通过改进检索规则，有效解决了传统方法的缺陷，是一种在少样本模仿学习中提升性能的有效方法。

Abstract: While large-scale robot datasets have propelled recent progress in imitation
learning, learning from smaller task specific datasets remains critical for
deployment in new environments and unseen tasks. One such approach to few-shot
imitation learning is retrieval-based imitation learning, which extracts
relevant samples from large, widely available prior datasets to augment a
limited demonstration dataset. To determine the relevant data from prior
datasets, retrieval-based approaches most commonly calculate a prior data
point's minimum distance to a point in the target dataset in latent space.
While retrieval-based methods have shown success using this metric for data
selection, we demonstrate its equivalence to the limit of a Gaussian kernel
density (KDE) estimate of the target data distribution. This reveals two
shortcomings of the retrieval rule used in prior work. First, it relies on
high-variance nearest neighbor estimates that are susceptible to noise. Second,
it does not account for the distribution of prior data when retrieving data. To
address these issues, we introduce Importance Weighted Retrieval (IWR), which
estimates importance weights, or the ratio between the target and prior data
distributions for retrieval, using Gaussian KDEs. By considering the
probability ratio, IWR seeks to mitigate the bias of previous selection rules,
and by using reasonable modeling parameters, IWR effectively smooths estimates
using all data points. Across both simulation environments and real-world
evaluations on the Bridge dataset we find that our method, IWR, consistently
improves performance of existing retrieval-based methods, despite only
requiring minor modifications.

</details>


### [55] [MoTo: A Zero-shot Plug-in Interaction-aware Navigation for General Mobile Manipulation](https://arxiv.org/abs/2509.01658)
*Zhenyu Wu,Angyuan Ma,Xiuwei Xu,Hang Yin,Yinan Liang,Ziwei Wang,Jiwen Lu,Haibin Yan*

Main category: cs.RO

TL;DR: 本文提出MoTo插件模块，结合现有操作基础模型赋予其移动操作能力，通过交互感知导航策略生成对接点，基于VLM的交互关键点框架实现零样本能力，结合运动规划目标优化轨迹，在OVMM和真实世界实验中成功率分别比SOTA高2.68%和16.67%


<details>
  <summary>Details</summary>
Motivation: 传统移动操作方法因缺乏大规模训练难以跨任务和环境泛化，现有操作基础模型虽在固定基座任务泛化能力强但受限于固定场景，需赋予其移动操作能力

Method: 设计MoTo插件模块：1.交互感知导航策略生成机器人对接点；2.基于VLM的多视图一致性交互关键点框架（针对目标物体和机械臂）实现零样本；3.移动基座和机械臂的运动规划目标（最小化关键点距离并保持轨迹物理可行性）

Result: 在OVMM数据集和真实世界实验中，MoTo的成功率分别比最先进的移动操作方法高出2.68%和16.67%，且无需额外训练数据

Conclusion: MoTo能有效结合现有操作基础模型实现移动操作，通过对接点导航、VLM关键点生成和轨迹优化，在零样本条件下提升移动操作成功率

Abstract: Mobile manipulation stands as a core challenge in robotics, enabling robots
to assist humans across varied tasks and dynamic daily environments.
Conventional mobile manipulation approaches often struggle to generalize across
different tasks and environments due to the lack of large-scale training.
However, recent advances in manipulation foundation models demonstrate
impressive generalization capability on a wide range of fixed-base manipulation
tasks, which are still limited to a fixed setting. Therefore, we devise a
plug-in module named MoTo, which can be combined with any off-the-shelf
manipulation foundation model to empower them with mobile manipulation ability.
Specifically, we propose an interaction-aware navigation policy to generate
robot docking points for generalized mobile manipulation. To enable zero-shot
ability, we propose an interaction keypoints framework via vision-language
models (VLM) under multi-view consistency for both target object and robotic
arm following instructions, where fixed-base manipulation foundation models can
be employed. We further propose motion planning objectives for the mobile base
and robot arm, which minimize the distance between the two keypoints and
maintain the physical feasibility of trajectories. In this way, MoTo guides the
robot to move to the docking points where fixed-base manipulation can be
successfully performed, and leverages VLM generation and trajectory
optimization to achieve mobile manipulation in a zero-shot manner, without any
requirement on mobile manipulation expert data. Extensive experimental results
on OVMM and real-world demonstrate that MoTo achieves success rates of 2.68%
and 16.67% higher than the state-of-the-art mobile manipulation methods,
respectively, without requiring additional training data.

</details>


### [56] [Articulated Object Estimation in the Wild](https://arxiv.org/abs/2509.01708)
*Abdelrhman Werby,Martin Büchner,Adrian Röfer,Chenguang Huang,Wolfram Burgard,Abhinav Valada*

Main category: cs.RO

TL;DR: 本文提出ArtiPoint框架，结合深度点跟踪与因子图优化，从RGB-D视频中估计关节物体模型，解决动态相机运动和部分可观测性问题，并发布首个以自我为中心的野生数据集Arti4D，实验表明其性能优于多种基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有关节估计方法主要针对受控环境，假设固定相机视角或直接观测物体状态，在真实无约束环境中易失效；而人类通过观察他人操作物体可轻松推断关节结构，受此启发进行研究。

Method: 引入ArtiPoint框架，结合深度点跟踪与因子图优化框架，直接从原始RGB-D视频中稳健估计关节部件轨迹和关节轴。

Result: 在Arti4D数据集上与多种经典和基于学习的基线方法进行基准测试，证明了ArtiPoint的优越性能。

Conclusion: ArtiPoint能在动态相机运动和部分可观测性下推断关节物体模型，发布的Arti4D数据集可促进该领域未来研究，代码和数据集已公开。

Abstract: Understanding the 3D motion of articulated objects is essential in robotic
scene understanding, mobile manipulation, and motion planning. Prior methods
for articulation estimation have primarily focused on controlled settings,
assuming either fixed camera viewpoints or direct observations of various
object states, which tend to fail in more realistic unconstrained environments.
In contrast, humans effortlessly infer articulation by watching others
manipulate objects. Inspired by this, we introduce ArtiPoint, a novel
estimation framework that can infer articulated object models under dynamic
camera motion and partial observability. By combining deep point tracking with
a factor graph optimization framework, ArtiPoint robustly estimates articulated
part trajectories and articulation axes directly from raw RGB-D videos. To
foster future research in this domain, we introduce Arti4D, the first
ego-centric in-the-wild dataset that captures articulated object interactions
at a scene level, accompanied by articulation labels and ground-truth camera
poses. We benchmark ArtiPoint against a range of classical and learning-based
baselines, demonstrating its superior performance on Arti4D. We make code and
Arti4D publicly available at https://artipoint.cs.uni-freiburg.de.

</details>


### [57] [Constrained Decoding for Robotics Foundation Models](https://arxiv.org/abs/2509.01728)
*Parv Kapoor,Akila Ganlath,Changliu Liu,Sebastian Scherer,Eunsuk Kang*

Main category: cs.RO

TL;DR: 提出了一种约束解码框架，在不重新训练的情况下，确保机器人基础模型生成的动作轨迹在运行时可证明地满足信号时序逻辑（STL）规范，提升行为正确性和安全性，并在最先进的导航基础模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 机器人基础模型虽具有端到端和通用能力，但仍受数据驱动，缺乏对行为正确性和安全约束的明确概念。

Method: 引入一种针对机器人基础模型的约束解码框架，该框架在动态系统中对动作轨迹施加逻辑约束，确保生成的动作在运行时无需重新训练即可满足信号时序逻辑（STL）规范，且与底层基础模型无关。

Result: 在最先进的导航基础模型上进行了综合评估，结果表明解码时干预不仅可用于过滤不安全动作，还有助于条件动作生成。

Conclusion: 所提出的约束解码框架有效解决了机器人基础模型缺乏行为正确性和安全约束的问题，提升了其在实际应用中的可靠性。

Abstract: Recent advances in the development of robotic foundation models have led to
promising end-to-end and general-purpose capabilities in robotic systems. These
models are pretrained on vast datasets of robot trajectories to process multi-
modal inputs and directly output a sequence of action that the system then
executes in the real world. Although this approach is attractive from the
perspective of im- proved generalization across diverse tasks, these models are
still data-driven and, therefore, lack explicit notions of behavioral
correctness and safety constraints. We address these limitations by introducing
a constrained decoding framework for robotics foundation models that enforces
logical constraints on action trajec- tories in dynamical systems. Our method
ensures that generated actions provably satisfy signal temporal logic (STL)
specifications at runtime without retraining, while remaining agnostic of the
underlying foundation model. We perform com- prehensive evaluation of our
approach across state-of-the-art navigation founda- tion models and we show
that our decoding-time interventions are useful not only for filtering unsafe
actions but also for conditional action-generation. Videos available on our
website: https://constrained-robot-fms.github.io

</details>


### [58] [Fail2Progress: Learning from Real-World Robot Failures with Stein Variational Inference](https://arxiv.org/abs/2509.01746)
*Yixuan Huang,Novella Alvina,Mohanraj Devendran Shanthi,Tucker Hermans*

Main category: cs.RO

TL;DR: 该研究提出Fail2Progress方法，利用Stein变分推断并行生成多个模拟环境，以高效生成针对观察到的故障的数据集，从而帮助技能效果模型从故障中学习并减少未来故障，在多种移动操作任务中表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 长期操作任务的技能效果模型在训练数据分布未覆盖的条件下容易失败，因此需要使机器人能够对故障进行推理并从中学习。

Method: 提出Fail2Progress方法，利用Stein变分推断并行生成多个模拟环境，以高效生成类似于观察到的故障的数据样本。

Result: 通过大规模模拟和真实世界实验，证明该方法在不同物体数量下均能很好地从故障中学习，并且在多种移动操作任务（如运输多个物体、整理受限货架、桌面整理）中优于多个基线。

Conclusion: Fail2Progress方法能够有效处理多种具有挑战性的移动操作任务，通过高效生成故障数据集并微调技能效果模型，可帮助模型从故障中恢复并减少未来故障，表现优于基线。

Abstract: Skill effect models for long-horizon manipulation tasks are prone to failures
in conditions not covered by training data distributions. Therefore, enabling
robots to reason about and learn from failures is necessary. We investigate the
problem of efficiently generating a dataset targeted to observed failures.
After fine-tuning a skill effect model on this dataset, we evaluate the extent
to which the model can recover from failures and minimize future failures. We
propose Fail2Progress, an approach that leverages Stein variational inference
to generate multiple simulation environments in parallel, enabling efficient
data sample generation similar to observed failures. Our method is capable of
handling several challenging mobile manipulation tasks, including transporting
multiple objects, organizing a constrained shelf, and tabletop organization.
Through large-scale simulation and real-world experiments, we demonstrate that
our approach excels at learning from failures across different numbers of
objects. Furthermore, we show that Fail2Progress outperforms several baselines.

</details>


### [59] [Non-conflicting Energy Minimization in Reinforcement Learning based Robot Control](https://arxiv.org/abs/2509.01765)
*Skand Peri,Akhil Perincherry,Bikram Pandit,Stefan Lee*

Main category: cs.RO

TL;DR: 本文提出一种无超参数梯度优化方法，通过任务与能量目标间的策略梯度投影，在不影响任务性能的前提下最小化能量消耗，在DM-Control和HumanoidBench基准测试中实现64%能耗降低，且在Unitree GO2四足机器人上验证了Sim2Real迁移效果。


<details>
  <summary>Details</summary>
Motivation: 强化学习中直接在奖励函数中惩罚能量消耗需仔细调整权重，易导致能量最小化损害任务成功的不良权衡。

Method: 受多任务学习启发，应用任务与能量目标间的策略梯度投影，推导不影响任务性能的能量最小化策略更新。

Result: 在DM-Control和HumanoidBench标准 locomotion 基准测试中，能耗减少64%，同时保持相当的任务性能；在Unitree GO2四足机器人上展示了节能策略的Sim2Real迁移。

Conclusion: 该方法易于在标准RL管道中实现，代码改动小，适用于任何策略梯度方法，为节能控制策略提供了一种有原则的奖励塑造替代方案。

Abstract: Efficient robot control often requires balancing task performance with energy
expenditure. A common approach in reinforcement learning (RL) is to penalize
energy use directly as part of the reward function. This requires carefully
tuning weight terms to avoid undesirable trade-offs where energy minimization
harms task success. In this work, we propose a hyperparameter-free gradient
optimization method to minimize energy expenditure without conflicting with
task performance. Inspired by recent works in multitask learning, our method
applies policy gradient projection between task and energy objectives to derive
policy updates that minimize energy expenditure in ways that do not impact task
performance. We evaluate this technique on standard locomotion benchmarks of
DM-Control and HumanoidBench and demonstrate a reduction of 64% energy usage
while maintaining comparable task performance. Further, we conduct experiments
on a Unitree GO2 quadruped showcasing Sim2Real transfer of energy efficient
policies. Our method is easy to implement in standard RL pipelines with minimal
code changes, is applicable to any policy gradient method, and offers a
principled alternative to reward shaping for energy efficient control policies.

</details>


### [60] [ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training](https://arxiv.org/abs/2509.01819)
*Ge Yan,Jiyue Zhu,Yuquan Deng,Shiqi Yang,Ri-Zhao Qiu,Xuxin Cheng,Marius Memmel,Ranjay Krishna,Ankit Goyal,Xiaolong Wang,Dieter Fox*

Main category: cs.RO

TL;DR: 本文介绍了ManiFlow，一种用于通用机器人操作的视觉运动模仿学习策略，可基于多样的视觉、语言和本体感觉输入生成精确的高维动作。


<details>
  <summary>Details</summary>
Motivation: 为实现通用机器人操作中精确、高维动作的生成，并高效处理多样输入模态。

Method: 利用流匹配和一致性训练，在1-2个推理步骤内实现高质量灵巧动作生成；提出DiT-X，一种具有自适应交叉注意力和AdaLN-Zero条件的扩散Transformer架构，实现动作令牌与多模态观察之间的细粒度特征交互。

Result: 在多样的模拟基准测试中持续改进，在单臂、双臂和类人机器人的真实世界任务中成功率几乎翻倍，且灵巧性不断提高；对新物体和背景变化具有强鲁棒性和泛化性，在更大规模数据集上具有强扩展能力。

Conclusion: ManiFlow通过流匹配、一致性训练及DiT-X架构，在模拟和真实世界任务中展现出优异性能，具备良好的鲁棒性、泛化性和扩展能力。

Abstract: This paper introduces ManiFlow, a visuomotor imitation learning policy for
general robot manipulation that generates precise, high-dimensional actions
conditioned on diverse visual, language and proprioceptive inputs. We leverage
flow matching with consistency training to enable high-quality dexterous action
generation in just 1-2 inference steps. To handle diverse input modalities
efficiently, we propose DiT-X, a diffusion transformer architecture with
adaptive cross-attention and AdaLN-Zero conditioning that enables fine-grained
feature interactions between action tokens and multi-modal observations.
ManiFlow demonstrates consistent improvements across diverse simulation
benchmarks and nearly doubles success rates on real-world tasks across
single-arm, bimanual, and humanoid robot setups with increasing dexterity. The
extensive evaluation further demonstrates the strong robustness and
generalizability of ManiFlow to novel objects and background changes, and
highlights its strong scaling capability with larger-scale datasets. Our
website: maniflow-policy.github.io.

</details>


### [61] [Multi-vessel Interaction-Aware Trajectory Prediction and Collision Risk Assessment](https://arxiv.org/abs/2509.01836)
*Md Mahbub Alam,Jose F. Rodrigues-Jr,Gabriel Spadon*

Main category: cs.RO

TL;DR: 本文提出了一种基于Transformer的多船轨迹预测框架，整合了碰撞风险分析，通过并行流编码运动学和物理特征、因果卷积、空间变换及混合位置嵌入，实现多船联合轨迹预测，并在大规模AIS数据上验证了其优于传统单船模型的预测能力，还能量化潜在碰撞风险，增强海事安全和决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动模型主要限于单船预测，忽视了船舶相互作用、导航规则和显式碰撞风险评估，无法满足增强态势感知和防止碰撞的需求。

Method: 该框架针对目标船识别附近船舶，通过并行流编码运动学和派生物理特征、因果卷积处理时间局部性、空间变换进行位置编码、混合位置嵌入捕捉局部运动模式和长程依赖，联合预测多船未来轨迹，并通过模拟预测轨迹间的相互作用量化碰撞风险。

Result: 在大规模真实AIS数据上使用联合多船指标评估，模型展示了超越传统单船位移误差的优越预测能力，并能量化潜在碰撞风险。

Conclusion: 所提出的基于Transformer的多船轨迹预测框架不仅在多船轨迹预测方面表现出色，还能通过预测轨迹间的相互作用模拟量化碰撞风险，为增强海事安全和决策支持提供可操作的见解。

Abstract: Accurate vessel trajectory prediction is essential for enhancing situational
awareness and preventing collisions. Still, existing data-driven models are
constrained mainly to single-vessel forecasting, overlooking vessel
interactions, navigation rules, and explicit collision risk assessment. We
present a transformer-based framework for multi-vessel trajectory prediction
with integrated collision risk analysis. For a given target vessel, the
framework identifies nearby vessels. It jointly predicts their future
trajectories through parallel streams encoding kinematic and derived physical
features, causal convolutions for temporal locality, spatial transformations
for positional encoding, and hybrid positional embeddings that capture both
local motion patterns and long-range dependencies. Evaluated on large-scale
real-world AIS data using joint multi-vessel metrics, the model demonstrates
superior forecasting capabilities beyond traditional single-vessel displacement
errors. By simulating interactions among predicted trajectories, the framework
further quantifies potential collision risks, offering actionable insights to
strengthen maritime safety and decision support.

</details>


### [62] [AI-Driven Marine Robotics: Emerging Trends in Underwater Perception and Ecosystem Monitoring](https://arxiv.org/abs/2509.01878)
*Scarlett Raine,Tobias Fischer*

Main category: cs.RO

TL;DR: 本文探讨水下AI作为新兴研究前沿，分析其从边缘应用转变为AI创新催化剂的驱动因素，包括生态监测需求、数据集民主化及研究者迁移，指出水下独特挑战推动弱监督学习等AI技术进步，并延伸至通用领域。


<details>
  <summary>Details</summary>
Motivation: 海洋生态系统受气候变化压力增大，需可扩展的AI驱动监测解决方案，水下AI成为研究前沿，将海洋感知从边缘应用转化为AI创新催化剂。

Method: 分析水下AI兴起的三个驱动因素（生态监测的环境必要性、公民科学平台促进的水下数据集民主化、研究者从饱和的陆地计算机视觉领域迁移），并探讨水下独特挑战对AI技术的推动作用，调查数据集、场景理解和3D重建的新兴趋势。

Result: 水下的浊度、隐秘物种检测等独特挑战正推动弱监督学习、开集识别和退化条件下鲁棒感知等基础AI技术进步，且水下AI的方法创新不仅限于海洋应用，还惠及通用计算机视觉、机器人学和环境监测。

Conclusion: 水下环境的限制正在推动基础模型、自监督学习和感知能力的边界，其方法论创新远超海洋应用，对通用计算机视觉、机器人技术和环境监测等领域有益。

Abstract: Marine ecosystems face increasing pressure due to climate change, driving the
need for scalable, AI-powered monitoring solutions. This paper examines the
rapid emergence of underwater AI as a major research frontier and analyzes the
factors that have transformed marine perception from a niche application into a
catalyst for AI innovation. We identify three convergent drivers: environmental
necessity for ecosystem-scale monitoring, democratization of underwater
datasets through citizen science platforms, and researcher migration from
saturated terrestrial computer vision domains. Our analysis reveals how unique
underwater challenges - turbidity, cryptic species detection, expert annotation
bottlenecks, and cross-ecosystem generalization - are driving fundamental
advances in weakly supervised learning, open-set recognition, and robust
perception under degraded conditions. We survey emerging trends in datasets,
scene understanding and 3D reconstruction, highlighting the paradigm shift from
passive observation toward AI-driven, targeted intervention capabilities. The
paper demonstrates how underwater constraints are pushing the boundaries of
foundation models, self-supervised learning, and perception, with
methodological innovations that extend far beyond marine applications to
benefit general computer vision, robotics, and environmental monitoring.

</details>


### [63] [AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving](https://arxiv.org/abs/2509.01944)
*Zhenlong Yuan,Jing Tang,Jinguo Luo,Rui Chen,Chengxuan Qian,Lei Sun,Xiangxiang Chu,Yujun Cai,Dapeng Zhang,Shuo Li*

Main category: cs.RO

TL;DR: 本文提出AutoDrive-R²框架，通过思维链处理和强化学习增强自动驾驶系统的推理与自我反思能力，包括构建nuScenesR²-6K数据集和使用GRPO算法，在nuScenes和Waymo数据集上表现出SOTA性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶中的VLA模型在决策过程的可解释性、连贯性及动作序列合理性方面研究不足。

Method: 提出AutoDrive-R²框架，包含：1. 构建nuScenesR²-6K思维链数据集用于监督微调，通过四步逻辑链和自我反思建立输入信息与输出轨迹的认知桥梁；2. 在强化学习阶段采用GRPO算法，结合基于物理的奖励框架（含空间对齐、车辆动力学、时间平滑性标准）。

Result: 在nuScenes和Waymo数据集上的广泛评估显示，所提方法实现了最先进的性能和强大的泛化能力。

Conclusion: AutoDrive-R²框架通过增强推理与自我反思能力，有效提升了自动驾驶系统的决策可解释性、连贯性及轨迹规划的可靠性与现实性。

Abstract: Vision-Language-Action (VLA) models in autonomous driving systems have
recently demonstrated transformative potential by integrating multimodal
perception with decision-making capabilities. However, the interpretability and
coherence of the decision process and the plausibility of action sequences
remain largely underexplored. To address these issues, we propose
AutoDrive-R$^2$, a novel VLA framework that enhances both reasoning and
self-reflection capabilities of autonomous driving systems through
chain-of-thought (CoT) processing and reinforcement learning (RL).
Specifically, we first propose an innovative CoT dataset named nuScenesR$^2$-6K
for supervised fine-tuning, which effectively builds cognitive bridges between
input information and output trajectories through a four-step logical chain
with self-reflection for validation. Moreover, to maximize both reasoning and
self-reflection during the RL stage, we further employ the Group Relative
Policy Optimization (GRPO) algorithm within a physics-grounded reward framework
that incorporates spatial alignment, vehicle dynamic, and temporal smoothness
criteria to ensure reliable and realistic trajectory planning. Extensive
evaluation results across both nuScenes and Waymo datasets demonstrates the
state-of-the-art performance and robust generalization capacity of our proposed
method.

</details>


### [64] [Hybrid Autonomy Framework for a Future Mars Science Helicopter](https://arxiv.org/abs/2509.01980)
*Luca Di Pierno,Robert Hewitt,Stephan Weiss,Roland Brockers*

Main category: cs.RO

TL;DR: 本文提出了一种确定性高级控制框架，将有限状态机（FSM）与行为树（BTs）集成，为火星科学直升机（MSH）等深空探测场景提供可扩展、鲁棒且计算高效的自主解决方案，并通过蒙特卡洛模拟和实地测试验证了其对离散事件和实时系统反馈的适应性。


<details>
  <summary>Details</summary>
Motivation: 由于地球-火星通信延迟大且任务复杂，需要先进的自主框架确保火星科学直升机（MSH）在无人工干预情况下，能基于任务目标和实时条件持续调整行为，实现安全高效运行。

Method: 提出集成有限状态机（FSM）与行为树（BTs）的混合自主框架，该框架中间件无关，可与F-Prime等系统集成，通过状态转换和动态调整行为执行来响应输入。

Result: 蒙特卡洛模拟和实地测试验证了该框架的鲁棒性和适应性，能对离散事件和实时系统反馈做出反应性和上下文感知的响应。

Conclusion: 该确定性高级控制框架为航空探索提供了可扩展、鲁棒且计算高效的自主解决方案，适用于火星科学直升机等关键场景，且可扩展到航空机器人之外的领域。

Abstract: Autonomous aerial vehicles, such as NASA's Ingenuity, enable rapid planetary
surface exploration beyond the reach of ground-based robots. Thus, NASA is
studying a Mars Science Helicopter (MSH), an advanced concept capable of
performing long-range science missions and autonomously navigating challenging
Martian terrain. Given significant Earth-Mars communication delays and mission
complexity, an advanced autonomy framework is required to ensure safe and
efficient operation by continuously adapting behavior based on mission
objectives and real-time conditions, without human intervention. This study
presents a deterministic high-level control framework for aerial exploration,
integrating a Finite State Machine (FSM) with Behavior Trees (BTs) to achieve a
scalable, robust, and computationally efficient autonomy solution for critical
scenarios like deep space exploration. In this paper we outline key
capabilities of a possible MSH and detail the FSM-BT hybrid autonomy framework
which orchestrates them to achieve the desired objectives. Monte Carlo
simulations and real field tests validate the framework, demonstrating its
robustness and adaptability to both discrete events and real-time system
feedback. These inputs trigger state transitions or dynamically adjust behavior
execution, enabling reactive and context-aware responses. The framework is
middleware-agnostic, supporting integration with systems like F-Prime and
extending beyond aerial robotics.

</details>


### [65] [Geometric Control of Mechanical Systems with Symmetries Based on Sliding Modes](https://arxiv.org/abs/2509.01985)
*Eduardo Espindola,Yu Tang*

Main category: cs.RO

TL;DR: 本文提出一种为具有对称性的机械系统（包括无约束和受约束，在主纤维丛上演化）设计滑模控制器的框架，通过利用对称性基于约化运动方程开发控制律，降低设计复杂度并避免特定李群坐标表示的困难选择，还在李雅普诺夫分析下证明了几乎全局渐近稳定性和局部指数稳定性，并应用于全驱动系统（刚性航天器）和欠驱动非完整系统（独轮移动机器人）。


<details>
  <summary>Details</summary>
Motivation: 为具有对称性的机械系统（无约束和受约束，在主纤维丛上演化）设计滑模控制器时，降低设计复杂度并避免特定李群坐标表示的困难选择。

Method: 基于约化运动方程开发控制律，利用对称性；在结构群上基于运动学控制器构建滑动子群，使滑动变量到达滑动子群时收敛到状态流形的单位元；在底空间上使用机械连接的局部形式设计基于一般滑动向量场的到达律，驱动滑动变量到滑动子群，其时间演化根据适当的协变导数给出。

Result: 通过李雅普诺夫分析证明了几乎全局渐近稳定性和局部指数稳定性；并将结果应用于全驱动系统（由反作用轮驱动的刚性航天器）和欠驱动非完整系统（由轮子驱动的独轮移动机器人），还对后者进行了仿真说明。

Conclusion: 所提出的框架可有效为具有对称性的机械系统设计滑模控制器，降低复杂度，避免特定李群坐标表示问题，且具有良好的稳定性，在全驱动和欠驱动系统中均有应用价值。

Abstract: In this paper, we propose a framework for designing sliding mode controllers
for a class of mechanical systems with symmetry, both unconstrained and
constrained, that evolve on principal fiber bundles. Control laws are developed
based on the reduced motion equations by exploring symmetries, leading to a
sliding mode control strategy where the reaching stage is executed on the base
space, and the sliding stage is performed on the structure group. Thus, design
complexity is reduced, and difficult choices for coordinate representations
when working with a particular Lie group are avoided. For this purpose, a
sliding subgroup is constructed on the structure group based on a kinematic
controller, and the sliding variable will converge to the identity of the state
manifold upon reaching the sliding subgroup. A reaching law based on a general
sliding vector field is then designed on the base space using the local form of
the mechanical connection to drive the sliding variable to the sliding
subgroup, and its time evolution is given according to the appropriate
covariant derivative. Almost global asymptotic stability and local exponential
stability are demonstrated using a Lyapunov analysis. We apply the results to a
fully actuated system (a rigid spacecraft actuated by reaction wheels) and a
subactuated nonholonomic system (unicycle mobile robot actuated by wheels),
which is also simulated for illustration.

</details>


### [66] [MIRAGE: Multimodal Intention Recognition and Admittance-Guided Enhancement in VR-based Multi-object Teleoperation](https://arxiv.org/abs/2509.01996)
*Chi Sun,Xian Wang,Abhishek Kumar,Chengbin Cui,Lik-Hang Lee*

Main category: cs.RO

TL;DR: This paper proposes a shared control framework combining a virtual admittance (VA) model and a Multimodal-CNN-based Human Intention Perception Network (MMIPN) to enhance teleoperation performance and user experience in multi-object teleoperation tasks in VR environments.


<details>
  <summary>Details</summary>
Motivation: Effective human-robot interaction (HRI) in multi-object teleoperation tasks faces significant challenges due to perceptual ambiguities in virtual reality (VR) environments and the limitations of single-modality intention recognition.

Method: The framework combines a VA model (which employs artificial potential fields to guide operators toward target objects by adjusting admittance force and optimizing motion trajectories) and MMIPN (which processes multimodal inputs including gaze movement, robot motions, and environmental context to estimate human grasping intentions).

Result: User study results showed that MMIPN significantly improved grasp success rates, the VA model enhanced movement efficiency by reducing path lengths, and gaze data emerged as the most crucial input modality.

Conclusion: These findings demonstrate the effectiveness of combining multimodal cues with implicit guidance in VR-based teleoperation, providing a robust solution for multi-object grasping tasks and enabling more natural interactions across various applications in the future.

Abstract: Effective human-robot interaction (HRI) in multi-object teleoperation tasks
faces significant challenges due to perceptual ambiguities in virtual reality
(VR) environments and the limitations of single-modality intention recognition.
This paper proposes a shared control framework that combines a virtual
admittance (VA) model with a Multimodal-CNN-based Human Intention Perception
Network (MMIPN) to enhance teleoperation performance and user experience. The
VA model employs artificial potential fields to guide operators toward target
objects by adjusting admittance force and optimizing motion trajectories. MMIPN
processes multimodal inputs, including gaze movement, robot motions, and
environmental context, to estimate human grasping intentions, helping to
overcome depth perception challenges in VR. Our user study evaluated four
conditions across two factors, and the results showed that MMIPN significantly
improved grasp success rates, while the VA model enhanced movement efficiency
by reducing path lengths. Gaze data emerged as the most crucial input modality.
These findings demonstrate the effectiveness of combining multimodal cues with
implicit guidance in VR-based teleoperation, providing a robust solution for
multi-object grasping tasks and enabling more natural interactions across
various applications in the future.

</details>


### [67] [Generalizing Unsupervised Lidar Odometry Model from Normal to Snowy Weather Conditions](https://arxiv.org/abs/2509.02011)
*Beibei Zhou,Zhiyuan Zhang,Zhenbo Song,Jianhui Guo,Hui Kong*

Main category: cs.RO

TL;DR: 本文提出一种无监督LiDAR里程计模型，通过Patch Spatial Measure（PSM）模块和Patch Point Weight Predictor（PPWP）实现有效去噪，结合强度阈值掩码和多模态特征融合提升恶劣天气（尤其是降雪）下的鲁棒性与实时性，在清晰和降雪天气均表现良好。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的LiDAR里程计模型在恶劣天气（尤其是降雪）下因对雪诱导噪声敏感而泛化能力差，限制了实际应用，需解决清晰与降雪天气条件下的性能差距。

Method: 1. 引入PSM模块评估每个补丁内点的分散度，检测稀疏离散噪声；2. 提出PPWP分配自适应点权重，增强局部区域判别能力；3. 应用强度阈值掩码快速抑制LiDAR附近密集雪花簇，再进行多模态特征融合优化点权重预测。

Result: 模型在清晰和降雪等多种场景下经过严格测试，实验结果证实其在清晰和降雪天气均具有稳健性能，提升了模型泛化能力。

Conclusion: 该方法通过有效去噪和实时优化，增强了LiDAR里程计模型在不同环境条件下的可靠性，为更广泛环境下运行的自主系统奠定基础。

Abstract: Deep learning-based LiDAR odometry is crucial for autonomous driving and
robotic navigation, yet its performance under adverse weather, especially
snowfall, remains challenging. Existing models struggle to generalize across
conditions due to sensitivity to snow-induced noise, limiting real-world use.
In this work, we present an unsupervised LiDAR odometry model to close the gap
between clear and snowy weather conditions. Our approach focuses on effective
denoising to mitigate the impact of snowflake noise and outlier points on pose
estimation, while also maintaining computational efficiency for real-time
applications.
  To achieve this, we introduce a Patch Spatial Measure (PSM) module that
evaluates the dispersion of points within each patch, enabling effective
detection of sparse and discrete noise.
  We further propose a Patch Point Weight Predictor (PPWP) to assign adaptive
point-wise weights, enhancing their discriminative capacity within local
regions. To support real-time performance, we first apply an intensity
threshold mask to quickly suppress dense snowflake clusters near the LiDAR, and
then perform multi-modal feature fusion to refine the point-wise weight
prediction, improving overall robustness under adverse weather. Our model is
trained in clear weather conditions and rigorously tested across various
scenarios, including snowy and dynamic. Extensive experimental results confirm
the effectiveness of our method, demonstrating robust performance in both clear
and snowy weather. This advancement enhances the model's generalizability and
paves the way for more reliable autonomous systems capable of operating across
a wider range of environmental conditions.

</details>


### [68] [Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance](https://arxiv.org/abs/2509.02055)
*Yang Zhang,Chenwei Wang,Ouyang Lu,Yuan Zhao,Yunfei Ge,Zhenglong Sun,Xiu Li,Chi Zhang,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: Vision-Language-Action (VLA)模型在通用机器人操作中潜力显著，但在适应下游任务时存在瓶颈，尤其是机器人形态或任务与预训练数据不同时，动作分布不匹配导致需大量数据和计算进行微调。本文提出Align-Then-stEer (ATE)框架，通过统一潜在空间对齐动作空间并在微调时引导模型输出分布向目标域，在模拟和现实世界的跨形态和跨任务操作中，与直接微调相比，模拟中平均多任务成功率提高达9.8%，现实世界跨形态场景成功率提升32%，为VLA模型部署到新机器人平台和任务提供通用轻量级解决方案。


<details>
  <summary>Details</summary>
Motivation: VLA模型在适应下游任务时，当机器人形态或任务与预训练数据不同，会导致动作分布显著不匹配，需要大量数据和计算进行有效微调，这是一个主要瓶颈，为解决此问题而开展研究。

Method: 提出Align-Then-stEer (ATE)框架，首先通过构建统一潜在空间来对齐不同的动作空间，其中受反向KL散度约束的变分自编码器将适应动作嵌入到预训练动作潜在分布的模式中；随后，在微调期间通过引导机制控制基于扩散或流的VLA的生成过程，将模型的输出分布推向目标域。

Result: 在模拟和现实世界中进行了跨形态和跨任务操作的广泛实验。与代表性VLA的直接微调相比，该方法在模拟中平均多任务成功率提高了9.8%，在现实世界的跨形态环境中实现了32%的显著成功率提升。

Conclusion: ATE是一种通用且轻量级的解决方案，极大地增强了将VLA模型部署到新机器人平台和任务的实用性。

Abstract: Vision-Language-Action (VLA) models pre-trained on large, diverse datasets
show remarkable potential for general-purpose robotic manipulation. However, a
primary bottleneck remains in adapting these models to downstream tasks,
especially when the robot's embodiment or the task itself differs from the
pre-training data. This discrepancy leads to a significant mismatch in action
distributions, demanding extensive data and compute for effective fine-tuning.
To address this challenge, we introduce \textbf{Align-Then-stEer
(\texttt{ATE})}, a novel, data-efficient, and plug-and-play adaptation
framework. \texttt{ATE} first aligns disparate action spaces by constructing a
unified latent space, where a variational autoencoder constrained by reverse KL
divergence embeds adaptation actions into modes of the pre-training action
latent distribution. Subsequently, it steers the diffusion- or flow-based VLA's
generation process during fine-tuning via a guidance mechanism that pushes the
model's output distribution towards the target domain. We conduct extensive
experiments on cross-embodiment and cross-task manipulation in both simulation
and real world. Compared to direct fine-tuning of representative VLAs, our
method improves the average multi-task success rate by up to \textbf{9.8\%} in
simulation and achieves a striking \textbf{32\% success rate gain} in a
real-world cross-embodiment setting. Our work presents a general and
lightweight solution that greatly enhances the practicality of deploying VLA
models to new robotic platforms and tasks.

</details>


### [69] [A Geometric Method for Base Parameter Analysis in Robot Inertia Identification Based on Projective Geometric Algebra](https://arxiv.org/abs/2509.02071)
*Guangzhen Sun,Ye Ding,Xiangyang Zhu*

Main category: cs.RO

TL;DR: 本文提出一种新的几何方法，利用射影几何代数重构刚体动力学，建立“四面体点（TP）”模型，推导出回归矩阵系数的闭式解，并提出三个基本原理，开发了动力学回归零空间生成器（DRNG）算法，能自动确定机器人系统的基惯性参数，在四种机器人上验证了其通用性、鲁棒性和高效性。


<details>
  <summary>Details</summary>
Motivation: 为解析确定机器人系统的基惯性参数，解决传统方法可能存在的复杂性和几何意义不明确等问题。

Method: 利用射影几何代数重构刚体动力学，建立TP模型；基于该模型推导出回归矩阵系数的闭式解；提出共享点、固定点和平面旋转三个基本原理；开发DRNG算法，通过O(N)预处理后理论上达到O(1)复杂度自动确定基参数。

Result: 在Puma560、Unitree Go2、2RRU-1RRS并联机构和2PRS-1PSR并联机构这四种机器人上验证，算法均成功识别出完整的基参数集，且在并联机构中表现出高鲁棒性和计算效率。

Conclusion: 所提出的方法具有通用性、鲁棒性和高效性，能有效确定机器人系统的基惯性参数。

Abstract: This paper proposes a novel geometric method for analytically determining the
base inertial parameters of robotic systems. The rigid body dynamics is
reformulated using projective geometric algebra, leading to a new
identification model named ``tetrahedral-point (TP)" model. Based on the rigid
body TP model, coefficients in the regresoor matrix of the identification model
are derived in closed-form, exhibiting clear geometric interpretations.
Building directly from the dynamic model, three foundational principles for
base parameter analysis are proposed: the shared points principle, fixed points
principle, and planar rotations principle. With these principles, algorithms
are developed to automatically determine all the base parameters. The core
algorithm, referred to as Dynamics Regressor Nullspace Generator (DRNG),
achieves $O(1)$-complexity theoretically following an $O(N)$-complexity
preprocessing stage, where $N$ is the number of rigid bodies. The proposed
method and algorithms are validated across four robots: Puma560, Unitree Go2, a
2RRU-1RRS parallel kinematics mechanism (PKM), and a 2PRS-1PSR PKM. In all
cases, the algorithms successfully identify the complete set of base
parameters. Notably, the approach demonstrates high robustness and
computational efficiency, particularly in the cases of PKMs. Through the
comprehensive demonstrations, the method is shown to be general, robust, and
efficient.

</details>


### [70] [Learning Social Heuristics for Human-Aware Path Planning](https://arxiv.org/abs/2509.02134)
*Andrea Eirale,Matteo Leonetti,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 本文提出了一种名为启发式规划与学习社会价值（HPLSV）的方法，通过学习封装社会导航成本的价值函数，并将其作为启发式搜索路径规划中的附加启发式，以解决社交机器人导航中需要符合社会规范的问题，初步应用于加入人群队列场景，旨在推广到更多人类活动。


<details>
  <summary>Details</summary>
Motivation: 现有社交机器人导航研究多关注无障碍物轨迹、保持社交距离及预测人类运动以优化导航，但为真正被社会接受，机器人需具备传统导航无法产生的特定社会规范，因此需要专门的学习过程。

Method: 提出启发式规划与学习社会价值（HPLSV）方法，学习封装社会导航成本的价值函数，并将其作为启发式搜索路径规划中的附加启发式。

Result: 在初步工作中，将该方法应用于加入人群队列这一常见社会场景。

Conclusion: 旨在将该方法推广到更多人类活动。

Abstract: Social robotic navigation has been at the center of numerous studies in
recent years. Most of the research has focused on driving the robotic agent
along obstacle-free trajectories, respecting social distances from humans, and
predicting their movements to optimize navigation. However, in order to really
be socially accepted, the robots must be able to attain certain social norms
that cannot arise from conventional navigation, but require a dedicated
learning process. We propose Heuristic Planning with Learned Social Value
(HPLSV), a method to learn a value function encapsulating the cost of social
navigation, and use it as an additional heuristic in heuristic-search path
planning. In this preliminary work, we apply the methodology to the common
social scenario of joining a queue of people, with the intention of
generalizing to further human activities.

</details>


### [71] [Systematic Evaluation of Trade-Offs in Motion Planning Algorithms for Optimal Industrial Robotic Work Cell Design](https://arxiv.org/abs/2509.02146)
*G. de Mathelin,C. Hartl-Nesic,A. Kugi*

Main category: cs.RO

TL;DR: 本文针对工业机器人工作单元性能优化中的双层优化问题，提出评估运动规划权衡的指标，并通过仿真研究简化对高层优化结果的影响，最终应用于模块化机器人的时间最优运动学设计。


<details>
  <summary>Details</summary>
Motivation: 工业机器人工作单元性能取决于布局超参数优化，但低层运动优化计算不可行导致权衡，其对整体性能影响需系统评估。

Method: 提出评估运动规划权衡的最优性、时间增益、鲁棒性和一致性指标，通过广泛仿真研究运动级优化简化对高层优化结果的影响。

Result: 未明确提及具体仿真结果数据，主要是研究了简化对高层优化结果的影响，实现了在计算复杂度和解决方案质量间的平衡。

Conclusion: 所提算法可应用于两个码垛场景下模块化机器人的时间最优运动学设计，为工业机器人工作单元优化提供了评估和平衡运动规划权衡的方法。

Abstract: The performance of industrial robotic work cells depends on optimizing
various hyperparameters referring to the cell layout, such as robot base
placement, tool placement, and kinematic design. Achieving this requires a
bilevel optimization approach, where the high-level optimization adjusts these
hyperparameters, and the low-level optimization computes robot motions.
However, computing the optimal robot motion is computationally infeasible,
introducing trade-offs in motion planning to make the problem tractable. These
trade-offs significantly impact the overall performance of the bilevel
optimization, but their effects still need to be systematically evaluated. In
this paper, we introduce metrics to assess these trade-offs regarding
optimality, time gain, robustness, and consistency. Through extensive
simulation studies, we investigate how simplifications in motion-level
optimization affect the high-level optimization outcomes, balancing
computational complexity with solution quality. The proposed algorithms are
applied to find the time-optimal kinematic design for a modular robot in two
palletization scenarios.

</details>


### [72] [Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety](https://arxiv.org/abs/2509.02163)
*Wenxiao Zhang,Xiangrui Kong,Conan Dewitt,Thomas Bräunl,Jin B. Hong*

Main category: cs.RO

TL;DR: 提出了一个统一框架，通过提示组装、状态管理和安全验证，在基于LLM的机器人系统中缓解提示注入攻击并增强操作安全性，实验显示在注入攻击下有30.8%的改进，复杂环境对抗条件下最高有325%的提升，该框架已开源。


<details>
  <summary>Details</summary>
Motivation: LLM集成到机器人系统虽革新了具身AI，但确保可靠性（包括对抗攻击的安全性和复杂环境中的安全性）仍是关键挑战。

Method: 结合提示组装、状态管理和安全验证的统一框架，使用性能和安全指标进行评估。

Result: 实验显示在注入攻击下有30.8%的改进，复杂环境对抗条件下相比基线场景最高有325%的提升。

Conclusion: 该工作弥合了基于LLM的机器人系统中安全性与安全性之间的差距，为在现实环境中部署可靠的LLM集成移动机器人提供了可操作的见解，框架已开源并提供模拟和物理部署演示。

Abstract: Integrating large language models (LLMs) into robotic systems has
revolutionised embodied artificial intelligence, enabling advanced
decision-making and adaptability. However, ensuring reliability, encompassing
both security against adversarial attacks and safety in complex environments,
remains a critical challenge. To address this, we propose a unified framework
that mitigates prompt injection attacks while enforcing operational safety
through robust validation mechanisms. Our approach combines prompt assembling,
state management, and safety validation, evaluated using both performance and
security metrics. Experiments show a 30.8% improvement under injection attacks
and up to a 325% improvement in complex environment settings under adversarial
conditions compared to baseline scenarios. This work bridges the gap between
safety and security in LLM-based robotic systems, offering actionable insights
for deploying reliable LLM-integrated mobile robots in real-world settings. The
framework is open-sourced with simulation and physical deployment demos at
https://llmeyesim.vercel.app/

</details>


### [73] [Adaptive Navigation Strategy for Low-Thrust Proximity Operations in Circular Relative Orbit](https://arxiv.org/abs/2509.02204)
*Dario Ruggiero,Mauro Mancini,Elisa Capello*

Main category: cs.RO

TL;DR: 本文提出一种基于自适应观测器的航天器导航策略，适用于圆形相对轨道场景，通过调整观测器增益提升状态估计性能，经仿真验证其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决航天器近距离操作（如编队飞行、非合作目标检查）中的导航挑战，传统时不变增益观测器存在轨迹跟踪精度不足和控制输入切换频繁的问题。

Method: 提出基于自适应观测器的导航策略，根据估计状态调整观测器增益；采用李雅普诺夫分析确保稳定性和准确性；结合视觉传感器数据进行仿真验证。

Result: 与传统时不变增益观测器相比，该方法提高了轨迹跟踪精度，减少了控制输入切换，在真实条件下的仿真中验证了有效性。

Conclusion: 该自适应观测器导航策略是航天器自主定位与控制的有前景解决方案，能有效提升圆形相对轨道场景下的状态估计快速收敛性和低噪声敏感性。

Abstract: This paper presents an adaptive observer-based navigation strategy for
spacecraft in Circular Relative Orbit (CRO) scenarios, addressing challenges in
proximity operations like formation flight and uncooperative target inspection.
The proposed method adjusts observer gains based on the estimated state to
achieve fast convergence and low noise sensitivity in state estimation. A
Lyapunov-based analysis ensures stability and accuracy, while simulations using
vision-based sensor data validate the approach under realistic conditions.
Compared to classical observers with time-invariant gains, the proposed method
enhances trajectory tracking precision and reduces control input switching,
making it a promising solution for autonomous spacecraft localization and
control.

</details>


### [74] [Human-Inspired Soft Anthropomorphic Hand System for Neuromorphic Object and Pose Recognition Using Multimodal Signals](https://arxiv.org/abs/2509.02275)
*Fengyi Wang,Xiangyu Fu,Nitish Thakor,Gordon Cheng*

Main category: cs.RO

TL;DR: 本文提出一种配备多种传感器的软拟人手，采用生物启发的编码方案将多模态感知数据转换为脉冲序列，通过脉冲神经网络处理，在物体识别上达到97.14%的准确率，并引入新型微分神经元模型增强材料分类，展示了多模态融合和神经形态方法在机器人感知中的优势。


<details>
  <summary>Details</summary>
Motivation: 受人类躯体感觉系统整合触觉、本体感觉和热信号等多模态反馈以实现全面感知和环境交互的生物机制启发，旨在使机器人系统实现高效、鲁棒且类人的感知。

Method: 开发了配备多种传感器的软拟人手系统，采用生物启发的编码方案将多模态感知数据转换为脉冲序列，利用脉冲神经网络（SNNs）进行高效处理，并引入新型微分神经元模型以捕捉动态热响应来增强材料分类。

Result: 该框架在不同姿态下的物体识别准确率达到97.14%，显著优于之前关于软手的研究，同时新型微分神经元模型有效增强了材料分类能力。

Conclusion: 多模态感知融合具有优势，神经形态方法在机器人系统中实现高效、鲁棒且类人感知方面具有潜力。

Abstract: The human somatosensory system integrates multimodal sensory feedback,
including tactile, proprioceptive, and thermal signals, to enable comprehensive
perception and effective interaction with the environment. Inspired by the
biological mechanism, we present a sensorized soft anthropomorphic hand
equipped with diverse sensors designed to emulate the sensory modalities of the
human hand. This system incorporates biologically inspired encoding schemes
that convert multimodal sensory data into spike trains, enabling
highly-efficient processing through Spiking Neural Networks (SNNs). By
utilizing these neuromorphic signals, the proposed framework achieves 97.14%
accuracy in object recognition across varying poses, significantly
outperforming previous studies on soft hands. Additionally, we introduce a
novel differentiator neuron model to enhance material classification by
capturing dynamic thermal responses. Our results demonstrate the benefits of
multimodal sensory fusion and highlight the potential of neuromorphic
approaches for achieving efficient, robust, and human-like perception in
robotic systems.

</details>


### [75] [Sem-RaDiff: Diffusion-Based 3D Radar Semantic Perception in Cluttered Agricultural Environments](https://arxiv.org/abs/2509.02283)
*Ruibin Zhang,Fei Gao*

Main category: cs.RO

TL;DR: 本文提出一种基于雷达的3D环境感知框架，用于农业场景中机器人自主导航，解决光学传感器易受遮挡和污染的问题，通过三个核心模块提升性能并降低计算与内存成本。


<details>
  <summary>Details</summary>
Motivation: 当前机器人自主导航常用的光学传感器（如相机、LiDAR）易受视觉遮挡影响，在农业场景中还面临车载传感器污染风险，导致性能下降或系统失效，因此需要替代方案。

Method: 该框架包含三个核心模块：1）并行帧累积以增强雷达原始数据的信噪比；2）基于扩散模型的分层学习框架，先过滤雷达旁瓣伪影，再生成细粒度3D语义点云；3）专为处理大规模雷达原始数据优化的稀疏3D网络。

Result: 在自建的真实农业场景数据集上，该方法相比现有方法在结构和语义预测性能上更优，同时计算成本降低51.3%，内存成本降低27.5%，还能对杆、线等细结构实现完整重建和准确分类。

Conclusion: 所提出的基于雷达的3D环境感知框架是农业场景中机器人自主导航的可行替代方案，具有密集准确的3D雷达感知潜力，在性能和效率上均有优势。

Abstract: Accurate and robust environmental perception is crucial for robot autonomous
navigation. While current methods typically adopt optical sensors (e.g.,
camera, LiDAR) as primary sensing modalities, their susceptibility to visual
occlusion often leads to degraded performance or complete system failure. In
this paper, we focus on agricultural scenarios where robots are exposed to the
risk of onboard sensor contamination. Leveraging radar's strong penetration
capability, we introduce a radar-based 3D environmental perception framework as
a viable alternative. It comprises three core modules designed for dense and
accurate semantic perception: 1) Parallel frame accumulation to enhance
signal-to-noise ratio of radar raw data. 2) A diffusion model-based
hierarchical learning framework that first filters radar sidelobe artifacts
then generates fine-grained 3D semantic point clouds. 3) A specifically
designed sparse 3D network optimized for processing large-scale radar raw data.
We conducted extensive benchmark comparisons and experimental evaluations on a
self-built dataset collected in real-world agricultural field scenes. Results
demonstrate that our method achieves superior structural and semantic
prediction performance compared to existing methods, while simultaneously
reducing computational and memory costs by 51.3% and 27.5%, respectively.
Furthermore, our approach achieves complete reconstruction and accurate
classification of thin structures such as poles and wires-which existing
methods struggle to perceive-highlighting its potential for dense and accurate
3D radar perception.

</details>


### [76] [Language-Guided Long Horizon Manipulation with LLM-based Planning and Visual Perception](https://arxiv.org/abs/2509.02324)
*Changshi Zhou,Haichuan Xu,Ningquan Gu,Zhipeng Wang,Bin Cheng,Pengpeng Zhang,Yanchao Dong,Mitsuhiro Hayashibe,Yanmin Zhou,Bin He*

Main category: cs.RO

TL;DR: 本文提出一个统一框架，整合基于LLM的规划器、基于VLM的感知系统和任务执行模块，以解决语言引导的长程可变形物体（如布料）操作问题，在模拟和真实场景中均表现出有效性和强泛化性。


<details>
  <summary>Details</summary>
Motivation: 语言引导的长程可变形物体操作面临高自由度、复杂动力学及准确视觉-语言接地的挑战，多步布料折叠任务尤其需要结构化长程规划和细粒度视觉感知。

Method: 提出统一框架，包括：1.基于LLM的规划器，将高级语言指令分解为低级动作原语；2.基于VLM的感知模块，采用SigLIP2驱动架构，结合双向交叉注意力融合机制和DoRA微调，实现语言条件下的细粒度视觉接地；3.任务执行模块。

Result: 模拟中，在已见指令、未见指令和未见任务上分别优于最先进基线2.23、1.87和33.3；真实机器人上，能跨不同布料材料和配置稳健执行语言指令的多步折叠序列，展现强泛化性。

Conclusion: 该框架有效解决了语言引导的长程布料折叠问题，在模拟和真实场景中均实现了高精度和强泛化性，为可变形物体操作提供了新方法。

Abstract: Language-guided long-horizon manipulation of deformable objects presents
significant challenges due to high degrees of freedom, complex dynamics, and
the need for accurate vision-language grounding. In this work, we focus on
multi-step cloth folding, a representative deformable-object manipulation task
that requires both structured long-horizon planning and fine-grained visual
perception. To this end, we propose a unified framework that integrates a Large
Language Model (LLM)-based planner, a Vision-Language Model (VLM)-based
perception system, and a task execution module. Specifically, the LLM-based
planner decomposes high-level language instructions into low-level action
primitives, bridging the semantic-execution gap, aligning perception with
action, and enhancing generalization. The VLM-based perception module employs a
SigLIP2-driven architecture with a bidirectional cross-attention fusion
mechanism and weight-decomposed low-rank adaptation (DoRA) fine-tuning to
achieve language-conditioned fine-grained visual grounding. Experiments in both
simulation and real-world settings demonstrate the method's effectiveness. In
simulation, it outperforms state-of-the-art baselines by 2.23, 1.87, and 33.3
on seen instructions, unseen instructions, and unseen tasks, respectively. On a
real robot, it robustly executes multi-step folding sequences from language
instructions across diverse cloth materials and configurations, demonstrating
strong generalization in practical scenarios. Project page:
https://language-guided.netlify.app/

</details>


### [77] [Physics-Informed Machine Learning with Adaptive Grids for Optical Microrobot Depth Estimation](https://arxiv.org/abs/2509.02343)
*Lan Wei,Lou Genoud,Dandan Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于物理信息的数据高效框架，用于光学微机器人的深度估计，通过结合卷积特征提取和基于物理的聚焦度量，并使用自适应网格策略，在减少数据需求的同时提高了深度估计精度。


<details>
  <summary>Details</summary>
Motivation: 光学微机器人在生物医学应用中需要精确的三维感知，但微机器人的透明特性和低对比度显微成像给传统深度学习方法带来挑战，且传统方法需要大量标注数据，获取成本高。

Method: 通过基于物理的聚焦度量（如熵、高斯拉普拉斯和梯度锐度）增强卷积特征提取，并采用自适应网格策略，在微机器人区域分配更精细的网格，在背景区域分配更粗的网格，以提高深度敏感性并降低计算复杂度。

Result: 在多种微机器人类型上的评估显示，该框架比基线模型有显著改进，MSE降低60%以上，R²在所有测试案例中均有提高；即使仅使用20%的数据训练，模型性能仍优于使用完整数据集训练的ResNet50。

Conclusion: 所提出的物理信息、数据高效框架有效解决了光学微机器人深度估计中的透明性和低对比度问题，且在有限数据条件下表现出强鲁棒性，为生物医学应用中的精确控制提供了有力支持。

Abstract: Optical microrobots actuated by optical tweezers (OT) offer great potential
for biomedical applications such as cell manipulation and microscale assembly.
These tasks demand accurate three-dimensional perception to ensure precise
control in complex and dynamic biological environments. However, the
transparent nature of microrobots and low-contrast microscopic imaging
challenge conventional deep learning methods, which also require large
annotated datasets that are costly to obtain. To address these challenges, we
propose a physics-informed, data-efficient framework for depth estimation of
optical microrobots. Our method augments convolutional feature extraction with
physics-based focus metrics, such as entropy, Laplacian of Gaussian, and
gradient sharpness, calculated using an adaptive grid strategy. This approach
allocates finer grids over microrobot regions and coarser grids over background
areas, enhancing depth sensitivity while reducing computational complexity. We
evaluate our framework on multiple microrobot types and demonstrate significant
improvements over baseline models. Specifically, our approach reduces mean
squared error (MSE) by over 60% and improves the coefficient of determination
(R^2) across all test cases. Notably, even when trained on only 20% of the
available data, our model outperforms ResNet50 trained on the full dataset,
highlighting its robustness under limited data conditions. Our code is
available at: https://github.com/LannWei/CBS2025.

</details>


### [78] [OpenGuide: Assistive Object Retrieval in Indoor Spaces for Individuals with Visual Impairments](https://arxiv.org/abs/2509.02425)
*Yifan Xu,Qianwei Wang,Vineet Kamat,Carol Menassa*

Main category: cs.RO

TL;DR: 本文介绍了OpenGuide，一种结合自然语言理解、视觉语言基础模型、前沿探索和部分可观测马尔可夫决策过程规划器的辅助移动机器人系统，旨在解决视障人士在复杂室内环境中定位和收集多个物体的挑战，通过模拟和真实世界实验证明其在任务成功率和搜索效率上优于先前方法，为辅助生活环境中可扩展的以人为中心的机器人辅助奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有辅助技术多关注基本导航或避障，很少有系统在现实、部分可观测的环境中提供可扩展且高效的多物体搜索能力，而室内复杂杂乱布局对视障人士定位和收集多个物体构成重大挑战。

Method: OpenGuide结合自然语言理解、视觉语言基础模型（VLM）、前沿探索和部分可观测马尔可夫决策过程（POMDP）规划器，通过价值衰减和信念空间推理实现对未检测到物体的稳健恢复，以解释开放词汇请求、推理物体-场景关系并自适应导航和定位多个目标物品。

Result: 在模拟和真实世界实验中，OpenGuide的任务成功率和搜索效率相比先前方法有显著提升。

Conclusion: 这项工作为辅助生活环境中可扩展的、以人为中心的机器人辅助奠定了基础。

Abstract: Indoor built environments like homes and offices often present complex and
cluttered layouts that pose significant challenges for individuals who are
blind or visually impaired, especially when performing tasks that involve
locating and gathering multiple objects. While many existing assistive
technologies focus on basic navigation or obstacle avoidance, few systems
provide scalable and efficient multi-object search capabilities in real-world,
partially observable settings. To address this gap, we introduce OpenGuide, an
assistive mobile robot system that combines natural language understanding with
vision-language foundation models (VLM), frontier-based exploration, and a
Partially Observable Markov Decision Process (POMDP) planner. OpenGuide
interprets open-vocabulary requests, reasons about object-scene relationships,
and adaptively navigates and localizes multiple target items in novel
environments. Our approach enables robust recovery from missed detections
through value decay and belief-space reasoning, resulting in more effective
exploration and object localization. We validate OpenGuide in simulated and
real-world experiments, demonstrating substantial improvements in task success
rate and search efficiency over prior methods. This work establishes a
foundation for scalable, human-centered robotic assistance in assisted living
environments.

</details>


### [79] [U-ARM : Ultra low-cost general teleoperation interface for robot manipulation](https://arxiv.org/abs/2509.02437)
*Yanwen Zou,Zhaoye Zhou,Chenyang Shi,Zewei Ye,Junda Huang,Yan Ding,Bo Zhao*

Main category: cs.RO

TL;DR: 提出低成本、快速适配的主从遥操作框架U-Arm，兼容多数商用机械臂，通过优化设计使6自由度主臂BOM成本仅50.5美元，7自由度56.8美元，提升数据采集效率39%并开源相关资源。


<details>
  <summary>Details</summary>
Motivation: 解决现有开源主从接口成本高、适配性差及冗余自由度控制难等问题，提供低成本且易用的遥操作方案。

Method: 设计三款结构不同但控制逻辑一致的3D打印主臂，优化机械设计和伺服电机选择，通过机械与控制优化减轻冗余自由度控制难题。

Result: 6-DoF主臂BOM成本50.5美元，7-DoF版本56.8美元；相比Joycon，数据采集效率提高39%，多操作场景任务成功率相当；开源CAD模型、仿真支持及真实世界操作数据。

Conclusion: U-Arm实现了低成本、高适配性和易用性，为商用机械臂遥操作提供经济高效的解决方案，并通过开源促进相关研究与应用。

Abstract: We propose U-Arm, a low-cost and rapidly adaptable leader-follower
teleoperation framework designed to interface with most of commercially
available robotic arms. Our system supports teleoperation through three
structurally distinct 3D-printed leader arms that share consistent control
logic, enabling seamless compatibility with diverse commercial robot
configurations. Compared with previous open-source leader-follower interfaces,
we further optimized both the mechanical design and servo selection, achieving
a bill of materials (BOM) cost of only \$50.5 for the 6-DoF leader arm and
\$56.8 for the 7-DoF version. To enhance usability, we mitigate the common
challenge in controlling redundant degrees of freedom by %engineering methods
mechanical and control optimizations. Experimental results demonstrate that
U-Arm achieves 39\% higher data collection efficiency and comparable task
success rates across multiple manipulation scenarios compared with Joycon,
another low-cost teleoperation interface. We have open-sourced all CAD models
of three configs and also provided simulation support for validating
teleoperation workflows. We also open-sourced real-world manipulation data
collected with U-Arm. The project website is
https://github.com/MINT-SJTU/LeRobot-Anything-U-Arm.

</details>


### [80] [Coral: A Unifying Abstraction Layer for Composable Robotics Software](https://arxiv.org/abs/2509.02453)
*Steven Swanbeck,Mitch Pryor*

Main category: cs.RO

TL;DR: 本文提出Coral，一种抽象层，用于构建、部署和协调独立软件组件，通过提高组合性实现快速系统集成，无需修改底层代码，并通过LiDAR SLAM和多机器人腐蚀缓解任务展示其实用性，同时开源发布。


<details>
  <summary>Details</summary>
Motivation: 机器人软件集成耗时且具挑战性，现有系统常为紧耦合的单体结构，小改动需大量工程投入。

Method: 提出Coral抽象层，不替换现有工具，而是引入更高层次抽象，将集成过程限制在语义上有意义的选择，减少配置负担同时不限制对不同领域、系统和任务的适应性。

Result: 通过LiDAR-based SLAM和多机器人腐蚀缓解任务等复杂场景集成软件，展示了Coral的实用性，实现了机器人软件的实用组合性，提供了可扩展的解决方案。

Conclusion: Coral解决了广泛的机器人系统集成挑战，提高了组件可重用性、系统可重构性，对专家和非专家用户都更易访问，并开源发布。

Abstract: Despite the multitude of excellent software components and tools available in
the robotics and broader software engineering communities, successful
integration of software for robotic systems remains a time-consuming and
challenging task for users of all knowledge and skill levels. And with robotics
software often being built into tightly coupled, monolithic systems, even minor
alterations to improve performance, adjust to changing task requirements, or
deploy to new hardware can require significant engineering investment. To help
solve this problem, this paper presents Coral, an abstraction layer for
building, deploying, and coordinating independent software components that
maximizes composability to allow for rapid system integration without modifying
low-level code. Rather than replacing existing tools, Coral complements them by
introducing a higher-level abstraction that constrains the integration process
to semantically meaningful choices, reducing the configuration burden without
limiting adaptability to diverse domains, systems, and tasks. We describe Coral
in detail and demonstrate its utility in integrating software for scenarios of
increasing complexity, including LiDAR-based SLAM and multi-robot corrosion
mitigation tasks. By enabling practical composability in robotics software,
Coral offers a scalable solution to a broad range of robotics system
integration challenges, improving component reusability, system
reconfigurability, and accessibility to both expert and non-expert users. We
release Coral open source.

</details>


### [81] [Classification of Vision-Based Tactile Sensors: A Review](https://arxiv.org/abs/2509.02478)
*Haoran Li,Yijiong Lin,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F Lepora*

Main category: cs.RO

TL;DR: 本文提出了一种基于接触到触觉图像的潜在转导机制的视觉触觉传感器（VBTS）新分类，将其分为标记基转导和强度基转导两种主要原理，并进一步细分亚型，同时对四种传感器的硬件特性进行比较研究，探讨了触觉信息解释方法，揭示了当前挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: VBTS虽有共同设计特征，但在传感原理、材料组成、多模态方法和数据解释方法上存在丰富多样性，需要一种新的分类来梳理该技术。

Method: 提出基于接触到触觉图像转导机制的分类，分为标记基转导（含简单标记基SMB和形态标记基MMB亚型）和强度基转导（含反射层基RLB和透明层基TLB亚型），并对四种传感器硬件特性（包括各种组合类型）进行比较研究，讨论触觉信息解释常用方法。

Result: 比较研究揭示了VBTS技术当前面临的一些挑战以及未来研究方向。

Conclusion: 该分类有助于梳理VBTS技术，比较研究为理解其硬件特性、信息解释方法及明确发展方向提供了参考。

Abstract: Vision-based tactile sensors (VBTS) have gained widespread application in
robotic hands, grippers and prosthetics due to their high spatial resolution,
low manufacturing costs, and ease of customization. While VBTSs have common
design features, such as a camera module, they can differ in a rich diversity
of sensing principles, material compositions, multimodal approaches, and data
interpretation methods. Here, we propose a novel classification of VBTS that
categorizes the technology into two primary sensing principles based on the
underlying transduction of contact into a tactile image: the Marker-Based
Transduction Principle and the Intensity-Based Transduction Principle.
Marker-Based Transduction interprets tactile information by detecting marker
displacement and changes in marker density. In contrast, Intensity-Based
Transduction maps external disturbances with variations in pixel values.
Depending on the design of the contact module, Marker-Based Transduction can be
further divided into two subtypes: Simple Marker-Based (SMB) and Morphological
Marker-Based (MMB) mechanisms. Similarly, the Intensity-Based Transduction
Principle encompasses the Reflective Layer-based (RLB) and Transparent
Layer-Based (TLB) mechanisms. This paper provides a comparative study of the
hardware characteristics of these four types of sensors including various
combination types, and discusses the commonly used methods for interpreting
tactile information. This~comparison reveals some current challenges faced by
VBTS technology and directions for future research.

</details>


### [82] [Fault-tolerant Model Predictive Control for Spacecraft](https://arxiv.org/abs/2509.02527)
*Raphael Stöckner,Pedro Roque,Maria Charitidou,Dimos V. Dimarogonas*

Main category: cs.RO

TL;DR: This article presents a Model Predictive Control for spacecraft trajectory and setpoint stabilization under multiple actuation failures, ensuring closed-loop asymptotic stability and recursive feasibility, demonstrated via open-source numerical results and ATMOS platform experiments.


<details>
  <summary>Details</summary>
Motivation: Given the cost and critical functions of satellite constellations, ensuring mission longevity and safe decommissioning is essential for space sustainability.

Method: The proposed solution is a Model Predictive Control that allows efficient control of the faulty spacecraft enabling safe navigation towards servicing or collision-free trajectories.

Result: The proposed scheme ensures closed-loop asymptotic stability and is shown to be recursively feasible, with efficacy demonstrated through open-source numerical results and realistic experiments using the ATMOS platform.

Conclusion: The Model Predictive Control presented is effective for spacecraft trajectory and setpoint stabilization under multiple actuation failures, contributing to space sustainability by enabling safe navigation of faulty spacecraft.

Abstract: Given the cost and critical functions of satellite constellations, ensuring
mission longevity and safe decommissioning is essential for space
sustainability. This article presents a Model Predictive Control for spacecraft
trajectory and setpoint stabilization under multiple actuation failures. The
proposed solution allows us to efficiently control the faulty spacecraft
enabling safe navigation towards servicing or collision-free trajectories. The
proposed scheme ensures closed-loop asymptotic stability and is shown to be
recursively feasible. We demonstrate its efficacy through open-source numerical
results and realistic experiments using the ATMOS platform.

</details>


### [83] [Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots](https://arxiv.org/abs/2509.02530)
*Minghuan Liu,Zhengbang Zhu,Xiaoshen Han,Peng Hu,Haotong Lin,Xinyao Li,Jingxiao Chen,Jiafeng Xu,Yichu Yang,Yunfeng Lin,Xinghang Li,Yong Yu,Weinan Zhang,Tao Kong,Bingyi Kang*

Main category: cs.RO

TL;DR: 本文提出相机深度模型（CDMs）作为日常深度相机的插件，通过神经网络数据引擎生成高质量模拟配对数据，实现深度去噪和精确化，首次使基于原始模拟深度训练的策略无需添加噪声或现实微调即可无缝迁移到真实机器人，在涉及复杂物体的长程任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 现代机器人操作主要依赖2D彩色视觉进行技能学习，但泛化能力差；人类在3D世界中交互时更依赖物理属性（距离、大小、形状等），而深度相机可获取3D几何信息，但现有深度相机存在精度有限和易受噪声影响的问题。

Method: 提出相机深度模型（CDMs），以RGB图像和原始深度信号为输入，输出去噪、精确的度量深度；开发神经网络数据引擎，通过建模深度相机的噪声模式从模拟中生成高质量配对数据。

Result: CDMs在深度预测中达到接近模拟级的精度，有效弥合了操作任务的模拟到现实差距；首次证明基于原始模拟深度训练的策略无需添加噪声或现实微调，可无缝迁移到真实机器人，在涉及铰接、反光和细长物体的两个具有挑战性的长程任务中几乎无性能下降。

Conclusion: 研究结果有望启发未来在利用模拟数据和3D信息构建通用机器人策略方面的研究。

Abstract: Modern robotic manipulation primarily relies on visual observations in a 2D
color space for skill learning but suffers from poor generalization. In
contrast, humans, living in a 3D world, depend more on physical properties-such
as distance, size, and shape-than on texture when interacting with objects.
Since such 3D geometric information can be acquired from widely available depth
cameras, it appears feasible to endow robots with similar perceptual
capabilities. Our pilot study found that using depth cameras for manipulation
is challenging, primarily due to their limited accuracy and susceptibility to
various types of noise. In this work, we propose Camera Depth Models (CDMs) as
a simple plugin on daily-use depth cameras, which take RGB images and raw depth
signals as input and output denoised, accurate metric depth. To achieve this,
we develop a neural data engine that generates high-quality paired data from
simulation by modeling a depth camera's noise pattern. Our results show that
CDMs achieve nearly simulation-level accuracy in depth prediction, effectively
bridging the sim-to-real gap for manipulation tasks. Notably, our experiments
demonstrate, for the first time, that a policy trained on raw simulated depth,
without the need for adding noise or real-world fine-tuning, generalizes
seamlessly to real-world robots on two challenging long-horizon tasks involving
articulated, reflective, and slender objects, with little to no performance
degradation. We hope our findings will inspire future research in utilizing
simulation data and 3D information in general robot policies.

</details>
