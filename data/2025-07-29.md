<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 42]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Extending Group Relative Policy Optimization to Continuous Control: A Theoretical Framework for Robotic Reinforcement Learning](https://arxiv.org/abs/2507.19555)
*Rajat Khanda,Mohammad Baqar,Sambuddha Chakrabarti,Satyasaran Changdar*

Main category: cs.RO

TL;DR: GRPO扩展到连续控制的理论框架，解决高维动作空间、稀疏奖励和时序动态问题。


<details>
  <summary>Details</summary>
Motivation: GRPO在离散动作空间中表现良好，但在连续控制（如机器人领域）中尚未探索。

Method: 引入基于轨迹的策略聚类、状态感知优势估计和正则化策略更新。

Result: 提供了收敛性和计算复杂度的理论分析。

Conclusion: 为未来在机器人系统中的实证验证奠定了基础。

Abstract: Group Relative Policy Optimization (GRPO) has shown promise in discrete
action spaces by eliminating value function dependencies through group-based
advantage estimation. However, its application to continuous control remains
unexplored, limiting its utility in robotics where continuous actions are
essential. This paper presents a theoretical framework extending GRPO to
continuous control environments, addressing challenges in high-dimensional
action spaces, sparse rewards, and temporal dynamics. Our approach introduces
trajectory-based policy clustering, state-aware advantage estimation, and
regularized policy updates designed for robotic applications. We provide
theoretical analysis of convergence properties and computational complexity,
establishing a foundation for future empirical validation in robotic systems
including locomotion and manipulation tasks.

</details>


### [2] [Reward-Augmented Reinforcement Learning for Continuous Control in Precision Autonomous Parking via Policy Optimization Methods](https://arxiv.org/abs/2507.19642)
*Ahmad Suleman,Misha Urooj Khan,Zeeshan Kaleem,Ali H. Alenezi,Iqra Shabbir Sinem Coleri,Chau Yuen*

Main category: cs.RO

TL;DR: 论文提出了一种奖励增强学习框架（RARLAP），用于解决自主停车（AP）中的复杂性问题，通过结构化奖励设计提升策略的适应性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自主停车面临空间限制、近距离障碍物交互和安全要求等挑战，传统方法缺乏适应性和泛化能力。

Method: 采用奖励增强学习框架，设计了三种结构化奖励策略（GOR、DPR、MAR），并在Unity仿真环境中训练。

Result: 实验表明，MAR策略成功率达91%，轨迹更平滑且行为更鲁棒，而GOR和DPR效果不佳。

Conclusion: RARLAP通过奖励增强有效解决了自主停车的复杂性问题，支持可扩展和高效的政策优化。

Abstract: Autonomous parking (AP) represents a critical yet complex subset of
intelligent vehicle automation, characterized by tight spatial constraints,
frequent close-range obstacle interactions, and stringent safety margins.
However, conventional rule-based and model-predictive methods often lack the
adaptability and generalization needed to handle the nonlinear and
environment-dependent complexities of AP. To address these limitations, we
propose a reward-augmented learning framework for AP (RARLAP), that mitigates
the inherent complexities of continuous-domain control by leveraging structured
reward design to induce smooth and adaptable policy behavior, trained entirely
within a high-fidelity Unity-based custom 3D simulation environment. We
systematically design and assess three structured reward strategies: goal-only
reward (GOR), dense proximity reward (DPR), and milestone-augmented reward
(MAR), each integrated with both on-policy and off-policy optimization
paradigms. Empirical evaluations demonstrate that the on-policy MAR achieves a
91\% success rate, yielding smoother trajectories and more robust behavior,
while GOR and DPR fail to guide effective learning. Convergence and trajectory
analyses demonstrate that the proposed framework enhances policy adaptability,
accelerates training, and improves safety in continuous control. Overall,
RARLAP establishes that reward augmentation effectively addresses complex
autonomous parking challenges, enabling scalable and efficient policy
optimization with both on- and off-policy methods. To support reproducibility,
the code accompanying this paper is publicly available.

</details>


### [3] [GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning](https://arxiv.org/abs/2507.19647)
*Amin Banayeeanzade,Fatemeh Bahrani,Yutai Zhou,Erdem Bıyık*

Main category: cs.RO

TL;DR: GABRIL利用人类注视数据改进模仿学习，减少因果混淆，提升性能。


<details>
  <summary>Details</summary>
Motivation: 模仿学习常因因果混淆导致性能下降，需解决此问题。

Method: 引入基于注视的GABRIL方法，通过正则化损失引导模型关注因果相关特征。

Result: 在Atari和CARLA中，GABRIL性能显著优于基线方法。

Conclusion: GABRIL不仅提升性能，还增强了模型的可解释性。

Abstract: Imitation Learning (IL) is a widely adopted approach which enables agents to
learn from human expert demonstrations by framing the task as a supervised
learning problem. However, IL often suffers from causal confusion, where agents
misinterpret spurious correlations as causal relationships, leading to poor
performance in testing environments with distribution shift. To address this
issue, we introduce GAze-Based Regularization in Imitation Learning (GABRIL), a
novel method that leverages the human gaze data gathered during the data
collection phase to guide the representation learning in IL. GABRIL utilizes a
regularization loss which encourages the model to focus on causally relevant
features identified through expert gaze and consequently mitigates the effects
of confounding variables. We validate our approach in Atari environments and
the Bench2Drive benchmark in CARLA by collecting human gaze datasets and
applying our method in both domains. Experimental results show that the
improvement of GABRIL over behavior cloning is around 179% more than the same
number for other baselines in the Atari and 76% in the CARLA setup. Finally, we
show that our method provides extra explainability when compared to regular IL
agents.

</details>


### [4] [RAKOMO: Reachability-Aware K-Order Markov Path Optimization for Quadrupedal Loco-Manipulation](https://arxiv.org/abs/2507.19652)
*Mattia Risiglione,Abdelrahman Abdalla,Victor Barasuol,Kim Tien Ly,Ioannis Havoutis,Claudio Semini*

Main category: cs.RO

TL;DR: RAKOMO是一种结合K-Order Markov Optimization（KOMO）和基于可达性边界的运动规划技术，用于解决腿式机械臂的运动规划问题。


<details>
  <summary>Details</summary>
Motivation: 腿式机械臂（如四足机器人配备机械臂）的运动规划需要考虑复杂的运动学约束，传统方法因接触不连续性和忽略腿部限制而面临挑战。

Method: 提出RAKOMO，结合KOMO和基于神经网络预测的可达性边界优化，快速收敛梯度运动规划。

Result: 在HyQReal四足机器人配备Kinova Gen3机械臂的拾取任务中，RAKOMO优于基线KOMO方法。

Conclusion: RAKOMO成功适应腿式机械臂的运动规划，高效完成移动操作任务。

Abstract: Legged manipulators, such as quadrupeds equipped with robotic arms, require
motion planning techniques that account for their complex kinematic constraints
in order to perform manipulation tasks both safely and effectively. However,
trajectory optimization methods often face challenges due to the hybrid
dynamics introduced by contact discontinuities, and tend to neglect leg
limitations during planning for computational reasons. In this work, we propose
RAKOMO, a path optimization technique that integrates the strengths of K-Order
Markov Optimization (KOMO) with a kinematically-aware criterion based on the
reachable region defined as reachability margin. We leverage a neural-network
to predict the margin and optimize it by incorporating it in the standard KOMO
formulation. This approach enables rapid convergence of gradient-based motion
planning -- commonly tailored for continuous systems -- while adapting it
effectively to legged manipulators, successfully executing loco-manipulation
tasks. We benchmark RAKOMO against a baseline KOMO approach through a set of
simulations for pick-and-place tasks with the HyQReal quadruped robot equipped
with a Kinova Gen3 robotic arm.

</details>


### [5] [PhysVarMix: Physics-Informed Variational Mixture Model for Multi-Modal Trajectory Prediction](https://arxiv.org/abs/2507.19701)
*Haichuan Li,Tomi Westerlund*

Main category: cs.RO

TL;DR: 提出了一种结合学习与物理约束的混合方法，用于多模态轨迹预测，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决复杂城市环境中多模态轨迹预测的挑战，确保预测的物理合理性和多样性。

Method: 使用变分贝叶斯混合模型捕捉多模态行为，结合物理约束和MPC平滑。

Result: 在基准数据集上表现优于现有方法，验证了各组件对预测准确性的贡献。

Conclusion: 该方法通过平衡数据驱动与物理约束，为城市环境中的不确定性提供了鲁棒解决方案。

Abstract: Accurate prediction of future agent trajectories is a critical challenge for
ensuring safe and efficient autonomous navigation, particularly in complex
urban environments characterized by multiple plausible future scenarios. In
this paper, we present a novel hybrid approach that integrates learning-based
with physics-based constraints to address the multi-modality inherent in
trajectory prediction. Our method employs a variational Bayesian mixture model
to effectively capture the diverse range of potential future behaviors, moving
beyond traditional unimodal assumptions. Unlike prior approaches that
predominantly treat trajectory prediction as a data-driven regression task, our
framework incorporates physical realism through sector-specific boundary
conditions and Model Predictive Control (MPC)-based smoothing. These
constraints ensure that predicted trajectories are not only data-consistent but
also physically plausible, adhering to kinematic and dynamic principles.
Furthermore, our method produces interpretable and diverse trajectory
predictions, enabling enhanced downstream decision-making and planning in
autonomous driving systems. We evaluate our approach on two benchmark datasets,
demonstrating superior performance compared to existing methods. Comprehensive
ablation studies validate the contributions of each component and highlight
their synergistic impact on prediction accuracy and reliability. By balancing
data-driven insights with physics-informed constraints, our approach offers a
robust and scalable solution for navigating the uncertainties of real-world
urban environments.

</details>


### [6] [DOA: A Degeneracy Optimization Agent with Adaptive Pose Compensation Capability based on Deep Reinforcement Learning](https://arxiv.org/abs/2507.19742)
*Yanbin Li,Canran Xiao,Hongyang He,Shenghai Yuan,Zong Ke,Jiajie Yu,Zixiong Qin,Zhiguo Zhang,Wenzheng Chi,Wei Zhang*

Main category: cs.RO

TL;DR: 使用PPO训练自适应退化优化代理（DOA）解决SLAM在长直走廊等环境中的退化问题，提出系统性方法应对数据获取瓶颈、样本质量下降和标注协议模糊性。


<details>
  <summary>Details</summary>
Motivation: 室内环境（如长直走廊）会导致SLAM严重退化问题，传统监督学习方法面临数据获取、样本质量和标注设计的挑战。

Method: 设计专用奖励函数引导代理感知退化环境，动态调整传感器贡献，结合转移学习模块提升泛化能力。

Result: 通过消融实验验证模型设计合理性，DOA在多种环境中表现出优于SOTA方法的退化检测和优化能力。

Conclusion: DOA能有效解决SLAM退化问题，具有跨环境泛化能力，为类似问题提供新思路。

Abstract: Particle filter-based 2D-SLAM is widely used in indoor localization tasks due
to its efficiency. However, indoor environments such as long straight corridors
can cause severe degeneracy problems in SLAM. In this paper, we use Proximal
Policy Optimization (PPO) to train an adaptive degeneracy optimization agent
(DOA) to address degeneracy problem. We propose a systematic methodology to
address three critical challenges in traditional supervised learning
frameworks: (1) data acquisition bottlenecks in degenerate dataset, (2)
inherent quality deterioration of training samples, and (3) ambiguity in
annotation protocol design. We design a specialized reward function to guide
the agent in developing perception capabilities for degenerate environments.
Using the output degeneracy factor as a reference weight, the agent can
dynamically adjust the contribution of different sensors to pose optimization.
Specifically, the observation distribution is shifted towards the motion model
distribution, with the step size determined by a linear interpolation formula
related to the degeneracy factor. In addition, we employ a transfer learning
module to endow the agent with generalization capabilities across different
environments and address the inefficiency of training in degenerate
environments. Finally, we conduct ablation studies to demonstrate the
rationality of our model design and the role of transfer learning. We also
compare the proposed DOA with SOTA methods to prove its superior degeneracy
detection and optimization capabilities across various environments.

</details>


### [7] [Skin-Machine Interface with Multimodal Contact Motion Classifier](https://arxiv.org/abs/2507.19760)
*Alberto Confente,Takanori Jin,Taisuke Kobayashi,Julio Rogelio Guadarrama-Olvera,Gordon Cheng*

Main category: cs.RO

TL;DR: 提出了一种利用皮肤传感器作为复杂机器人操作界面的新框架，通过多模态触觉信息分类实现机器人动作控制。


<details>
  <summary>Details</summary>
Motivation: 探索皮肤传感器作为新型操作界面的潜力，以提升机器人控制的多样性和直观性。

Method: 采用基于循环神经网络的学习分类器，结合多模态传感和柔性支撑设计。

Result: 分类器准确率超过95%，成功应用于双臂移动机械臂的多任务执行。

Conclusion: 多模态传感和柔性支撑设计是提升分类器性能的关键，皮肤-机器接口具有广泛应用前景。

Abstract: This paper proposes a novel framework for utilizing skin sensors as a new
operation interface of complex robots. The skin sensors employed in this study
possess the capability to quantify multimodal tactile information at multiple
contact points. The time-series data generated from these sensors is
anticipated to facilitate the classification of diverse contact motions
exhibited by an operator. By mapping the classification results with robot
motion primitives, a diverse range of robot motions can be generated by
altering the manner in which the skin sensors are interacted with. In this
paper, we focus on a learning-based contact motion classifier employing
recurrent neural networks. This classifier is a pivotal factor in the success
of this framework. Furthermore, we elucidate the requisite conditions for
software-hardware designs. Firstly, multimodal sensing and its comprehensive
encoding significantly contribute to the enhancement of classification accuracy
and learning stability. Utilizing all modalities simultaneously as inputs to
the classifier proves to be an effective approach. Secondly, it is essential to
mount the skin sensors on a flexible and compliant support to enable the
activation of three-axis accelerometers. These accelerometers are capable of
measuring horizontal tactile information, thereby enhancing the correlation
with other modalities. Furthermore, they serve to absorb the noises generated
by the robot's movements during deployment. Through these discoveries, the
accuracy of the developed classifier surpassed 95 %, enabling the dual-arm
mobile manipulator to execute a diverse range of tasks via the Skin-Machine
Interface. https://youtu.be/UjUXT4Z4BC8

</details>


### [8] [Ag2x2: Robust Agent-Agnostic Visual Representations for Zero-Shot Bimanual Manipulation](https://arxiv.org/abs/2507.19817)
*Ziyin Xiong,Yinghan Chen,Puhao Li,Yixin Zhu,Tengyu Liu,Siyuan Huang*

Main category: cs.RO

TL;DR: Ag2x2是一个通过协调感知视觉表示实现双手机器人操作的框架，在13种任务中达到73.5%的成功率，优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 双手机器人操作因其协调控制的复杂性而具有挑战性，现有方法忽略了关键的特定代理信息。

Method: Ag2x2通过联合编码物体状态和手部运动模式的视觉表示，保持代理无关性。

Result: 在Bi-DexHands和PerAct2的13种任务中，Ag2x2表现优异，甚至超过专家设计的奖励策略。

Conclusion: Ag2x2为无需专家监督的复杂双手机器人技能学习提供了可扩展的解决方案。

Abstract: Bimanual manipulation, fundamental to human daily activities, remains a
challenging task due to its inherent complexity of coordinated control. Recent
advances have enabled zero-shot learning of single-arm manipulation skills
through agent-agnostic visual representations derived from human videos;
however, these methods overlook crucial agent-specific information necessary
for bimanual coordination, such as end-effector positions. We propose Ag2x2, a
computational framework for bimanual manipulation through coordination-aware
visual representations that jointly encode object states and hand motion
patterns while maintaining agent-agnosticism. Extensive experiments demonstrate
that Ag2x2 achieves a 73.5% success rate across 13 diverse bimanual tasks from
Bi-DexHands and PerAct2, including challenging scenarios with deformable
objects like ropes. This performance outperforms baseline methods and even
surpasses the success rate of policies trained with expert-engineered rewards.
Furthermore, we show that representations learned through Ag2x2 can be
effectively leveraged for imitation learning, establishing a scalable pipeline
for skill acquisition without expert supervision. By maintaining robust
performance across diverse tasks without human demonstrations or engineered
rewards, Ag2x2 represents a step toward scalable learning of complex bimanual
robotic skills.

</details>


### [9] [A 4D Radar Camera Extrinsic Calibration Tool Based on 3D Uncertainty Perspective N Points](https://arxiv.org/abs/2507.19829)
*Chuan Cao,Xiaoning Wang,Wenqian Xi,Han Zhang,Weidong Chen,Jingchuan Wang*

Main category: cs.RO

TL;DR: 提出了一种针对4D成像雷达与相机系统的外参标定框架，通过3DUPnP算法显式建模雷达测量中的球坐标噪声传播，显著提升了标定精度。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达与相机系统的精确外参标定对机器人多模态感知至关重要，但受限于传感器噪声和复杂误差传播，现有方法效果不佳。

Method: 采用空间3D不确定性感知PnP算法（3DUPnP），显式建模雷达球坐标噪声传播，并在坐标变换中补偿非零误差期望。

Result: 实验验证表明，3DUPnP在仿真和物理实验中均优于现有CPnP基线，标定一致性和精度显著提升。

Conclusion: 该研究为配备毫米波雷达和相机的机器人系统提供了一种鲁棒的标定解决方案，适用于自动驾驶和机器人感知应用。

Abstract: 4D imaging radar is a type of low-cost millimeter-wave radar(costing merely
10-20$\%$ of lidar systems) capable of providing range, azimuth, elevation, and
Doppler velocity information. Accurate extrinsic calibration between
millimeter-wave radar and camera systems is critical for robust multimodal
perception in robotics, yet remains challenging due to inherent sensor noise
characteristics and complex error propagation. This paper presents a systematic
calibration framework to address critical challenges through a spatial 3d
uncertainty-aware PnP algorithm (3DUPnP) that explicitly models spherical
coordinate noise propagation in radar measurements, then compensating for
non-zero error expectations during coordinate transformations. Finally,
experimental validation demonstrates significant performance improvements over
state-of-the-art CPnP baseline, including improved consistency in simulations
and enhanced precision in physical experiments. This study provides a robust
calibration solution for robotic systems equipped with millimeter-wave radar
and cameras, tailored specifically for autonomous driving and robotic
perception applications.

</details>


### [10] [Feeling the Force: A Nuanced Physics-based Traversability Sensor for Navigation in Unstructured Vegetation](https://arxiv.org/abs/2507.19831)
*Zaar Khizar,Johann Laconte,Roland Lenain,Romuald Aufrere*

Main category: cs.RO

TL;DR: 论文提出了一种新型传感器，用于直接测量植被对机器人施加的力，以评估其安全性和可穿越性。


<details>
  <summary>Details</summary>
Motivation: 机器人在非结构化自然环境中工作时，植被作为可穿越障碍物具有独特的机械特性，需要更细致的方法来评估其安全性。

Method: 设计了一种新型传感器，直接捕捉植被对机器人的反作用力，并通过实验验证其有效性。

Result: 传感器能够测量细微的力变化，为导航决策提供量化指标。

Conclusion: 这种基于力的方法为未来学习算法的开发奠定了基础。

Abstract: In many applications, robots are increasingly deployed in unstructured and
natural environments where they encounter various types of vegetation.
Vegetation presents unique challenges as a traversable obstacle, where the
mechanical properties of the plants can influence whether a robot can safely
collide with and overcome the obstacle. A more nuanced approach is required to
assess the safety and traversability of these obstacles, as collisions can
sometimes be safe and necessary for navigating through dense or unavoidable
vegetation. This paper introduces a novel sensor designed to directly measure
the applied forces exerted by vegetation on a robot: by directly capturing the
push-back forces, our sensor provides a detailed understanding of the
interactions between the robot and its surroundings. We demonstrate the
sensor's effectiveness through experimental validations, showcasing its ability
to measure subtle force variations. This force-based approach provides a
quantifiable metric that can inform navigation decisions and serve as a
foundation for developing future learning algorithms.

</details>


### [11] [PlaneHEC: Efficient Hand-Eye Calibration for Multi-view Robotic Arm via Any Point Cloud Plane Detection](https://arxiv.org/abs/2507.19851)
*Ye Wang,Haodong Jing,Yang Liao,Yongqiang Ma,Nanning Zheng*

Main category: cs.RO

TL;DR: PlaneHEC是一种无需复杂模型、仅需深度相机即可完成的手眼标定方法，利用任意平面表面实现最优且快速的标定。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖精确几何模型或人工辅助，泛化性差且复杂低效。

Method: 引入基于平面约束的手眼标定方程，结合闭式解和迭代优化提高精度。

Result: 在仿真和真实环境中验证，优于其他点云标定方法。

Conclusion: PlaneHEC为多智能体系统和具身智能发展提供了通用且快速的标定方案。

Abstract: Hand-eye calibration is an important task in vision-guided robotic systems
and is crucial for determining the transformation matrix between the camera
coordinate system and the robot end-effector. Existing methods, for multi-view
robotic systems, usually rely on accurate geometric models or manual
assistance, generalize poorly, and can be very complicated and inefficient.
Therefore, in this study, we propose PlaneHEC, a generalized hand-eye
calibration method that does not require complex models and can be accomplished
using only depth cameras, which achieves the optimal and fastest calibration
results using arbitrary planar surfaces like walls and tables. PlaneHEC
introduces hand-eye calibration equations based on planar constraints, which
makes it strongly interpretable and generalizable. PlaneHEC also uses a
comprehensive solution that starts with a closed-form solution and improves it
withiterative optimization, which greatly improves accuracy. We comprehensively
evaluated the performance of PlaneHEC in both simulated and real-world
environments and compared the results with other point-cloud-based calibration
methods, proving its superiority. Our approach achieves universal and fast
calibration with an innovative design of computational models, providing a
strong contribution to the development of multi-agent systems and embodied
intelligence.

</details>


### [12] [Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models](https://arxiv.org/abs/2507.19854)
*Anjali R. Menon,Rohit K. Sharma,Priya Singh,Chengyu Wang,Aurora M. Ferreira,Mateja Novak*

Main category: cs.RO

TL;DR: 论文提出了一种名为“思考、行动、学习”（T-A-L）的闭环框架，解决了LLMs在机器人任务规划中的脆弱性问题，通过持续交互实现自主学习和策略优化。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在机器人任务规划中多为开环系统，无法适应动态环境中的突发情况，限制了其实际应用。

Method: T-A-L框架通过“思考”（任务分解）、“行动”（执行与反馈收集）、“学习”（自我反思与策略修正）形成闭环，利用经验记忆优化未来规划。

Result: 实验表明，T-A-L框架在复杂任务中成功率超过97%，平均仅需9次试验即可收敛，且能泛化到未见任务。

Conclusion: T-A-L框架显著提升了机器人的鲁棒性和适应性，为实现真正自主的机器人代理迈出重要一步。

Abstract: The integration of Large Language Models (LLMs) into robotics has unlocked
unprecedented capabilities in high-level task planning. However, most current
systems operate in an open-loop fashion, where LLMs act as one-shot planners,
rendering them brittle and unable to adapt to unforeseen circumstances in
dynamic physical environments. To overcome this limitation, this paper
introduces the "Think, Act, Learn" (T-A-L) framework, a novel architecture that
enables an embodied agent to autonomously learn and refine its policies through
continuous interaction. Our framework establishes a closed-loop cycle where an
LLM first "thinks" by decomposing high-level commands into actionable plans.
The robot then "acts" by executing these plans while gathering rich, multimodal
sensory feedback. Critically, the "learn" module processes this feedback to
facilitate LLM-driven self-reflection, allowing the agent to perform causal
analysis on its failures and generate corrective strategies. These insights are
stored in an experiential memory to guide future planning cycles. We
demonstrate through extensive experiments in both simulation and the real world
that our T-A-L agent significantly outperforms baseline methods, including
open-loop LLMs, Behavioral Cloning, and traditional Reinforcement Learning. Our
framework achieves over a 97% success rate on complex, long-horizon tasks,
converges to a stable policy in an average of just 9 trials, and exhibits
remarkable generalization to unseen tasks. This work presents a significant
step towards developing more robust, adaptive, and truly autonomous robotic
agents.

</details>


### [13] [Homotopy-aware Multi-agent Navigation via Distributed Model Predictive Control](https://arxiv.org/abs/2507.19860)
*Haoze Dong,Meng Guo,Chengyi He,Zhongkui Li*

Main category: cs.RO

TL;DR: 提出了一种分布式轨迹规划框架，通过全局路径和局部轨迹协作解决多智能体在密集环境中的死锁问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体轨迹规划在密集障碍环境中容易发生死锁，尤其是在狭窄走廊中。

Method: 结合全局层面的同伦感知最优路径规划和局部层面的模型预测控制轨迹优化，并采用在线重规划策略。

Result: 实验表明，该方法显著减少了死锁，成功率从4%-13%提升至90%以上。

Conclusion: 通过全局路径的时间感知同伦特性和局部优化，有效解决了多智能体轨迹规划中的死锁问题。

Abstract: Multi-agent trajectory planning requires ensuring both safety and efficiency,
yet deadlocks remain a significant challenge, especially in obstacle-dense
environments. Such deadlocks frequently occur when multiple agents attempt to
traverse the same long and narrow corridor simultaneously. To address this, we
propose a novel distributed trajectory planning framework that bridges the gap
between global path and local trajectory cooperation. At the global level, a
homotopy-aware optimal path planning algorithm is proposed, which fully
leverages the topological structure of the environment. A reference path is
chosen from distinct homotopy classes by considering both its spatial and
temporal properties, leading to improved coordination among agents globally. At
the local level, a model predictive control-based trajectory optimization
method is used to generate dynamically feasible and collision-free
trajectories. Additionally, an online replanning strategy ensures its
adaptability to dynamic environments. Simulations and experiments validate the
effectiveness of our approach in mitigating deadlocks. Ablation studies
demonstrate that by incorporating time-aware homotopic properties into the
underlying global paths, our method can significantly reduce deadlocks and
improve the average success rate from 4%-13% to over 90% in randomly generated
dense scenarios.

</details>


### [14] [Bridging Simulation and Usability: A User-Friendly Framework for Scenario Generation in CARLA](https://arxiv.org/abs/2507.19883)
*Ahmed Abouelazm,Mohammad Mahmoud,Conrad Walter,Oleksandr Shchetsura,Erne Hussong,Helen Gremmelmaier,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 提出了一种无需编程的交互式场景生成框架，用于自动驾驶系统的仿真验证。


<details>
  <summary>Details</summary>
Motivation: 现实世界测试自动驾驶系统成本高、耗时长且不安全，而现有仿真工具需要编程知识，限制了非技术用户的使用。

Method: 开发了一个图形化界面框架，支持手动和自动生成场景，采用基于图的场景表示方法。

Result: 框架降低了使用门槛，支持多样化场景生成，提高了仿真验证的效率和可访问性。

Conclusion: 该框架为研究人员、工程师和政策制定者提供了更高效的测试工具，推动了自动驾驶验证的普及。

Abstract: Autonomous driving promises safer roads, reduced congestion, and improved
mobility, yet validating these systems across diverse conditions remains a
major challenge. Real-world testing is expensive, time-consuming, and sometimes
unsafe, making large-scale validation impractical. In contrast, simulation
environments offer a scalable and cost-effective alternative for rigorous
verification and validation. A critical component of the validation process is
scenario generation, which involves designing and configuring traffic scenarios
to evaluate autonomous systems' responses to various events and uncertainties.
However, existing scenario generation tools often require programming
knowledge, limiting accessibility for non-technical users. To address this
limitation, we present an interactive, no-code framework for scenario
generation. Our framework features a graphical interface that enables users to
create, modify, save, load, and execute scenarios without needing coding
expertise or detailed simulation knowledge. Unlike script-based tools such as
Scenic or ScenarioRunner, our approach lowers the barrier to entry and supports
a broader user base. Central to our framework is a graph-based scenario
representation that facilitates structured management, supports both manual and
automated generation, and enables integration with deep learning-based scenario
and behavior generation methods. In automated mode, the framework can randomly
sample parameters such as actor types, behaviors, and environmental conditions,
allowing the generation of diverse and realistic test datasets. By simplifying
the scenario generation process, this framework supports more efficient testing
workflows and increases the accessibility of simulation-based validation for
researchers, engineers, and policymakers.

</details>


### [15] [High-Speed Event Vision-Based Tactile Roller Sensor for Large Surface Measurements](https://arxiv.org/abs/2507.19914)
*Akram Khairi,Hussain Sajwani,Abdallah Mohammad Alkilany,Laith AbuAssi,Mohamad Halwani,Islam Mohamed Zaid,Ahmed Awadalla,Dewald Swart,Abdulla Ayyad,Yahya Zweiri*

Main category: cs.RO

TL;DR: 提出了一种新型触觉传感器，结合神经形态相机和滚动机制，实现快速、连续、高分辨率的3D表面扫描。


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器在大面积扫描时速度慢且易受运动模糊影响，需要一种更高效的解决方案。

Method: 使用神经形态相机和滚动机制，结合改进的事件多视图立体方法进行3D重建，并采用多参考贝叶斯融合策略提高精度。

Result: 扫描速度达0.5 m/s，平均绝对误差低于100微米，比现有方法快11倍；特征识别速度提升2.6倍。

Conclusion: 该方法显著提升了触觉传感器的扫描速度和精度，适用于工业表面检测。

Abstract: Inspecting large-scale industrial surfaces like aircraft fuselages for
quality control requires capturing their precise 3D surface geometry at high
resolution. Vision-based tactile sensors (VBTSs) offer high local resolution
but require slow 'press-and-lift' measurements stitched for large areas.
Approaches with sliding or roller/belt VBTS designs provide measurements
continuity. However, they face significant challenges respectively: sliding
struggles with friction/wear and both approaches are speed-limited by
conventional camera frame rates and motion blur, making large-area scanning
time consuming. Thus, a rapid, continuous, high-resolution method is needed. We
introduce a novel tactile sensor integrating a neuromorphic camera in a rolling
mechanism to achieve this. Leveraging its high temporal resolution and
robustness to motion blur, our system uses a modified event-based multi-view
stereo approach for 3D reconstruction. We demonstrate state-of-the-art scanning
speeds up to 0.5 m/s, achieving Mean Absolute Error below 100 microns -- 11
times faster than prior continuous tactile sensing methods. A multi-reference
Bayesian fusion strategy enhances accuracy (reducing MAE by 25.2\% compared to
EMVS) and mitigates curvature errors. We also validate high-speed feature
recognition via Braille reading 2.6 times faster than previous approaches.

</details>


### [16] [Spatial Language Likelihood Grounding Network for Bayesian Fusion of Human-Robot Observations](https://arxiv.org/abs/2507.19947)
*Supawich Sitdhipol,Waritwong Sukprasongdee,Ekapol Chuangsuwanich,Rina Tse*

Main category: cs.RO

TL;DR: FP-LGN模型通过三阶段课程学习，将人类空间语言与地图图像特征关联，实现不确定性感知的信息融合，提升人机协作任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决机器人感知限制，通过融合人类观察信息，尤其是空间语言的不确定性建模。

Method: 提出FP-LGN模型，学习地图图像特征与空间语义关系，作为概率估计器捕捉语言的不确定性。

Result: FP-LGN在NLL指标上匹配专家规则，且更鲁棒；不确定性感知融合显著提升任务性能。

Conclusion: FP-LGN有效支持异构信息融合，为人机协作任务提供可靠的不确定性建模。

Abstract: Fusing information from human observations can help robots overcome sensing
limitations in collaborative tasks. However, an uncertainty-aware fusion
framework requires a grounded likelihood representing the uncertainty of human
inputs. This paper presents a Feature Pyramid Likelihood Grounding Network
(FP-LGN) that grounds spatial language by learning relevant map image features
and their relationships with spatial relation semantics. The model is trained
as a probability estimator to capture aleatoric uncertainty in human language
using three-stage curriculum learning. Results showed that FP-LGN matched
expert-designed rules in mean Negative Log-Likelihood (NLL) and demonstrated
greater robustness with lower standard deviation. Collaborative sensing results
demonstrated that the grounded likelihood successfully enabled
uncertainty-aware fusion of heterogeneous human language observations and robot
sensor measurements, achieving significant improvements in human-robot
collaborative task performance.

</details>


### [17] [A roadmap for AI in robotics](https://arxiv.org/abs/2507.19975)
*Aude Billard,Alin Albu-Schaeffer,Michael Beetz,Wolfram Burgard,Peter Corke,Matei Ciocarlie,Ravinder Dahiya,Danica Kragic,Ken Goldberg,Yukie Nagai,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本文评估了AI在机器人领域的成就，并提出了短期和中期的研究路线图，探讨了数据集、算法设计、人机协作等挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨如何利用AI技术解决机器人部署中的挑战，推动机器人在日常生活中的广泛应用。

Method: 通过评估自1990年代以来AI在机器人领域的进展，提出研究路线图，涵盖数据集更新、算法设计、人机协作等方面。

Result: 提出了解决机器人技术挑战的具体方向，包括数据集多样性、算法通用性、透明性和安全性。

Conclusion: 长期挑战在于设计能够终身学习、安全部署且计算成本可持续的机器人。

Abstract: AI technologies, including deep learning, large-language models have gone
from one breakthrough to the other. As a result, we are witnessing growing
excitement in robotics at the prospect of leveraging the potential of AI to
tackle some of the outstanding barriers to the full deployment of robots in our
daily lives. However, action and sensing in the physical world pose greater and
different challenges than analysing data in isolation. As the development and
application of AI in robotic products advances, it is important to reflect on
which technologies, among the vast array of network architectures and learning
models now available in the AI field, are most likely to be successfully
applied to robots; how they can be adapted to specific robot designs, tasks,
environments; which challenges must be overcome. This article offers an
assessment of what AI for robotics has achieved since the 1990s and proposes a
short- and medium-term research roadmap listing challenges and promises. These
range from keeping up-to-date large datasets, representatives of a diversity of
tasks robots may have to perform, and of environments they may encounter, to
designing AI algorithms tailored specifically to robotics problems but generic
enough to apply to a wide range of applications and transfer easily to a
variety of robotic platforms. For robots to collaborate effectively with
humans, they must predict human behavior without relying on bias-based
profiling. Explainability and transparency in AI-driven robot control are not
optional but essential for building trust, preventing misuse, and attributing
responsibility in accidents. We close on what we view as the primary long-term
challenges, that is, to design robots capable of lifelong learning, while
guaranteeing safe deployment and usage, and sustainable computational costs.

</details>


### [18] [CLASP: General-Purpose Clothes Manipulation with Semantic Keypoints](https://arxiv.org/abs/2507.19983)
*Yuhong Deng,Chao Tang,Cunjun Yu,Linfeng Li,David Hsu*

Main category: cs.RO

TL;DR: CLASP提出了一种基于语义关键点的通用衣物操作方法，适用于多种衣物类型和任务，通过视觉语言模型和预建技能库实现高效操作。


<details>
  <summary>Details</summary>
Motivation: 现有衣物操作方法局限于特定任务和衣物类型，CLASP旨在解决复杂衣物几何带来的挑战，实现通用操作。

Method: 利用语义关键点（如左袖、右肩）作为中间表示，结合视觉语言模型进行任务规划，并通过预建技能库执行动作。

Result: 仿真和真实机器人实验表明，CLASP在多种任务和衣物类型上优于现有方法，表现出强泛化能力。

Conclusion: CLASP通过语义关键点有效连接感知与动作，为通用衣物操作提供了可行方案。

Abstract: Clothes manipulation, such as folding or hanging, is a critical capability
for home service robots. Despite recent advances, most existing methods remain
limited to specific tasks and clothes types, due to the complex,
high-dimensional geometry of clothes. This paper presents CLothes mAnipulation
with Semantic keyPoints (CLASP), which aims at general-purpose clothes
manipulation over different clothes types, T-shirts, shorts, skirts, long
dresses, ... , as well as different tasks, folding, flattening, hanging, ... .
The core idea of CLASP is semantic keypoints -- e.g., ''left sleeve'', ''right
shoulder'', etc. -- a sparse spatial-semantic representation that is salient
for both perception and action. Semantic keypoints of clothes can be reliably
extracted from RGB-D images and provide an effective intermediate
representation of clothes manipulation policies. CLASP uses semantic keypoints
to bridge high-level task planning and low-level action execution. At the high
level, it exploits vision language models (VLMs) to predict task plans over the
semantic keypoints. At the low level, it executes the plans with the help of a
simple pre-built manipulation skill library. Extensive simulation experiments
show that CLASP outperforms state-of-the-art baseline methods on multiple tasks
across diverse clothes types, demonstrating strong performance and
generalization. Further experiments with a Franka dual-arm system on four
distinct tasks -- folding, flattening, hanging, and placing -- confirm CLASP's
performance on a real robot.

</details>


### [19] [Robot Excavation and Manipulation of Geometrically Cohesive Granular Media](https://arxiv.org/abs/2507.19999)
*Laura Treers,Daniel Soto,Joonha Hwang,Michael A. D. Goodisman,Daniel I. Goldman*

Main category: cs.RO

TL;DR: 论文探讨了机器人群体如何通过操纵纠缠颗粒材料构建随机结构，并研究了材料初始条件对机器人性能的影响。


<details>
  <summary>Details</summary>
Motivation: 传统建筑依赖预先设计的蓝图和材料，而随机结构则依赖材料特性而非预先设计。机器人群体可能成为构建此类结构的新工具。

Method: 开发了一个机器人物理模型，用于与几何粘性颗粒介质交互，测试不同初始压缩状态下的机器人性能。

Result: 机器人性能受材料初始压缩状态影响显著，运输质量变化高达75%。拉伸测试揭示了材料强度与初始压缩加载的关系。

Conclusion: 材料特性（如堆积和纠缠）对机器人操作有重要影响，未来需进一步研究机器人与纠缠材料的交互机制。

Abstract: Construction throughout history typically assumes that its blueprints and
building blocks are pre-determined. However, recent work suggests that
alternative approaches can enable new paradigms for structure formation.
Aleatory architectures, or those which rely on the properties of their granular
building blocks rather than pre-planned design or computation, have thus far
relied on human intervention for their creation. We imagine that robotic swarms
could be valuable to create such aleatory structures by manipulating and
forming structures from entangled granular materials. To discover principles by
which robotic systems can effectively manipulate soft matter, we develop a
robophysical model for interaction with geometrically cohesive granular media
composed of u-shape particles. This robotic platform uses environmental signals
to autonomously coordinate excavation, transport, and deposition of material.
We test the effect of substrate initial conditions by characterizing robot
performance in two different material compaction states and observe as much as
a 75% change in transported mass depending on initial substrate compressive
loading. These discrepancies suggest the functional role that material
properties such as packing and cohesion/entanglement play in excavation and
construction. To better understand these material properties, we develop an
apparatus for tensile testing of the geometrically cohesive substrates, which
reveals how entangled material strength responds strongly to initial
compressive loading. These results explain the variation observed in robotic
performance and point to future directions for better understanding robotic
interaction mechanics with entangled materials.

</details>


### [20] [SuperMag: Vision-based Tactile Data Guided High-resolution Tactile Shape Reconstruction for Magnetic Tactile Sensors](https://arxiv.org/abs/2507.20002)
*Peiyao Hou,Danning Sun,Meng Wang,Yuzhe Huang,Zeyu Zhang,Hangxin Liu,Wanlin Li,Ziyuan Jiao*

Main category: cs.RO

TL;DR: SuperMag利用高分辨率视觉触觉传感器数据监督磁触觉传感器的超分辨率重建，提升其空间分辨率。


<details>
  <summary>Details</summary>
Motivation: 磁触觉传感器（MBTS）设计紧凑且高频操作，但稀疏阵列导致空间分辨率有限。

Method: 通过同步收集高分辨率触觉形状和磁信号数据，采用条件变分自编码器进行形状重建。

Result: MBTS采样频率达125 Hz，形状重建推理时间小于2.5 ms。

Conclusion: 跨模态协同提升了MBTS的触觉感知能力，有望用于高精度机器人任务。

Abstract: Magnetic-based tactile sensors (MBTS) combine the advantages of compact
design and high-frequency operation but suffer from limited spatial resolution
due to their sparse taxel arrays. This paper proposes SuperMag, a tactile shape
reconstruction method that addresses this limitation by leveraging
high-resolution vision-based tactile sensor (VBTS) data to supervise MBTS
super-resolution. Co-designed, open-source VBTS and MBTS with identical contact
modules enable synchronized data collection of high-resolution shapes and
magnetic signals via a symmetric calibration setup. We frame tactile shape
reconstruction as a conditional generative problem, employing a conditional
variational auto-encoder to infer high-resolution shapes from low-resolution
MBTS inputs. The MBTS achieves a sampling frequency of 125 Hz, whereas the
shape reconstruction sustains an inference time within 2.5 ms. This
cross-modality synergy advances tactile perception of the MBTS, potentially
unlocking its new capabilities in high-precision robotic tasks.

</details>


### [21] [When Engineering Outruns Intelligence: A Re-evaluation of Instruction-Guided Navigation](https://arxiv.org/abs/2507.20021)
*Matin Aghaei,Mohammad Ali Alomrani,Yingxue Zhang,Mahdi Biparva*

Main category: cs.RO

TL;DR: 研究发现，在目标导航任务中，几何启发式方法（DWFE）比大型语言模型（LLM）更能提升性能，而轻量级语言先验（SHF）仅带来小幅改进。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLM）在目标导航任务中的实际贡献，验证其是否真正提升了规划能力。

Method: 1. 移除InstructNav中的动态导航提示、开放词汇检测器和直觉显著性图，替换为简单的距离加权边界探索器（DWFE）。2. 在DWFE基础上添加轻量级语言先验（SHF）。

Result: DWFE将成功率从58.0%提升至61.1%，SPL从20.9%提升至36.0%；SHF进一步带来+2%的成功率和+0.9%的SPL提升。

Conclusion: 边界几何启发式是性能提升的主要驱动力，而非LLM的推理能力；未来需设计度量感知提示或离线语义图以验证LLM的智能贡献。

Abstract: Large language models (LLMs) are often credited with recent leaps in
ObjectGoal Navigation, yet the extent to which they improve planning remains
unclear. We revisit this question on the HM3D-v1 validation split. First, we
strip InstructNav of its Dynamic Chain-of-Navigation prompt, open-vocabulary
GLEE detector and Intuition saliency map, and replace them with a simple
Distance-Weighted Frontier Explorer (DWFE). This geometry-only heuristic raises
Success from 58.0% to 61.1% and lifts SPL from 20.9% to 36.0% over 2 000
validation episodes, outperforming all previous training-free baselines.
Second, we add a lightweight language prior (SHF); on a 200-episode subset this
yields a further +2% Success and +0.9% SPL while shortening paths by five steps
on average. Qualitative trajectories confirm the trend: InstructNav back-tracks
and times-out, DWFE reaches the goal after a few islands, and SHF follows an
almost straight route. Our results indicate that frontier geometry, not
emergent LLM reasoning, drives most reported gains, and suggest that
metric-aware prompts or offline semantic graphs are necessary before
attributing navigation success to "LLM intelligence."

</details>


### [22] [Digital and Robotic Twinning for Validation of Proximity Operations and Formation Flying](https://arxiv.org/abs/2507.20034)
*Aviad Golan,Gregory Zin,Zahra Ahmed,Emily Bates,Toby Bell,Pol Francesch Huc,Samuel Y. W. Low,Juergen Bosse,Simone D'Amico*

Main category: cs.RO

TL;DR: 本文提出了一种统一的数字和机器人孪生框架，用于多模态GNC系统的验证，展示了数字与机器人孪生之间的一致性。


<details>
  <summary>Details</summary>
Motivation: 由于太空环境的复杂性，验证GNC系统具有挑战性，需要一种能够连接仿真和实际行为的V&V流程。

Method: 开发了一个端到端的数字和机器人孪生框架，包括三个测试平台（GRAND、TRON和OS），用于验证RF和视觉导航技术。

Result: 通过LEO中的RPO任务场景验证了GNC系统的性能和鲁棒性，展示了数字与机器人孪生的一致性。

Conclusion: 混合孪生框架为GNC系统的真实评估和验证提供了可靠的方法。

Abstract: In spacecraft Rendezvous, Proximity Operations (RPO), and Formation Flying
(FF), the Guidance Navigation and Control (GNC) system is safety-critical and
must meet strict performance requirements. However, validating such systems is
challenging due to the complexity of the space environment, necessitating a
verification and validation (V&V) process that bridges simulation and
real-world behavior. The key contribution of this paper is a unified,
end-to-end digital and robotic twinning framework that enables software- and
hardware-in-the-loop testing for multi-modal GNC systems. The robotic twin
includes three testbeds at Stanford's Space Rendezvous Laboratory (SLAB): the
GNSS and Radiofrequency Autonomous Navigation Testbed for Distributed Space
Systems (GRAND) to validate RF-based navigation techniques, and the Testbed for
Rendezvous and Optical Navigation (TRON) and Optical Stimulator (OS) to
validate vision-based methods. The test article for this work is an integrated
multi-modal GNC software stack for RPO and FF developed at SLAB. This paper
introduces the hybrid framework and summarizes calibration and error
characterization for the robotic twin. Then, the GNC stack's performance and
robustness is characterized using the integrated digital and robotic twinning
pipeline for a full-range RPO mission scenario in Low-Earth Orbit (LEO). The
results shown in the paper demonstrate consistency between digital and robotic
twins, validating the hybrid twinning pipeline as a reliable framework for
realistic assessment and verification of GNC systems.

</details>


### [23] [A real-time full-chain wearable sensor-based musculoskeletal simulation: an OpenSim-ROS Integration](https://arxiv.org/abs/2507.20049)
*Frederico Belmonte Klein,Zhaoyuan Wan,Huawei Wang,Ruoli Wang*

Main category: cs.RO

TL;DR: 提出了一种基于OpenSimRT、ROS和可穿戴传感器的实时集成框架，用于解决肌肉骨骼建模和模拟中的成本高、计算复杂和软件集成问题。


<details>
  <summary>Details</summary>
Motivation: 当前肌肉骨骼建模和模拟技术因传感器成本高、实验室设置复杂、计算需求大及软件工具集成不足而难以广泛应用。

Method: 结合OpenSimRT、ROS和可穿戴传感器，开发了一个实时集成框架，用于描述逆运动学和估计逆动力学及肌肉激活。

Result: 框架能较好地描述上下肢的逆运动学，并有效估计踝关节的逆动力学和下肢主要肌肉的激活情况。

Conclusion: 该研究为复杂实时和可穿戴传感器的人体运动分析系统奠定了基础，有望推动康复、机器人和外骨骼设计技术的发展。

Abstract: Musculoskeletal modeling and simulations enable the accurate description and
analysis of the movement of biological systems with applications such as
rehabilitation assessment, prosthesis, and exoskeleton design. However, the
widespread usage of these techniques is limited by costly sensors,
laboratory-based setups, computationally demanding processes, and the use of
diverse software tools that often lack seamless integration. In this work, we
address these limitations by proposing an integrated, real-time framework for
musculoskeletal modeling and simulations that leverages OpenSimRT, the robotics
operating system (ROS), and wearable sensors. As a proof-of-concept, we
demonstrate that this framework can reasonably well describe inverse kinematics
of both lower and upper body using either inertial measurement units or
fiducial markers. Additionally, we show that it can effectively estimate
inverse dynamics of the ankle joint and muscle activations of major lower limb
muscles during daily activities, including walking, squatting and sit to stand,
stand to sit when combined with pressure insoles. We believe this work lays the
groundwork for further studies with more complex real-time and wearable
sensor-based human movement analysis systems and holds potential to advance
technologies in rehabilitation, robotics and exoskeleton designs.

</details>


### [24] [Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots](https://arxiv.org/abs/2507.20217)
*Wei Cui,Haoyu Wang,Wenkang Qin,Yijie Guo,Gang Han,Wen Zhao,Jiahang Cao,Zhang Zhang,Jiaru Zhong,Jingkai Sun,Pihai Sun,Shuai Shi,Botuo Jiang,Jiahao Ma,Jiaxu Wang,Hao Cheng,Zhichao Liu,Yang Wang,Zheng Zhu,Guan Huang,Jian Tang,Qiang Zhang*

Main category: cs.RO

TL;DR: Humanoid Occupancy是一个多模态占用感知系统，整合硬件和软件组件，为仿人机器人提供全面的环境理解。


<details>
  <summary>Details</summary>
Motivation: 仿人机器人需要丰富的语义和3D几何信息以实现环境理解，占用表示被广泛认为适合这一需求。

Method: 系统采用多模态融合技术生成网格占用输出，解决运动干扰和遮挡问题，并开发了首个全景占用数据集。

Result: Humanoid Occupancy为仿人机器人提供了有效的环境感知，并为标准化视觉模块奠定了基础。

Conclusion: 该系统为仿人机器人在复杂现实场景中的广泛应用铺平了道路。

Abstract: Humanoid robot technology is advancing rapidly, with manufacturers
introducing diverse heterogeneous visual perception modules tailored to
specific scenarios. Among various perception paradigms, occupancy-based
representation has become widely recognized as particularly suitable for
humanoid robots, as it provides both rich semantic and 3D geometric information
essential for comprehensive environmental understanding. In this work, we
present Humanoid Occupancy, a generalized multimodal occupancy perception
system that integrates hardware and software components, data acquisition
devices, and a dedicated annotation pipeline. Our framework employs advanced
multi-modal fusion techniques to generate grid-based occupancy outputs encoding
both occupancy status and semantic labels, thereby enabling holistic
environmental understanding for downstream tasks such as task planning and
navigation. To address the unique challenges of humanoid robots, we overcome
issues such as kinematic interference and occlusion, and establish an effective
sensor layout strategy. Furthermore, we have developed the first panoramic
occupancy dataset specifically for humanoid robots, offering a valuable
benchmark and resource for future research and development in this domain. The
network architecture incorporates multi-modal feature fusion and temporal
information integration to ensure robust perception. Overall, Humanoid
Occupancy delivers effective environmental perception for humanoid robots and
establishes a technical foundation for standardizing universal visual modules,
paving the way for the widespread deployment of humanoid robots in complex
real-world scenarios.

</details>


### [25] [Tactile-Guided Robotic Ultrasound: Mapping Preplanned Scan Paths for Intercostal Imaging](https://arxiv.org/abs/2507.20282)
*Yifan Zhang,Dianye Huang,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: 论文提出了一种利用触觉信号生成超声扫描路径的方法，以解决肋间成像中的挑战，并通过实验验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人超声系统在肋间成像中因缺乏有效扫描路径生成方法而受限的问题。

Method: 利用触觉信号提取肋骨表面点云，通过插值和配准生成扫描路径，并引入自动倾斜角调整方法。

Result: 扫描路径的MNND和HD误差分别为3.41 mm和3.65 mm，重建对象的误差为0.69 mm和2.2 mm。

Conclusion: 该方法在肋间超声成像中表现出高效性和准确性，具有临床应用潜力。

Abstract: Medical ultrasound (US) imaging is widely used in clinical examinations due
to its portability, real-time capability, and radiation-free nature. To address
inter- and intra-operator variability, robotic ultrasound systems have gained
increasing attention. However, their application in challenging intercostal
imaging remains limited due to the lack of an effective scan path generation
method within the constrained acoustic window. To overcome this challenge, we
explore the potential of tactile cues for characterizing subcutaneous rib
structures as an alternative signal for ultrasound segmentation-free bone
surface point cloud extraction. Compared to 2D US images, 1D tactile-related
signals offer higher processing efficiency and are less susceptible to acoustic
noise and artifacts. By leveraging robotic tracking data, a sparse tactile
point cloud is generated through a few scans along the rib, mimicking human
palpation. To robustly map the scanning trajectory into the intercostal space,
the sparse tactile bone location point cloud is first interpolated to form a
denser representation. This refined point cloud is then registered to an
image-based dense bone surface point cloud, enabling accurate scan path mapping
for individual patients. Additionally, to ensure full coverage of the object of
interest, we introduce an automated tilt angle adjustment method to visualize
structures beneath the bone. To validate the proposed method, we conducted
comprehensive experiments on four distinct phantoms. The final scanning
waypoint mapping achieved Mean Nearest Neighbor Distance (MNND) and Hausdorff
distance (HD) errors of 3.41 mm and 3.65 mm, respectively, while the
reconstructed object beneath the bone had errors of 0.69 mm and 2.2 mm compared
to the CT ground truth.

</details>


### [26] [Decentralized Uncertainty-Aware Multi-Agent Collision Avoidance With Model Predictive Path Integral](https://arxiv.org/abs/2507.20293)
*Stepan Dergachev,Konstantin Yakovlev*

Main category: cs.RO

TL;DR: 提出了一种结合MPPI和概率ORCA的新方法，用于多智能体导航，确保安全高效。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体导航中的不确定性和噪声问题，需要兼顾运动学约束和安全性。

Method: 将MPPI与概率ORCA结合，通过二阶锥规划在采样过程中引入安全约束。

Result: 在密集环境中表现优于ORCA-DD和B-UAVC，成功率高且实用性强。

Conclusion: 该方法在多智能体导航中具有高效性和安全性，适用于实际机器人平台。

Abstract: Decentralized multi-agent navigation under uncertainty is a complex task that
arises in numerous robotic applications. It requires collision avoidance
strategies that account for both kinematic constraints, sensing and action
execution noise. In this paper, we propose a novel approach that integrates the
Model Predictive Path Integral (MPPI) with a probabilistic adaptation of
Optimal Reciprocal Collision Avoidance. Our method ensures safe and efficient
multi-agent navigation by incorporating probabilistic safety constraints
directly into the MPPI sampling process via a Second-Order Cone Programming
formulation. This approach enables agents to operate independently using local
noisy observations while maintaining safety guarantees. We validate our
algorithm through extensive simulations with differential-drive robots and
benchmark it against state-of-the-art methods, including ORCA-DD and B-UAVC.
Results demonstrate that our approach outperforms them while achieving high
success rates, even in densely populated environments. Additionally, validation
in the Gazebo simulator confirms its practical applicability to robotic
platforms.

</details>


### [27] [Advancing Shared and Multi-Agent Autonomy in Underwater Missions: Integrating Knowledge Graphs and Retrieval-Augmented Generation](https://arxiv.org/abs/2507.20370)
*Michele Grimaldi,Carlo Cernicchiaro,Sebastian Realpe Rua,Alaaeddine El-Masri-El-Chaarani,Markus Buchholz,Loizos Michael,Pere Ridao Rodriguez,Ignacio Carlucho,Yvan R. Petillot*

Main category: cs.RO

TL;DR: 论文探讨了如何利用知识图谱和RAG系统提升水下机器人自主性，实现多智能体自主与共享自主性，确保任务验证和行为完整性。


<details>
  <summary>Details</summary>
Motivation: 水下环境的复杂性和动态性对机器人自主性提出高要求，需结合人类监督以确保信任和效率。

Method: 采用知识图谱和RAG系统增强大型语言模型，结合领域分类法，支持多智能体自主决策和人机交互。

Result: 实验显示该方法实现了100%任务验证和行为完整性，且结构化知识能有效减少LLM幻觉。

Conclusion: 结构化知识（知识图谱和分类法）对提升水下机器人自主性和决策质量至关重要。

Abstract: Robotic platforms have become essential for marine operations by providing
regular and continuous access to offshore assets, such as underwater
infrastructure inspection, environmental monitoring, and resource exploration.
However, the complex and dynamic nature of underwater environments,
characterized by limited visibility, unpredictable currents, and communication
constraints, presents significant challenges that demand advanced autonomy
while ensuring operator trust and oversight. Central to addressing these
challenges are knowledge representation and reasoning techniques, particularly
knowledge graphs and retrieval-augmented generation (RAG) systems, that enable
robots to efficiently structure, retrieve, and interpret complex environmental
data. These capabilities empower robotic agents to reason, adapt, and respond
effectively to changing conditions. The primary goal of this work is to
demonstrate both multi-agent autonomy and shared autonomy, where multiple
robotic agents operate independently while remaining connected to a human
supervisor. We show how a RAG-powered large language model, augmented with
knowledge graph data and domain taxonomy, enables autonomous multi-agent
decision-making and facilitates seamless human-robot interaction, resulting in
100\% mission validation and behavior completeness. Finally, ablation studies
reveal that without structured knowledge from the graph and/or taxonomy, the
LLM is prone to hallucinations, which can compromise decision quality.

</details>


### [28] [Bipedalism for Quadrupedal Robots: Versatile Loco-Manipulation through Risk-Adaptive Reinforcement Learning](https://arxiv.org/abs/2507.20382)
*Yuyou Zhang,Radu Corcodel,Ding Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于风险适应的分布强化学习框架，使四足机器人能够用后腿行走，释放前腿进行环境交互。


<details>
  <summary>Details</summary>
Motivation: 四足机器人的腿用作操纵器会影响其运动能力，而加装手臂会增加系统复杂性。为了解决这一问题，研究团队引入了双足行走模式。

Method: 采用风险适应的分布强化学习框架，动态调整风险偏好，基于回报分布的不确定性（变异系数）进行训练。

Result: 仿真实验显示该方法优于基线，实际部署在Unitree Go2机器人上，展示了多种任务的执行能力和鲁棒性。

Conclusion: 该方法成功实现了四足机器人的双足行走，释放前腿进行多功能环境交互，同时保持了鲁棒性和性能。

Abstract: Loco-manipulation of quadrupedal robots has broadened robotic applications,
but using legs as manipulators often compromises locomotion, while mounting
arms complicates the system. To mitigate this issue, we introduce bipedalism
for quadrupedal robots, thus freeing the front legs for versatile interactions
with the environment. We propose a risk-adaptive distributional Reinforcement
Learning (RL) framework designed for quadrupedal robots walking on their hind
legs, balancing worst-case conservativeness with optimal performance in this
inherently unstable task. During training, the adaptive risk preference is
dynamically adjusted based on the uncertainty of the return, measured by the
coefficient of variation of the estimated return distribution. Extensive
experiments in simulation show our method's superior performance over
baselines. Real-world deployment on a Unitree Go2 robot further demonstrates
the versatility of our policy, enabling tasks like cart pushing, obstacle
probing, and payload transport, while showcasing robustness against challenging
dynamics and external disturbances.

</details>


### [29] [Model-Structured Neural Networks to Control the Steering Dynamics of Autonomous Race Cars](https://arxiv.org/abs/2507.20427)
*Mattia Piccinini,Aniello Mungiello,Georg Jank,Gastone Pietro Rosati Papini,Francesco Biral,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种结合车辆动力学先验知识的模型结构化神经网络（MS-NN-steer），用于自动驾驶赛车中的转向控制，在精度和泛化能力上优于通用神经网络和A2RL冠军团队的控制器。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶赛车需要安全且鲁棒的决策算法，但传统神经网络的“黑盒”特性限制了其可解释性。

Method: 设计了MS-NN-steer，将非线性车辆动力学的先验知识融入神经网络架构。

Result: 在A2RL真实数据测试中，MS-NN-steer在小训练集下表现更优，对权重初始化不敏感，且性能超越冠军团队控制器。

Conclusion: MS-NN-steer通过结合先验知识，提升了自动驾驶赛车转向控制的性能和可靠性。

Abstract: Autonomous racing has gained increasing attention in recent years, as a safe
environment to accelerate the development of motion planning and control
methods for autonomous driving. Deep learning models, predominantly based on
neural networks (NNs), have demonstrated significant potential in modeling the
vehicle dynamics and in performing various tasks in autonomous driving.
However, their black-box nature is critical in the context of autonomous
racing, where safety and robustness demand a thorough understanding of the
decision-making algorithms. To address this challenge, this paper proposes
MS-NN-steer, a new Model-Structured Neural Network for vehicle steering
control, integrating the prior knowledge of the nonlinear vehicle dynamics into
the neural architecture. The proposed controller is validated using real-world
data from the Abu Dhabi Autonomous Racing League (A2RL) competition, with
full-scale autonomous race cars. In comparison with general-purpose NNs,
MS-NN-steer is shown to achieve better accuracy and generalization with small
training datasets, while being less sensitive to the weights' initialization.
Also, MS-NN-steer outperforms the steering controller used by the A2RL winning
team. Our implementation is available open-source in a GitHub repository.

</details>


### [30] [Learning Physical Interaction Skills from Human Demonstrations](https://arxiv.org/abs/2507.20445)
*Tianyu Li,Hengbo Ma,Sehoon Ha,Kwonjoon Lee*

Main category: cs.RO

TL;DR: 提出了一种名为BuddyImitation的框架，通过Embedded Interaction Graph（EIG）从人类演示中学习全身交互行为，适用于形态各异的智能体。


<details>
  <summary>Details</summary>
Motivation: 解决智能体在形态与演示者差异显著时学习物理交互技能的挑战，克服现有方法依赖手工目标或形态相似性的局限性。

Method: 提取交互动态的紧凑可转移表示EIG，作为模仿目标训练控制策略，生成语义有意义且物理可行的动作。

Result: 在多种智能体和交互场景（如格斗、握手、猜拳、跳舞）中验证了框架的有效性。

Conclusion: 展示了通过跨形态交互学习实现协调行为的潜力。

Abstract: Learning physical interaction skills, such as dancing, handshaking, or
sparring, remains a fundamental challenge for agents operating in human
environments, particularly when the agent's morphology differs significantly
from that of the demonstrator. Existing approaches often rely on handcrafted
objectives or morphological similarity, limiting their capacity for
generalization. Here, we introduce a framework that enables agents with diverse
embodiments to learn wholebbody interaction behaviors directly from human
demonstrations. The framework extracts a compact, transferable representation
of interaction dynamics, called the Embedded Interaction Graph (EIG), which
captures key spatiotemporal relationships between the interacting agents. This
graph is then used as an imitation objective to train control policies in
physics-based simulations, allowing the agent to generate motions that are both
semantically meaningful and physically feasible. We demonstrate BuddyImitation
on multiple agents, such as humans, quadrupedal robots with manipulators, or
mobile manipulators and various interaction scenarios, including sparring,
handshaking, rock-paper-scissors, or dancing. Our results demonstrate a
promising path toward coordinated behaviors across morphologically distinct
characters via cross embodiment interaction learning.

</details>


### [31] [LLMs-guided adaptive compensator: Bringing Adaptivity to Automatic Control Systems with Large Language Models](https://arxiv.org/abs/2507.20509)
*Zhongchao Zhou,Yuxi Lu,Yaonan Zhu,Yifan Zhao,Bin He,Liang He,Wenwen Yu,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: LLM引导的自适应补偿器框架在机器人控制中表现优于传统方法，降低了推理复杂度并提升了适应性。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在自动控制领域的应用，特别是在自适应控制中，以解决现有方法在复杂系统和实际验证中的不足。

Method: 提出LLM引导的自适应补偿器框架，利用LLM根据未知系统与参考系统的差异设计补偿器。

Result: 实验表明，该方法在软体和类人机器人中表现优于传统自适应控制器，并具有更强的泛化性和鲁棒性。

Conclusion: 该研究为LLM在自动控制中的应用开辟了新方向，提供了更高的实用性和部署性。

Abstract: With rapid advances in code generation, reasoning, and problem-solving, Large
Language Models (LLMs) are increasingly applied in robotics. Most existing work
focuses on high-level tasks such as task decomposition. A few studies have
explored the use of LLMs in feedback controller design; however, these efforts
are restricted to overly simplified systems, fixed-structure gain tuning, and
lack real-world validation. To further investigate LLMs in automatic control,
this work targets a key subfield: adaptive control. Inspired by the framework
of model reference adaptive control (MRAC), we propose an LLM-guided adaptive
compensator framework that avoids designing controllers from scratch. Instead,
the LLMs are prompted using the discrepancies between an unknown system and a
reference system to design a compensator that aligns the response of the
unknown system with that of the reference, thereby achieving adaptivity.
Experiments evaluate five methods: LLM-guided adaptive compensator, LLM-guided
adaptive controller, indirect adaptive control, learning-based adaptive
control, and MRAC, on soft and humanoid robots in both simulated and real-world
environments. Results show that the LLM-guided adaptive compensator outperforms
traditional adaptive controllers and significantly reduces reasoning complexity
compared to the LLM-guided adaptive controller. The Lyapunov-based analysis and
reasoning-path inspection demonstrate that the LLM-guided adaptive compensator
enables a more structured design process by transforming mathematical
derivation into a reasoning task, while exhibiting strong generalizability,
adaptability, and robustness. This study opens a new direction for applying
LLMs in the field of automatic control, offering greater deployability and
practicality compared to vision-language models.

</details>


### [32] [Large-Scale LiDAR-Inertial Dataset for Degradation-Robust High-Precision Mapping](https://arxiv.org/abs/2507.20516)
*Xiaofeng Jin,Ningbo Bu,Shijie Wang,Jianfei Ge,Jiangjian Xiao,Matteo Matteucci*

Main category: cs.RO

TL;DR: 该论文提出了一个大规模、高精度的LiDAR-惯性里程计（LIO）数据集，用于验证LIO系统在复杂现实场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究中LIO系统在复杂现实场景中的验证不足，因此需要提供更全面的数据集来评估其泛化能力。

Method: 数据集通过定制背包平台收集，包含多光束LiDAR、工业级IMU和RTK-GNSS模块，覆盖四种不同环境，面积从60,000到750,000平方米。

Result: 数据集包含长轨迹、复杂场景和高精度地面真实值，通过SLAM优化与RTK-GNSS锚定融合生成，并通过倾斜摄影测量和RTK-GNSS验证轨迹精度。

Conclusion: 该数据集为评估LIO系统在高精度实际测绘场景中的泛化能力提供了全面基准。

Abstract: This paper introduces a large-scale, high-precision LiDAR-Inertial Odometry
(LIO) dataset, aiming to address the insufficient validation of LIO systems in
complex real-world scenarios in existing research. The dataset covers four
diverse real-world environments spanning 60,000 to 750,000 square meters,
collected using a custom backpack-mounted platform equipped with multi-beam
LiDAR, an industrial-grade IMU, and RTK-GNSS modules. The dataset includes long
trajectories, complex scenes, and high-precision ground truth, generated by
fusing SLAM-based optimization with RTK-GNSS anchoring, and validated for
trajectory accuracy through the integration of oblique photogrammetry and
RTK-GNSS. This dataset provides a comprehensive benchmark for evaluating the
generalization ability of LIO systems in practical high-precision mapping
scenarios.

</details>


### [33] [Uni-Mapper: Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments](https://arxiv.org/abs/2507.20538)
*Gilhwan Kang,Hogyun Kim,Byunghee Choi,Seokhwan Jeong,Young-Sik Shin,Younggun Cho*

Main category: cs.RO

TL;DR: Uni-Mapper是一个动态感知的3D点云地图合并框架，用于多模态LiDAR系统，解决了动态环境和不同传感器模态下的地图统一问题。


<details>
  <summary>Details</summary>
Motivation: 统一不同地图对于多机器人协作和多会话操作至关重要，但动态环境和传感器差异导致点云分布不一致，影响地图对齐。

Method: Uni-Mapper包括动态对象移除、动态感知闭环检测和多模态LiDAR地图合并模块，采用体素自由空间哈希图和全局描述符。

Result: 在动态环境和异构LiDAR数据集上表现优异，优于现有方法。

Conclusion: Uni-Mapper在多模态传感器和动态环境中实现了鲁棒的地图合并和闭环检测。

Abstract: The unification of disparate maps is crucial for enabling scalable robot
operation across multiple sessions and collaborative multi-robot scenarios.
However, achieving a unified map robust to sensor modalities and dynamic
environments remains a challenging problem. Variations in LiDAR types and
dynamic elements lead to differences in point cloud distribution and scene
consistency, hindering reliable descriptor generation and loop closure
detection essential for accurate map alignment. To address these challenges,
this paper presents Uni-Mapper, a dynamic-aware 3D point cloud map merging
framework for multi-modal LiDAR systems. It comprises dynamic object removal,
dynamic-aware loop closure, and multi-modal LiDAR map merging modules. A
voxel-wise free space hash map is built in a coarse-to-fine manner to identify
and reject dynamic objects via temporal occupancy inconsistencies. The removal
module is integrated with a LiDAR global descriptor, which encodes preserved
static local features to ensure robust place recognition in dynamic
environments. In the final stage, multiple pose graph optimizations are
conducted for both intra-session and inter-map loop closures. We adopt a
centralized anchor-node strategy to mitigate intra-session drift errors during
map merging. In the final stage, centralized anchor-node-based pose graph
optimization is performed to address intra- and inter-map loop closures for
globally consistent map merging. Our framework is evaluated on diverse
real-world datasets with dynamic objects and heterogeneous LiDARs, showing
superior performance in loop detection across sensor modalities, robust mapping
in dynamic environments, and accurate multi-map alignment over existing
methods. Project Page: https://sparolab.github.io/research/uni_mapper.

</details>


### [34] [Methods for the Segmentation of Reticular Structures Using 3D LiDAR Data: A Comparative Evaluation](https://arxiv.org/abs/2507.20589)
*Francisco J. Soler Mora,Adrián Peidró Vidal,Marc Fabregat-Jaén,Luis Payá Castelló,Óscar Reinoso García*

Main category: cs.RO

TL;DR: 论文提出两种方法（分析算法和深度学习模型）用于桁架结构中可导航表面的分割，比较了它们的性能，并展示了在自主导航中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 桁架结构的检查和维护成本高且危险，现有研究多关注故障检测或机器人设计，而自主导航研究较少。

Method: 提出分析算法（基于点云平面块的特征分解）和深度学习模型（PointNet、PointNet++、MinkUNet34C、PointTransformerV3）进行可导航表面分割。

Result: 分析算法参数调整简单且性能接近深度学习模型；深度学习模型（如PointTransformerV3）在分割精度上更优（mIoU约97%）。

Conclusion: 两种方法各有优劣，为复杂桁架环境中的自主导航提供了实用指导。

Abstract: Reticular structures form the backbone of major infrastructure like bridges,
pylons, and airports, but their inspection and maintenance are costly and
hazardous, often requiring human intervention. While prior research has focused
on fault detection via images or robotic platform design, the autonomous
navigation of robots within these structures is less explored. This study
addresses that gap by proposing methods to detect navigable surfaces in truss
structures, enhancing the autonomy of climbing robots. The paper introduces
several approaches for binary segmentation of navigable surfaces versus
background from 3D point clouds of metallic trusses. These methods fall into
two categories: analytical algorithms and deep learning models. The analytical
approach features a custom algorithm that segments structures by analyzing the
eigendecomposition of planar patches in the point cloud. In parallel, advanced
deep learning models PointNet, PointNet++, MinkUNet34C, and PointTransformerV3
are trained and evaluated for the same task. Comparative analysis shows that
the analytical algorithm offers easier parameter tuning and performance
comparable to deep learning models, which, while more computationally
intensive, excel in segmentation accuracy. Notably, PointTransformerV3 achieves
a Mean Intersection Over Union (mIoU) of about 97%. The study demonstrates the
promise of both analytical and deep learning methods for improving autonomous
navigation in complex truss environments. The results highlight the trade-offs
between computational efficiency and segmentation performance, providing
valuable guidance for future research and practical applications in autonomous
infrastructure inspection and maintenance.

</details>


### [35] [FMimic: Foundation Models are Fine-grained Action Learners from Human Videos](https://arxiv.org/abs/2507.20622)
*Guangyan Chen,Meiling Wang,Te Cui,Yao Mu,Haoyang Lu,Zicai Peng,Mengxiao Hu,Tianxing Zhou,Mengyin Fu,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: FMimic利用基础模型直接从少量人类视频中学习可泛化的精细动作技能，显著提升了视觉模仿学习的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖预定义的运动原语执行物理交互，限制了机器人系统的灵活性。

Method: 提出FMimic，利用基础模型直接从人类视频中学习精细动作技能。

Result: FMimic在单视频和五视频条件下均表现优异，在多任务和真实世界任务中分别提升39%和29%。

Conclusion: FMimic显著提升了视觉模仿学习的性能，尤其在精细动作和长时程任务中表现突出。

Abstract: Visual imitation learning (VIL) provides an efficient and intuitive strategy
for robotic systems to acquire novel skills. Recent advancements in foundation
models, particularly Vision Language Models (VLMs), have demonstrated
remarkable capabilities in visual and linguistic reasoning for VIL tasks.
Despite this progress, existing approaches primarily utilize these models for
learning high-level plans from human demonstrations, relying on pre-defined
motion primitives for executing physical interactions, which remains a major
bottleneck for robotic systems. In this work, we present FMimic, a novel
paradigm that harnesses foundation models to directly learn generalizable
skills at even fine-grained action levels, using only a limited number of human
videos. Extensive experiments demonstrate that our FMimic delivers strong
performance with a single human video, and significantly outperforms all other
methods with five videos. Furthermore, our method exhibits significant
improvements of over 39% and 29% in RLBench multi-task experiments and
real-world manipulation tasks, respectively, and exceeds baselines by more than
34% in high-precision tasks and 47% in long-horizon tasks.

</details>


### [36] [A Strawberry Harvesting Tool with Minimal Footprint](https://arxiv.org/abs/2507.20784)
*Mohamed Sorour,Mohamed Heshmat,Khaled Elgeneidy,Pål Johan From*

Main category: cs.RO

TL;DR: 提出了一种新型草莓采摘原型，通过激光切割茎干，减少接触并延长果实保鲜期。


<details>
  <summary>Details</summary>
Motivation: 传统采摘方法可能传播植物病害，且保鲜效果不佳，需一种更高效、卫生的方法。

Method: 使用平滑夹具将茎干引导至精确位置，通过高温激光切割茎干，杀菌并延长保鲜。

Result: 成功实现室内采摘，切割时间2.88秒，循环时间5.56秒，优化了激光参数。

Conclusion: 该方法高效、卫生，能显著延长草莓保鲜期，适用于室内种植场景。

Abstract: In this paper, a novel prototype for harvesting table-top grown strawberries
is presented, that is minimalist in its footprint interacting with the fruit.
In our methodology, a smooth trapper manipulates the stem into a precise groove
location at which a distant laser beam is focused. The tool reaches
temperatures as high as 188{\deg} Celsius and as such killing germs and
preventing the spread of local plant diseases. The burnt stem wound preserves
water content and in turn the fruit shelf life. Cycle and cut times achieved
are 5.56 and 2.88 seconds respectively in successful in-door harvesting
demonstration. Extensive experiments are performed to optimize the laser spot
diameter and lateral speed against the cutting time.

</details>


### [37] [LanternNet: A Novel Hub-and-Spoke System to Seek and Suppress Spotted Lanternfly Populations](https://arxiv.org/abs/2507.20800)
*Vinil Polepalli*

Main category: cs.RO

TL;DR: LanternNet是一种新型自主机器人系统，用于检测和抑制斑点灯笼蝇（SLF）种群，相比传统方法更高效、环保且可扩展。


<details>
  <summary>Details</summary>
Motivation: 斑点灯笼蝇对农业和生态系统造成严重威胁，现有控制方法效率低且对环境有害。

Method: LanternNet采用中心-辐条系统，结合YOLOv8计算机视觉模型和三种机器人辐条，实现精准检测和针对性任务。

Result: 实地部署5周后，SLF种群显著减少，树木健康指标改善，且成本效益优于传统方法。

Conclusion: LanternNet展示了机器人与AI在入侵物种管理和环境保护中的变革潜力。

Abstract: The invasive spotted lanternfly (SLF) poses a significant threat to
agriculture and ecosystems, causing widespread damage. Current control methods,
such as egg scraping, pesticides, and quarantines, prove labor-intensive,
environmentally hazardous, and inadequate for long-term SLF suppression. This
research introduces LanternNet, a novel autonomous robotic Hub-and-Spoke system
designed for scalable detection and suppression of SLF populations. A central,
tree-mimicking hub utilizes a YOLOv8 computer vision model for precise SLF
identification. Three specialized robotic spokes perform targeted tasks: pest
neutralization, environmental monitoring, and navigation/mapping. Field
deployment across multiple infested sites over 5 weeks demonstrated
LanternNet's efficacy. Quantitative analysis revealed significant reductions (p
< 0.01, paired t-tests) in SLF populations and corresponding improvements in
tree health indicators across the majority of test sites. Compared to
conventional methods, LanternNet offers substantial cost advantages and
improved scalability. Furthermore, the system's adaptability for enhanced
autonomy and targeting of other invasive species presents significant potential
for broader ecological impact. LanternNet demonstrates the transformative
potential of integrating robotics and AI for advanced invasive species
management and improved environmental outcomes.

</details>


### [38] [Hanging Around: Cognitive Inspired Reasoning for Reactive Robotics](https://arxiv.org/abs/2507.20832)
*Mihai Pomarlan,Stefano De Giorgis,Rachel Ringe,Maria M. Hedblom,Nikolaos Tsiogkas*

Main category: cs.RO

TL;DR: 论文提出了一种神经符号模块化架构，用于反应式机器人，结合神经组件和符号推理，使机器人能够识别环境元素并自主扩展知识。


<details>
  <summary>Details</summary>
Motivation: 解决人工代理在自然环境中操作时的空间感知、对象功能检测和动态变化等挑战，特别是识别和监控相关环境元素的能力。

Method: 结合神经组件（对象识别和图像处理）与符号推理（基于本体结构的知识表示），通过观察学习新概念并调整感知。

Result: 在模拟环境中，代理通过学习识别对象部分（如支撑关系中的部分），并能够规划复杂任务。

Conclusion: 该方法展示了代理通过系统观察扩展知识的能力，突显了深度推理与感知结合的潜力。

Abstract: Situationally-aware artificial agents operating with competence in natural
environments face several challenges: spatial awareness, object affordance
detection, dynamic changes and unpredictability. A critical challenge is the
agent's ability to identify and monitor environmental elements pertinent to its
objectives. Our research introduces a neurosymbolic modular architecture for
reactive robotics. Our system combines a neural component performing object
recognition over the environment and image processing techniques such as
optical flow, with symbolic representation and reasoning. The reasoning system
is grounded in the embodied cognition paradigm, via integrating image schematic
knowledge in an ontological structure. The ontology is operatively used to
create queries for the perception system, decide on actions, and infer
entities' capabilities derived from perceptual data. The combination of
reasoning and image processing allows the agent to focus its perception for
normal operation as well as discover new concepts for parts of objects involved
in particular interactions. The discovered concepts allow the robot to
autonomously acquire training data and adjust its subsymbolic perception to
recognize the parts, as well as making planning for more complex tasks feasible
by focusing search on those relevant object parts. We demonstrate our approach
in a simulated world, in which an agent learns to recognize parts of objects
involved in support relations. While the agent has no concept of handle
initially, by observing examples of supported objects hanging from a hook it
learns to recognize the parts involved in establishing support and becomes able
to plan the establishment/destruction of the support relation. This underscores
the agent's capability to expand its knowledge through observation in a
systematic way, and illustrates the potential of combining deep reasoning
[...].

</details>


### [39] [Free Energy-Inspired Cognitive Risk Integration for AV Navigation in Pedestrian-Rich Environments](https://arxiv.org/abs/2507.20850)
*Meiting Dang,Yanping Wu,Yafei Wang,Dezong Zhao,David Flynn,Chongfeng Wei*

Main category: cs.RO

TL;DR: 提出了一种基于自由能原理的认知过程建模框架，用于自动驾驶车辆与行人的交互，提升了安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究在复杂多智能体交互环境中难以实现人类化的预测与决策，尤其是与弱势道路使用者的交互。

Method: 结合认知不确定性和物理风险的融合度量，改进社会力模型，并利用图卷积网络和软演员-评论家架构进行决策。

Result: 仿真结果表明，该框架在安全性、效率和流畅性上优于现有方法。

Conclusion: 该框架为自动驾驶车辆与行人的交互提供了更真实的建模方法，具有实际应用潜力。

Abstract: Recent advances in autonomous vehicle (AV) behavior planning have shown
impressive social interaction capabilities when interacting with other road
users. However, achieving human-like prediction and decision-making in
interactions with vulnerable road users remains a key challenge in complex
multi-agent interactive environments. Existing research focuses primarily on
crowd navigation for small mobile robots, which cannot be directly applied to
AVs due to inherent differences in their decision-making strategies and dynamic
boundaries. Moreover, pedestrians in these multi-agent simulations follow fixed
behavior patterns that cannot dynamically respond to AV actions. To overcome
these limitations, this paper proposes a novel framework for modeling
interactions between the AV and multiple pedestrians. In this framework, a
cognitive process modeling approach inspired by the Free Energy Principle is
integrated into both the AV and pedestrian models to simulate more realistic
interaction dynamics. Specifically, the proposed pedestrian Cognitive-Risk
Social Force Model adjusts goal-directed and repulsive forces using a fused
measure of cognitive uncertainty and physical risk to produce human-like
trajectories. Meanwhile, the AV leverages this fused risk to construct a
dynamic, risk-aware adjacency matrix for a Graph Convolutional Network within a
Soft Actor-Critic architecture, allowing it to make more reasonable and
informed decisions. Simulation results indicate that our proposed framework
effectively improves safety, efficiency, and smoothness of AV navigation
compared to the state-of-the-art method.

</details>


### [40] [Uncertainty-aware Planning with Inaccurate Models for Robotized Liquid Handling](https://arxiv.org/abs/2507.20861)
*Marco Faroni,Carlo Odesco,Andrea Zanchettin,Paolo Rocco*

Main category: cs.RO

TL;DR: 论文提出了一种基于不确定性感知的蒙特卡洛树搜索（MCTS）算法，用于提升复杂机器人任务（如液体倾倒）的准确性。


<details>
  <summary>Details</summary>
Motivation: 物理仿真和学习模型在复杂机器人任务中存在准确性不足的问题，尤其是面对新情况时表现不佳。

Method: 通过结合模型不确定性估计，MCTS策略偏向预测不确定性较低的动作。

Result: 在液体倾倒任务中，该方法在数据有限的情况下仍提高了成功率，优于传统方法。

Conclusion: 该方法展示了在机器人任务中实现鲁棒决策的潜力。

Abstract: Physics-based simulations and learning-based models are vital for complex
robotics tasks like deformable object manipulation and liquid handling.
However, these models often struggle with accuracy due to epistemic uncertainty
or the sim-to-real gap. For instance, accurately pouring liquid from one
container to another poses challenges, particularly when models are trained on
limited demonstrations and may perform poorly in novel situations. This paper
proposes an uncertainty-aware Monte Carlo Tree Search (MCTS) algorithm designed
to mitigate these inaccuracies. By incorporating estimates of model
uncertainty, the proposed MCTS strategy biases the search towards actions with
lower predicted uncertainty. This approach enhances the reliability of planning
under uncertain conditions. Applied to a liquid pouring task, our method
demonstrates improved success rates even with models trained on minimal data,
outperforming traditional methods and showcasing its potential for robust
decision-making in robotics.

</details>


### [41] [A Human-in-the-loop Approach to Robot Action Replanning through LLM Common-Sense Reasoning](https://arxiv.org/abs/2507.20870)
*Elena Merlo,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出了一种结合视觉和自然语言输入的方法，通过LLM增强机器人执行计划，提高非专家编程的效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 为非专家提供更直观的机器人编程工具，解决仅依赖视觉输入的局限性和单次演示的不足。

Method: 利用人类反馈和LLM的常识推理，通过自然语言输入调整基于RGB视频生成的机器人执行计划。

Result: 实验表明该方法能有效纠正视觉错误并适应新指令，无需额外演示。

Conclusion: 交互式计划优化和幻觉纠正提升了系统鲁棒性，为非专家编程提供了高效解决方案。

Abstract: To facilitate the wider adoption of robotics, accessible programming tools
are required for non-experts. Observational learning enables intuitive human
skills transfer through hands-on demonstrations, but relying solely on visual
input can be inefficient in terms of scalability and failure mitigation,
especially when based on a single demonstration. This paper presents a
human-in-the-loop method for enhancing the robot execution plan, automatically
generated based on a single RGB video, with natural language input to a Large
Language Model (LLM). By including user-specified goals or critical task
aspects and exploiting the LLM common-sense reasoning, the system adjusts the
vision-based plan to prevent potential failures and adapts it based on the
received instructions. Experiments demonstrated the framework intuitiveness and
effectiveness in correcting vision-derived errors and adapting plans without
requiring additional demonstrations. Moreover, interactive plan refinement and
hallucination corrections promoted system robustness.

</details>


### [42] [PixelNav: Towards Model-based Vision-Only Navigation with Topological Graphs](https://arxiv.org/abs/2507.20892)
*Sergey Bakulin,Timur Akhtyamov,Denis Fatykhov,German Devchich,Gonzalo Ferrer*

Main category: cs.RO

TL;DR: 提出了一种结合深度学习和经典模型规划算法的混合方法，用于移动机器人的纯视觉导航，解决了纯数据驱动模型的训练数据需求大和可解释性差的问题。


<details>
  <summary>Details</summary>
Motivation: 纯数据驱动的端到端模型虽然灵活适应性强，但需要大量训练数据且可解释性有限，限制了实际应用。

Method: 采用分层系统，结合模型预测控制、可通行性估计、视觉地点识别和位姿估计等技术，使用拓扑图表示目标环境。

Result: 实验证明该方法高效且比端到端方法更具可扩展性和可解释性。

Conclusion: 提出的混合方法在纯视觉导航中表现出色，兼具灵活性和可解释性。

Abstract: This work proposes a novel hybrid approach for vision-only navigation of
mobile robots, which combines advances of both deep learning approaches and
classical model-based planning algorithms. Today, purely data-driven end-to-end
models are dominant solutions to this problem. Despite advantages such as
flexibility and adaptability, the requirement of a large amount of training
data and limited interpretability are the main bottlenecks for their practical
applications. To address these limitations, we propose a hierarchical system
that utilizes recent advances in model predictive control, traversability
estimation, visual place recognition, and pose estimation, employing
topological graphs as a representation of the target environment. Using such a
combination, we provide a scalable system with a higher level of
interpretability compared to end-to-end approaches. Extensive real-world
experiments show the efficiency of the proposed method.

</details>
