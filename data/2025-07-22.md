<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach](https://arxiv.org/abs/2507.14249)
*Yuejiao Xie,Maonan Wang,Di Zhou,Man-On Pun,Zhu Han*

Main category: cs.RO

TL;DR: 本文提出构建无线电地图评估城市空域通信质量，并引入多源混合注意力强化学习（MSHA-RL）框架，以解决城市空中交通（UAM）轨迹规划中通信质量保障和动态乘客需求响应的挑战，实验表明该方法能实现通信合规的轨迹规划，减少旅行时间并提高运营效率，同时保障乘客安全。


<details>
  <summary>Details</summary>
Motivation: UAM轨迹规划需优先考虑通信质量以确保安全，且作为空中出租车需适应实时乘客请求，尤其是拼车场景中需求不可预测，但传统基于预定义路线的策略缺乏灵活性，无法满足多样的乘客出行需求。

Method: 首先构建无线电地图评估城市空域通信质量，然后引入多源混合注意力强化学习（MSHA-RL）框架，该模型先对维度差距大的多样数据源进行对齐，再采用混合注意力平衡全局和局部见解，以实现响应式实时路径规划。

Result: 实验结果表明，该方法能够实现通信合规的轨迹规划，减少旅行时间，提高运营效率，同时优先保障乘客安全。

Conclusion: 所提出的构建无线电地图和MSHA-RL框架的方法，有效解决了UAM轨迹规划中的通信质量和动态需求响应问题，提升了UAM系统的安全性、效率和适应性。

Abstract: Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions
to alleviate urban congestion, with path planning becoming a key focus area.
Unlike ground transportation, UAM trajectory planning has to prioritize
communication quality for accurate location tracking in constantly changing
environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,
requires adaptive planning to respond to real-time passenger requests,
especially in ride-sharing scenarios where passenger demands are unpredictable
and dynamic. However, conventional trajectory planning strategies based on
predefined routes lack the flexibility to meet varied passenger ride demands.
To address these challenges, this work first proposes constructing a radio map
to evaluate the communication quality of urban airspace. Building on this, we
introduce a novel Multi-Source Hybrid Attention Reinforcement Learning
(MSHA-RL) framework for the challenge of effectively focusing on passengers and
UAM locations, which arises from the significant dimensional disparity between
the representations. This model first generates the alignment among diverse
data sources with large gap dimensions before employing hybrid attention to
balance global and local insights, thereby facilitating responsive, real-time
path planning. Extensive experimental results demonstrate that the approach
enables communication-compliant trajectory planning, reducing travel time and
enhancing operational efficiency while prioritizing passenger safety.

</details>


### [2] [A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators](https://arxiv.org/abs/2507.14274)
*Andreas Mueller,Shivesh Kumar,Thomas Kordik*

Main category: cs.RO

TL;DR: 本文首次研究了带串联弹性执行器（SEA）的并联机器人（PKM）轨迹控制，关键是高效计算逆动力学解的二阶时间导数，利用PKM拓扑特性复用串联机器人逆动力学递归算法，基于李群公式推导，并通过6-DOF Gough-Stewart平台和平面PKM的数值结果验证。


<details>
  <summary>Details</summary>
Motivation: 串联弹性执行器（SEA）的串联机器人模型轨迹跟踪控制需逆动力学解的二阶时间导数算法已存在，但带SEA的并联机器人（PKM）轨迹控制尚未被研究，而高效计算逆动力学解的二阶时间导数是关键，此问题在文献中未被提出。

Method: 利用并联机器人（PKM）的特殊拓扑结构，复用串联机器人逆动力学的递归算法，采用李群公式推导所有关系。

Result: 针对6-DOF Gough-Stewart平台（作为外骨骼一部分）和应用基于平坦性控制方案的平面PKM，给出了数值结果。

Conclusion: 本文首次解决了带SEA的PKM轨迹控制中逆动力学解二阶时间导数的高效计算问题，为该领域提供了可行方法。

Abstract: Series elastic actuators (SEA) were introduced for serial robotic arms. Their
model-based trajectory tracking control requires the second time derivatives of
the inverse dynamics solution, for which algorithms were proposed. Trajectory
control of parallel kinematics manipulators (PKM) equipped with SEAs has not
yet been pursued. Key element for this is the computationally efficient
evaluation of the second time derivative of the inverse dynamics solution. This
has not been presented in the literature, and is addressed in the present paper
for the first time. The special topology of PKM is exploited reusing the
recursive algorithms for evaluating the inverse dynamics of serial robots. A
Lie group formulation is used and all relations are derived within this
framework. Numerical results are presented for a 6-DOF Gough-Stewart platform
(as part of an exoskeleton), and for a planar PKM when a flatness-based control
scheme is applied.

</details>


### [3] [Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support](https://arxiv.org/abs/2507.14412)
*Mengxue Fu,Zhonghao Shi,Minyu Huang,Siqi Liu,Mina Kian,Yirui Song,Maja J. Matarić*

Main category: cs.RO

TL;DR: 本文提出将端到端语音语言模型（SLMs）集成到社交辅助机器人（SARs）中，以解决现有对话管道在实时延迟、回应和个性化语音对话方面的限制，通过用户研究评估了系统可用性并基于反馈确定了需改进的方向，如实时动作同步、优化提示或微调以符合心理健康实践及更具表现力的语音生成。


<details>
  <summary>Details</summary>
Motivation: 现有社交辅助机器人（SARs）的对话管道在实时延迟、回应和个性化语音对话方面存在局限性，需要解决这些问题以提升SARs的辅助效果。

Method: 进行了一项小规模的参与者内用户研究，对象为11名大学生，评估了集成SLM的SAR对话系统的可用性，并通过用户反馈识别剩余的局限性。

Result: 用户认为SLM驱动的SAR系统能够提供共情反馈、自然的轮流对话、回应和适应性回应，但机器人的非语言行为缺乏多样性且与对话同步性差，SLM的语言反馈较为通用和重复。

Conclusion: 研究结果强调了实时机器人动作与对话同步、改进提示或微调以生成更符合心理健康实践的输出以及更具表现力和适应性的语音生成的必要性。

Abstract: Socially assistive robots (SARs) have shown great potential for supplementing
well-being support. However, prior studies have found that existing dialogue
pipelines for SARs remain limited in real-time latency, back-channeling, and
personalized speech dialogue. Toward addressing these limitations, we propose
using integrated end-to-end speech-language models (SLMs) with SARs. This work
1) evaluated the usability of an SLM-enabled SAR dialogue system through a
small user study, and 2) identified remaining limitations through study user
feedback to inform future improvements. We conducted a small within-participant
user study with university students (N = 11) whose results showed that
participants perceived an SLM-enabled SAR system as capable of providing
empathetic feedback, natural turn-taking, back-channeling, and adaptive
responses. We also found that participants reported the robot's nonverbal
behaviors as lacking variability and synchronization with conversation, and the
SLM's verbal feedback as generic and repetitive. These findings highlighted the
need for real-time robot movement synchronized with conversation, improved
prompting or fine-tuning to generate outputs better aligned with mental health
practices, and more expressive, adaptive vocal generation.

</details>


### [4] [Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking](https://arxiv.org/abs/2507.14455)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 该研究表明，只要周期非光滑或混合系统的模态和时序行为一致，时间延迟嵌入技术可将其建模为线性状态空间系统，并将该方法扩展到弹跳摆和最简单步行者两个系统，进而提出一种新颖的状态历史增强线性二次调节器（LQR）用于反馈控制。


<details>
  <summary>Details</summary>
Motivation: 传统时间延迟嵌入技术用于非线性光滑系统构建线性状态空间模型，而周期非光滑或混合系统能否用该方法建模尚需验证。

Method: 将时间延迟嵌入技术扩展应用于周期非光滑或混合系统，通过利用系统当前和过去的状态历史，为弹跳摆和带控制输入的最简单步行者生成线性模型，并基于此设计状态历史增强的LQR。

Result: 成功将时间延迟嵌入技术扩展到两个周期混合系统（弹跳摆和最简单步行者），生成了线性模型，并提出了状态历史增强LQR用于反馈控制。

Conclusion: 只要周期非光滑或混合系统的模态和时序行为一致，时间延迟嵌入技术可将其建模为线性状态空间系统，且基于此设计的状态历史增强LQR能有效利用状态历史进行反馈控制。

Abstract: Time-delay embedding is a technique that uses snapshots of state history over
time to build a linear state space model of a nonlinear smooth system. We
demonstrate that periodic non-smooth or hybrid system can also be modeled as a
linear state space system using this approach as long as its behavior is
consistent in modes and timings. We extended time-delay embeddings to generate
a linear model of two periodic hybrid systems: the bouncing pendulum and the
simplest walker with control inputs. This leads to a novel state history
augmented linear quadratic regulator (LQR) which uses current and past state
history for feedback control.

</details>


### [5] [A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0](https://arxiv.org/abs/2507.14538)
*Jin Chai,Xiang Yao,Mengfan Hou,Yanghong Li,Erbao Dong*

Main category: cs.RO

TL;DR: CYJ Hand-0是一款21自由度仿人灵巧手，采用形状记忆合金（SMAs）和直流电机相结合的混合肌腱驱动系统，通过高强度钓鱼线作为人工肌腱和全3D打印AlSi10Mg金属框架模拟人手骨骼和肌腱肌肉结构，集成线性电机驱动模块控制手指屈曲、SMA模块实现手指伸展和侧向外展，经基于Arduino Mega 2560的控制系统验证了设计有效性和仿生灵活性。


<details>
  <summary>Details</summary>
Motivation: 开发具有仿生灵巧性的仿人灵巧手，以模拟人手的骨骼和肌腱肌肉结构，实现手指的多种运动功能。

Method: 采用混合肌腱驱动系统，结合SMAs和直流电机；使用高强度钓鱼线作为人工肌腱，全3D打印AlSi10Mg金属框架；设计线性电机驱动模块控制手指屈曲，SMA模块实现手指伸展和侧向外展，并将这些模块集成到紧凑的混合驱动单元中，安装在定制的后部支撑结构上；通过基于Arduino Mega 2560的控制系统进行机械和运动学实验。

Result: 机械和运动学实验验证了设计的有效性，并展示了其仿生灵巧性。

Conclusion: CYJ Hand-0的设计有效，具备仿生灵巧性，混合肌腱驱动系统和3D打印金属框架等设计方案可行。

Abstract: CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid
tendon-driven actuation system that combines shape memory alloys (SMAs) and DC
motors. The hand employs high-strength fishing line as artificial tendons and
uses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal
and tendon-muscle structure of the human hand. A linear motor-driven module
controls finger flexion, while an SMA-based module enables finger extension and
lateral abduction. These modules are integrated into a compact hybrid actuation
unit mounted on a custom rear support structure. Mechanical and kinematic
experiments, conducted under an Arduino Mega 2560-based control system,
validate the effectiveness of the design and demonstrate its biomimetic
dexterity.

</details>


### [6] [BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives](https://arxiv.org/abs/2507.14582)
*Zezhi Liu,Shizhen Wu,Hanqian Luo,Deyun Qin,Yongchun Fang*

Main category: cs.RO

TL;DR: 本文提出BT-TL-DMPs分层框架，集成行为树（BT）、时序逻辑（TL）和动态运动基元（DMPs），解决机器人在长时任务中泛化学习操作技能的问题，通过STL规范任务需求并生成BTs，优化DMP力项以适应新环境，经仿真和实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 在从演示中学习（LfD）领域，机器人难以将学到的操作技能泛化到新场景的长时任务中，尤其在具有复杂约束的多阶段场景下，难以适应不同任务和运动需求的新环境。

Method: 提出BT-TL-DMPs分层框架，集成BT、TL和DMPs。使用信号时序逻辑（STL）规范复杂长时任务需求和约束，将其转化为反应式模块化BTs用于高层决策；提出STL约束的DMP优化方法，优化DMP力项，使运动基元在满足时空需求的同时保留演示学习的基本动力学。

Result: 通过仿真验证了在各种STL约束下的泛化能力，并在多个长时机器人操作任务上进行了真实世界实验，结果表明该框架有效弥合了符号-运动差距，实现了更可靠和可泛化的复杂机器人自主操作。

Conclusion: 所提出的BT-TL-DMPs框架能有效解决机器人在长时任务中泛化学习操作技能的问题，通过STL规范任务、生成BTs和优化DMPs，实现了复杂环境下可靠且可泛化的自主操作。

Abstract: In the field of Learning from Demonstration (LfD), enabling robots to
generalize learned manipulation skills to novel scenarios for long-horizon
tasks remains challenging. Specifically, it is still difficult for robots to
adapt the learned skills to new environments with different task and motion
requirements, especially in long-horizon, multi-stage scenarios with intricate
constraints. This paper proposes a novel hierarchical framework, called
BT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and
Dynamical Movement Primitives (DMPs) to address this problem. Within this
framework, Signal Temporal Logic (STL) is employed to formally specify complex,
long-horizon task requirements and constraints. These STL specifications are
systematically transformed to generate reactive and modular BTs for high-level
decision-making task structure. An STL-constrained DMP optimization method is
proposed to optimize the DMP forcing term, allowing the learned motion
primitives to adapt flexibly while satisfying intricate spatiotemporal
requirements and, crucially, preserving the essential dynamics learned from
demonstrations. The framework is validated through simulations demonstrating
generalization capabilities under various STL constraints and real-world
experiments on several long-horizon robotic manipulation tasks. The results
demonstrate that the proposed framework effectively bridges the symbolic-motion
gap, enabling more reliable and generalizable autonomous manipulation for
complex robotic tasks.

</details>


### [7] [Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition](https://arxiv.org/abs/2507.14605)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 本文利用Koopman算子理论和扩展动态模态分解（EDMD）创建高维空间线性模型以保留四足机器人运动方程非线性，对空中和地面接触阶段采用不同线性模型，通过线性模型预测控制（LMPC）实现了平地形和崎岖地形下的跳跃、小跑及步态转换。


<details>
  <summary>Details</summary>
Motivation: LMPC依赖运动方程线性化可能导致解质量差，需解决四足机器人在线最优控制中因线性化带来的问题以实现新场景下的运动规划。

Method: 使用Koopman算子理论和EDMD构建高维空间线性模型，为空中和地面接触阶段分别建立不同线性模型，结合LMPC进行控制。

Result: 成功展示了平地形和崎岖地形下的跳跃、小跑步态以及跳跃-小跑、小跑-跳跃的步态转换。

Conclusion: Koopman算子理论可用于创建四足系统混合模型，实现多种步态及步态转换的在线生成。

Abstract: Online optimal control of quadrupedal robots would enable them to plan their
movement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged
as a practical approach for real-time control. In LMPC, an optimization problem
with a quadratic cost and linear constraints is formulated over a finite
horizon and solved on the fly. However, LMPC relies on linearizing the
equations of motion (EOM), which may lead to poor solution quality. In this
paper, we use Koopman operator theory and the Extended Dynamic Mode
Decomposition (EDMD) to create a linear model of the system in high dimensional
space, thus retaining the nonlinearity of the EOM. We model the aerial phase
and ground contact phases using different linear models. Then, using LMPC, we
demonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait
transitions in level and rough terrains. The main novelty is the use of Koopman
operator theory to create hybrid models of a quadrupedal system and demonstrate
the online generation of multiple gaits and gaits transitions.

</details>


### [8] [Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks](https://arxiv.org/abs/2507.14694)
*Yue Ma,Kanglei Zhou,Fuyang Yu,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.RO

TL;DR: 本文提出ProbHMI方法，通过可逆网络将姿态参数化到解耦潜空间，实现概率动力学建模，在3D人体运动预测中同时提升确定性和多样性预测性能，并验证了不确定性校准对风险感知决策的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体运动预测方法因隐式概率表示难以建模不确定性，而在人机协作等安全关键场景中，为最小化风险，对每个预测进行不确定性估计（基于概率密度或分位数的置信度）至关重要。

Method: 提出ProbHMI，引入可逆网络将姿态参数化到解耦潜空间以实现概率动力学建模，然后通过预测模块显式预测未来潜分布，从而有效量化不确定性。

Result: 在基准测试中，ProbHMI在确定性和多样性预测方面均取得良好性能，同时验证了不确定性校准，这对风险感知决策至关重要。

Conclusion: ProbHMI通过显式概率建模解决了现有方法的不确定性量化难题，兼顾预测性能与不确定性校准，为安全关键场景下的风险感知决策提供支持。

Abstract: 3D human motion forecasting aims to enable autonomous applications.
Estimating uncertainty for each prediction (i.e., confidence based on
probability density or quantile) is essential for safety-critical contexts like
human-robot collaboration to minimize risks. However, existing diverse motion
forecasting approaches struggle with uncertainty quantification due to implicit
probabilistic representations hindering uncertainty modeling. We propose
ProbHMI, which introduces invertible networks to parameterize poses in a
disentangled latent space, enabling probabilistic dynamics modeling. A
forecasting module then explicitly predicts future latent distributions,
allowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI
achieves strong performance for both deterministic and diverse prediction while
validating uncertainty calibration, critical for risk-aware decision making.

</details>


### [9] [Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.14700)
*Nicholas Mohammad,Nicola Bezzo*

Main category: cs.RO

TL;DR: 本文提出一种结合控制李雅普诺夫函数（CLF）和控制障碍函数（CBF）的模型预测轮廓控制（MPCC）框架，通过自由空间走廊的安全约束及基于Soft Actor-Critic（SAC）策略动态调整CBF参数，以解决未知复杂环境中机器人安全导航问题，并经仿真和实验验证。


<details>
  <summary>Details</summary>
Motivation: 现有模型预测轮廓控制（MPCC）在机器人避障中虽能实现精确轨迹跟踪，但缺乏正式的安全保证，无法满足未知复杂环境下的安全导航需求。

Method: 提出CLF和CBF增强的MPCC框架，利用规划轨迹周围的自由空间走廊生成安全约束；通过SAC策略在运行时动态调整CBF参数以提升可行性。

Result: 通过大量仿真和移动机器人在未知复杂环境中的导航实验验证了该方法的有效性。

Conclusion: 所提框架能够在未知复杂环境中为机器人提供安全导航能力，动态调整CBF参数可增强控制可行性。

Abstract: Safe navigation in unknown and cluttered environments remains a challenging
problem in robotics. Model Predictive Contour Control (MPCC) has shown promise
for performant obstacle avoidance by enabling precise and agile trajectory
tracking, however, existing methods lack formal safety assurances. To address
this issue, we propose a general Control Lyapunov Function (CLF) and Control
Barrier Function (CBF) enabled MPCC framework that enforces safety constraints
derived from a free-space corridor around the planned trajectory. To enhance
feasibility, we dynamically adapt the CBF parameters at runtime using a Soft
Actor-Critic (SAC) policy. The approach is validated with extensive simulations
and an experiment on mobile robot navigation in unknown cluttered environments.

</details>


### [10] [Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls](https://arxiv.org/abs/2507.14721)
*Keita Kobashi,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 该研究针对遮挡抓取问题，提出了一种分层强化学习框架，结合Q学习和条件变分自编码器（CVAE），并通过领域随机化提升泛化能力，在模拟中训练后成功实现真实世界的抓取任务。


<details>
  <summary>Details</summary>
Motivation: 现有研究在处理遮挡抓取时，常假设存在短墙等环境特征以辅助物体姿态调整（如旋转），但现实场景中可能缺乏此类条件，若环境特征过大/过高，单纯旋转仍无法使物体可抓取，需结合多种动作类型。

Method: 提出分层强化学习框架：高层策略用Q学习选择动作类型，低层技能在连续空间采样具体动作；采用CVAE根据物体点云和技能ID推断执行动作的合适位置；训练低层技能时应用领域随机化。

Result: 在模拟中用类盒物体训练RL策略，部署到真实世界6个物体上，实验证明方法具有良好泛化性和稳健的模拟到现实迁移性能，成功率可观。

Conclusion: 所提分层强化学习框架能有效解决因环境遮挡导致的抓取难题，通过结合高层动作选择、低层技能执行及CVAE引导位置推断，实现了复杂环境下的遮挡抓取任务。

Abstract: This study addresses the problem of occluded grasping, where primary grasp
configurations of an object are not available due to occlusion with
environment. Simple parallel grippers often struggle with such tasks due to
limited dexterity and actuation constraints. Prior works have explored object
pose reorientation such as pivoting by utilizing extrinsic contacts between an
object and an environment feature like a wall, to make the object graspable.
However, such works often assume the presence of a short wall, and this
assumption may not always hold in real-world scenarios. If the wall available
for interaction is too large or too tall, the robot may still fail to grasp the
object even after pivoting, and the robot must combine different types of
actions to grasp. To address this, we propose a hierarchical reinforcement
learning (RL) framework. We use Q-learning to train a high-level policy that
selects the type of action expected to yield the highest reward. The selected
low-level skill then samples a specific robot action in continuous space. To
guide the robot to an appropriate location for executing the selected action,
we adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on
the object point cloud and the skill ID, enabling it to infer a suitable
location based on the object geometry and the selected skill. To promote
generalization, we apply domain randomization during the training of low-level
skills. The RL policy is trained entirely in simulation with a box-like object
and deployed to six objects in real world. We conduct experiments to evaluate
our method and demonstrate both its generalizability and robust sim-to-real
transfer performance with promising success rates.

</details>


### [11] [X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots](https://arxiv.org/abs/2507.14731)
*Haitong Wang,Aaron Hao Tan,Angus Fung,Goldie Nejat*

Main category: cs.RO

TL;DR: 本文提出X-Nav框架，通过两阶段学习（专家策略训练与通用策略蒸馏）实现端到端跨机器人形态导航，能零样本迁移至未见形态和真实环境，性能随训练形态数量增加而提升。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法主要针对特定机器人形态设计，限制了在不同机器人平台的通用性。

Method: X-Nav包含两个学习阶段：1)使用深度强化学习和特权观测训练多种专家策略（针对大量随机生成的机器人形态）；2)通过导航动作分块与Transformer（Nav-ACT）从专家策略中蒸馏出单一通用策略，该策略直接将视觉和本体感受观测映射到低级控制命令。

Result: 模拟实验表明X-Nav实现了对未见形态和逼真环境的零样本迁移；可扩展性研究显示，随着随机生成形态数量增加，性能提升；消融实验证实了设计选择；真实世界实验验证了其在真实环境中的通用性。

Conclusion: X-Nav框架能够实现端到端跨形态导航，单一通用策略可部署于轮式和四足机器人等多种形态，具有良好的零样本迁移能力和可扩展性，并在真实环境中得到验证。

Abstract: Existing navigation methods are primarily designed for specific robot
embodiments, limiting their generalizability across diverse robot platforms. In
this paper, we introduce X-Nav, a novel framework for end-to-end
cross-embodiment navigation where a single unified policy can be deployed
across various embodiments for both wheeled and quadrupedal robots. X-Nav
consists of two learning stages: 1) multiple expert policies are trained using
deep reinforcement learning with privileged observations on a wide range of
randomly generated robot embodiments; and 2) a single general policy is
distilled from the expert policies via navigation action chunking with
transformer (Nav-ACT). The general policy directly maps visual and
proprioceptive observations to low-level control commands, enabling
generalization to novel robot embodiments. Simulated experiments demonstrated
that X-Nav achieved zero-shot transfer to both unseen embodiments and
photorealistic environments. A scalability study showed that the performance of
X-Nav improves when trained with an increasing number of randomly generated
embodiments. An ablation study confirmed the design choices of X-Nav.
Furthermore, real-world experiments were conducted to validate the
generalizability of X-Nav in real-world environments.

</details>


### [12] [KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning](https://arxiv.org/abs/2507.14820)
*Bingran Chen,Baorun Li,Jian Yang,Yong Liu,Guangyao Zhai*

Main category: cs.RO

TL;DR: 本文提出KGN-Pro，一种新型抓取网络，通过保留2D表示的效率和细粒度抓取能力，同时集成基于概率PnP层的直接3D优化，解决了以往方法在小物体、传感器噪声、标注成本及3D信息利用不足等问题，实验表明其抓取覆盖率和成功率优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 以往6-DoF抓取估计方法存在不足：直接从点云生成抓取面临小物体和传感器噪声挑战；从RGB图像推断3D信息需昂贵标注且有离散化问题；近期基于2D关键点和PnP算法的方法因非可微性和仅依赖2D监督，无法充分利用丰富3D信息。

Method: KGN-Pro编码RGB-D图像对生成关键点图，输出2D置信图以加权关键点在重投影误差最小化中的贡献，通过概率建模加权平方重投影误差和，将3D监督有效传递至2D关键点预测，实现端到端学习。

Result: 在模拟和真实平台上的实验表明，KGN-Pro在抓取覆盖率和成功率方面优于现有方法。

Conclusion: KGN-Pro通过结合2D表示优势与概率PnP层的3D优化，有效解决了以往6-DoF抓取估计方法的缺陷，提升了抓取性能。

Abstract: High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation
to serve as a basic function. Previous approaches either directly generate
grasps from point-cloud data, suffering from challenges with small objects and
sensor noise, or infer 3D information from RGB images, which introduces
expensive annotation requirements and discretization issues. Recent methods
mitigate some challenges by retaining a 2D representation to estimate grasp
keypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF
poses. However, these methods are limited by their non-differentiable nature
and reliance solely on 2D supervision, which hinders the full exploitation of
rich 3D information. In this work, we present KGN-Pro, a novel grasping network
that preserves the efficiency and fine-grained object grasping of previous KGNs
while integrating direct 3D optimization through probabilistic PnP layers.
KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further
outputs a 2D confidence map to weight keypoint contributions during
re-projection error minimization. By modeling the weighted sum of squared
re-projection errors probabilistically, the network effectively transmits 3D
supervision to its 2D keypoint predictions, enabling end-to-end learning.
Experiments on both simulated and real-world platforms demonstrate that KGN-Pro
outperforms existing methods in terms of grasp cover rate and success rate.

</details>


### [13] [CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning](https://arxiv.org/abs/2507.14903)
*Pan Hu*

Main category: cs.RO

TL;DR: 本文提出了一种名为Cohesive Decision-Guided Motion Planning (CDGMP)的框架，该框架利用混合专家(MoE)启发的架构结合多策略强化学习，紧密集成决策制定（高速公路车道选择）和运动规划（生成控制命令），以提升自动驾驶汽车在不同交通场景中的适应性、鲁棒性和安全性，为现实世界的自动驾驶挑战提供可扩展解决方案。


<details>
  <summary>Details</summary>
Motivation: 在联网自动驾驶汽车(CAVs)中，实现灵活安全的车道选择和精确的轨迹执行仍是一项重大挑战。

Method: 提出CDGMP框架，通过MoE启发的架构结合多策略强化学习，利用门控机制协调多个专用子网络，将复杂驾驶任务分解为模块化组件，每个子网络专注于驾驶的特定方面，在推理过程中仅激活最相关的模块。

Result: 仿真结果表明，CDGMP在车道选择和运动规划方面均表现出可靠的性能（视频链接：https://youtu.be/_-4OXNHV0UY）。

Conclusion: CDGMP提高了CAVs在不同交通场景中的适应性和鲁棒性，为现实世界的自动驾驶挑战提供了可扩展的解决方案，其架构原理（尤其是MoE的使用）也为其他高维决策和控制任务提供了坚实基础。

Abstract: Autonomous driving demands reliable and efficient solutions to closely
related problems such as decision-making and motion planning. In this work,
decision-making refers specifically to highway lane selection, while motion
planning involves generating control commands (such as speed and steering) to
reach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs),
achieving both flexible and safe lane selection alongside precise trajectory
execution remains a significant challenge. This paper proposes a framework
called Cohesive Decision-Guided Motion Planning (CDGMP), which tightly
integrates decision-making and motion planning using a Mixture of Experts (MoE)
inspired architecture combined with multi-policy reinforcement learning. By
coordinating multiple specialized sub-networks through a gating mechanism, the
method decomposes the complex driving task into modular components. Each
sub-network focuses on a specific aspect of driving, improving efficiency by
activating only the most relevant modules during inference. This design also
enhances safety through modular specialization. CDGMP improves the adaptability
and robustness of CAVs across diverse traffic scenarios, offering a scalable
solution to real-world autonomy challenges. The architectural principles behind
CDGMP, especially the use of MoE, also provide a strong foundation for other
high-dimensional decision and control tasks. Simulation results (available at
https://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane
selection and motion planning.

</details>


### [14] [One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner](https://arxiv.org/abs/2507.14914)
*Zhexuan Xu,Jie Wang,Siyuan Xu,Zijie Geng,Mingxuan Yuan,Feng Wu*

Main category: cs.RO

TL;DR: 提出Flora，一种三阶段的考虑馈通和布局感知的矩形布图规划器，以解决现有布图规划方法与后续物理设计阶段集成不足的问题，实验表明其在HPWL、FTpin、FTmod和组件布局性能上优于最新技术。


<details>
  <summary>Details</summary>
Motivation: 现有布图规划方法常无法与后续物理设计阶段集成，导致模块内组件布局次优和模块间馈通过多。

Method: Flora分为三阶段：第一阶段使用线掩码和位置掩码技术实现HPWL和馈通的粗粒度优化；第二阶段在固定轮廓约束下通过局部调整模块形状实现零空白布局，进行馈通的细粒度优化并改善组件布局；第三阶段利用基于快速树搜索的方法高效放置每个模块内的组件（包括宏和标准单元），随后根据布局结果调整模块边界以实现跨阶段优化。

Result: 实验结果显示，Flora优于最新的布图规划方法，HPWL平均减少6%，FTpin减少5.16%，FTmod减少29.15%，组件布局性能提高14%。

Conclusion: Flora通过三阶段设计有效解决了现有布图规划与后续物理设计集成不足的问题，在多项指标上表现更优。

Abstract: Floorplanning determines the shapes and locations of modules on a chip canvas
and plays a critical role in optimizing the chip's Power, Performance, and Area
(PPA) metrics. However, existing floorplanning approaches often fail to
integrate with subsequent physical design stages, leading to suboptimal
in-module component placement and excessive inter-module feedthrough. To tackle
this challenge, we propose Flora, a three-stage feedthrough and placement aware
rectilinear floorplanner. In the first stage, Flora employs wiremask and
position mask techniques to achieve coarse-grained optimization of HPWL and
feedthrough. In the second stage, under the constraint of a fixed outline,
Flora achieves a zero-whitespace layout by locally resizing module shapes,
thereby performing fine-grained optimization of feedthrough and improving
component placement. In the third stage, Flora utilizes a fast tree
search-based method to efficiently place components-including macros and
standard cells-within each module, subsequently adjusting module boundaries
based on the placement results to enable cross-stage optimization. Experimental
results show that Flora outperforms recent state-of-the-art floorplanning
approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,
29.15% in FTmod, and a 14% improvement in component placement performance.

</details>


### [15] [Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly](https://arxiv.org/abs/2507.14929)
*Tero Kaarlela,Sami Salo,Jose Outeiro*

Main category: cs.RO

TL;DR: 本文提出了一种远程操作系统，用于电动汽车电池（EVB）的安全拆卸与分类，结合远程操作与自动化，通过人类在环创建拆卸序列、RGB相机对齐物理与数字孪生及ROS机器人数字孪生，以提高安全性、适应性和效率，减少劳动力依赖并增加回收吞吐量，在线试点研究表明该方案具有用户友好潜力。


<details>
  <summary>Details</summary>
Motivation: 当前手动拆卸过程使工人面临触电和有毒化学物质等危险，需要一种更安全的EVB拆卸与分类方法。

Method: 提出远程操作系统，采用人类在环创建和保存未知EVB类型的拆卸序列，利用RGB相机对齐EVB的物理与数字孪生，基于ROS中间件构建机器人数字孪生，结合远程操作与自动化的混合方法。

Result: 在线试点研究评估了该方法的可用性，结果表明其具有作为用户友好解决方案的潜力，能减少劳动力依赖并提高电池回收吞吐量。

Conclusion: 该混合方法通过结合远程操作和自动化，在EVB拆卸和分类中提高了安全性、适应性和效率，具有经济贡献和用户友好性，支持电动汽车的可持续转型。

Abstract: Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a
sustainable transition to electric vehicles by enabling a closed-loop supply
chain. Currently, the manual disassembly process exposes workers to hazards,
including electrocution and toxic chemicals. We propose a teleoperated system
for the safe disassembly and sorting of EVBs. A human-in-the-loop can create
and save disassembly sequences for unknown EVB types, enabling future
automation. An RGB camera aligns the physical and digital twins of the EVB, and
the digital twin of the robot is based on the Robot Operating System (ROS)
middleware. This hybrid approach combines teleoperation and automation to
improve safety, adaptability, and efficiency in EVB disassembly and sorting.
The economic contribution is realized by reducing labor dependency and
increasing throughput in battery recycling. An online pilot study was set up to
evaluate the usability of the presented approach, and the results demonstrate
the potential as a user-friendly solution.

</details>


### [16] [Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry](https://arxiv.org/abs/2507.14931)
*Qiaoqiao Ren,Remko Proesmans,Arend Pissens,Lara Dehandschutter,William Denecker,Lotte Rouckhout,Joke Carrette,Peter Vanhopplinus,Tony Belpaeme,Francis wyffels*

Main category: cs.RO

TL;DR: 本文探讨了在法医精神健康护理环境中，如何通过共同设计开发陪伴机器人，以帮助监测和调节患者压力，同时跟踪其互动行为用于长期干预。研究在法医精神病诊所与患者、护理人员和治疗师开展了四次共同设计工作坊，强调赋权患者并根据其情绪状态调整方案。


<details>
  <summary>Details</summary>
Motivation: 法医精神健康护理环境存在高度官僚主义、风险规避和自主性受限等问题，患者常失去生活控制权，导致心理压力加剧甚至被隔离，因此需要开发能帮助监测和调节压力并跟踪互动行为的工具。

Method: 在法医精神病诊所与患者、护理人员和治疗师进行了四次共同设计工作坊：向治疗师展示初始推测原型以反思共同关注、伦理风险和期望功能；与患者开展创意构思会议；第三次工作坊聚焦定义所需功能和情绪反应；计划进行最终原型演示以收集患者直接反馈。

Result: 强调了在设计过程中赋权患者以及根据患者当前情绪状态调整提案的重要性，目标是让患者在设计过程中拥有权力并确保每个患者的声音被听到。

Conclusion: 通过共同设计开发陪伴机器人有助于在法医精神健康护理中更好地满足患者需求，赋权患者参与设计过程并关注其情绪状态对提升干预效果具有重要意义。

Abstract: Forensic mental health care involves the treatment of individuals with severe
mental disorders who have committed violent offences. These settings are often
characterized by high levels of bureaucracy, risk avoidance, and restricted
autonomy. Patients frequently experience a profound loss of control over their
lives, leading to heightened psychological stress-sometimes resulting in
isolation as a safety measure. In this study, we explore how co-design can be
used to collaboratively develop a companion robot that helps monitor and
regulate stress while maintaining tracking of the patients' interaction
behaviours for long-term intervention. We conducted four co-design workshops in
a forensic psychiatric clinic with patients, caregivers, and therapists. Our
process began with the presentation of an initial speculative prototype to
therapists, enabling reflection on shared concerns, ethical risks, and
desirable features. This was followed by a creative ideation session with
patients, a third workshop focused on defining desired functions and emotional
responses, and we are planning a final prototype demo to gather direct patient
feedback. Our findings emphasize the importance of empowering patients in the
design process and adapting proposals based on their current emotional state.
The goal was to empower the patient in the design process and ensure each
patient's voice was heard.

</details>


### [17] [Heterogeneous object manipulation on nonlinear soft surface through linear controller](https://arxiv.org/abs/2507.14967)
*Pratik Ingle,Kasper Støy,Andres Faiña*

Main category: cs.RO

TL;DR: 本文提出一种基于PID的线性闭环反馈控制策略，用于MANTA-RAY系统上的异质物体操作，无需大量黑盒训练，通过几何变换驱动PID控制器将倾斜角控制输出映射为执行器命令，经仿真和实验验证可成功操作多种几何形状、重量和纹理的物体，包括易碎品，具有高度泛化性和实用性。


<details>
  <summary>Details</summary>
Motivation: 高密度执行器阵列因自由度（DOF）增加导致操纵表面控制复杂，维护和控制成本随阵列/表面尺寸呈指数增长，基于学习的控制方法需大量训练样本且难以泛化到异质物体。

Method: 引入简单、精确且鲁棒的基于PID的线性闭环反馈控制策略，采用几何变换驱动的PID控制器，直接将倾斜角控制输出（1D/2D）映射为执行器命令，无需大量黑盒训练。

Result: 通过仿真和物理系统实验，成功操纵具有不同几何形状、重量和纹理的物体，包括鸡蛋和苹果等易碎物体。

Conclusion: 该方法具有高度泛化性，为软机器人操纵表面上的物体操纵提供了实用可靠的解决方案，无需高昂的训练需求，便于实际应用。

Abstract: Manipulation surfaces indirectly control and reposition objects by actively
modifying their shape or properties rather than directly gripping objects.
These surfaces, equipped with dense actuator arrays, generate dynamic
deformations. However, a high-density actuator array introduces considerable
complexity due to increased degrees of freedom (DOF), complicating control
tasks. High DOF restrict the implementation and utilization of manipulation
surfaces in real-world applications as the maintenance and control of such
systems exponentially increase with array/surface size. Learning-based control
approaches may ease the control complexity, but they require extensive training
samples and struggle to generalize for heterogeneous objects. In this study, we
introduce a simple, precise and robust PID-based linear close-loop feedback
control strategy for heterogeneous object manipulation on MANTA-RAY
(Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation
density). Our approach employs a geometric transformation-driven PID
controller, directly mapping tilt angle control outputs(1D/2D) to actuator
commands to eliminate the need for extensive black-box training. We validate
the proposed method through simulations and experiments on a physical system,
successfully manipulating objects with diverse geometries, weights and
textures, including fragile objects like eggs and apples. The outcomes
demonstrate that our approach is highly generalized and offers a practical and
reliable solution for object manipulation on soft robotic manipulation,
facilitating real-world implementation without prohibitive training demands.

</details>


### [18] [FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models](https://arxiv.org/abs/2507.14975)
*Yufan Song,Jiatao Zhang,Zeng Gu,Qingmiao Liang,Tuocheng Hu,Wei Song,Shiqiang Zhu*

Main category: cs.RO

TL;DR: 本文提出Flexible Constructivism Reflection Framework (FCRF)，一种基于导师-执行者架构的新型框架，旨在通过灵活的自我反思机制提升家庭机器人在复杂长时任务中的自主纠错能力，实验表明FCRF显著提高了性能和反思灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型（LLMs）的任务规划纠错方法受限于僵化的自我反思机制，影响其有效性，因此受人类认知适应启发，提出FCRF以解决该问题。

Method: 提出FCRF，采用导师-执行者架构，使LLMs能基于任务难度进行灵活自我反思，并将历史有价值经验与失败教训建设性整合。

Result: 在AlfWorld仿真和真实物理环境中对多种家庭任务进行评估，结果表明FCRF显著提升了复杂长时机器人任务的整体性能和自我反思灵活性。

Conclusion: FCRF通过灵活的自我反思机制和经验整合，有效提高了家庭机器人在复杂长时任务中的自主纠错能力和执行可靠性。

Abstract: Autonomous error correction is critical for domestic robots to achieve
reliable execution of complex long-horizon tasks. Prior work has explored
self-reflection in Large Language Models (LLMs) for task planning error
correction; however, existing methods are constrained by inflexible
self-reflection mechanisms that limit their effectiveness. Motivated by these
limitations and inspired by human cognitive adaptation, we propose the Flexible
Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture
that enables LLMs to perform flexible self-reflection based on task difficulty,
while constructively integrating historical valuable experience with failure
lessons. We evaluated FCRF on diverse domestic tasks through simulation in
AlfWorld and physical deployment in the real-world environment. Experimental
results demonstrate that FCRF significantly improves overall performance and
self-reflection flexibility in complex long-horizon robotic tasks.

</details>


### [19] [CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions](https://arxiv.org/abs/2507.15022)
*Sumeadh MS,Kevin Dsouza,Ravi Prakash*

Main category: cs.RO

TL;DR: 本文提出基于分裂保形预测的验证策略CPED-NCBFs，以解决从专家演示中学习的神经网络控制障碍函数（NCBFs）在整个状态空间的安全性验证问题，克服现有方法保守性强的局限，并在点质量系统和单轮模型上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有从专家演示中学习控制障碍函数（CBFs）的方法中，使用神经网络表示的CBFs（NCBFs）难以在整个状态空间验证安全性，现有验证技术（如SMT求解器、混合整数规划、区间传播等）常产生宽松、保守的边界。

Method: 采用基于分裂保形预测的验证策略CPED-NCBFs来验证从专家演示中学习的NCBF。

Result: 在点质量系统和单轮模型上验证了所提方法的有效性。

Conclusion: 所提CPED-NCBFs策略能有效解决NCBFs的安全性验证问题，克服了现有方法的保守性局限。

Abstract: Among the promising approaches to enforce safety in control systems, learning
Control Barrier Functions (CBFs) from expert demonstrations has emerged as an
effective strategy. However, a critical challenge remains: verifying that the
learned CBFs truly enforce safety across the entire state space. This is
especially difficult when CBF is represented using neural networks (NCBFs).
Several existing verification techniques attempt to address this problem
including SMT-based solvers, mixed-integer programming (MIP), and interval or
bound-propagation methods but these approaches often introduce loose,
conservative bounds. To overcome these limitations, in this work we use
CPED-NCBFs a split-conformal prediction based verification strategy to verify
the learned NCBF from the expert demonstrations. We further validate our method
on point mass systems and unicycle models to demonstrate the effectiveness of
the proposed theory.

</details>


### [20] [Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper](https://arxiv.org/abs/2507.15062)
*Xinyue Zhu,Binghao Huang,Yunzhu Li*

Main category: cs.RO

TL;DR: 本文提出一种集成触觉传感器的便携式轻量级抓取器，可在多样化、真实世界和野外环境中同步采集视觉和触觉数据，并基于此硬件提出跨模态表示学习框架，该框架能整合视觉和触觉信号并保留其独特特征，在试管插入和移液器液体转移等精细任务中验证了更高的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有手持抓取器设计大多缺乏触觉传感，而触觉反馈在精确操作中起关键作用。

Method: 设计集成触觉传感器的硬件抓取器实现视觉和触觉数据同步采集，提出跨模态表示学习框架整合两种信号并保留其独特特征，学习过程产生关注物理交互相关接触区域的可解释表示。

Result: 该方法在试管插入和移液器液体转移等精细任务中，相比现有方法提高了准确性和对外界干扰的鲁棒性，支持基于多模态反馈的精确机器人操作。

Conclusion: 所提出的便携式轻量级抓取器及跨模态表示学习框架，能有效实现视觉和触觉数据的同步采集与融合，提升了下游操作任务中策略学习的效率和效果，在精细操作任务中表现出优异性能。

Abstract: Handheld grippers are increasingly used to collect human demonstrations due
to their ease of deployment and versatility. However, most existing designs
lack tactile sensing, despite the critical role of tactile feedback in precise
manipulation. We present a portable, lightweight gripper with integrated
tactile sensors that enables synchronized collection of visual and tactile data
in diverse, real-world, and in-the-wild settings. Building on this hardware, we
propose a cross-modal representation learning framework that integrates visual
and tactile signals while preserving their distinct characteristics. The
learning procedure allows the emergence of interpretable representations that
consistently focus on contacting regions relevant for physical interactions.
When used for downstream manipulation tasks, these representations enable more
efficient and effective policy learning, supporting precise robotic
manipulation based on multimodal feedback. We validate our approach on
fine-grained tasks such as test tube insertion and pipette-based fluid
transfer, demonstrating improved accuracy and robustness under external
disturbances. Our project page is available at
https://binghao-huang.github.io/touch_in_the_wild/ .

</details>


### [21] [Search-Based Autonomous Vehicle Motion Planning Using Game Theory](https://arxiv.org/abs/2507.15088)
*Pouya Panahandeh,Mohammad Pirani,Baris Fidan,Amir Khajepour*

Main category: cs.RO

TL;DR: 本文提出一种基于搜索的交互式运动规划方案，将其他道路使用者视为智能体，实现自动驾驶车辆（AVs）的实时路径规划，并通过WATonoBus实验验证其性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统基于搜索的运动规划方法将其他道路使用者视为静态障碍物，无法生成真实路径，需解决此问题并实现实时应用。

Method: 采用基于搜索的交互式运动规划方案，结合博弈论方法，将其他道路使用者视为智能体而非静态障碍物。

Result: 该方案计算时间低，可实时实现，通过与现有技术对比及WATonoBus实验验证，性能更优。

Conclusion: 提出的运动规划方案能生成更真实路径，计算时间低可实时应用，实验证明其性能优于现有技术。

Abstract: In this paper, we propose a search-based interactive motion planning scheme
for autonomous vehicles (AVs), using a game-theoretic approach. In contrast to
traditional search-based approaches, the newly developed approach considers
other road users (e.g. drivers and pedestrians) as intelligent agents rather
than static obstacles. This leads to the generation of a more realistic path
for the AV. Due to the low computational time, the proposed motion planning
scheme is implementable in real-time applications. The performance of the
developed motion planning scheme is compared with existing motion planning
techniques and validated through experiments using WATonoBus, an electrical
all-weather autonomous shuttle bus.

</details>


### [22] [Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions](https://arxiv.org/abs/2507.15155)
*Majid Roshanfar,Alex Zhang,Changyan He,Amir Hooshiar,Dale J. Podolsky,Thomas Looi,Eric Diller*

Main category: cs.RO

TL;DR: 本文介绍了一种基于学习的建模框架，用于内窥镜经鼻脑肿瘤切除的磁控软吸装置，实现了亚毫米级形状预测精度和实时推理，推动了磁驱动软机器人工具在微创神经外科中的智能控制发展。


<details>
  <summary>Details</summary>
Motivation: 为解决磁驱动超弹性软体机器人在微创神经外科应用中复杂非线性行为的建模问题，避免依赖简化的物理假设，实现智能控制。

Method: 该装置采用生物相容性SIL 30材料3D打印，集成嵌入式光纤布拉格光栅（FBG）传感器进行实时形状反馈，形状重建使用四个贝塞尔控制点表示；基于5097个实验样本（涵盖磁场强度0-14 mT、驱动频率0.2-1.0 Hz、垂直尖端距离90-100 mm），训练了神经网络（NN）和随机森林（RF）数据驱动模型。

Result: 随机森林模型在所有指标上优于神经网络，控制点预测的均方根误差为0.087 mm，形状重建的平均误差为0.064 mm；特征重要性分析显示磁场分量主要影响远端控制点，频率和距离影响基部配置。

Conclusion: 这种基于学习的方法有效建模了磁驱动下超弹性软体机器人的复杂非线性行为，通过亚毫米级形状预测精度和实时推理，为磁驱动软机器人工具在微创神经外科的智能控制迈出了重要一步。

Abstract: This letter introduces a novel learning-based modeling framework for a
magnetically steerable soft suction device designed for endoscopic endonasal
brain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm
inner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material,
and integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape
feedback. Shape reconstruction is represented using four Bezier control points,
enabling a compact and smooth model of the device's deformation. A data-driven
model was trained on 5,097 experimental samples covering a range of magnetic
field magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical
tip distances (90-100 mm), using both Neural Network (NN) and Random Forest
(RF) architectures. The RF model outperformed the NN across all metrics,
achieving a mean root mean square error of 0.087 mm in control point prediction
and a mean shape reconstruction error of 0.064 mm. Feature importance analysis
further revealed that magnetic field components predominantly influence distal
control points, while frequency and distance affect the base configuration.
This learning-based approach effectively models the complex nonlinear behavior
of hyperelastic soft robots under magnetic actuation without relying on
simplified physical assumptions. By enabling sub-millimeter shape prediction
accuracy and real-time inference, this work represents an advancement toward
the intelligent control of magnetically actuated soft robotic tools in
minimally invasive neurosurgery.

</details>


### [23] [CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer](https://arxiv.org/abs/2507.15189)
*Kevin Christiansen Marsim,Jinwoo Jeon,Yeeun Kim,Myeongwoo Jeong,Hyun Myung*

Main category: cs.RO

TL;DR: 提出CHADET（跨层次注意力深度补全Transformer）轻量级网络，利用RGB图像和稀疏深度点生成精确密集深度图，通过深度块提取特征和跨层次注意力模块优化图像特征，在KITTI、NYUv2和VOID数据集上验证，提升深度图质量并减少内存使用，解决现有方法在计算效率与准确性间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度补全方法在推理时存在计算效率与准确性的显著权衡，内存和计算需求大，不适合实时应用，需在提高处理速度的同时提升深度信息的完整性和准确性以增强机器人任务性能。

Method: 提出CHADET轻量级深度补全网络，从RGB图像和稀疏深度点对中，通过深度块提取特征并传递给轻量级Transformer解码器，解码器中使用新颖的跨层次注意力模块，利用深度信息优化图像特征。

Result: 在KITTI、NYUv2和VOID数据集上验证，该方法提升了深度图预测质量并减少了内存使用。

Conclusion: CHADET轻量级网络能有效解决现有方法的权衡问题，生成准确密集深度图，适用于实时应用，提升机器人任务性能。

Abstract: Depth information which specifies the distance between objects and current
position of the robot is essential for many robot tasks such as navigation.
Recently, researchers have proposed depth completion frameworks to provide
dense depth maps that offer comprehensive information about the surrounding
environment. However, existing methods show significant trade-offs between
computational efficiency and accuracy during inference. The substantial memory
and computational requirements make them unsuitable for real-time applications,
highlighting the need to improve the completeness and accuracy of depth
information while improving processing speed to enhance robot performance in
various tasks. To address these challenges, in this paper, we propose
CHADET(cross-hierarchical-attention depth-completion transformer), a
lightweight depth-completion network that can generate accurate dense depth
maps from RGB images and sparse depth points. For each pair, its feature is
extracted from the depthwise blocks and passed to the equally lightweight
transformer-based decoder. In the decoder, we utilize the novel
cross-hierarchical-attention module that refines the image features from the
depth information. Our approach improves the quality and reduces memory usage
of the depth map prediction, as validated in both KITTI, NYUv2, and VOID
datasets.

</details>


### [24] [VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving](https://arxiv.org/abs/2507.15266)
*Haichao Liu,Haoren Guo,Pei Liu,Benshan Ma,Yuxiang Zhang,Jun Ma,Tong Heng Lee*

Main category: cs.RO

TL;DR: 提出VLM-UDMC框架，融合视觉语言模型增强城市自动驾驶决策与运动控制，结合场景推理和风险感知，通过模拟和实车实验验证有效性并开源。


<details>
  <summary>Details</summary>
Motivation: 模仿人类驾驶员的场景理解和风险感知注意力能力，确保城市自动驾驶的透明度和可解释性。

Method: 构建视觉语言模型增强的统一决策与运动控制框架，上层慢系统采用两步推理策略（RAG技术）生成风险感知洞察，轻量级多核分解LSTM预测异质交通参与者轨迹，基于实时环境变化动态重构最优运动规划。

Result: 通过模拟和实车实验验证，VLM-UDMC有效利用场景理解和注意力分解实现合理驾驶决策，提升城市驾驶整体性能。

Conclusion: VLM-UDMC框架能有效融合场景理解与风险感知，改善城市自动驾驶决策与运动控制，开源项目可供参考。

Abstract: Scene understanding and risk-aware attentions are crucial for human drivers
to make safe and effective driving decisions. To imitate this cognitive ability
in urban autonomous driving while ensuring the transparency and
interpretability, we propose a vision-language model (VLM)-enhanced unified
decision-making and motion control framework, named VLM-UDMC. This framework
incorporates scene reasoning and risk-aware insights into an upper-level slow
system, which dynamically reconfigures the optimal motion planning for the
downstream fast system. The reconfiguration is based on real-time environmental
changes, which are encoded through context-aware potential functions. More
specifically, the upper-level slow system employs a two-step reasoning policy
with Retrieval-Augmented Generation (RAG), leveraging foundation models to
process multimodal inputs and retrieve contextual knowledge, thereby generating
risk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM
provides real-time trajectory predictions for heterogeneous traffic
participants by extracting smoother trend representations for short-horizon
trajectory prediction. The effectiveness of the proposed VLM-UDMC framework is
verified via both simulations and real-world experiments with a full-size
autonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively
leverages scene understanding and attention decomposition for rational driving
decisions, thus improving the overall urban driving performance. Our
open-source project is available at https://github.com/henryhcliu/vlmudmc.git.

</details>


### [25] [RepILN: Reparameterized Inertial Localization Network](https://arxiv.org/abs/2507.15293)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出一种重参数化惯性定位网络，通过多分支训练和单路径推理提升参数效率，结合时间尺度稀疏注意力机制和门控卷积单元捕获长短期依赖，在公共基准上实现精度与模型紧凑性的良好权衡


<details>
  <summary>Details</summary>
Motivation: 数据驱动的惯性定位方法依赖复杂网络架构导致计算资源受限，且忽视惯性测量中的长期依赖建模，限制定位性能

Method: 使用多分支结构训练以增强特征提取，推理时转为等效单路径架构；引入时间尺度稀疏注意力机制捕获长期依赖；结合门控卷积单元整合长程依赖与局部细粒度特征

Result: 在RoNIN数据集上，与RoNIN-ResNet相比，绝对轨迹误差（ATE）降低2.59%，参数数量减少3.86%

Conclusion: 该方法在公共基准上实现了精度与模型紧凑性的良好权衡

Abstract: Inertial localization is regarded as a promising positioning solution for
consumer-grade IoT devices due to its cost-effectiveness and independence from
external infrastructure. However, data-driven inertial localization methods
often rely on increasingly complex network architectures to improve accuracy,
which challenges the limited computational resources of IoT devices. Moreover,
these methods frequently overlook the importance of modeling long-term
dependencies in inertial measurements - a critical factor for accurate
trajectory reconstruction - thereby limiting localization performance. To
address these challenges, we propose a reparameterized inertial localization
network that uses a multi-branch structure during training to enhance feature
extraction. At inference time, this structure is transformed into an equivalent
single-path architecture to improve parameter efficiency. To further capture
long-term dependencies in motion trajectories, we introduce a temporal-scale
sparse attention mechanism that selectively emphasizes key trajectory segments
while suppressing noise. Additionally, a gated convolutional unit is
incorporated to effectively integrate long-range dependencies with local
fine-grained features. Extensive experiments on public benchmarks demonstrate
that our method achieves a favorable trade-off between accuracy and model
compactness. For example, on the RoNIN dataset, our approach reduces the
Absolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while
reducing the number of parameters by 3.86%.

</details>


### [26] [Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe](https://arxiv.org/abs/2507.15444)
*Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本文提出首个基于实时流场测量的四旋翼在窄管道悬停闭环控制系统，通过低延迟事件烟雾测速法、基于循环卷积神经网络的扰动估计器及强化学习训练的控制器，实现有效抗干扰，尤其在横向平移时防止碰撞，为复杂气动环境飞行研究开辟新方向，并揭示窄圆管内飞行流场特征。


<details>
  <summary>Details</summary>
Motivation: 自主四旋翼在管道等受限空间飞行面临非定常自诱导气动干扰挑战，现有方法或依赖持续运动或悬停稳定性有限。

Method: 开发低延迟事件烟雾测速法估计高时间分辨率局部气流，结合循环卷积神经网络扰动估计器实时推断力和扭矩扰动，并集成到强化学习训练的基于学习的控制器中。

Result: 流反馈控制在管道横截面横向平移机动中特别有效，实时扰动信息使控制器能有效抵消瞬态气动效应，防止与管壁碰撞，首次实现基于实时流场测量闭环控制的空中机器人演示。

Conclusion: 本工作为气动复杂环境飞行研究开辟新方向，同时揭示窄圆管内飞行时出现的特征流场结构，为机器人学与流体力学交叉领域提供新见解。

Abstract: Autonomous quadrotor flight in confined spaces such as pipes and tunnels
presents significant challenges due to unsteady, self-induced aerodynamic
disturbances. Very recent advances have enabled flight in such conditions, but
they either rely on constant motion through the pipe to mitigate airflow
recirculation effects or suffer from limited stability during hovering. In this
work, we present the first closed-loop control system for quadrotors for
hovering in narrow pipes that leverages real-time flow field measurements. We
develop a low-latency, event-based smoke velocimetry method that estimates
local airflow at high temporal resolution. This flow information is used by a
disturbance estimator based on a recurrent convolutional neural network, which
infers force and torque disturbances in real time. The estimated disturbances
are integrated into a learning-based controller trained via reinforcement
learning. The flow-feedback control proves particularly effective during
lateral translation maneuvers in the pipe cross-section. There, the real-time
disturbance information enables the controller to effectively counteract
transient aerodynamic effects, thereby preventing collisions with the pipe
wall. To the best of our knowledge, this work represents the first
demonstration of an aerial robot with closed-loop control informed by real-time
flow field measurements. This opens new directions for research on flight in
aerodynamically complex environments. In addition, our work also sheds light on
the characteristic flow structures that emerge during flight in narrow,
circular pipes, providing new insights at the intersection of robotics and
fluid dynamics.

</details>


### [27] [The Emergence of Deep Reinforcement Learning for Path Planning](https://arxiv.org/abs/2507.15469)
*Thanh Thi Nguyen,Saeid Nahavandi,Imran Razzak,Dung Nguyen,Nhat Truong Pham,Quoc Viet Hung Nguyen*

Main category: cs.RO

TL;DR: 本文综述了传统路径规划方法及深度强化学习（DRL）在该领域的最新进展，涵盖传统算法与DRL方法的分类、优缺点分析，并指出混合方法等未来研究方向


<details>
  <summary>Details</summary>
Motivation: 复杂动态环境下对自主系统的需求增加，推动智能路径规划方法研究

Method: 综述传统路径规划方法（如图搜索、线性规划、进化计算）及深度强化学习（DRL）的最新进展，对传统和基于学习的范式关键算法分类，分析其优缺点

Result: 总结了传统方法与DRL在路径规划中的优势（如传统方法的确定性可靠性、DRL的适应性）和局限（如计算效率、可扩展性等），并识别了开放挑战

Conclusion: 指出混合DRL与传统规划技术的方法是未来研究的重要方向，以结合学习适应性和确定性可靠性，实现鲁棒自主导航

Abstract: The increasing demand for autonomous systems in complex and dynamic
environments has driven significant research into intelligent path planning
methodologies. For decades, graph-based search algorithms, linear programming
techniques, and evolutionary computation methods have served as foundational
approaches in this domain. Recently, deep reinforcement learning (DRL) has
emerged as a powerful method for enabling autonomous agents to learn optimal
navigation strategies through interaction with their environments. This survey
provides a comprehensive overview of traditional approaches as well as the
recent advancements in DRL applied to path planning tasks, focusing on
autonomous vehicles, drones, and robotic platforms. Key algorithms across both
conventional and learning-based paradigms are categorized, with their
innovations and practical implementations highlighted. This is followed by a
thorough discussion of their respective strengths and limitations in terms of
computational efficiency, scalability, adaptability, and robustness. The survey
concludes by identifying key open challenges and outlining promising avenues
for future research. Special attention is given to hybrid approaches that
integrate DRL with classical planning techniques to leverage the benefits of
both learning-based adaptability and deterministic reliability, offering
promising directions for robust and resilient autonomous navigation.

</details>


### [28] [All-UWB SLAM Using UWB Radar and UWB AOA](https://arxiv.org/abs/2507.15474)
*Charith Premachandra,Achala Athukorala,U-Xuan Tan*

Main category: cs.RO

TL;DR: 本文提出一种将超宽带（UWB）到达角（AOA）测量集成到基于UWB雷达的SLAM系统中的新方法，以提高在特征匮乏的视觉受限环境中SLAM的准确性和可扩展性，实验结果表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 现有基于UWB雷达的SLAM方法依赖环境中的可区分特征作为地标，但受环境中特征数量限制，在特征匮乏的视觉受限环境中性能不足。

Method: 通过机器人在环境 mapping 过程中动态部署UWB锚节点-标签单元，获取UWB AOA测量值，并将其集成到UWB雷达SLAM系统中，同时讨论并解决了UWB AOA测量单元的现有约束。

Result: 实验结果表明，将UWB AOA单元与UWB雷达集成能够在视觉受限且特征匮乏的环境中实现SLAM。

Conclusion: 集成UWB AOA测量可有效提升基于UWB雷达的SLAM在特征匮乏视觉受限环境中的准确性和可扩展性，使SLAM在该类环境中成为可能。

Abstract: There has been a growing interest in autonomous systems designed to operate
in adverse conditions (e.g. smoke, dust), where the visible light spectrum
fails. In this context, Ultra-wideband (UWB) radar is capable of penetrating
through such challenging environmental conditions due to the lower frequency
components within its broad bandwidth. Therefore, UWB radar has emerged as a
potential sensing technology for Simultaneous Localization and Mapping (SLAM)
in vision-denied environments where optical sensors (e.g. LiDAR, Camera) are
prone to failure. Existing approaches involving UWB radar as the primary
exteroceptive sensor generally extract features in the environment, which are
later initialized as landmarks in a map. However, these methods are constrained
by the number of distinguishable features in the environment. Hence, this paper
proposes a novel method incorporating UWB Angle of Arrival (AOA) measurements
into UWB radar-based SLAM systems to improve the accuracy and scalability of
SLAM in feature-deficient environments. The AOA measurements are obtained using
UWB anchor-tag units which are dynamically deployed by the robot in featureless
areas during mapping of the environment. This paper thoroughly discusses
prevailing constraints associated with UWB AOA measurement units and presents
solutions to overcome them. Our experimental results show that integrating UWB
AOA units with UWB radar enables SLAM in vision-denied feature-deficient
environments.

</details>


### [29] [The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents](https://arxiv.org/abs/2507.15478)
*Simon Kohaut,Felix Divo,Navid Hamid,Benedict Flade,Julian Eggert,Devendra Singh Dhami,Kristian Kersting*

Main category: cs.RO

TL;DR: 本文展示神经符号系统如何为自主智能体在不确定环境中确保可靠且符合规则的行为提供解决方案，提出宪法控制器（CoCo）框架并引入自我怀疑概念，在实际空中移动研究中证明其优势。


<details>
  <summary>Details</summary>
Motivation: 自主智能体在不确定环境中实现可靠且符合规则的行为仍是现代机器人技术的基本挑战。

Method: 引入宪法控制器（CoCo）框架，该框架通过对表示共享交通空间等约束的深度概率逻辑程序进行推理来增强智能体的安全性和可靠性；同时提出自我怀疑概念，将其实现为基于行驶速度、使用的传感器或健康因素等怀疑特征的概率密度。

Result: 在实际空中移动研究中，展示了CoCo对于智能自主系统学习适当怀疑并安全、合规地导航复杂和不确定环境的优势。

Conclusion: 神经符号系统通过结合结构化推理和灵活表示，为解决自主智能体在不确定环境中的可靠性和规则合规行为问题提供了强大方案，CoCo框架及自我怀疑概念有效提升了智能体的安全性和导航能力。

Abstract: Ensuring reliable and rule-compliant behavior of autonomous agents in
uncertain environments remains a fundamental challenge in modern robotics. Our
work shows how neuro-symbolic systems, which integrate probabilistic, symbolic
white-box reasoning models with deep learning methods, offer a powerful
solution to this challenge. This enables the simultaneous consideration of
explicit rules and neural models trained on noisy data, combining the strength
of structured reasoning with flexible representations. To this end, we
introduce the Constitutional Controller (CoCo), a novel framework designed to
enhance the safety and reliability of agents by reasoning over deep
probabilistic logic programs representing constraints such as those found in
shared traffic spaces. Furthermore, we propose the concept of self-doubt,
implemented as a probability density conditioned on doubt features such as
travel velocity, employed sensors, or health factors. In a real-world aerial
mobility study, we demonstrate CoCo's advantages for intelligent autonomous
systems to learn appropriate doubts and navigate complex and uncertain
environments safely and compliantly.

</details>


### [30] [Robots for Kiwifruit Harvesting and Pollination](https://arxiv.org/abs/2507.15484)
*Jamie Bell*

Main category: cs.RO

TL;DR: 本研究是开发用于棚架结构猕猴桃果园的移动机器人项目的一部分，涉及猕猴桃采摘、人工授粉和导航等方面，设计了多种猕猴桃采摘机构，测试显示其中一种能可靠采摘且可达80%以上果实（优于之前的70%），人工授粉通过检测花朵并从喷杆喷雾实现，导航方面利用3D激光雷达提取特征并测试了30多公里自主行驶，计算机视觉算法与3D激光雷达行跟随效果相当。


<details>
  <summary>Details</summary>
Motivation: 开发能在棚架结构猕猴桃果园中执行目标花粉喷洒和自动化采摘的移动机器人。

Method: 设计多种猕猴桃采摘机构并测试其中一种；通过检测花朵并从喷杆喷雾进行人工授粉，同时测量 canopy 高度调整喷杆；利用3D激光雷达从猕猴桃果园数据中提取结构定义特征，测试3D激光雷达导航系统（行跟随、行尾检测和转弯），并测试计算机视觉的行检测和行跟随算法。

Result: 测试的猕猴桃采摘机构能可靠采摘，可达80%以上果实（优于之前的70%）；人工授粉可在行驶速度达1.4 ms-1时进行；3D激光雷达导航系统在猕猴桃果园自主行驶超过30公里；计算机视觉算法与3D激光雷达行跟随效果相当。

Conclusion: 研究在猕猴桃果园移动机器人的采摘、授粉和导航方面取得进展，采摘机构果实可达率提升，授粉和导航系统经测试有效，计算机视觉与激光雷达导航效果相当。

Abstract: This research was a part of a project that developed mobile robots that
performed targeted pollen spraying and automated harvesting in pergola
structured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were
designed and field testing of one of the concepts showed that the mechanism
could reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism
was able to reach over 80 percent of fruit in the cluttered kiwifruit canopy,
whereas the previous state of the art mechanism was only able to reach less
than 70 percent of the fruit. Artificial pollination was performed by detecting
flowers and then spraying pollen in solution onto the detected flowers from a
line of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the
height of the canopy was measured and the spray boom was moved up and down to
keep the boom close enough to the flowers for the spray to reach the flowers,
while minimising collisions with the canopy. Mobile robot navigation was
performed using a 2D lidar in apple orchards and vineyards. Lidar navigation in
kiwifruit orchards was more challenging because the pergola structure only
provides a small amount of data for the direction of rows, compared to the
amount of data from the overhead canopy, the undulating ground and other
objects in the orchards. Multiple methods are presented here for extracting
structure defining features from 3D lidar data in kiwifruit orchards. In
addition, a 3D lidar navigation system -- which performed row following, row
end detection and row end turns -- was tested for over 30 km of autonomous
driving in kiwifruit orchards. Computer vision algorithms for row detection and
row following were also tested. The computer vision algorithm worked as well as
the 3D lidar row following method in testing.

</details>


### [31] [GR-3 Technical Report](https://arxiv.org/abs/2507.15493)
*Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang*

Main category: cs.RO

TL;DR: 本文报告了通用机器人策略GR-3的最新进展，它是一个大规模视觉-语言-动作(VLA)模型，具备泛化到新对象、环境和抽象概念指令的能力，能通过少量人类轨迹数据高效微调，并在长程和灵巧任务中表现出色，通过多方面训练方法实现，还介绍了配套的ByteMini机器人，实验表明其在多种任务上超越SOTA基线π₀。


<details>
  <summary>Details</summary>
Motivation: 构建能够在日常生活中协助人类的通用机器人。

Method: 采用多方面训练方法，包括与网络规模视觉-语言数据共同训练、通过VR设备收集的人类轨迹数据进行高效微调，以及利用机器人轨迹数据进行有效的模仿学习。

Result: GR-3在多种具有挑战性的任务上超越了最先进的基线方法π₀，并且能高效微调以适应新环境，在长程、灵巧任务（包括双手机械臂操作和移动）中表现出稳健可靠的性能。

Conclusion: GR-3是朝着构建能在日常生活中协助人类的通用机器人迈出的重要一步。

Abstract: We report our recent progress towards building generalist robot policies, the
development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.
It showcases exceptional capabilities in generalizing to novel objects,
environments, and instructions involving abstract concepts. Furthermore, it can
be efficiently fine-tuned with minimal human trajectory data, enabling rapid
and cost-effective adaptation to new settings. GR-3 also excels in handling
long-horizon and dexterous tasks, including those requiring bi-manual
manipulation and mobile movement, showcasing robust and reliable performance.
These capabilities are achieved through a multi-faceted training recipe that
includes co-training with web-scale vision-language data, efficient fine-tuning
from human trajectory data collected via VR devices, and effective imitation
learning with robot trajectory data. In addition, we introduce ByteMini, a
versatile bi-manual mobile robot designed with exceptional flexibility and
reliability, capable of accomplishing a wide range of tasks when integrated
with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the
state-of-the-art baseline method, $\pi_0$, on a wide variety of challenging
tasks. We hope GR-3 can serve as a step towards building generalist robots
capable of assisting humans in daily life.

</details>


### [32] [CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions](https://arxiv.org/abs/2507.15499)
*Jongseok Lee,Timo Birr,Rudolph Triebel,Tamim Asfour*

Main category: cs.RO

TL;DR: 本文提出CLEVER，一种基于深度神经网络（DNNs）的主动学习系统，用于鲁棒语义感知，能在数据流中遇故障时寻求人类支持并在线适应DNNs，最终完成语义感知任务，且首次在真实机器人上实现基于流的主动学习，证明可提升DNN语义感知的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对基于DNN的语义感知在数据流场景下的鲁棒性问题，需要一种能在遇到故障时寻求人类支持并在线适应的系统，以实现可靠的语义感知任务。

Method: 核心是贝叶斯公式设计，通过先验编码领域知识，构建主动学习系统，在数据流中遇故障时寻求人类支持并基于人类指令在线调整DNNs。

Result: 通过用户验证研究以及在类人机器人和可变形物体上的实验，证明了CLEVER的能力，且首次在真实机器人上实现基于流的主动学习，表明可实际提升DNN语义感知的鲁棒性。

Conclusion: CLEVER系统满足实现上述能力的多项需求，其贝叶斯公式设计是关键，实验验证了其有效性，为提升DNN语义感知鲁棒性提供了实践证据。

Abstract: We propose CLEVER, an active learning system for robust semantic perception
with Deep Neural Networks (DNNs). For data arriving in streams, our system
seeks human support when encountering failures and adapts DNNs online based on
human instructions. In this way, CLEVER can eventually accomplish the given
semantic perception tasks. Our main contribution is the design of a system that
meets several desiderata of realizing the aforementioned capabilities. The key
enabler herein is our Bayesian formulation that encodes domain knowledge
through priors. Empirically, we not only motivate CLEVER's design but further
demonstrate its capabilities with a user validation study as well as
experiments on humanoid and deformable objects. To our knowledge, we are the
first to realize stream-based active learning on a real robot, providing
evidence that the robustness of the DNN-based semantic perception can be
improved in practice. The project website can be accessed at
https://sites.google.com/view/thecleversystem.

</details>


### [33] [Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding](https://arxiv.org/abs/2507.15604)
*Johannes Hartwig,Philipp Lienhardt,Dominik Henrich*

Main category: cs.RO

TL;DR: 本文旨在通过消除专用有效载荷惯性参数（PIP）校准需求，使非专业用户更高效地编程协作机器人接触运动，利用非接触运动部分估计PIP，结果显示质量估计准确，质心和惯性张量受噪声和激励不足影响，表明手动引导时PIP估计可行但需足够加速度。


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人可用性增加，需满足几乎无编程知识用户高效操作系统的需求，现有框架在编程接触运动时除速度和力外还需PIP知识，因此要消除PIP校准以实现灵活工具更换。

Method: 利用手动引导中任务包含的非接触运动部分，采用已建立的估计技术来估计机器人的PIP。

Result: 有效载荷质量估计准确，而质心和惯性张量受噪声及激励不足影响。

Conclusion: 手动引导时进行PIP估计具有可行性，但准确估计需要足够的有效载荷加速度。

Abstract: As the availability of cobots increases, it is essential to address the needs
of users with little to no programming knowledge to operate such systems
efficiently. Programming concepts often use intuitive interaction modalities,
such as hand guiding, to address this. When programming in-contact motions,
such frameworks require knowledge of the robot tool's payload inertial
parameters (PIP) in addition to the demonstrated velocities and forces to
ensure effective hybrid motion-force control. This paper aims to enable
non-expert users to program in-contact motions more efficiently by eliminating
the need for a dedicated PIP calibration, thereby enabling flexible robot tool
changes. Since demonstrated tasks generally also contain motions with
non-contact, our approach uses these parts to estimate the robot's PIP using
established estimation techniques. The results show that the estimation of the
payload's mass is accurate, whereas the center of mass and the inertia tensor
are affected by noise and a lack of excitation. Overall, these findings show
the feasibility of PIP estimation during hand guiding but also highlight the
need for sufficient payload accelerations for an accurate estimation.

</details>


### [34] [A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning](https://arxiv.org/abs/2507.15607)
*Yanbo Chen,Yunzhe Tan,Yaojia Wang,Zhengzhe Xu,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 本文提出一种新型通用车辆-拖车导航系统，集成混合名义运动学模型与轻量级在线残差学习模块，并开发带加权模型组合策略的模型预测控制框架，通过多拖车类型和不同负载条件的实际实验验证了其无需手动调优或特定校准的鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 车辆-拖车系统在机场、超市、音乐会场地等环境中的自主导航至关重要，但此类系统（尤其带万向轮的拖车）的精确建模仍具挑战。

Method: 提出混合名义运动学模型（结合车辆经典非完整约束与基于神经网络的拖车运动学），集成轻量级在线残差学习模块以纠正实时建模差异和干扰；开发带加权模型组合策略的模型预测控制框架，提升长时预测精度并确保更安全的运动规划。

Result: 通过涉及多种拖车类型和不同负载条件的大量实际实验验证，该方法表现出稳健性能，无需手动调优或拖车特定校准。

Conclusion: 所提出的通用车辆-拖车导航系统有效解决了精确建模难题，在多种实际场景下展现出良好的鲁棒性和实用性。

Abstract: Autonomous navigation of vehicle-trailer systems is crucial in environments
like airports, supermarkets, and concert venues, where various types of
trailers are needed to navigate with different payloads and conditions.
However, accurately modeling such systems remains challenging, especially for
trailers with castor wheels. In this work, we propose a novel universal
vehicle-trailer navigation system that integrates a hybrid nominal kinematic
model--combining classical nonholonomic constraints for vehicles and neural
network-based trailer kinematics--with a lightweight online residual learning
module to correct real-time modeling discrepancies and disturbances.
Additionally, we develop a model predictive control framework with a weighted
model combination strategy that improves long-horizon prediction accuracy and
ensures safer motion planning. Our approach is validated through extensive
real-world experiments involving multiple trailer types and varying payload
conditions, demonstrating robust performance without manual tuning or
trailer-specific calibration.

</details>


### [35] [Optimizing Force Signals from Human Demonstrations of In-Contact Motions](https://arxiv.org/abs/2507.15608)
*Johannes Hartwig,Fabian Viessmann,Dominik Henrich*

Main category: cs.RO

TL;DR: 针对非机器人编程专家，本文探讨通过优化力信号来更好地匹配人类在动觉引导中的意图，比较不同滤波方法并提出峰值检测法处理首次接触偏差，评估了专门的误差标准并分析参数影响，使单个运动质量在误差标准上提升高达20%，有助于改善机器人编程可用性及人机交互。


<details>
  <summary>Details</summary>
Motivation: 非机器人编程专家在动觉引导中，人类演示的输入信号不精确且有噪声，直接复现运动或作为机器学习输入时存在问题。

Method: 比较不同信号滤波方法，并提出峰值检测法处理信号中的首次接触偏差，同时评估专门的输入与人类意图信号间的误差标准，分析关键参数对滤波方法的影响。

Result: 单个运动的质量在误差标准上可提升高达20%。

Conclusion: 所提出的贡献能够提高机器人编程的可用性以及人机之间的交互。

Abstract: For non-robot-programming experts, kinesthetic guiding can be an intuitive
input method, as robot programming of in-contact tasks is becoming more
prominent. However, imprecise and noisy input signals from human demonstrations
pose problems when reproducing motions directly or using the signal as input
for machine learning methods. This paper explores optimizing force signals to
correspond better to the human intention of the demonstrated signal. We compare
different signal filtering methods and propose a peak detection method for
dealing with first-contact deviations in the signal. The evaluation of these
methods considers a specialized error criterion between the input and the
human-intended signal. In addition, we analyze the critical parameters'
influence on the filtering methods. The quality for an individual motion could
be increased by up to \SI{20}{\percent} concerning the error criterion. The
proposed contribution can improve the usability of robot programming and the
interaction between humans and robots.

</details>


### [36] [EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation](https://arxiv.org/abs/2507.15649)
*Haocheng Xu,Haodong Zhang,Zhenghan Chen,Rong Xiong*

Main category: cs.RO

TL;DR: 本文提出一种基于强化学习的框架，用于仿人机器人在模仿人类上身动作时保持整体稳定性，包括重定向网络生成训练数据集、可执行运动先验（EMP）模块调整目标运动，并通过仿真和实测试验验证了实用性。


<details>
  <summary>Details</summary>
Motivation: 仿人机器人在站立姿势下的可控范围有限，影响全身稳定性，需研究在适应上身运动时的稳定站立问题。

Method: 1. 设计重定向网络生成大规模上身运动数据集，用于训练强化学习策略，结合领域随机化增强鲁棒性；2. 提出可执行运动先验（EMP）模块，根据机器人当前状态调整输入目标运动，在最小化运动幅度变化的同时提高站立稳定性。

Result: 通过仿真和真实世界测试评估了该框架，证明了其实用性。

Conclusion: 该基于强化学习的框架能使仿人机器人在模仿人类上身动作时有效保持整体稳定性，具有实际应用价值。

Abstract: To support humanoid robots in performing manipulation tasks, it is essential
to study stable standing while accommodating upper-body motions. However, the
limited controllable range of humanoid robots in a standing position affects
the stability of the entire body. Thus we introduce a reinforcement learning
based framework for humanoid robots to imitate human upper-body motions while
maintaining overall stability. Our approach begins with designing a retargeting
network that generates a large-scale upper-body motion dataset for training the
reinforcement learning (RL) policy, which enables the humanoid robot to track
upper-body motion targets, employing domain randomization for enhanced
robustness. To avoid exceeding the robot's execution capability and ensure
safety and stability, we propose an Executable Motion Prior (EMP) module, which
adjusts the input target movements based on the robot's current state. This
adjustment improves standing stability while minimizing changes to motion
amplitude. We evaluate our framework through simulation and real-world tests,
demonstrating its practical applicability.

</details>


### [37] [Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms](https://arxiv.org/abs/2507.15677)
*Huayue Liang,Yanbo Chen,Hongyang Cheng,Yanzhao Yu,Shoujie Li,Junbo Tan,Xueqian Wang,Long Zeng*

Main category: cs.RO

TL;DR: 本文提出一种仅依赖输入输出数据的模型预测控制（MPC）方法，以提高柔性绳驱动机械臂（FCRA）的控制精度，包括开发隐式模型、引入数据选择算法（DSA）减少求解时间并验证了其在真实平台上的有效性


<details>
  <summary>Details</summary>
Motivation: 柔性绳驱动机械臂（FCRA）因绳索的弹性、滞后和摩擦等固有特性，在建模和控制方面存在困难

Method: 1. 基于输入输出数据开发隐式模型并集成到MPC优化框架；2. 引入数据选择算法（DSA）筛选能最佳表征系统的数据；3. 仿真研究超参数对跟踪误差的影响

Result: 在真实FCRA平台验证中，平均定位精度约2.070 mm；轨迹跟踪测试中，与PID方法1.418°的平均跟踪误差相比，所提方法平均跟踪误差为0.541°

Conclusion: 所提基于数据的MPC方法能有效提高FCRA的控制精度，数据选择算法使每步求解时间减少约80%至4 ms左右

Abstract: Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant
motion. Still, the inherent properties of cables, such as resilience,
hysteresis, and friction, often lead to particular difficulties in modeling and
control. This paper proposes a model predictive control (MPC) method that
relies exclusively on input-output data, without a physical model, to improve
the control accuracy of FCRAs. First, we develop an implicit model based on
input-output data and integrate it into an MPC optimization framework. Second,
a data selection algorithm (DSA) is introduced to filter the data that best
characterize the system, thereby reducing the solution time per step to
approximately 4 ms, which is an improvement of nearly 80%. Lastly, the
influence of hyperparameters on tracking error is investigated through
simulation. The proposed method has been validated on a real FCRA platform,
including five-point positioning accuracy tests, a five-point response tracking
test, and trajectory tracking for letter drawing. The results demonstrate that
the average positioning accuracy is approximately 2.070 mm. Moreover, compared
to the PID method with an average tracking error of 1.418{\deg}, the proposed
method achieves an average tracking error of 0.541{\deg}.

</details>


### [38] [Strong, Accurate, and Low-Cost Robot Manipulator](https://arxiv.org/abs/2507.15693)
*Georges Chebly,Spencer Little,Nisal Perera,Aliya Abedeen,Ken Suzuki,Donghyun Kim*

Main category: cs.RO

TL;DR: 本文提出Forte，一种全3D打印的6自由度机械臂，在材料成本低于215美元的情况下实现近工业级性能（0.63kg负载、0.467m工作范围、亚毫米级重复性），是适用于从课堂教育到AI实验的低成本教育性机械臂，突破现有低成本教育臂的性能限制。


<details>
  <summary>Details</summary>
Motivation: 作为适用于课堂教育到AI实验等广泛应用的可及性机器人，突破现有低成本教育臂的性能限制。

Method: 采用经济高效的机械设计，结合基于绞盘的缆绳驱动、同步带、简单张紧机构、轻量化3D打印结构以及用于结构刚度的拓扑优化，通过精心的传动系统工程，在不依赖大功率电子设备或昂贵制造工艺的情况下最小化间隙并保持控制保真度。

Result: 实验验证表明Forte实现了高重复性和负载能力，为课堂教学和先进机器人研究提供了有吸引力的机器人平台。

Conclusion: Forte是一种全3D打印的低成本6自由度机械臂，具有近工业级性能，适用于广泛应用，为教育和研究提供了有价值的平台。

Abstract: This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed
to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach,
and sub-millimeter repeatability - at a material cost under $215. As an
accessible robot for broad applications across classroom education to AI
experiments, Forte pushes forward the performance limitations of existing
low-cost educational arms. We introduce a cost-effective mechanical design that
combines capstan-based cable drives, timing belts, simple tensioning
mechanisms, and lightweight 3D-printed structures, along with topology
optimization for structural stiffness. Through careful drivetrain engineering,
we minimize backlash and maintain control fidelity without relying on
high-power electronics or expensive manufacturing processes. Experimental
validation demonstrates that Forte achieves high repeatability and load
capacity, offering a compelling robotic platform for both classroom instruction
and advanced robotics research.

</details>


### [39] [Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages](https://arxiv.org/abs/2507.15710)
*Lu Huang,Lingxiao Meng,Jiankun Wang,Xingjian Jing*

Main category: cs.RO

TL;DR: 提出一种简单高效的基于采样的规划框架及其双向版本，通过整合不同规划粒度水平，解决高维配置空间中采样效率低的问题，在复杂配置空间（如狭窄通道）中表现优于现有方法，并在仿真和实际机器人实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: 基于采样的算法在高维配置空间运动规划中广泛应用，但在具有狭窄通道的复杂配置空间中，由于采样效率低，性能下降；现有方法使用手工或学习的启发式引导采样至有用区域，但缺乏对各种问题的通用性或需要大量预先训练。

Method: 提出一种基于采样的规划框架及其双向版本，通过整合不同规划粒度水平，以不同分辨率的均匀随机样本探测配置空间，并在线探索这些多分辨率样本，在穿越大型自由配置空间时偏向稀疏样本，实现稀疏和密集样本的无缝过渡。

Result: 仿真结果表明，在SE(2)、SE(3)和R^14具有挑战性地形的环境中，该方法优于多种最先进的基于采样的规划器；在Franka Emika Panda机器人的受限工作空间实验中也证明了其优越性。

Conclusion: 该方法通过整合不同规划粒度，能在复杂配置空间中导航，同时保持规划速度和完备性，在仿真和实际机器人实验中均表现出优越性。

Abstract: Sampling-based algorithms are widely used for motion planning in
high-dimensional configuration spaces. However, due to low sampling efficiency,
their performance often diminishes in complex configuration spaces with narrow
corridors. Existing approaches address this issue using handcrafted or learned
heuristics to guide sampling toward useful regions. Unfortunately, these
strategies often lack generalizability to various problems or require extensive
prior training. In this paper, we propose a simple yet efficient sampling-based
planning framework along with its bidirectional version that overcomes these
issues by integrating different levels of planning granularity. Our approach
probes configuration spaces with uniform random samples at varying resolutions
and explores these multi-resolution samples online with a bias towards sparse
samples when traveling large free configuration spaces. By seamlessly
transitioning between sparse and dense samples, our approach can navigate
complex configuration spaces while maintaining planning speed and completeness.
The simulation results demonstrate that our approach outperforms several
state-of-the-art sampling-based planners in $\mathbb{SE}(2)$, $\mathbb{SE}(3)$,
and $\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments
conducted with the Franka Emika Panda robot operating in a constrained
workspace provide additional evidence of the superiority of the proposed
method.

</details>


### [40] [DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models](https://arxiv.org/abs/2507.15716)
*Ziyu Wan,Lin Zhao*

Main category: cs.RO

TL;DR: 本文提出DiffPF，一种利用扩散模型进行动态系统状态估计的可微分粒子滤波器，通过将扩散模型条件化于预测粒子和当前观测来学习灵活的后验采样器，在多种场景中优于现有滤波基线。


<details>
  <summary>Details</summary>
Motivation: 传统可微分粒子滤波器需要重要性加权且依赖预定义或低容量的提议分布，难以处理复杂、高维及多模态的滤波分布。

Method: DiffPF通过将扩散模型条件化于预测粒子和当前观测，学习灵活的后验采样器，实现从复杂分布中准确、等权重采样。

Result: 在单模态和高度多模态分布场景、模拟及现实任务中均优于现有滤波基线，高度多模态全局定位基准上估计精度提升82.8%，KITTI视觉里程计基准上提升26%。

Conclusion: DiffPF是首个将条件扩散模型集成到粒子滤波中的方法，实现高质量后验采样，产生更多信息粒子，显著改进状态估计。

Abstract: This paper proposes DiffPF, a differentiable particle filter that leverages
diffusion models for state estimation in dynamic systems. Unlike conventional
differentiable particle filters, which require importance weighting and
typically rely on predefined or low-capacity proposal distributions. DiffPF
learns a flexible posterior sampler by conditioning a diffusion model on
predicted particles and the current observation. This enables accurate,
equally-weighted sampling from complex, high-dimensional, and multimodal
filtering distributions. We evaluate DiffPF across a range of scenarios,
including both unimodal and highly multimodal distributions, and test it on
simulated as well as real-world tasks, where it consistently outperforms
existing filtering baselines. In particular, DiffPF achieves an 82.8%
improvement in estimation accuracy on a highly multimodal global localization
benchmark, and a 26% improvement on the real-world KITTI visual odometry
benchmark, compared to state-of-the-art differentiable filters. To the best of
our knowledge, DiffPF is the first method to integrate conditional diffusion
models into particle filtering, enabling high-quality posterior sampling that
produces more informative particles and significantly improves state
estimation.

</details>


### [41] [Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction](https://arxiv.org/abs/2507.15729)
*Jens V. Rüppel,Andrey Rudenko,Tim Schreiter,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 本文提出了一种基于凝视和语音的辅助机器人界面，该界面能通过多视觉输入感知工作环境并支持动态用户任务，其模块化设计可适应不同任务和机器人，支持实时语言交互状态表示和快速机载感知模块，实验室研究表明基于LLM的方法在适应性、用户参与度和任务执行指标上有提升但可能产生冗余输出，而脚本化管道更适合简单任务。


<details>
  <summary>Details</summary>
Motivation: 现有HRI系统在解释和遵循用户指令、动作生成及机器人任务解决方面取得进展，但在协作任务中对用户的双向、多模态和上下文感知支持仍是开放挑战。

Method: 提出凝视和语音告知的辅助机器人界面，系统模块化且可迁移以适应不同任务和机器人，能实时使用基于语言的交互状态表示和快速机载感知模块，开发得到多个公共传播活动支持，并在两项实验室研究中与传统脚本化HRI管道比较性能和用户评分。

Result: 实验室研究发现，基于LLM的方法增强了适应性，略微提高了用户参与度和任务执行指标，但可能产生冗余输出；而脚本化管道更适合更直接的任务。

Conclusion: 基于LLM的辅助机器人界面在适应性等方面有优势但存在冗余输出问题，脚本化管道适用于简单任务，该研究为改进HRI系统的鲁棒性和用户体验提供了重要考虑。

Abstract: The rapid development of Large Language Models (LLMs) creates an exciting
potential for flexible, general knowledge-driven Human-Robot Interaction (HRI)
systems for assistive robots. Existing HRI systems demonstrate great progress
in interpreting and following user instructions, action generation, and robot
task solving. On the other hand, bi-directional, multi-modal, and context-aware
support of the user in collaborative tasks still remains an open challenge. In
this paper, we present a gaze- and speech-informed interface to the assistive
robot, which is able to perceive the working environment from multiple vision
inputs and support the dynamic user in their tasks. Our system is designed to
be modular and transferable to adapt to diverse tasks and robots, and it is
capable of real-time use of language-based interaction state representation and
fast on board perception modules. Its development was supported by multiple
public dissemination events, contributing important considerations for improved
robustness and user experience. Furthermore, in two lab studies, we compare the
performance and user ratings of our system with those of a traditional scripted
HRI pipeline. Our findings indicate that an LLM-based approach enhances
adaptability and marginally improves user engagement and task execution metrics
but may produce redundant output, while a scripted pipeline is well suited for
more straightforward tasks.

</details>


### [42] [Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs](https://arxiv.org/abs/2507.15782)
*Ruochu Yang,Yu Zhou,Fumin Zhang,Mengxue Hou*

Main category: cs.RO

TL;DR: 本文针对家庭机器人在开放集物体操作和大环境导航方面的智能不足问题，提出了一种名为Inter-LLM的交错式LLM与运动规划算法，通过设计多模态动作成本相似性函数优化长程规划，在模拟实验中整体任务性能提升30%。


<details>
  <summary>Details</summary>
Motivation: 家庭机器人仍缺乏类人智能，尤其在操作开放集物体和高效准确导航大环境方面存在不足，需解决大型场景图中的广义多物体收集问题，该问题因需在高不确定性下的广阔动作状态空间进行长程规划而极具挑战性。

Method: 提出了一种新颖的交错式LLM和运动规划算法Inter-LLM，通过设计多模态动作成本相似性函数，使算法既能反映历史又能展望未来以优化计划，在质量和效率间取得良好平衡。

Result: 模拟实验表明，与最新研究相比，该算法在完成人类指令、最大化任务成功率和最小化任务成本方面，整体任务性能提升了30%。

Conclusion: 所提出的Inter-LLM算法有效解决了家庭机器人在长程复杂任务中的规划难题，显著提升了整体任务性能。

Abstract: Household robots have been a longstanding research topic, but they still lack
human-like intelligence, particularly in manipulating open-set objects and
navigating large environments efficiently and accurately. To push this
boundary, we consider a generalized multi-object collection problem in large
scene graphs, where the robot needs to pick up and place multiple objects
across multiple locations in a long mission of multiple human commands. This
problem is extremely challenging since it requires long-horizon planning in a
vast action-state space under high uncertainties. To this end, we propose a
novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a
multimodal action cost similarity function, our algorithm can both reflect the
history and look into the future to optimize plans, striking a good balance of
quality and efficiency. Simulation experiments demonstrate that compared with
latest works, our algorithm improves the overall mission performance by 30% in
terms of fulfilling human commands, maximizing mission success rates, and
minimizing mission costs.

</details>


### [43] [Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers](https://arxiv.org/abs/2507.15833)
*Ian Chuang,Andrew Lee,Dechen Gao,Jinyu Zou,Iman Soltani*

Main category: cs.RO

TL;DR: 本文探讨将类人主动凝视融入机器人策略以提升效率和性能，基于AV-ALOHA平台构建主动视觉系统，提出同时收集人类眼动数据和机器人演示的框架，将凝视信息集成到ViT中，通过两种凝视模仿与预测方法，结果表明该方法减少计算开销并提升高精度任务性能和对未见过干扰物的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 人类视觉是由凝视驱动的高度主动过程，能将注意力和注视导向任务相关区域并显著减少视觉处理量，而机器人学习系统通常依赖对原始相机图像的被动、统一处理，故探索将类人主动凝视融入机器人策略以提升效率和性能。

Method: 基于AV-ALOHA机器人仿真平台，引入同时收集人类操作员眼动数据和机器人演示的框架，构建包含人类凝视的机器人策略训练的仿真基准和数据集；将凝视信息通过受图像分割启发的注视区域斑块标记化方案集成到Vision Transformers（ViTs）中；探索两种从人类数据进行凝视模仿与预测的方法：一是两阶段模型预测凝视以指导注视和动作，二是将凝视融入动作空间，使策略端到端联合预测凝视和动作。

Result: 与统一斑块标记化相比，注视区域斑块标记化方案显著减少标记数量（从而减少计算量），且不牺牲感兴趣区域附近的视觉保真度；该方法大幅降低计算开销，同时提升高精度任务的性能和对未见过干扰物的鲁棒性。

Conclusion: 人类启发的视觉处理为机器人视觉系统提供了有用的归纳偏置。

Abstract: Human vision is a highly active process driven by gaze, which directs
attention and fixation to task-relevant regions and dramatically reduces visual
processing. In contrast, robot learning systems typically rely on passive,
uniform processing of raw camera images. In this work, we explore how
incorporating human-like active gaze into robotic policies can enhance both
efficiency and performance. We build on recent advances in foveated image
processing and apply them to an Active Vision robot system that emulates both
human head movement and eye tracking. Extending prior work on the AV-ALOHA
robot simulation platform, we introduce a framework for simultaneously
collecting eye-tracking data and robot demonstrations from a human operator as
well as a simulation benchmark and dataset for training robot policies that
incorporate human gaze. Given the widespread use of Vision Transformers (ViTs)
in robot learning, we integrate gaze information into ViTs using a foveated
patch tokenization scheme inspired by recent work in image segmentation.
Compared to uniform patch tokenization, this significantly reduces the number
of tokens-and thus computation-without sacrificing visual fidelity near regions
of interest. We also explore two approaches to gaze imitation and prediction
from human data. The first is a two-stage model that predicts gaze to guide
foveation and action; the second integrates gaze into the action space,
allowing the policy to jointly predict gaze and actions end-to-end. Our results
show that our method for foveated robot vision not only drastically reduces
computational overhead, but also improves performance for high precision tasks
and robustness to unseen distractors. Together, these findings suggest that
human-inspired visual processing offers a useful inductive bias for robotic
vision systems. https://ian-chuang.github.io/gaze-av-aloha/

</details>
