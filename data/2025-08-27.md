<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning](https://arxiv.org/abs/2508.18397)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: 离线强化学习（RL）在自动驾驶车辆规划中面临数据不平衡问题，本文通过六种数据筛选策略显著提升了安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶日志中数据不平衡问题，避免因罕见事件数据不足导致的策略脆弱和不安全。

Method: 比较六种关键性权重方案（启发式、不确定性和行为基），在Waymax模拟器中训练七个目标条件CQL代理。

Result: 所有数据筛选方法均优于基线，基于模型不确定性的方法将碰撞率从16.0%降至5.5%。

Conclusion: 智能非均匀采样是构建安全可靠自动驾驶代理的关键，不同时间尺度权重各有优势。

Abstract: Offline Reinforcement Learning (RL) presents a promising paradigm for
training autonomous vehicle (AV) planning policies from large-scale, real-world
driving logs. However, the extreme data imbalance in these logs, where mundane
scenarios vastly outnumber rare "long-tail" events, leads to brittle and unsafe
policies when using standard uniform data sampling. In this work, we address
this challenge through a systematic, large-scale comparative study of data
curation strategies designed to focus the learning process on information-rich
samples. We investigate six distinct criticality weighting schemes which are
categorized into three families: heuristic-based, uncertainty-based, and
behavior-based. These are evaluated at two temporal scales, the individual
timestep and the complete scenario. We train seven goal-conditioned
Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based
architecture and evaluate them in the high-fidelity Waymax simulator. Our
results demonstrate that all data curation methods significantly outperform the
baseline. Notably, data-driven curation using model uncertainty as a signal
achieves the most significant safety improvements, reducing the collision rate
by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear
trade-off where timestep-level weighting excels at reactive safety while
scenario-level weighting improves long-horizon planning. Our work provides a
comprehensive framework for data curation in Offline RL and underscores that
intelligent, non-uniform sampling is a critical component for building safe and
reliable autonomous agents.

</details>


### [2] [Maintenance automation: methods for robotics manipulation planning and execution](https://arxiv.org/abs/2508.18399)
*Christian Friedrich,Ralf Gulde,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 提出了一种基于规划和控制的机器人系统，用于自动化维护任务，包括拆卸和组装操作。


<details>
  <summary>Details</summary>
Motivation: 自动化复杂任务需要解决规划、控制和执行问题，尤其是在环境不确定的情况下。

Method: 系统基于CAD和RGBD数据规划，将符号计划转化为可执行的机器人指令。

Result: 通过实际应用验证了系统的有效性。

Conclusion: 这是将理论成果转化为实际机器人解决方案的第一步。

Abstract: Automating complex tasks using robotic systems requires skills for planning,
control and execution. This paper proposes a complete robotic system for
maintenance automation, which can automate disassembly and assembly operations
under environmental uncertainties (e.g. deviations between prior plan
information). The cognition of the robotic system is based on a planning
approach (using CAD and RGBD data) and includes a method to interpret a
symbolic plan and transform it to a set of executable robot instructions. The
complete system is experimentally evaluated using real-world applications. This
work shows the first step to transfer these theoretical results into a
practical robotic solution.

</details>


### [3] [Efficient task and path planning for maintenance automation using a robot system](https://arxiv.org/abs/2508.18400)
*Christian Friedrich,Akos Csiszar,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 提出了一种结合离线CAD数据和在线RGBD视觉系统的智能自动化维护方法，通过概率滤波补偿不确定性，并采用符号描述和采样方法进行任务规划，优化路径规划以减少时间。


<details>
  <summary>Details</summary>
Motivation: 工厂未来的智能自动化需求，尤其是维护任务的自动化，需要机器人系统能自主规划任务和路径，同时处理环境不确定性。

Method: 结合离线CAD数据和在线RGBD视觉系统，使用概率滤波补偿不确定性；采用符号描述和采样方法进行任务规划；优化路径规划算法以减少时间。

Result: 实验验证了方法的有效性，并讨论了其性能。

Conclusion: 该方法特别适用于维护自动化，能够有效处理环境不确定性并优化任务和路径规划。

Abstract: The research and development of intelligent automation solutions is a
ground-breaking point for the factory of the future. A promising and
challenging mission is the use of autonomous robot systems to automate tasks in
the field of maintenance. For this purpose, the robot system must be able to
plan autonomously the different manipulation tasks and the corresponding paths.
Basic requirements are the development of algorithms with a low computational
complexity and the possibility to deal with environmental uncertainties. In
this work, an approach is presented, which is especially suited to solve the
problem of maintenance automation. For this purpose, offline data from CAD is
combined with online data from an RGBD vision system via a probabilistic
filter, to compensate uncertainties from offline data. For planning the
different tasks, a method is explained, which use a symbolic description,
founded on a novel sampling-based method to compute the disassembly space. For
path planning we use global state-of-the art algorithms with a method that
allows the adaption of the exploration stepsize in order to reduce the planning
time. Every method is experimentally validated and discussed.

</details>


### [4] [PneuGelSight: Soft Robotic Vision-Based Proprioception and Tactile Sensing](https://arxiv.org/abs/2508.18443)
*Ruohan Zhang,Uksang Yoo,Yichen Li,Arpit Argawal,Wenzhen Yuan*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的软体机器人传感方法，通过嵌入式摄像头实现高分辨率本体感知和触觉传感，并开发了仿真到现实的零样本知识迁移管道。


<details>
  <summary>Details</summary>
Motivation: 软体气动机器人在工业和人际交互应用中具有灵活性和适应性，但需要先进的传感技术以实现触觉反馈和本体感知。

Method: 开发了PneuGelSight气动机器人，结合嵌入式摄像头实现传感，并提出了仿真到现实的优化管道。

Result: PneuGelSight和仿真到现实管道为软体机器人提供了一种新颖、易实现且鲁棒的传感方法。

Conclusion: 该方法为开发具有增强感知能力的先进软体机器人铺平了道路。

Abstract: Soft pneumatic robot manipulators are popular in industrial and
human-interactive applications due to their compliance and flexibility.
However, deploying them in real-world scenarios requires advanced sensing for
tactile feedback and proprioception. Our work presents a novel vision-based
approach for sensorizing soft robots. We demonstrate our approach on
PneuGelSight, a pioneering pneumatic manipulator featuring high-resolution
proprioception and tactile sensing via an embedded camera. To optimize the
sensor's performance, we introduce a comprehensive pipeline that accurately
simulates its optical and dynamic properties, facilitating a zero-shot
knowledge transition from simulation to real-world applications. PneuGelSight
and our sim-to-real pipeline provide a novel, easily implementable, and robust
sensing methodology for soft robots, paving the way for the development of more
advanced soft robots with enhanced sensory capabilities.

</details>


### [5] [Mimicking associative learning of rats via a neuromorphic robot in open field maze using spatial cell models](https://arxiv.org/abs/2508.18460)
*Tianze Liu,Md Abu Bakr Siddique,Hongyu An*

Main category: cs.RO

TL;DR: 论文提出通过模拟动物的联想学习机制，增强智能机器人在资源受限环境中的自主能力，减少对大数据和神经网络的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动的AI方法依赖大数据和高能耗，在资源受限的应用中（如行星探索）适应性差。模拟动物的联想学习可以提升机器人的自主性和适应性。

Method: 通过神经形态机器人模拟啮齿类动物在开放迷宫环境中的联想学习，利用空间细胞（如位置细胞和网格细胞）的模型。

Result: 目标是实现实时场景中的在线联想学习，优化机器人在动态环境中的自主导航能力。

Conclusion: 该研究旨在通过生物空间认知与机器人技术的结合，推动自主系统的进步。

Abstract: Data-driven Artificial Intelligence (AI) approaches have exhibited remarkable
prowess across various cognitive tasks using extensive training data. However,
the reliance on large datasets and neural networks presents challenges such as
highpower consumption and limited adaptability, particularly in
SWaP-constrained applications like planetary exploration. To address these
issues, we propose enhancing the autonomous capabilities of intelligent robots
by emulating the associative learning observed in animals. Associative learning
enables animals to adapt to their environment by memorizing concurrent events.
By replicating this mechanism, neuromorphic robots can navigate dynamic
environments autonomously, learning from interactions to optimize performance.
This paper explores the emulation of associative learning in rodents using
neuromorphic robots within open-field maze environments, leveraging insights
from spatial cells such as place and grid cells. By integrating these models,
we aim to enable online associative learning for spatial tasks in real-time
scenarios, bridging the gap between biological spatial cognition and robotics
for advancements in autonomous systems.

</details>


### [6] [SignLoc: Robust Localization using Navigation Signs and Public Maps](https://arxiv.org/abs/2508.18606)
*Nicky Zimmerman,Joel Loo,Ayush Agrawal,David Hsu*

Main category: cs.RO

TL;DR: SignLoc是一种利用导航标志进行机器人全局定位的方法，无需先前的传感器建图。


<details>
  <summary>Details</summary>
Motivation: 导航标志和地图（如平面图和街道地图）在人类环境中广泛使用，但机器人系统很少利用它们。

Method: SignLoc从输入地图中提取导航图，并使用概率观测模型将检测到的标志与图匹配，实现鲁棒的拓扑语义定位。

Result: 在多样的大规模环境中（如大学校园、购物中心和医院综合体），SignLoc仅需观察一到两个标志即可可靠定位机器人。

Conclusion: SignLoc展示了利用导航标志进行机器人定位的潜力，无需依赖传感器建图。

Abstract: Navigation signs and maps, such as floor plans and street maps, are widely
available and serve as ubiquitous aids for way-finding in human environments.
Yet, they are rarely used by robot systems. This paper presents SignLoc, a
global localization method that leverages navigation signs to localize the
robot on publicly available maps -- specifically floor plans and OpenStreetMap
(OSM) graphs -- without prior sensor-based mapping. SignLoc first extracts a
navigation graph from the input map. It then employs a probabilistic
observation model to match directional and locational cues from the detected
signs to the graph, enabling robust topo-semantic localization within a Monte
Carlo framework. We evaluated SignLoc in diverse large-scale environments: part
of a university campus, a shopping mall, and a hospital complex. Experimental
results show that SignLoc reliably localizes the robot after observing only one
to two signs.

</details>


### [7] [Integration of Robot and Scene Kinematics for Sequential Mobile Manipulation Planning](https://arxiv.org/abs/2508.18627)
*Ziyuan Jiao,Yida Niu,Zeyu Zhang,Yangyang Wu,Yao Su,Yixin Zhu,Hangxin Liu,Song-Chun Zhu*

Main category: cs.RO

TL;DR: 提出了一种Sequential Mobile Manipulation Planning (SMMP)框架，通过整合环境结构和机器人运动学，构建Augmented Configuration Space (A-Space)，显著提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决长时域多步移动操作任务中导航和操作约束分离的问题，提升机器人与关节物体的交互能力。

Method: 采用三级规划框架：任务规划生成符号动作序列，优化运动规划计算连续轨迹，中间阶段选择可行目标。

Result: 仿真实验显示任务成功率提高84.6%，真实机器人系统验证了其在多种物体和长时域任务中的有效性。

Conclusion: 将场景运动学建模为规划实体，提供了一种可扩展且通用的复杂机器人操作方法。

Abstract: We present a Sequential Mobile Manipulation Planning (SMMP) framework that
can solve long-horizon multi-step mobile manipulation tasks with coordinated
whole-body motion, even when interacting with articulated objects. By
abstracting environmental structures as kinematic models and integrating them
with the robot's kinematics, we construct an Augmented Configuration Apace
(A-Space) that unifies the previously separate task constraints for navigation
and manipulation, while accounting for the joint reachability of the robot
base, arm, and manipulated objects. This integration facilitates efficient
planning within a tri-level framework: a task planner generates symbolic action
sequences to model the evolution of A-Space, an optimization-based motion
planner computes continuous trajectories within A-Space to achieve desired
configurations for both the robot and scene elements, and an intermediate plan
refinement stage selects action goals that ensure long-horizon feasibility. Our
simulation studies first confirm that planning in A-Space achieves an 84.6\%
higher task success rate compared to baseline methods. Validation on real
robotic systems demonstrates fluid mobile manipulation involving (i) seven
types of rigid and articulated objects across 17 distinct contexts, and (ii)
long-horizon tasks of up to 14 sequential steps. Our results highlight the
significance of modeling scene kinematics into planning entities, rather than
encoding task-specific constraints, offering a scalable and generalizable
approach to complex robotic manipulation.

</details>


### [8] [Engineering Automotive Digital Twins on Standardized Architectures: A Case Study](https://arxiv.org/abs/2508.18662)
*Stefan Ramdhan,Winnie Trandinh,Istvan David,Vera Pantelic,Mark Lawford*

Main category: cs.RO

TL;DR: 研究了ISO 23247参考架构在汽车数字孪生（DT）开发中的适用性，通过自适应巡航控制DT案例，分析了其优缺点并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 汽车行业对数字孪生技术的需求增长，但缺乏相关架构指南，ISO 23247是目前为数不多的可行起点。

Method: 通过开发1/10比例自动驾驶车辆的自适应巡航控制DT案例研究，评估ISO 23247参考架构的适用性。

Result: 识别了参考架构的优势和局限性，为研究人员、从业者和标准开发者提供了未来方向。

Conclusion: ISO 23247参考架构在汽车DT开发中具有一定适用性，但仍需改进和扩展。

Abstract: Digital twin (DT) technology has become of interest in the automotive
industry. There is a growing need for smarter services that utilize the unique
capabilities of DTs, ranging from computer-aided remote control to cloud-based
fleet coordination. Developing such services starts with the software
architecture. However, the scarcity of DT architectural guidelines poses a
challenge for engineering automotive DTs. Currently, the only DT architectural
standard is the one defined in ISO 23247. Though not developed for automotive
systems, it is one of the few feasible starting points for automotive DTs. In
this work, we investigate the suitability of the ISO 23247 reference
architecture for developing automotive DTs. Through the case study of
developing an Adaptive Cruise Control DT for a 1/10\textsuperscript{th}-scale
autonomous vehicle, we identify some strengths and limitations of the reference
architecture and begin distilling future directions for researchers,
practitioners, and standard developers.

</details>


### [9] [Deep Sensorimotor Control by Imitating Predictive Models of Human Motion](https://arxiv.org/abs/2508.18691)
*Himanshu Gaurav Singh,Pieter Abbeel,Jitendra Malik,Antonio Loquercio*

Main category: cs.RO

TL;DR: 提出了一种通过模仿人类运动预测模型来训练机器人传感器运动策略的新方法，无需梯度运动重定向或对抗损失，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 随着机器人与人类之间的体现差距缩小，利用人类与周围环境互动的数据集进行机器人学习成为可能。

Method: 通过模仿人类运动预测模型，训练传感器运动策略，利用机器人末端执行器关键点与人体关键点的运动相似性。

Result: 该方法在多种机器人和任务中表现优异，显著优于现有基线，并能替代精心设计的密集奖励和课程。

Conclusion: 该方法有效利用了人类场景互动数据集的规模和多样性，为机器人学习提供了新思路。

Abstract: As the embodiment gap between a robot and a human narrows, new opportunities
arise to leverage datasets of humans interacting with their surroundings for
robot learning. We propose a novel technique for training sensorimotor policies
with reinforcement learning by imitating predictive models of human motions.
Our key insight is that the motion of keypoints on human-inspired robot
end-effectors closely mirrors the motion of corresponding human body keypoints.
This enables us to use a model trained to predict future motion on human data
\emph{zero-shot} on robot data. We train sensorimotor policies to track the
predictions of such a model, conditioned on a history of past robot states,
while optimizing a relatively sparse task reward. This approach entirely
bypasses gradient-based kinematic retargeting and adversarial losses, which
limit existing methods from fully leveraging the scale and diversity of modern
human-scene interaction datasets. Empirically, we find that our approach can
work across robots and tasks, outperforming existing baselines by a large
margin. In addition, we find that tracking a human motion model can substitute
for carefully designed dense rewards and curricula in manipulation tasks. Code,
data and qualitative results available at
https://jirl-upenn.github.io/track_reward/.

</details>


### [10] [AgriChrono: A Multi-modal Dataset Capturing Crop Growth and Lighting Variability with a Field Robot](https://arxiv.org/abs/2508.18694)
*Jaehwan Jeong,Tuan-Anh Vu,Mohammad Jony,Shahab Ahmad,Md. Mukhlesur Rahman,Sangpil Kim,M. Khalid Jawed*

Main category: cs.RO

TL;DR: AgriChrono是一个新型机器人数据收集平台和多模态数据集，旨在捕捉真实农业环境的动态条件，弥补现有静态数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多在静态或受控环境中收集，缺乏传感器多样性和时间跨度，无法反映真实农田的动态变化，导致模型泛化能力差。

Method: 开发了AgriChrono平台，集成多种传感器，远程同步采集RGB、深度、LiDAR和IMU数据，支持长期动态数据收集。

Result: 在AgriChrono数据集上测试了多种3D重建模型，展示了其在动态条件下提升模型泛化能力的研究价值。

Conclusion: AgriChrono为动态农业环境下的模型研究提供了宝贵资源，代码和数据集已开源。

Abstract: Existing datasets for precision agriculture have primarily been collected in
static or controlled environments such as indoor labs or greenhouses, often
with limited sensor diversity and restricted temporal span. These conditions
fail to reflect the dynamic nature of real farmland, including illumination
changes, crop growth variation, and natural disturbances. As a result, models
trained on such data often lack robustness and generalization when applied to
real-world field scenarios. In this paper, we present AgriChrono, a novel
robotic data collection platform and multi-modal dataset designed to capture
the dynamic conditions of real-world agricultural environments. Our platform
integrates multiple sensors and enables remote, time-synchronized acquisition
of RGB, Depth, LiDAR, and IMU data, supporting efficient and repeatable
long-term data collection across varying illumination and crop growth stages.
We benchmark a range of state-of-the-art 3D reconstruction models on the
AgriChrono dataset, highlighting the difficulty of reconstruction in real-world
field environments and demonstrating its value as a research asset for
advancing model generalization under dynamic conditions. The code and dataset
are publicly available at: https://github.com/StructuresComp/agri-chrono

</details>


### [11] [Enhancing Video-Based Robot Failure Detection Using Task Knowledge](https://arxiv.org/abs/2508.18705)
*Santosh Thoduka,Sebastian Houben,Juergen Gall,Paul G. Plöger*

Main category: cs.RO

TL;DR: 提出了一种基于视频的机器人任务失败检测方法，利用时空知识和任务相关对象信息，通过数据增强提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有失败检测方法在真实场景中表现不佳，需要更可靠的方法来触发安全操作或任务重规划。

Method: 利用机器人动作和任务相关对象的时空信息，结合可变帧率的数据增强方法。

Result: 在ARMBench数据集上F1分数从77.9提升到81.4，证明了时空信息的重要性。

Conclusion: 时空信息对失败检测至关重要，未来可进一步探索合适的启发式方法。

Abstract: Robust robotic task execution hinges on the reliable detection of execution
failures in order to trigger safe operation modes, recovery strategies, or task
replanning. However, many failure detection methods struggle to provide
meaningful performance when applied to a variety of real-world scenarios. In
this paper, we propose a video-based failure detection approach that uses
spatio-temporal knowledge in the form of the actions the robot performs and
task-relevant objects within the field of view. Both pieces of information are
available in most robotic scenarios and can thus be readily obtained. We
demonstrate the effectiveness of our approach on three datasets that we amend,
in part, with additional annotations of the aforementioned task-relevant
knowledge. In light of the results, we also propose a data augmentation method
that improves performance by applying variable frame rates to different parts
of the video. We observe an improvement from 77.9 to 80.0 in F1 score on the
ARMBench dataset without additional computational expense and an additional
increase to 81.4 with test-time augmentation. The results emphasize the
importance of spatio-temporal information during failure detection and suggest
further investigation of suitable heuristics in future implementations. Code
and annotations are available.

</details>


### [12] [HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation](https://arxiv.org/abs/2508.18802)
*Li Sun,Jiefeng Wu,Feng Chen,Ruizhe Liu,Yanchao Yang*

Main category: cs.RO

TL;DR: HyperTASR是一个基于超网络的框架，动态调整场景表示以适应任务目标和执行阶段，显著提升了机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的任务无关表示提取方法无法模拟人类认知中的动态感知适应，限制了机器人操作任务的学习效率。

Method: 通过超网络生成条件化的表示变换参数，将任务上下文和状态依赖处理路径分离，优化表示质量。

Result: 在仿真和真实环境中均表现出性能提升，能够选择性关注任务相关信息。

Conclusion: HyperTASR通过动态调整表示，更接近人类自适应感知，为机器人操作任务提供了高效解决方案。

Abstract: Effective policy learning for robotic manipulation requires scene
representations that selectively capture task-relevant environmental features.
Current approaches typically employ task-agnostic representation extraction,
failing to emulate the dynamic perceptual adaptation observed in human
cognition. We present HyperTASR, a hypernetwork-driven framework that modulates
scene representations based on both task objectives and the execution phase.
Our architecture dynamically generates representation transformation parameters
conditioned on task specifications and progression state, enabling
representations to evolve contextually throughout task execution. This approach
maintains architectural compatibility with existing policy learning frameworks
while fundamentally reconfiguring how visual features are processed. Unlike
methods that simply concatenate or fuse task embeddings with task-agnostic
representations, HyperTASR establishes computational separation between
task-contextual and state-dependent processing paths, enhancing learning
efficiency and representational quality. Comprehensive evaluations in both
simulation and real-world environments demonstrate substantial performance
improvements across different representation paradigms. Through ablation
studies and attention visualization, we confirm that our approach selectively
prioritizes task-relevant scene information, closely mirroring human adaptive
perception during manipulation tasks. The project website is at
\href{https://lisunphil.github.io/HyperTASR_projectpage/}{lisunphil.github.io/HyperTASR\_projectpage}.

</details>


### [13] [Learning Real-World Acrobatic Flight from Human Preferences](https://arxiv.org/abs/2508.18817)
*Colin Merk,Ismail Geles,Jiaxu Xing,Angel Romero,Giorgia Ramponi,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 论文提出了一种基于偏好的强化学习方法（PbRL）用于敏捷无人机控制，通过改进的Reward Ensemble under Confidence（REC）提升了偏好建模和学习稳定性，并在仿真和现实环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决传统强化学习中手动设计奖励函数的困难，尤其是在复杂动态任务（如特技飞行）中，人类偏好难以形式化的问题。

Method: 方法基于Preference-based Proximal Policy Optimization（Preference PPO），提出了REC扩展，通过改进奖励学习目标来优化偏好建模和学习稳定性。

Result: 实验结果显示，REC方法达到了88.4%的奖励性能，优于标准Preference PPO的55.2%，并成功将策略迁移到真实无人机上执行特技动作。

Conclusion: 结论表明PbRL能有效捕捉复杂的人类偏好目标，同时揭示了手动设计奖励函数的局限性（仅60.7%与人类偏好一致）。

Abstract: Preference-based reinforcement learning (PbRL) enables agents to learn
control policies without requiring manually designed reward functions, making
it well-suited for tasks where objectives are difficult to formalize or
inherently subjective. Acrobatic flight poses a particularly challenging
problem due to its complex dynamics, rapid movements, and the importance of
precise execution. In this work, we explore the use of PbRL for agile drone
control, focusing on the execution of dynamic maneuvers such as powerloops.
Building on Preference-based Proximal Policy Optimization (Preference PPO), we
propose Reward Ensemble under Confidence (REC), an extension to the reward
learning objective that improves preference modeling and learning stability.
Our method achieves 88.4% of the shaped reward performance, compared to 55.2%
with standard Preference PPO. We train policies in simulation and successfully
transfer them to real-world drones, demonstrating multiple acrobatic maneuvers
where human preferences emphasize stylistic qualities of motion. Furthermore,
we demonstrate the applicability of our probabilistic reward model in a
representative MuJoCo environment for continuous control. Finally, we highlight
the limitations of manually designed rewards, observing only 60.7% agreement
with human preferences. These results underscore the effectiveness of PbRL in
capturing complex, human-centered objectives across both physical and simulated
domains.

</details>


### [14] [AS2FM: Enabling Statistical Model Checking of ROS 2 Systems for Robust Autonomy](https://arxiv.org/abs/2508.18820)
*Christian Henkel,Marco Lampacrescia,Michaela Klauck,Matteo Morelli*

Main category: cs.RO

TL;DR: 提出了一种使用统计模型检查（SMC）在设计时验证自主机器人系统属性的新方法，并开发了工具AS2FM。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在未知环境中运行的系统设计具有挑战性，需要验证其属性。

Method: 扩展SCXML格式以建模系统组件，开发AS2FM工具将模型转换为JANI格式，利用SMC工具验证属性。

Result: 在ROS 2机器人操作案例中成功识别问题，验证时间短且线性扩展。

Conclusion: 该方法在系统功能支持和验证效率上优于现有技术。

Abstract: Designing robotic systems to act autonomously in unforeseen environments is a
challenging task. This work presents a novel approach to use formal
verification, specifically Statistical Model Checking (SMC), to verify system
properties of autonomous robots at design-time. We introduce an extension of
the SCXML format, designed to model system components including both Robot
Operating System 2 (ROS 2) and Behavior Tree (BT) features. Further, we
contribute Autonomous Systems to Formal Models (AS2FM), a tool to translate the
full system model into JANI. The use of JANI, a standard format for
quantitative model checking, enables verification of system properties with
off-the-shelf SMC tools. We demonstrate the practical usability of AS2FM both
in terms of applicability to real-world autonomous robotic control systems, and
in terms of verification runtime scaling. We provide a case study, where we
successfully identify problems in a ROS 2-based robotic manipulation use case
that is verifiable in less than one second using consumer hardware.
Additionally, we compare to the state of the art and demonstrate that our
method is more comprehensive in system feature support, and that the
verification runtime scales linearly with the size of the model, instead of
exponentially.

</details>


### [15] [VisionSafeEnhanced VPC: Cautious Predictive Control with Visibility Constraints under Uncertainty for Autonomous Robotic Surgery](https://arxiv.org/abs/2508.18937)
*Wang Jiayin,Wei Yanran,Jiang Lei,Guo Xiaoyu,Zheng Ayong,Zhao Weidong,Li Zhongkui*

Main category: cs.RO

TL;DR: 论文提出了一种名为VisionSafeEnhanced Visual Predictive Control (VPC)的鲁棒且适应不确定性的框架，用于自主控制腹腔镜，确保在不确定性下的视野安全。


<details>
  <summary>Details</summary>
Motivation: 现有基于像素的视觉伺服控制在复杂干扰下可能影响手术安全性和视觉体验，因此需要一种更鲁棒的方法。

Method: 结合高斯过程回归进行不确定性量化，并提出一种基于概率保证的安全感知轨迹优化框架。

Result: 在实验中，该方法保持了近乎完美的目标可见性（>99.9%），并减少了跟踪误差。

Conclusion: 提出的VPC框架在复杂干扰下表现出色，显著提升了手术安全性和视觉体验。

Abstract: Autonomous control of the laparoscope in robot-assisted Minimally Invasive
Surgery (MIS) has received considerable research interest due to its potential
to improve surgical safety. Despite progress in pixel-level Image-Based Visual
Servoing (IBVS) control, the requirement of continuous visibility and the
existence of complex disturbances, such as parameterization error, measurement
noise, and uncertainties of payloads, could degrade the surgeon's visual
experience and compromise procedural safety. To address these limitations, this
paper proposes VisionSafeEnhanced Visual Predictive Control (VPC), a robust and
uncertainty-adaptive framework for autonomous laparoscope control that
guarantees Field of View (FoV) safety under uncertainty. Firstly, Gaussian
Process Regression (GPR) is utilized to perform hybrid (deterministic +
stochastic) quantification of operational uncertainties including residual
model uncertainties, stochastic uncertainties, and external disturbances. Based
on uncertainty quantification, a novel safety aware trajectory optimization
framework with probabilistic guarantees is proposed, where a
uncertainty-adaptive safety Control Barrier Function (CBF) condition is given
based on uncertainty propagation, and chance constraints are simultaneously
formulated based on probabilistic approximation. This uncertainty aware
formulation enables adaptive control effort allocation, minimizing unnecessary
camera motion while maintaining robustness. The proposed method is validated
through comparative simulations and experiments on a commercial surgical robot
platform (MicroPort MedBot Toumai) performing a sequential multi-target lymph
node dissection. Compared with baseline methods, the framework maintains
near-perfect target visibility (>99.9%), reduces tracking e

</details>


### [16] [Enhanced UAV Path Planning Using the Tangent Intersection Guidance (TIG) Algorithm](https://arxiv.org/abs/2508.18967)
*Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira*

Main category: cs.RO

TL;DR: TIG算法通过椭圆切线交点方法生成无人机路径，在静态和动态环境中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 无人机的高效安全导航对作战支持、包裹递送和搜救等应用至关重要。

Method: 采用椭圆切线交点法生成可行路径，结合启发式规则选择最优路径，并通过二次贝塞尔曲线平滑技术优化路径。

Result: TIG算法在静态环境中生成路径时间短（0.01秒起）、转弯角度少，优于A*等算法；在未知环境中实时避障能力优于APF等算法。

Conclusion: TIG算法在路径规划中表现出高效性和实时性，适用于多种复杂环境。

Abstract: Efficient and safe navigation of Unmanned Aerial Vehicles (UAVs) is critical
for various applications, including combat support, package delivery and Search
and Rescue Operations. This paper introduces the Tangent Intersection Guidance
(TIG) algorithm, an advanced approach for UAV path planning in both static and
dynamic environments. The algorithm uses the elliptic tangent intersection
method to generate feasible paths. It generates two sub-paths for each threat,
selects the optimal route based on a heuristic rule, and iteratively refines
the path until the target is reached. Considering the UAV kinematic and dynamic
constraints, a modified smoothing technique based on quadratic B\'ezier curves
is adopted to generate a smooth and efficient route. Experimental results show
that the TIG algorithm can generate the shortest path in less time, starting
from 0.01 seconds, with fewer turning angles compared to A*, PRM, RRT*, Tangent
Graph, and Static APPATT algorithms in static environments. Furthermore, in
completely unknown and partially known environments, TIG demonstrates efficient
real-time path planning capabilities for collision avoidance, outperforming APF
and Dynamic APPATT algorithms.

</details>


### [17] [HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots](https://arxiv.org/abs/2508.19002)
*Shipeng Lyu,Fangyuan Wang,Weiwei Lin,Luhao Zhu,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: HuBE框架通过双层闭环设计解决了人形机器人运动生成中的行为相似性和适当性问题，并支持跨平台适应性。


<details>
  <summary>Details</summary>
Motivation: 人形机器人运动生成中行为相似性与适当性的平衡及跨平台适应性不足是当前挑战。

Method: 提出HuBE框架，结合机器人状态、目标姿态和情境信息，构建HPose数据集，并采用骨骼缩放数据增强策略。

Result: HuBE在多平台上显著提升运动相似性、行为适当性和计算效率。

Conclusion: HuBE为跨平台人形机器人行为执行提供了可靠基础。

Abstract: Achieving both behavioral similarity and appropriateness in human-like motion
generation for humanoid robot remains an open challenge, further compounded by
the lack of cross-embodiment adaptability. To address this problem, we propose
HuBE, a bi-level closed-loop framework that integrates robot state, goal poses,
and contextual situations to generate human-like behaviors, ensuring both
behavioral similarity and appropriateness, and eliminating structural
mismatches between motion generation and execution. To support this framework,
we construct HPose, a context-enriched dataset featuring fine-grained
situational annotations. Furthermore, we introduce a bone scaling-based data
augmentation strategy that ensures millimeter-level compatibility across
heterogeneous humanoid robots. Comprehensive evaluations on multiple commercial
platforms demonstrate that HuBE significantly improves motion similarity,
behavioral appropriateness, and computational efficiency over state-of-the-art
baselines, establishing a solid foundation for transferable and human-like
behavior execution across diverse humanoid robots.

</details>


### [18] [An LLM-powered Natural-to-Robotic Language Translation Framework with Correctness Guarantees](https://arxiv.org/abs/2508.19074)
*ZhenDong Chen,ZhanShang Nie,ShiXing Wan,JunYi Li,YongTian Cheng,Shuai Zhao*

Main category: cs.RO

TL;DR: NRTrans框架通过自然-机器人语言翻译和反馈微调，提升轻量级LLM生成机器人控制程序的正确性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖LLM直接生成程序，但由于LLM不一致性和任务复杂性，导致大量编程错误，尤其是轻量级LLM效果不佳。

Method: 提出Robot Skill Language (RSL)抽象控制程序细节，构建RSL编译器和调试器验证程序并提供反馈，通过迭代优化确保程序正确性。

Result: 实验表明NRTrans在多种LLM和任务中优于现有方法，轻量级LLM也能实现高成功率。

Conclusion: NRTrans通过RSL和反馈机制显著提升LLM生成机器人控制程序的可靠性，适用于轻量级LLM。

Abstract: The Large Language Models (LLM) are increasingly being deployed in robotics
to generate robot control programs for specific user tasks, enabling embodied
intelligence. Existing methods primarily focus on LLM training and prompt
design that utilize LLMs to generate executable programs directly from user
tasks in natural language. However, due to the inconsistency of the LLMs and
the high complexity of the tasks, such best-effort approaches often lead to
tremendous programming errors in the generated code, which significantly
undermines the effectiveness especially when the light-weight LLMs are applied.
This paper introduces a natural-robotic language translation framework that (i)
provides correctness verification for generated control programs and (ii)
enhances the performance of LLMs in program generation via feedback-based
fine-tuning for the programs. To achieve this, a Robot Skill Language (RSL) is
proposed to abstract away from the intricate details of the control programs,
bridging the natural language tasks with the underlying robot skills. Then, the
RSL compiler and debugger are constructed to verify RSL programs generated by
the LLM and provide error feedback to the LLM for refining the outputs until
being verified by the compiler. This provides correctness guarantees for the
LLM-generated programs before being offloaded to the robots for execution,
significantly enhancing the effectiveness of LLM-powered robotic applications.
Experiments demonstrate NRTrans outperforms the existing method under a range
of LLMs and tasks, and achieves a high success rate for light-weight LLMs.

</details>


### [19] [DELIVER: A System for LLM-Guided Coordinated Multi-Robot Pickup and Delivery using Voronoi-Based Relay Planning](https://arxiv.org/abs/2508.19114)
*Alkesh K. Srivastava,Jared Michael Levin,Alexander Derrico,Philip Dames*

Main category: cs.RO

TL;DR: DELIVER是一个基于自然语言指令的多机器人协作拾取与交付框架，结合了自然语言理解、空间分解、接力规划和运动执行，实现了高效、可扩展的协调。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在真实环境中基于自然语言指令的协作问题，提升任务效率和可扩展性。

Method: 使用LLaMA3解析指令，Voronoi空间分解定义机器人操作区域，计算最优接力点，并通过有限状态机控制行为。

Result: 在仿真和实际硬件中验证，DELIVER在不同团队规模下保持任务成本稳定，单机器人工作量减少55%，且接力机器人数量随团队规模增长保持较低水平。

Conclusion: DELIVER展示了模块化和可扩展的架构，推动了语言引导的多机器人协调技术的发展。

Abstract: We present DELIVER (Directed Execution of Language-instructed Item Via
Engineered Relay), a fully integrated framework for cooperative multi-robot
pickup and delivery driven by natural language commands. DELIVER unifies
natural language understanding, spatial decomposition, relay planning, and
motion execution to enable scalable, collision-free coordination in real-world
settings. Given a spoken or written instruction, a lightweight instance of
LLaMA3 interprets the command to extract pickup and delivery locations. The
environment is partitioned using a Voronoi tessellation to define
robot-specific operating regions. Robots then compute optimal relay points
along shared boundaries and coordinate handoffs. A finite-state machine governs
each robot's behavior, enabling robust execution. We implement DELIVER on the
MultiTRAIL simulation platform and validate it in both ROS2-based Gazebo
simulations and real-world hardware using TurtleBot3 robots. Empirical results
show that DELIVER maintains consistent mission cost across varying team sizes
while reducing per-agent workload by up to 55% compared to a single-agent
system. Moreover, the number of active relay agents remains low even as team
size increases, demonstrating the system's scalability and efficient agent
utilization. These findings underscore DELIVER's modular and extensible
architecture for language-guided multi-robot coordination, advancing the
frontiers of cyber-physical system integration.

</details>


### [20] [ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments](https://arxiv.org/abs/2508.19131)
*Shreya Gummadi,Mateus V. Gasparino,Gianluca Capezzuto,Marcelo Becker,Girish Chowdhary*

Main category: cs.RO

TL;DR: ZeST利用大型语言模型的视觉推理能力实时生成地形可通行性地图，避免机器人暴露于危险环境，提供了一种零样本、安全且可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要将机器人置于危险环境中收集数据，存在设备和安全风险，亟需一种更安全的替代方案。

Method: 利用大型语言模型（LLMs）的视觉推理能力，实时生成地形可通行性地图，实现零样本预测。

Result: 在室内和室外环境中，ZeST比其他先进方法更安全且能持续到达目标。

Conclusion: ZeST提供了一种安全、高效且可扩展的地形可通行性预测方法，推动了自主导航系统的发展。

Abstract: The advancement of robotics and autonomous navigation systems hinges on the
ability to accurately predict terrain traversability. Traditional methods for
generating datasets to train these prediction models often involve putting
robots into potentially hazardous environments, posing risks to equipment and
safety. To solve this problem, we present ZeST, a novel approach leveraging
visual reasoning capabilities of Large Language Models (LLMs) to create a
traversability map in real-time without exposing robots to danger. Our approach
not only performs zero-shot traversability and mitigates the risks associated
with real-world data collection but also accelerates the development of
advanced navigation systems, offering a cost-effective and scalable solution.
To support our findings, we present navigation results, in both controlled
indoor and unstructured outdoor environments. As shown in the experiments, our
method provides safer navigation when compared to other state-of-the-art
methods, constantly reaching the final goal.

</details>


### [21] [Uncertainty-Resilient Active Intention Recognition for Robotic Assistants](https://arxiv.org/abs/2508.19150)
*Juan Carlos Saborío,Marc Vinci,Oscar Lima,Sebastian Stock,Lennart Niecksch,Martin Günther,Alexander Sung,Joachim Hertzberg,Martin Atzmüller*

Main category: cs.RO

TL;DR: 论文提出了一种基于POMDP的框架，用于在不确定性和传感器噪声下实现机器人助手的自主行为。


<details>
  <summary>Details</summary>
Motivation: 当前机器人助手的行为通常依赖于显式提示或假设完美信息，忽略了人类意图识别中的不确定性和感知错误。

Method: 采用意图识别的POMDP框架，结合实时传感器数据和规划器，实现协作规划和不确定性下的行动。

Result: 框架在物理机器人上成功测试，表现出色。

Conclusion: 该框架为解决机器人助手在不确定性环境中的自主行为提供了有效方案。

Abstract: Purposeful behavior in robotic assistants requires the integration of
multiple components and technological advances. Often, the problem is reduced
to recognizing explicit prompts, which limits autonomy, or is oversimplified
through assumptions such as near-perfect information. We argue that a critical
gap remains unaddressed -- specifically, the challenge of reasoning about the
uncertain outcomes and perception errors inherent to human intention
recognition. In response, we present a framework designed to be resilient to
uncertainty and sensor noise, integrating real-time sensor data with a
combination of planners. Centered around an intention-recognition POMDP, our
approach addresses cooperative planning and acting under uncertainty. Our
integrated framework has been successfully tested on a physical robot with
promising results.

</details>


### [22] [QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning](https://arxiv.org/abs/2508.19153)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: QuadKAN结合强化学习和视觉引导，通过Kolmogorov-Arnold Networks实现稳健的四足运动控制，提升效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 结合本体感觉与视觉以实现更稳健的运动控制。

Method: 提出QuadKAN框架，采用样条编码器和融合头，结合MMDR和PPO进行端到端训练。

Result: 在多样地形中表现优于现有方法，实现更高回报、更远距离和更少碰撞。

Conclusion: 样条参数化策略为视觉引导运动提供了简单、有效且可解释的解决方案。

Abstract: We address vision-guided quadruped motion control with reinforcement learning
(RL) and highlight the necessity of combining proprioception with vision for
robust control. We propose QuadKAN, a spline-parameterized cross-modal policy
instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates
a spline encoder for proprioception and a spline fusion head for
proprioception-vision inputs. This structured function class aligns the
state-to-action mapping with the piecewise-smooth nature of gait, improving
sample efficiency, reducing action jitter and energy consumption, and providing
interpretable posture-action sensitivities. We adopt Multi-Modal Delay
Randomization (MMDR) and perform end-to-end training with Proximal Policy
Optimization (PPO). Evaluations across diverse terrains, including both even
and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate
that QuadKAN achieves consistently higher returns, greater distances, and fewer
collisions than state-of-the-art (SOTA) baselines. These results show that
spline-parameterized policies offer a simple, effective, and interpretable
alternative for robust vision-guided locomotion. A repository will be made
available upon acceptance.

</details>


### [23] [Real-time Testing of Satellite Attitude Control With a Reaction Wheel Hardware-In-the-Loop Platform](https://arxiv.org/abs/2508.19164)
*Morokot Sakal,George Nehma,Camilo Riano-Rios,Madhur Tiwari*

Main category: cs.RO

TL;DR: 提出了一种用于卫星姿态控制系统的硬件在环（HIL）测试方法，具备反作用轮健康估计功能。


<details>
  <summary>Details</summary>
Motivation: 通过真实动量交换设备验证控制器的有效性，推动航天器姿态控制算法的全面测试框架。

Method: 构建HIL测试平台，包括无刷直流电机、CAN总线通信、嵌入式计算机执行控制与自适应算法，以及卫星模拟器生成传感器数据和响应外部执行器动作。

Result: 提出了反作用轮故障人工诱导方法，并总结了相关问题和经验教训。

Conclusion: 该研究为航天器姿态控制算法的验证提供了重要步骤和实用测试框架。

Abstract: We propose the Hardware-in-the-Loop (HIL) test of an adaptive satellite
attitude control system with reaction wheel health estimation capabilities.
Previous simulations and Software-in-the-Loop testing have prompted further
experiments to explore the validity of the controller with real momentum
exchange devices in the loop. This work is a step toward a comprehensive
testing framework for validation of spacecraft attitude control algorithms. The
proposed HIL testbed includes brushless DC motors and drivers that communicate
using a CAN bus, an embedded computer that executes control and adaptation
laws, and a satellite simulator that produces simulated sensor data, estimated
attitude states, and responds to actions of the external actuators. We propose
methods to artificially induce failures on the reaction wheels, and present
related issues and lessons learned.

</details>


### [24] [Direction Informed Trees (DIT*): Optimal Path Planning via Direction Filter and Direction Cost Heuristic](https://arxiv.org/abs/2508.19168)
*Liding Zhang,Kejia Chen,Kuanqi Cai,Yu Zhang,Yixuan Dang,Yansong Wu,Zhenshan Bing,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: DIT*是一种基于采样的路径规划算法，通过优化搜索方向实现目标偏向探索，比现有算法收敛更快。


<details>
  <summary>Details</summary>
Motivation: 现有启发式算法在准确性和计算效率之间存在冲突，难以同时满足。

Method: 定义边为广义向量，结合相似性索引建立方向过滤器，用于选择最近邻和估计方向成本。

Result: 在R^4到R^16的测试问题中，DIT*比现有单查询采样规划器收敛更快，并在实际环境中验证。

Conclusion: DIT*通过高效共享方向信息，显著提升了路径规划的效率和性能。

Abstract: Optimal path planning requires finding a series of feasible states from the
starting point to the goal to optimize objectives. Popular path planning
algorithms, such as Effort Informed Trees (EIT*), employ effort heuristics to
guide the search. Effective heuristics are accurate and computationally
efficient, but achieving both can be challenging due to their conflicting
nature. This paper proposes Direction Informed Trees (DIT*), a sampling-based
planner that focuses on optimizing the search direction for each edge,
resulting in goal bias during exploration. We define edges as generalized
vectors and integrate similarity indexes to establish a directional filter that
selects the nearest neighbors and estimates direction costs. The estimated
direction cost heuristics are utilized in edge evaluation. This strategy allows
the exploration to share directional information efficiently. DIT* convergence
faster than existing single-query, sampling-based planners on tested problems
in R^4 to R^16 and has been demonstrated in real-world environments with
various planning tasks. A video showcasing our experimental results is
available at: https://youtu.be/2SX6QT2NOek

</details>


### [25] [From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity](https://arxiv.org/abs/2508.19172)
*Luca Grillotti,Lisa Coiffard,Oscar Pang,Maxence Faldor,Antoine Cully*

Main category: cs.RO

TL;DR: URSA是一种扩展的QDAC方法，能够在真实世界中自主发现和掌握多样化的机器人技能，适用于无监督和启发式驱动的场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要手动定义技能空间和调整启发式，限制了实际应用。URSA旨在解决这些限制，实现更自主的机器人学习。

Method: URSA扩展了QDAC，支持无监督和启发式驱动的技能发现，直接在真实世界中学习多样化技能。

Result: 在Unitree A1四足机器人上成功发现多样化运动技能，并在下游任务（如损伤适应）中优于基线方法。

Conclusion: URSA为真实世界机器人学习提供了新框架，减少了人工干预，推动了更自主和适应性强的机器人系统发展。

Abstract: Autonomous skill discovery aims to enable robots to acquire diverse behaviors
without explicit supervision. Learning such behaviors directly on physical
hardware remains challenging due to safety and data efficiency constraints.
Existing methods, including Quality-Diversity Actor-Critic (QDAC), require
manually defined skill spaces and carefully tuned heuristics, limiting
real-world applicability. We propose Unsupervised Real-world Skill Acquisition
(URSA), an extension of QDAC that enables robots to autonomously discover and
master diverse, high-performing skills directly in the real world. We
demonstrate that URSA successfully discovers diverse locomotion skills on a
Unitree A1 quadruped in both simulation and the real world. Our approach
supports both heuristic-driven skill discovery and fully unsupervised settings.
We also show that the learned skill repertoire can be reused for downstream
tasks such as real-world damage adaptation, where URSA outperforms all
baselines in 5 out of 9 simulated and 3 out of 5 real-world damage scenarios.
Our results establish a new framework for real-world robot learning that
enables continuous skill discovery with limited human intervention,
representing a significant step toward more autonomous and adaptable robotic
systems. Demonstration videos are available at
http://adaptive-intelligent-robotics.github.io/URSA .

</details>


### [26] [Real-Time Model Checking for Closed-Loop Robot Reactive Planning](https://arxiv.org/abs/2508.19186)
*Christopher Chandler,Bernd Porr,Giulia Lafratta,Alice Miller*

Main category: cs.RO

TL;DR: 提出了一种基于模型检查的实时多步规划和避障方法，适用于低功耗设备的自主机器人。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用模型检查技术实现实时多步规划和避障，模仿生物智能的核心知识和注意力机制。

Method: 开发了一种小型专用模型检查算法，通过临时控制系统链应对环境扰动，并利用2D LiDAR数据的离散化进行多步规划。

Result: 实验证明该方法在复杂场景中优于单步规划的反应式代理，且无需预计算数据。

Conclusion: 该方法为自动驾驶车辆的安全、可靠和可解释规划提供了案例研究。

Abstract: We present a new application of model checking which achieves real-time
multi-step planning and obstacle avoidance on a real autonomous robot. We have
developed a small, purpose-built model checking algorithm which generates plans
in situ based on "core" knowledge and attention as found in biological agents.
This is achieved in real-time using no pre-computed data on a low-powered
device. Our approach is based on chaining temporary control systems which are
spawned to counteract disturbances in the local environment that disrupt an
autonomous agent from its preferred action (or resting state). A novel
discretization of 2D LiDAR data sensitive to bounded variations in the local
environment is used. Multi-step planning using model checking by forward
depth-first search is applied to cul-de-sac and playground scenarios. Both
empirical results and informal proofs of two fundamental properties of our
approach demonstrate that model checking can be used to create efficient
multi-step plans for local obstacle avoidance, improving on the performance of
a reactive agent which can only plan one step. Our approach is an instructional
case study for the development of safe, reliable and explainable planning in
the context of autonomous vehicles.

</details>


### [27] [AutoRing: Imitation Learning--based Autonomous Intraocular Foreign Body Removal Manipulation with Eye Surgical Robot](https://arxiv.org/abs/2508.19191)
*Yue Wang,Wenjie Deng,Haotian Xue,Di Cui,Yiqi Chen,Mingchuan Zhou,Haochao Ying,Jian Wu*

Main category: cs.RO

TL;DR: AutoRing是一个模仿学习框架，用于自主处理眼内异物环操作，解决了运动缩放和RCM点变化带来的运动学不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统依赖手动远程操作，学习曲线陡峭，难以实现毫米级精度的眼内操作。

Method: 结合动态RCM校准和RCM-ACT架构，利用立体视觉数据和专家演示的仪器运动学进行训练。

Result: 在未校准显微镜条件下成功完成环抓取和定位任务，无需显式深度感知。

Conclusion: AutoRing为开发智能眼外科系统提供了可行框架，支持复杂眼内手术。

Abstract: Intraocular foreign body removal demands millimeter-level precision in
confined intraocular spaces, yet existing robotic systems predominantly rely on
manual teleoperation with steep learning curves. To address the challenges of
autonomous manipulation (particularly kinematic uncertainties from variable
motion scaling and variation of the Remote Center of Motion (RCM) point), we
propose AutoRing, an imitation learning framework for autonomous intraocular
foreign body ring manipulation. Our approach integrates dynamic RCM calibration
to resolve coordinate-system inconsistencies caused by intraocular instrument
variation and introduces the RCM-ACT architecture, which combines
action-chunking transformers with real-time kinematic realignment. Trained
solely on stereo visual data and instrument kinematics from expert
demonstrations in a biomimetic eye model, AutoRing successfully completes ring
grasping and positioning tasks without explicit depth sensing. Experimental
validation demonstrates end-to-end autonomy under uncalibrated microscopy
conditions. The results provide a viable framework for developing intelligent
eye-surgical systems capable of complex intraocular procedures.

</details>


### [28] [Planning-Query-Guided Model Generation for Model-Based Deformable Object Manipulation](https://arxiv.org/abs/2508.19199)
*Alex LaGrassa,Zixuan Huang,Dmitry Berenson,Oliver Kroemer*

Main category: cs.RO

TL;DR: 提出了一种自动生成任务特定、空间自适应动力学模型的方法，通过预测区域分辨率来优化规划速度和任务性能。


<details>
  <summary>Details</summary>
Motivation: 高维空间（如涉及可变形物体）的高效规划需要计算上可处理且足够表达的动力学模型。

Method: 基于扩散的模型生成器根据规划查询的起点和目标点云预测区域分辨率，采用两阶段数据收集优化分辨率。

Result: 在树木操纵任务中，规划速度提高了一倍，任务性能仅略有下降。

Conclusion: 该方法为利用历史规划数据生成计算高效且表达充分的动力学模型提供了新思路。

Abstract: Efficient planning in high-dimensional spaces, such as those involving
deformable objects, requires computationally tractable yet sufficiently
expressive dynamics models. This paper introduces a method that automatically
generates task-specific, spatially adaptive dynamics models by learning which
regions of the object require high-resolution modeling to achieve good task
performance for a given planning query. Task performance depends on the complex
interplay between the dynamics model, world dynamics, control, and task
requirements. Our proposed diffusion-based model generator predicts per-region
model resolutions based on start and goal pointclouds that define the planning
query. To efficiently collect the data for learning this mapping, a two-stage
process optimizes resolution using predictive dynamics as a prior before
directly optimizing using closed-loop performance. On a tree-manipulation task,
our method doubles planning speed with only a small decrease in task
performance over using a full-resolution model. This approach informs a path
towards using previous planning and control data to generate computationally
efficient yet sufficiently expressive dynamics models for new tasks.

</details>


### [29] [MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2508.19236)
*Hao Shi,Bin Xie,Yingfei Liu,Lin Sun,Fengrong Liu,Tiancai Wang,Erjin Zhou,Haoqiang Fan,Xiangyu Zhang,Gao Huang*

Main category: cs.RO

TL;DR: MemoryVLA是一个受人类记忆机制启发的机器人操作框架，通过工作记忆和长期记忆的结合，显著提升了长时程任务的性能。


<details>
  <summary>Details</summary>
Motivation: 机器人操作任务通常具有非马尔可夫性，现有VLA模型因忽略时间上下文而难以处理长时程任务。

Method: 提出Cognition-Memory-Action框架，结合工作记忆和记忆库，通过扩散动作专家生成时间感知的动作序列。

Result: 在仿真和真实任务中表现优异，成功率显著高于基线模型，如Bridge任务提升14.6%。

Conclusion: MemoryVLA通过模拟人类记忆机制，有效解决了长时程机器人操作任务中的时间依赖问题。

Abstract: Temporal context is essential for robotic manipulation because such tasks are
inherently non-Markovian, yet mainstream VLA models typically overlook it and
struggle with long-horizon, temporally dependent tasks. Cognitive science
suggests that humans rely on working memory to buffer short-lived
representations for immediate control, while the hippocampal system preserves
verbatim episodic details and semantic gist of past experience for long-term
memory. Inspired by these mechanisms, we propose MemoryVLA, a
Cognition-Memory-Action framework for long-horizon robotic manipulation. A
pretrained VLM encodes the observation into perceptual and cognitive tokens
that form working memory, while a Perceptual-Cognitive Memory Bank stores
low-level details and high-level semantics consolidated from it. Working memory
retrieves decision-relevant entries from the bank, adaptively fuses them with
current tokens, and updates the bank by merging redundancies. Using these
tokens, a memory-conditioned diffusion action expert yields temporally aware
action sequences. We evaluate MemoryVLA on 150+ simulation and real-world tasks
across three robots. On SimplerEnv-Bridge, Fractal, and LIBERO-5 suites, it
achieves 71.9%, 72.7%, and 96.5% success rates, respectively, all outperforming
state-of-the-art baselines CogACT and pi-0, with a notable +14.6 gain on
Bridge. On 12 real-world tasks spanning general skills and long-horizon
temporal dependencies, MemoryVLA achieves 84.0% success rate, with long-horizon
tasks showing a +26 improvement over state-of-the-art baseline. Project Page:
https://shihao1895.github.io/MemoryVLA

</details>
