<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Fluidically Innervated Lattices Make Versatile and Durable Tactile Sensors](https://arxiv.org/abs/2507.21225)
*Annan Zhang,Miguel Flores-Acton,Andy Yu,Anshul Gupta,Maggie Yao,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一种基于3D打印弹性体晶格和嵌入式空气通道的被动软机器人指尖触觉传感器，通过检测压力变化实现触觉感知，具有简单、可扩展和耐用的特点。


<details>
  <summary>Details</summary>
Motivation: 触觉感知对机器人在动态和非结构化环境中的导航至关重要，尤其是在精细操作、表面探索和人机交互中。现有方法通常依赖复杂材料或设计，亟需一种简单且耐用的解决方案。

Method: 采用3D打印弹性体晶格和嵌入式空气通道（称为流体神经化），通过检测密封空气通道内的压力变化实现触觉感知。开发了几何模型和神经网络预测接触位置和力，并集成导纳控制器模拟弹簧行为。

Result: 传感器表现出高耐用性（抗冲击和循环负载），并能通过触觉反馈实现环境探索。神经网络和几何模型能准确预测接触位置和力。

Conclusion: 流体神经化技术提供了一种简单、可扩展且耐用的触觉感知方案，为多功能机器人操作开辟了新机会。

Abstract: Tactile sensing plays a fundamental role in enabling robots to navigate
dynamic and unstructured environments, particularly in applications such as
delicate object manipulation, surface exploration, and human-robot interaction.
In this paper, we introduce a passive soft robotic fingertip with integrated
tactile sensing, fabricated using a 3D-printed elastomer lattice with embedded
air channels. This sensorization approach, termed fluidic innervation,
transforms the lattice into a tactile sensor by detecting pressure changes
within sealed air channels, providing a simple yet robust solution to tactile
sensing in robotics. Unlike conventional methods that rely on complex materials
or designs, fluidic innervation offers a simple, scalable, single-material
fabrication process. We characterize the sensors' response, develop a geometric
model to estimate tip displacement, and train a neural network to accurately
predict contact location and contact force. Additionally, we integrate the
fingertip with an admittance controller to emulate spring-like behavior,
demonstrate its capability for environment exploration through tactile
feedback, and validate its durability under high impact and cyclic loading
conditions. This tactile sensing technique offers advantages in terms of
simplicity, adaptability, and durability and opens up new opportunities for
versatile robotic manipulation.

</details>


### [2] [Diffusion Denoiser-Aided Gyrocompassing](https://arxiv.org/abs/2507.21245)
*Gershy Ben-Arie,Daniel Engelsman,Rotem Dror,Itzik Klein*

Main category: cs.RO

TL;DR: 提出了一种基于扩散去噪的陀螺罗盘方法，显著提高了低成本陀螺仪的导航精度。


<details>
  <summary>Details</summary>
Motivation: 低成本陀螺仪在无外部导航辅助时，导航精度受限，需要解决这一问题以提高自主平台的导航性能。

Method: 结合扩散去噪框架和增强的学习型航向估计模型，处理原始惯性传感器信号。

Result: 实验显示，该方法比基于模型的陀螺罗盘精度提高26%，比其他学习驱动方法提高15%。

Conclusion: 该方法为低成本陀螺仪在自主平台中的导航提供了更准确和鲁棒的解决方案。

Abstract: An accurate initial heading angle is essential for efficient and safe
navigation across diverse domains. Unlike magnetometers, gyroscopes can provide
accurate heading reference independent of the magnetic disturbances in a
process known as gyrocompassing. Yet, accurate and timely gyrocompassing, using
low-cost gyroscopes, remains a significant challenge in scenarios where
external navigation aids are unavailable. Such challenges are commonly
addressed in real-world applications such as autonomous vehicles, where size,
weight, and power limitations restrict sensor quality, and noisy measurements
severely degrade gyrocompassing performance. To cope with this challenge, we
propose a novel diffusion denoiser-aided gyrocompass approach. It integrates a
diffusion-based denoising framework with an enhanced learning-based heading
estimation model. The diffusion denoiser processes raw inertial sensor signals
before input to the deep learning model, resulting in accurate gyrocompassing.
Experiments using both simulated and real sensor data demonstrate that our
proposed approach improves gyrocompassing accuracy by 26% compared to
model-based gyrocompassing and by 15% compared to other learning-driven
approaches. This advancement holds particular significance for ensuring
accurate and robust navigation in autonomous platforms that incorporate
low-cost gyroscopes within their navigation systems.

</details>


### [3] [NMPCM: Nonlinear Model Predictive Control on Resource-Constrained Microcontrollers](https://arxiv.org/abs/2507.21259)
*Van Chung Nguyen,Pratik Walunj,Chuong Le,An Duy Nguyen,Hung Manh La*

Main category: cs.RO

TL;DR: 提出了一种在微控制器上高效部署非线性模型预测控制（NMPC）的方法，用于控制四旋翼无人机。


<details>
  <summary>Details</summary>
Motivation: NMPC虽然能有效控制高动态机器人系统，但其高计算复杂度使其难以在资源受限的微控制器上实现。

Method: 优化计算效率，同时保持高控制精度，通过Gazebo/ROS仿真和实际实验验证。

Result: 实现了高频NMPC实时执行，验证了方法的有效性。

Conclusion: 该方法为在微控制器上实现NMPC提供了可行方案，适用于实时系统。

Abstract: Nonlinear Model Predictive Control (NMPC) is a powerful approach for
controlling highly dynamic robotic systems, as it accounts for system dynamics
and optimizes control inputs at each step. However, its high computational
complexity makes implementation on resource-constrained microcontrollers
impractical. While recent studies have demonstrated the feasibility of Model
Predictive Control (MPC) with linearized dynamics on microcontrollers, applying
full NMPC remains a significant challenge. This work presents an efficient
solution for generating and deploying NMPC on microcontrollers (NMPCM) to
control quadrotor UAVs. The proposed method optimizes computational efficiency
while maintaining high control accuracy. Simulations in Gazebo/ROS and
real-world experiments validate the effectiveness of the approach,
demonstrating its capability to achieve high-frequency NMPC execution in
real-time systems. The code is available at:
https://github.com/aralab-unr/NMPCM.

</details>


### [4] [Autonomous Exploration with Terrestrial-Aerial Bimodal Vehicles](https://arxiv.org/abs/2507.21338)
*Yuman Gao,Ruibin Zhang,Tiancheng Lai,Yanjun Cao,Chao Xu,Fei Gao*

Main category: cs.RO

TL;DR: 提出了一种分层框架，用于陆地-空中双模态车辆在探索任务中优化能量和时间约束。


<details>
  <summary>Details</summary>
Motivation: 结合空中机器人的高机动性和地面机器人的长续航能力，双模态车辆在自主探索中具有潜力，但需解决能量和时间约束问题。

Method: 采用分层框架，包括环境信息提取、双模态视点生成、扩展蒙特卡洛树搜索优化模态选择和视点序列，以及改进的双模态运动规划器。

Result: 通过大量仿真和真实平台部署验证了系统的有效性。

Conclusion: 提出的系统能够有效管理能量和时间约束，提升双模态车辆的探索能力。

Abstract: Terrestrial-aerial bimodal vehicles, which integrate the high mobility of
aerial robots with the long endurance of ground robots, offer significant
potential for autonomous exploration. Given the inherent energy and time
constraints in practical exploration tasks, we present a hierarchical framework
for the bimodal vehicle to utilize its flexible locomotion modalities for
exploration. Beginning with extracting environmental information to identify
informative regions, we generate a set of potential bimodal viewpoints. To
adaptively manage energy and time constraints, we introduce an extended Monte
Carlo Tree Search approach that strategically optimizes both modality selection
and viewpoint sequencing. Combined with an improved bimodal vehicle motion
planner, we present a complete bimodal energy- and time-aware exploration
system. Extensive simulations and deployment on a customized real-world
platform demonstrate the effectiveness of our system.

</details>


### [5] [Projecting the New Body: How Body Image Evolves During Learning to Walk with a Wearable Robot](https://arxiv.org/abs/2507.21384)
*I-Chieh Lee,He Huang*

Main category: cs.RO

TL;DR: 研究探讨了穿戴机器人对步态表现和身体感知的影响，发现运动学习可以改善实际和感知步态，但感知与实际运动间仍存在差距。


<details>
  <summary>Details</summary>
Motivation: 探索穿戴机器人如何影响人类运动系统和身体感知，以及如何通过训练改善穿戴者与机器人的协调性。

Method: 使用SCoMo测量步态表现和感知身体图像，基于人类运动学习理论进行训练。

Result: 运动学习改善了实际和感知步态，但感知与实际运动间存在持续差异，可能与缺乏直接感觉和控制有关。

Conclusion: 增强穿戴机器人的感知和定期校准身体图像对有效训练和开发更具体的辅助技术至关重要。

Abstract: Advances in wearable robotics challenge the traditional definition of human
motor systems, as wearable robots redefine body structure, movement capability,
and perception of their own bodies. We measured gait performance and perceived
body images via Selected Coefficient of Perceived Motion, SCoMo, after each
training session. Based on human motor learning theory extended to wearer-robot
systems, we hypothesized that learning the perceived body image when walking
with a robotic leg co-evolves with the actual gait improvement and becomes more
certain and more accurate to the actual motion. Our result confirmed that motor
learning improved both physical and perceived gait pattern towards normal,
indicating that via practice the wearers incorporated the robotic leg into
their sensorimotor systems to enable wearer-robot movement coordination.
However, a persistent discrepancy between perceived and actual motion remained,
likely due to the absence of direct sensation and control of the prosthesis
from wearers. Additionally, the perceptual overestimation at the later training
sessions might limit further motor improvement. These findings suggest that
enhancing the human sense of wearable robots and frequent calibrating
perception of body image are essential for effective training with lower limb
wearable robots and for developing more embodied assistive technologies.

</details>


### [6] [Sound Source Localization for Human-Robot Interaction in Outdoor Environments](https://arxiv.org/abs/2507.21431)
*Victor Liu,Timothy Du,Jordy Sehn,Jack Collier,François Grondin*

Main category: cs.RO

TL;DR: 提出了一种基于麦克风阵列和异步近场麦克风的声源定位策略，结合信号粗对齐和时域声学回声消除算法，显著提升了噪声环境下的定位精度。


<details>
  <summary>Details</summary>
Motivation: 解决噪声环境下机器人声源定位的挑战，以实现与操作员的精准交互。

Method: 结合信号粗对齐和时域声学回声消除算法，估计时频理想比率掩码以隔离目标语音。

Result: 在1dB信噪比下，平均角度误差为4度，95%的定位精度在5度以内，显著优于现有方法。

Conclusion: 该方法在噪声环境下实现了高精度的声源定位，为机器人交互提供了可靠支持。

Abstract: This paper presents a sound source localization strategy that relies on a
microphone array embedded in an unmanned ground vehicle and an asynchronous
close-talking microphone near the operator. A signal coarse alignment strategy
is combined with a time-domain acoustic echo cancellation algorithm to estimate
a time-frequency ideal ratio mask to isolate the target speech from
interferences and environmental noise. This allows selective sound source
localization, and provides the robot with the direction of arrival of sound
from the active operator, which enables rich interaction in noisy scenarios.
Results demonstrate an average angle error of 4 degrees and an accuracy within
5 degrees of 95\% at a signal-to-noise ratio of 1dB, which is significantly
superior to the state-of-the-art localization methods.

</details>


### [7] [Multifunctional physical reservoir computing in soft tensegrity robots](https://arxiv.org/abs/2507.21496)
*Ryo Terajima,Katsuma Inoue,Kohei Nakajima,Yasuo Kuniyoshi*

Main category: cs.RO

TL;DR: 利用软体机器人的非线性动力学实现多行为控制，发现未训练吸引子反映机器人固有特性。


<details>
  <summary>Details</summary>
Motivation: 探索物理储层计算（PRC）在软体机器人多行为控制中的应用，揭示未训练吸引子的存在及其对具身认知的意义。

Method: 通过模拟研究，将PRC框架应用于张力平衡机器人，分析其多稳态动力学和吸引子特性。

Result: 系统表现出多稳态特性，存在未训练吸引子，反映机器人固有结构和环境交互。

Conclusion: PRC为理解具身认知提供了新视角，未训练吸引子的研究潜力有待进一步探索。

Abstract: Recent studies have demonstrated that the dynamics of physical systems can be
utilized for the desired information processing under the framework of physical
reservoir computing (PRC). Robots with soft bodies are examples of such
physical systems, and their nonlinear body-environment dynamics can be used to
compute and generate the motor signals necessary for the control of their own
behavior. In this simulation study, we extend this approach to control and
embed not only one but also multiple behaviors into a type of soft robot called
a tensegrity robot. The resulting system, consisting of the robot and the
environment, is a multistable dynamical system that converges to different
attractors from varying initial conditions. Furthermore, attractor analysis
reveals that there exist "untrained attractors" in the state space of the
system outside the training data. These untrained attractors reflect the
intrinsic properties and structures of the tensegrity robot and its
interactions with the environment. The impacts of these recent findings in PRC
remain unexplored in embodied AI research. We here illustrate their potential
to understand various features of embodied cognition that have not been fully
addressed to date.

</details>


### [8] [Decision Transformer-Based Drone Trajectory Planning with Dynamic Safety-Efficiency Trade-Offs](https://arxiv.org/abs/2507.21506)
*Chang-Hun Ji,SiWoon Song,Youn-Hee Han,SungTae Moon*

Main category: cs.RO

TL;DR: 提出了一种基于决策变换器的无人机轨迹规划器，通过单一参数RTG动态调整安全与效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统多项式规划器需要专家调参且难以实现理想权衡，而强化学习规划器未明确处理安全与效率的权衡。

Method: 使用决策变换器框架，引入RTG作为温度参数动态调整权衡，无需专家知识。

Result: 仿真和实际实验表明，该规划器能通过RTG动态调整权衡，并在不同RTG设置下优于基线方法。

Conclusion: 该方法可靠且实用，能灵活适应不同任务需求。

Abstract: A drone trajectory planner should be able to dynamically adjust the
safety-efficiency trade-off according to varying mission requirements in
unknown environments. Although traditional polynomial-based planners offer
computational efficiency and smooth trajectory generation, they require expert
knowledge to tune multiple parameters to adjust this trade-off. Moreover, even
with careful tuning, the resulting adjustment may fail to achieve the desired
trade-off. Similarly, although reinforcement learning-based planners are
adaptable in unknown environments, they do not explicitly address the
safety-efficiency trade-off. To overcome this limitation, we introduce a
Decision Transformer-based trajectory planner that leverages a single
parameter, Return-to-Go (RTG), as a \emph{temperature parameter} to dynamically
adjust the safety-efficiency trade-off. In our framework, since RTG intuitively
measures the safety and efficiency of a trajectory, RTG tuning does not require
expert knowledge. We validate our approach using Gazebo simulations in both
structured grid and unstructured random environments. The experimental results
demonstrate that our planner can dynamically adjust the safety-efficiency
trade-off by simply tuning the RTG parameter. Furthermore, our planner
outperforms existing baseline methods across various RTG settings, generating
safer trajectories when tuned for safety and more efficient trajectories when
tuned for efficiency. Real-world experiments further confirm the reliability
and practicality of our proposed planner.

</details>


### [9] [LITE: A Learning-Integrated Topological Explorer for Multi-Floor Indoor Environments](https://arxiv.org/abs/2507.21517)
*Junhao Chen,Zhen Zhang,Chengrui Zhu,Xiaojun Hou,Tianyang Hu,Huifeng Wu,Yong Liu*

Main category: cs.RO

TL;DR: 提出了一种学习集成的拓扑探索器LITE，用于多楼层室内环境，通过分解环境为楼层-楼梯拓扑，结合2D探索方法实现3D探索，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 多楼层室内探索是一个开放的研究领域，现有学习型探索器多限于2D环境，需要扩展到3D场景。

Method: LITE将环境分解为楼层-楼梯拓扑，结合YOLO11实例分割模型和有限状态机实现楼层切换，并采用基于注意力的2D探索策略。

Result: 在HM3D和MP3D数据集上，LITE的探索效率显著优于基线方法，且适用于多种2D探索方法。

Conclusion: LITE在多楼层室内探索中表现出高效性和通用性，并在真实四足机器人上验证了其泛化能力。

Abstract: This work focuses on multi-floor indoor exploration, which remains an open
area of research. Compared to traditional methods, recent learning-based
explorers have demonstrated significant potential due to their robust
environmental learning and modeling capabilities, but most are restricted to 2D
environments. In this paper, we proposed a learning-integrated topological
explorer, LITE, for multi-floor indoor environments. LITE decomposes the
environment into a floor-stair topology, enabling seamless integration of
learning or non-learning-based 2D exploration methods for 3D exploration. As we
incrementally build floor-stair topology in exploration using YOLO11-based
instance segmentation model, the agent can transition between floors through a
finite state machine. Additionally, we implement an attention-based 2D
exploration policy that utilizes an attention mechanism to capture spatial
dependencies between different regions, thereby determining the next global
goal for more efficient exploration. Extensive comparison and ablation studies
conducted on the HM3D and MP3D datasets demonstrate that our proposed 2D
exploration policy significantly outperforms all baseline explorers in terms of
exploration efficiency. Furthermore, experiments in several 3D multi-floor
environments indicate that our framework is compatible with various 2D
exploration methods, facilitating effective multi-floor indoor exploration.
Finally, we validate our method in the real world with a quadruped robot,
highlighting its strong generalization capabilities.

</details>


### [10] [Model Predictive Adversarial Imitation Learning for Planning from Observation](https://arxiv.org/abs/2507.21533)
*Tyler Han,Yanda Bao,Bhaumik Mehta,Gabriel Guo,Anubhav Vishwakarma,Emily Kang,Sanghun Jung,Rosario Scalise,Jason Zhou,Bryan Xu,Byron Boots*

Main category: cs.RO

TL;DR: 论文提出了一种结合逆强化学习和模型预测控制的端到端规划学习方法，显著提升了样本效率、泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 人类演示数据通常模糊且不完整，需要一种既能模仿又能可靠规划的模仿学习方法。

Method: 通过逆强化学习（IRL）学习奖励函数，并用规划代理替代策略，结合对抗模仿学习实现端到端交互学习。

Result: 在模拟控制和真实导航实验中，该方法在样本效率、分布外泛化和鲁棒性方面表现显著提升。

Conclusion: 该方法在复杂性和安全性方面具有优势，适用于少样本或单样本观察演示场景。

Abstract: Human demonstration data is often ambiguous and incomplete, motivating
imitation learning approaches that also exhibit reliable planning behavior. A
common paradigm to perform planning-from-demonstration involves learning a
reward function via Inverse Reinforcement Learning (IRL) then deploying this
reward via Model Predictive Control (MPC). Towards unifying these methods, we
derive a replacement of the policy in IRL with a planning-based agent. With
connections to Adversarial Imitation Learning, this formulation enables
end-to-end interactive learning of planners from observation-only
demonstrations. In addition to benefits in interpretability, complexity, and
safety, we study and observe significant improvements on sample efficiency,
out-of-distribution generalization, and robustness. The study includes
evaluations in both simulated control benchmarks and real-world navigation
experiments using few-to-single observation-only demonstrations.

</details>


### [11] [Pretraining a Unified PDDL Domain from Real-World Demonstrations for Generalizable Robot Task Planning](https://arxiv.org/abs/2507.21545)
*Haoming Ye,Yunxiao Xiao,Cewu Lu,Panpan Cai*

Main category: cs.RO

TL;DR: UniDomain框架通过预训练PDDL领域，结合机器人操作演示，实现零样本复杂任务规划，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs和VLMs在长时程结构和符号基础方面的不足，提升机器人任务规划的泛化能力。

Method: 从12,393个操作视频中提取原子领域，构建统一领域，并通过检索和融合生成高质量元领域。

Result: 在零样本任务中，任务成功率提高58%，计划最优性提升160%。

Conclusion: UniDomain在复杂任务规划中表现出色，具有广泛的应用潜力。

Abstract: Robotic task planning in real-world environments requires reasoning over
implicit constraints from language and vision. While LLMs and VLMs offer strong
priors, they struggle with long-horizon structure and symbolic grounding.
Existing methods that combine LLMs with symbolic planning often rely on
handcrafted or narrow domains, limiting generalization. We propose UniDomain, a
framework that pre-trains a PDDL domain from robot manipulation demonstrations
and applies it for online robotic task planning. It extracts atomic domains
from 12,393 manipulation videos to form a unified domain with 3137 operators,
2875 predicates, and 16481 causal edges. Given a target class of tasks, it
retrieves relevant atomics from the unified domain and systematically fuses
them into high-quality meta-domains to support compositional generalization in
planning. Experiments on diverse real-world tasks show that UniDomain solves
complex, unseen tasks in a zero-shot manner, achieving up to 58% higher task
success and 160% improvement in plan optimality over state-of-the-art LLM and
LLM-PDDL baselines.

</details>


### [12] [Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments](https://arxiv.org/abs/2507.21553)
*Federica Di Lauro,Domenico G. Sorrenti,Miguel Angel Sotelo*

Main category: cs.RO

TL;DR: 多机器人SLAM系统在复杂环境中存在闭环检测误报问题，提出新启发式方法改进。


<details>
  <summary>Details</summary>
Motivation: 研究多机器人SLAM系统在复杂环境（如地下隧道）中的局限性，尤其是闭环检测的高误报率。

Method: 分析分散式LiDAR SLAM系统流程，提出新启发式方法。

Result: 发现闭环检测是主要失败原因，新方法有效减少误报。

Conclusion: 改进闭环检测性能，并指出未来研究方向。

Abstract: Multi-robot SLAM aims at localizing and building a map with multiple robots,
interacting with each other. In the work described in this article, we analyze
the pipeline of a decentralized LiDAR SLAM system to study the current
limitations of the state of the art, and we discover a significant source of
failures, i.e., that the loop detection is the source of too many false
positives. We therefore develop and propose a new heuristic to overcome these
limitations. The environment taken as reference in this work is the highly
challenging case of underground tunnels. We also highlight potential new
research areas still under-explored.

</details>


### [13] [Research Challenges and Progress in the End-to-End V2X Cooperative Autonomous Driving Competition](https://arxiv.org/abs/2507.21610)
*Ruiyang Hao,Haibao Yu,Jiaru Zhong,Chuanye Wang,Jiahao Wang,Yiming Kan,Wenxian Yang,Siqi Fan,Huilin Yin,Jianing Qiu,Yao Mu,Jiankai Sun,Li Chen,Walter Zimmer,Dandan Zhang,Shanghang Zhang,Mac Schwager,Wei Huang,Xiaobo Zhang,Ping Luo,Zaiqing Nie*

Main category: cs.RO

TL;DR: 论文介绍了V2X合作挑战赛的设计与成果，旨在解决多源传感器数据融合和动态环境下的技术挑战，推动V2X协同自动驾驶系统的发展。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的快速发展，V2X通信成为扩展感知范围和提升驾驶安全的关键技术，但多源传感器数据融合和动态环境下的技术挑战仍需解决。

Method: 通过组织End-to-End Autonomous Driving through V2X Cooperation Challenge，基于UniV2X框架和V2X-Seq-SPD数据集，设立两个赛道：协同时间感知和协同端到端规划。

Result: 挑战赛吸引了全球30多个团队参与，建立了统一的协同驾驶系统评估基准，并分析了带宽感知融合、鲁棒多智能体规划和异构传感器集成等关键技术问题。

Conclusion: 挑战赛通过解决通信和数据融合的实际约束，为可扩展和可靠的V2X协同自动驾驶系统的发展做出了贡献。

Abstract: With the rapid advancement of autonomous driving technology,
vehicle-to-everything (V2X) communication has emerged as a key enabler for
extending perception range and enhancing driving safety by providing visibility
beyond the line of sight. However, integrating multi-source sensor data from
both ego-vehicles and infrastructure under real-world constraints, such as
limited communication bandwidth and dynamic environments, presents significant
technical challenges. To facilitate research in this area, we organized the
End-to-End Autonomous Driving through V2X Cooperation Challenge, which features
two tracks: cooperative temporal perception and cooperative end-to-end
planning. Built on the UniV2X framework and the V2X-Seq-SPD dataset, the
challenge attracted participation from over 30 teams worldwide and established
a unified benchmark for evaluating cooperative driving systems. This paper
describes the design and outcomes of the challenge, highlights key research
problems including bandwidth-aware fusion, robust multi-agent planning, and
heterogeneous sensor integration, and analyzes emerging technical trends among
top-performing solutions. By addressing practical constraints in communication
and data fusion, the challenge contributes to the development of scalable and
reliable V2X-cooperative autonomous driving systems.

</details>


### [14] [Adaptive Prior Scene-Object SLAM for Dynamic Environments](https://arxiv.org/abs/2507.21709)
*Haolan Zhang,Thanh Nguyen Canh,Chenghao Li,Nak Young Chong*

Main category: cs.RO

TL;DR: 提出了一种基于场景对象的可靠性评估框架和姿态优化策略，显著提升了动态环境下的SLAM定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法在动态环境中因假设静态环境而存在显著定位漂移，现有系统在视角突变和动态物体处理上仍有不足。

Method: 通过当前帧质量指标和场景变化评估SLAM稳定性，并利用可靠帧信息优化相机姿态估计。

Result: 在TUM RGB-D数据集上验证了定位精度和系统鲁棒性的显著提升。

Conclusion: 所提框架和策略有效解决了动态干扰问题，适用于挑战性动态场景。

Abstract: Visual Simultaneous Localization and Mapping (SLAM) plays a vital role in
real-time localization for autonomous systems. However, traditional SLAM
methods, which assume a static environment, often suffer from significant
localization drift in dynamic scenarios. While recent advancements have
improved SLAM performance in such environments, these systems still struggle
with localization drift, particularly due to abrupt viewpoint changes and
poorly characterized moving objects. In this paper, we propose a novel
scene-object-based reliability assessment framework that comprehensively
evaluates SLAM stability through both current frame quality metrics and scene
changes relative to reliable reference frames. Furthermore, to tackle the lack
of error correction mechanisms in existing systems when pose estimation becomes
unreliable, we employ a pose refinement strategy that leverages information
from reliable frames to optimize camera pose estimation, effectively mitigating
the adverse effects of dynamic interference. Extensive experiments on the TUM
RGB-D datasets demonstrate that our approach achieves substantial improvements
in localization accuracy and system robustness under challenging dynamic
scenarios.

</details>


### [15] [Multi-UAV Deployment in Obstacle-Cluttered Environments with LOS Connectivity](https://arxiv.org/abs/2507.21772)
*Yuda Chen,Shuaikang Wang,Jie Li,Meng Guo*

Main category: cs.RO

TL;DR: 论文提出了一种基于最小边RRT?算法的多无人机网络部署方法，并设计了分布式模型预测控制策略，确保无人机在复杂环境中的通信和运动协调。


<details>
  <summary>Details</summary>
Motivation: 在障碍物密集环境中，多无人机通信受限，需通过多跳网络部署中继无人机，但面临网络结构设计和运动协调的挑战。

Method: 采用最小边RRT?算法设计生成树拓扑，减少部署无人机数量；提出分布式模型预测控制策略，结合距离和视线连接约束。

Result: 理论保证无人机轨迹无碰撞且始终保持团队视线连接，仿真和硬件实验验证了方法的有效性。

Conclusion: 该方法高效解决了多无人机在复杂环境中的通信和运动协调问题，具有实际应用价值。

Abstract: A reliable communication network is essential for multiple UAVs operating
within obstacle-cluttered environments, where limited communication due to
obstructions often occurs. A common solution is to deploy intermediate UAVs to
relay information via a multi-hop network, which introduces two challenges: (i)
how to design the structure of multihop networks; and (ii) how to maintain
connectivity during collaborative motion. To this end, this work first proposes
an efficient constrained search method based on the minimumedge RRT? algorithm,
to find a spanning-tree topology that requires a less number of UAVs for the
deployment task. Then, to achieve this deployment, a distributed model
predictive control strategy is proposed for the online motion coordination. It
explicitly incorporates not only the inter-UAV and UAVobstacle distance
constraints, but also the line-of-sight (LOS) connectivity constraint. These
constraints are well-known to be nonlinear and often tackled by various
approximations. In contrast, this work provides a theoretical guarantee that
all agent trajectories are ensured to be collision-free with a teamwise LOS
connectivity at all time. Numerous simulations are performed in 3D valley-like
environments, while hardware experiments validate its dynamic adaptation when
the deployment position changes online.

</details>


### [16] [MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects](https://arxiv.org/abs/2507.21796)
*Yuying Zhang,Kevin Sebastian Luck,Francesco Verdoja,Ville Kyrki,Joni Pajarinen*

Main category: cs.RO

TL;DR: MoDeSuite是首个针对机器人学习的移动操作可变形物体任务套件，包含8个任务，旨在填补标准化基准的空白。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习算法在操作可变形物体方面存在挑战，缺乏标准化基准。

Method: 提出MoDeSuite任务套件，训练强化学习和模仿学习算法，并在仿真和真实机器人（Spot）上验证。

Result: 展示了算法的性能及仿真到现实的迁移潜力。

Conclusion: MoDeSuite有望推动涉及可变形物体的移动操作研究。

Abstract: Mobile manipulation is a critical capability for robots operating in diverse,
real-world environments. However, manipulating deformable objects and materials
remains a major challenge for existing robot learning algorithms. While various
benchmarks have been proposed to evaluate manipulation strategies with rigid
objects, there is still a notable lack of standardized benchmarks that address
mobile manipulation tasks involving deformable objects.
  To address this gap, we introduce MoDeSuite, the first Mobile Manipulation
Deformable Object task suite, designed specifically for robot learning.
MoDeSuite consists of eight distinct mobile manipulation tasks covering both
elastic objects and deformable objects, each presenting a unique challenge
inspired by real-world robot applications. Success in these tasks requires
effective collaboration between the robot's base and manipulator, as well as
the ability to exploit the deformability of the objects. To evaluate and
demonstrate the use of the proposed benchmark, we train two state-of-the-art
reinforcement learning algorithms and two imitation learning algorithms,
highlighting the difficulties encountered and showing their performance in
simulation. Furthermore, we demonstrate the practical relevance of the suite by
deploying the trained policies directly into the real world with the Spot
robot, showcasing the potential for sim-to-real transfer. We expect that
MoDeSuite will open a novel research domain in mobile manipulation involving
deformable objects. Find more details, code, and videos at
https://sites.google.com/view/modesuite/home.

</details>


### [17] [Interactive Adversarial Testing of Autonomous Vehicles with Adjustable Confrontation Intensity](https://arxiv.org/abs/2507.21814)
*Yicheng Guo,Chengkai Xu,Jiaqi Liu,Hao Zhang,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: 提出ExamPPO框架，用于自适应和强度可控的自动驾驶车辆测试，通过智能考官模型和多头注意力增强策略网络，提升对抗测试的交互性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有测试方法依赖高质量数据、交互能力弱且对抗鲁棒性低，无法满足自动驾驶车辆在高风险交互场景中的测试需求。

Method: 将周围车辆建模为智能考官，引入多头注意力增强策略网络和对抗因子，实现场景自适应和强度可控的测试。

Result: 实验表明ExamPPO能有效调节对抗行为、暴露AV决策弱点，并在异构环境中泛化。

Conclusion: ExamPPO为自动驾驶决策系统的安全性和智能性评估提供了统一且可复现的解决方案。

Abstract: Scientific testing techniques are essential for ensuring the safe operation
of autonomous vehicles (AVs), with high-risk, highly interactive scenarios
being a primary focus. To address the limitations of existing testing methods,
such as their heavy reliance on high-quality test data, weak interaction
capabilities, and low adversarial robustness, this paper proposes ExamPPO, an
interactive adversarial testing framework that enables scenario-adaptive and
intensity-controllable evaluation of autonomous vehicles. The framework models
the Surrounding Vehicle (SV) as an intelligent examiner, equipped with a
multi-head attention-enhanced policy network, enabling context-sensitive and
sustained behavioral interventions. A scalar confrontation factor is introduced
to modulate the intensity of adversarial behaviors, allowing continuous,
fine-grained adjustment of test difficulty. Coupled with structured evaluation
metrics, ExamPPO systematically probes AV's robustness across diverse scenarios
and strategies. Extensive experiments across multiple scenarios and AV
strategies demonstrate that ExamPPO can effectively modulate adversarial
behavior, expose decision-making weaknesses in tested AVs, and generalize
across heterogeneous environments, thereby offering a unified and reproducible
solution for evaluating the safety and intelligence of autonomous
decision-making systems.

</details>


### [18] [Evaluating Interactions between Automated Vehicles and Cyclists using a coupled In-the-Loop Test Environment](https://arxiv.org/abs/2507.21859)
*Michael Kaiser,Clemens Groß,Lisa Marie Otto,Steffen Müller*

Main category: cs.RO

TL;DR: 提出并验证了一种耦合的循环测试环境，用于在虚拟环境中实现真实骑行者与自动驾驶车辆的闭环双向交互。


<details>
  <summary>Details</summary>
Motivation: 提高与弱势道路使用者（如骑行者）交互的自动驾驶系统测试的真实性和安全性。

Method: 通过Unreal Engine 5开发的虚拟环境，将骑行者与自动驾驶车辆测试台耦合，实现实时交互。

Result: 验证实验表明该方法可行，并展示了其在自动驾驶系统评估中的优势和局限性。

Conclusion: 该方法为自动驾驶系统与骑行者交互的测试提供了安全且可控的环境，具有实际应用潜力。

Abstract: Testing and evaluating automated driving systems (ADS) in interactions with
vulnerable road users (VRUs), such as cyclists, are essential for improving the
safety of VRUs, but often lack realism. This paper presents and validates a
coupled in-the-loop test environment that integrates a Cyclist-in-the Loop test
bench with a Vehicle-in-the-Loop test bench via a virtual environment (VE)
developed in Unreal Engine 5. The setup enables closed-loop, bidirectional
interaction between a real human cyclist and a real automated vehicle under
safe and controllable conditions. The automated vehicle reacts to cyclist
gestures via stimulated camera input, while the cyclist, riding a stationary
bicycle, perceives and reacts to the vehicle in the VE in real time. Validation
experiments are conducted using a real automated shuttle bus with a
track-and-follow function, performing three test maneuvers - straight-line
driving with stop, circular track driving, and double lane change - on a
proving ground and in the coupled in-the-loop test environment. The performance
is evaluated by comparing the resulting vehicle trajectories in both
environments. Additionally, the introduced latencies of individual components
in the test setup are measured. The results demonstrate the feasibility of the
approach and highlight its strengths and limitations for realistic ADS
evaluation.

</details>


### [19] [A Systematic Robot Design Optimization Methodology with Application to Redundant Dual-Arm Manipulators](https://arxiv.org/abs/2507.21896)
*Dominic Guri,George Kantor*

Main category: cs.RO

TL;DR: 提出了一种四部分设计优化方法，用于自动化开发任务特定的机器人系统，并在辣椒采摘中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 农业环境中机器人部署的优化放置问题复杂且直觉驱动，限制了机器人自动化的普及。

Method: 包括机器人设计模型、任务与环境模拟表示、任务特定性能指标和优化算法。

Result: 在可达性成功率上至少提升14%，灵巧性提升30%以上。

Conclusion: 该方法显著提升了机器人系统的性能，适用于复杂农业环境。

Abstract: One major recurring challenge in deploying manipulation robots is determining
the optimal placement of manipulators to maximize performance. This challenge
is exacerbated in complex, cluttered agricultural environments of high-value
crops, such as flowers, fruits, and vegetables, that could greatly benefit from
robotic systems tailored to their specific requirements. However, the design of
such systems remains a challenging, intuition-driven process, limiting the
affordability and adoption of robotics-based automation by domain experts like
farmers. To address this challenge, we propose a four-part design optimization
methodology for automating the development of task-specific robotic systems.
This framework includes (a) a robot design model, (b) task and environment
representations for simulation, (c) task-specific performance metrics, and (d)
optimization algorithms for refining configurations. We demonstrate our
framework by optimizing a dual-arm robotic system for pepper harvesting using
two off-the-shelf redundant manipulators. To enhance performance, we introduce
novel task metrics that leverage self-motion manifolds to characterize
manipulator redundancy comprehensively. Our results show that our framework
achieves simultaneous improvements in reachability success rates and
improvements in dexterity. Specifically, our approach improves reachability
success by at least 14\% over baseline methods and achieves over 30\%
improvement in dexterity based on our task-specific metric.

</details>


### [20] [ODE Methods for Computing One-Dimensional Self-Motion Manifolds](https://arxiv.org/abs/2507.21957)
*Dominic Guri,George Kantor*

Main category: cs.RO

TL;DR: 本文提出了一种计算冗余机械臂自运动流形（SMMs）的新方法，通过ODE公式和固定步长积分器实现全局逆运动学解，并扩展到棱柱关节系统。


<details>
  <summary>Details</summary>
Motivation: 冗余机械臂的逆运动学问题存在多个局部最优解，传统数值方法无法提供全局解。SMMs能表示所有解，但现有方法未涵盖棱柱关节系统。

Method: 引入基于ODE的公式计算SMMs，使用固定步长积分器；提出搜索断开SMM组件的方法，并扩展到棱柱关节系统。

Result: 方法无需额外IK细化即可精确计算SMM解，并通过示例展示了其可行性和局限性。

Conclusion: 本文方法为冗余机械臂提供了全局IK解，填补了棱柱关节系统的研究空白，但存在计算复杂性和局限性。

Abstract: Redundant manipulators are well understood to offer infinite joint
configurations for achieving a desired end-effector pose. The multiplicity of
inverse kinematics (IK) solutions allows for the simultaneous solving of
auxiliary tasks like avoiding joint limits or obstacles. However, the most
widely used IK solvers are numerical gradient-based iterative methods that
inherently return a locally optimal solution. In this work, we explore the
computation of self-motion manifolds (SMMs), which represent the set of all
joint configurations that solve the inverse kinematics problem for redundant
manipulators. Thus, SMMs are global IK solutions for redundant manipulators. We
focus on task redundancies of dimensionality 1, introducing a novel ODE
formulation for computing SMMs using standard explicit fixed-step ODE
integrators. We also address the challenge of ``inducing'' redundancy in
otherwise non-redundant manipulators assigned to tasks naturally described by
one degree of freedom less than the non-redundant manipulator. Furthermore,
recognizing that SMMs can consist of multiple disconnected components, we
propose methods for searching for these separate SMM components. Our
formulations and algorithms compute accurate SMM solutions without requiring
additional IK refinement, and we extend our methods to prismatic joint systems
-- an area not covered in current SMM literature. This manuscript presents the
derivation of these methods and several examples that show how the methods work
and their limitations.

</details>


### [21] [A Deep Learning-Driven Autonomous System for Retinal Vein Cannulation: Validation Using a Chicken Embryo Model](https://arxiv.org/abs/2507.21965)
*Yi Wang,Peiyao Zhang,Mojtaba Esfandiari,Peter Gehlbach,Iulian I. Iordachita*

Main category: cs.RO

TL;DR: 论文提出了一种自动化机器人系统，结合深度学习模型和OCT成像，用于视网膜静脉插管手术，显著提高了手术精度和效率。


<details>
  <summary>Details</summary>
Motivation: 视网膜静脉插管手术因静脉细小脆弱且需高精度操作而具有挑战性，需要机器人辅助以提高准确性和稳定性。

Method: 采用自上而下的显微镜和B-scan OCT成像进行深度感知，利用深度学习模型实现实时针头导航、接触检测和静脉穿刺识别。

Result: 系统在鸡胚胎模型中实现了85%的穿刺事件识别准确率，显著减少了导航和穿刺时间。

Conclusion: 结合先进成像和深度学习可自动化显微手术任务，为更安全可靠的视网膜静脉插管手术提供了可能。

Abstract: Retinal vein cannulation (RVC) is a minimally invasive microsurgical
procedure for treating retinal vein occlusion (RVO), a leading cause of vision
impairment. However, the small size and fragility of retinal veins, coupled
with the need for high-precision, tremor-free needle manipulation, create
significant technical challenges. These limitations highlight the need for
robotic assistance to improve accuracy and stability. This study presents an
automated robotic system with a top-down microscope and B-scan optical
coherence tomography (OCT) imaging for precise depth sensing. Deep
learning-based models enable real-time needle navigation, contact detection,
and vein puncture recognition, using a chicken embryo model as a surrogate for
human retinal veins. The system autonomously detects needle position and
puncture events with 85% accuracy. The experiments demonstrate notable
reductions in navigation and puncture times compared to manual methods. Our
results demonstrate the potential of integrating advanced imaging and deep
learning to automate microsurgical tasks, providing a pathway for safer and
more reliable RVC procedures with enhanced precision and reproducibility.

</details>


### [22] [DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments](https://arxiv.org/abs/2507.21981)
*Yufei Jia,Guangyu Wang,Yuhang Dong,Junzhe Wu,Yupei Zeng,Haonan Lin,Zifan Wang,Haizhou Ge,Weibin Gu,Kairui Ding,Zike Yan,Yunjie Cheng,Yue Li,Ziming Wang,Chuxuan Li,Wei Sui,Lu Shi,Guanzhong Tian,Ruqi Huang,Guyue Zhou*

Main category: cs.RO

TL;DR: 提出首个基于3DGS的统一、模块化开源仿真框架Discoverse，用于Real2Sim2Real机器人学习，支持多传感器并行模拟和精确物理，实现零样本Sim2Real迁移。


<details>
  <summary>Details</summary>
Motivation: 解决复杂真实场景的几何和外观超现实合成问题，分析并弥合Sim2Real差距，推动大规模机器人学习和复杂机器人基准测试。

Method: 结合Gaussian Splatting和MuJoCo技术，支持现有3D资产、机器人模型和ROS插件，实现多传感器并行模拟和精确物理。

Result: 在模仿学习中展示了最先进的零样本Sim2Real迁移性能。

Conclusion: Discoverse为机器人学习提供了高效、真实的仿真环境，显著提升了Sim2Real迁移能力。

Abstract: We present the first unified, modular, open-source 3DGS-based simulation
framework for Real2Sim2Real robot learning. It features a holistic Real2Sim
pipeline that synthesizes hyper-realistic geometry and appearance of complex
real-world scenarios, paving the way for analyzing and bridging the Sim2Real
gap. Powered by Gaussian Splatting and MuJoCo, Discoverse enables massively
parallel simulation of multiple sensor modalities and accurate physics, with
inclusive supports for existing 3D assets, robot models, and ROS plugins,
empowering large-scale robot learning and complex robotic benchmarks. Through
extensive experiments on imitation learning, Discoverse demonstrates
state-of-the-art zero-shot Sim2Real transfer performance compared to existing
simulators. For code and demos: https://air-discoverse.github.io/.

</details>


### [23] [A Nonlinear MPC Framework for Loco-Manipulation of Quadrupedal Robots with Non-Negligible Manipulator Dynamics](https://arxiv.org/abs/2507.22042)
*Ruturaj Sambhus,Kapi Ketan Mehta,Ali MirMohammad Sadeghi,Basit Muhammad Imran,Jeeseop Kim,Taizoon Chunawala,Vittorio Pastore,Sujith Vijayan,Kaveh Akbari Hamed*

Main category: cs.RO

TL;DR: 提出了一种针对四足机器人操作任务的高效非线性模型预测控制（NMPC）框架，结合分解策略实现实时控制。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在执行操作任务时，由于机械臂动力学不可忽略，传统方法难以高效处理高自由度模型。

Method: 采用分解策略，将运动模板模型（如单刚体模型）与机械臂全阶动力学模型耦合，实现扭矩级控制。

Result: 在60 Hz的实时频率下解决NMPC问题，并通过硬件实验验证了鲁棒性。

Conclusion: 该框架在复杂操作任务中表现出色，能有效应对外部干扰、负载变化和不平坦地形。

Abstract: Model predictive control (MPC) combined with reduced-order template models
has emerged as a powerful tool for trajectory optimization in dynamic legged
locomotion. However, loco-manipulation tasks performed by legged robots
introduce additional complexity, necessitating computationally efficient MPC
algorithms capable of handling high-degree-of-freedom (DoF) models. This letter
presents a computationally efficient nonlinear MPC (NMPC) framework tailored
for loco-manipulation tasks of quadrupedal robots equipped with robotic
manipulators whose dynamics are non-negligible relative to those of the
quadruped. The proposed framework adopts a decomposition strategy that couples
locomotion template models -- such as the single rigid body (SRB) model -- with
a full-order dynamic model of the robotic manipulator for torque-level control.
This decomposition enables efficient real-time solution of the NMPC problem in
a receding horizon fashion at 60 Hz. The optimal state and input trajectories
generated by the NMPC for locomotion are tracked by a low-level nonlinear
whole-body controller (WBC) running at 500 Hz, while the optimal torque
commands for the manipulator are directly applied. The layered control
architecture is validated through extensive numerical simulations and hardware
experiments on a 15-kg Unitree Go2 quadrupedal robot augmented with a 4.4-kg
4-DoF Kinova arm. Given that the Kinova arm dynamics are non-negligible
relative to the Go2 base, the proposed NMPC framework demonstrates robust
stability in performing diverse loco-manipulation tasks, effectively handling
external disturbances, payload variations, and uneven terrain.

</details>
