<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 11]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning](https://arxiv.org/abs/2508.15874)
*Yijun Liu,Yuwei Liu,Yuan Meng,Jieheng Zhang,Yuwei Zhou,Ye Li,Jiacheng Jiang,Kangye Ji,Shijia Ge,Zhi Wang,Wenwu Zhu*

Main category: cs.RO

TL;DR: SP是一种空间感知的视觉运动机器人操作框架，通过显式空间建模和推理提升机器人控制的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉中心层次化体现模型缺乏空间感知能力，限制了其在复杂环境中将视觉计划转化为可执行控制的效果。

Method: SP包含三个模块：空间条件体现视频生成模块、基于空间的动作预测模块和空间推理反馈策略。

Result: SP在11个多样化任务中平均成功率达86.7%，比最佳基线平均提升33.0%。

Conclusion: SP显著提升了体现模型在机器人控制应用中的实用性。

Abstract: Vision-centric hierarchical embodied models have demonstrated strong
potential for long-horizon robotic control. However, existing methods lack
spatial awareness capabilities, limiting their effectiveness in bridging visual
plans to actionable control in complex environments. To address this problem,
we propose Spatial Policy (SP), a unified spatial-aware visuomotor robotic
manipulation framework via explicit spatial modeling and reasoning.
Specifically, we first design a spatial-conditioned embodied video generation
module to model spatially guided predictions through a spatial plan table.
Then, we propose a spatial-based action prediction module to infer executable
actions with coordination. Finally, we propose a spatial reasoning feedback
policy to refine the spatial plan table via dual-stage replanning. Extensive
experiments show that SP significantly outperforms state-of-the-art baselines,
achieving a 33.0% average improvement over the best baseline. With an 86.7%
average success rate across 11 diverse tasks, SP substantially enhances the
practicality of embodied models for robotic control applications. Code and
checkpoints are maintained at
https://plantpotatoonmoon.github.io/SpatialPolicy/.

</details>


### [2] [UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation](https://arxiv.org/abs/2508.15972)
*Zhaodong Jiang,Ashish Sinha,Tongtong Cao,Yuan Ren,Bingbing Liu,Binbin Xu*

Main category: cs.RO

TL;DR: UnPose是一个零样本、无模型的6D物体姿态估计和重建框架，利用预训练扩散模型的3D先验和不确定性估计，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖CAD模型，成本高且不实用；现有方法需要额外训练或产生幻觉几何。UnPose旨在解决这些问题。

Method: 从单视角RGB-D帧出发，利用多视角扩散模型和3D高斯泼溅表示估计初始3D模型，并通过不确定性引导的增量优化提升精度。

Result: 实验表明，UnPose在6D姿态估计和3D重建质量上显著优于现有方法，并在实际机器人任务中验证了实用性。

Conclusion: UnPose通过扩散模型的先验和不确定性估计，实现了高效、准确的零样本姿态估计和重建，具有实际应用价值。

Abstract: Estimating the 6D pose of novel objects is a fundamental yet challenging
problem in robotics, often relying on access to object CAD models. However,
acquiring such models can be costly and impractical. Recent approaches aim to
bypass this requirement by leveraging strong priors from foundation models to
reconstruct objects from single or multi-view images, but typically require
additional training or produce hallucinated geometry. To this end, we propose
UnPose, a novel framework for zero-shot, model-free 6D object pose estimation
and reconstruction that exploits 3D priors and uncertainty estimates from a
pre-trained diffusion model. Specifically, starting from a single-view RGB-D
frame, UnPose uses a multi-view diffusion model to estimate an initial 3D model
using 3D Gaussian Splatting (3DGS) representation, along with pixel-wise
epistemic uncertainty estimates. As additional observations become available,
we incrementally refine the 3DGS model by fusing new views guided by the
diffusion model's uncertainty, thereby continuously improving the pose
estimation accuracy and 3D reconstruction quality. To ensure global
consistency, the diffusion prior-generated views and subsequent observations
are further integrated in a pose graph and jointly optimized into a coherent
3DGS field. Extensive experiments demonstrate that UnPose significantly
outperforms existing approaches in both 6D pose estimation accuracy and 3D
reconstruction quality. We further showcase its practical applicability in
real-world robotic manipulation tasks.

</details>


### [3] [GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System](https://arxiv.org/abs/2508.15990)
*Hung-Jui Huang,Mohammad Amin Mirzaee,Michael Kaess,Wenzhen Yuan*

Main category: cs.RO

TL;DR: GelSLAM是一种仅依赖触觉感知的实时3D SLAM系统，用于长时间估计物体姿态和高保真重建物体形状。


<details>
  <summary>Details</summary>
Motivation: 触觉感知在精确性和抗遮挡方面优于视觉方法，适用于高精度操作任务。

Method: 利用触觉衍生的表面法线和曲率进行鲁棒跟踪和闭环，避免传统点云方法的局限性。

Result: 实时跟踪物体运动误差低、漂移小，重建形状精度达亚毫米级，适用于低纹理物体。

Conclusion: GelSLAM扩展了触觉感知的全局和长期空间感知能力，为精确操作任务奠定基础。

Abstract: Accurately perceiving an object's pose and shape is essential for precise
grasping and manipulation. Compared to common vision-based methods, tactile
sensing offers advantages in precision and immunity to occlusion when tracking
and reconstructing objects in contact. This makes it particularly valuable for
in-hand and other high-precision manipulation tasks. In this work, we present
GelSLAM, a real-time 3D SLAM system that relies solely on tactile sensing to
estimate object pose over long periods and reconstruct object shapes with high
fidelity. Unlike traditional point cloud-based approaches, GelSLAM uses
tactile-derived surface normals and curvatures for robust tracking and loop
closure. It can track object motion in real time with low error and minimal
drift, and reconstruct shapes with submillimeter accuracy, even for low-texture
objects such as wooden tools. GelSLAM extends tactile sensing beyond local
contact to enable global, long-horizon spatial perception, and we believe it
will serve as a foundation for many precise manipulation tasks involving
interaction with objects in hand. The video demo is available on our website:
https://joehjhuang.github.io/gelslam.

</details>


### [4] [Self-Aligning EPM Connector: A Versatile Solution for Adaptive and Multi-Modal Interfaces](https://arxiv.org/abs/2508.16008)
*Bingchao Wang,Adam A. Stokes*

Main category: cs.RO

TL;DR: 多功能连接器基于电永磁技术，集成自对准、机械耦合、流体传输和数据通信，适用于模块化机器人等领域。


<details>
  <summary>Details</summary>
Motivation: 开发一种多功能、紧凑且低能耗的连接器，满足模块化机器人、电动汽车充电等应用需求。

Method: 采用电永磁技术，结合SLA-3D打印结构，实现自对准、流体传输和数据通信功能。

Result: 实验显示连接器具有可靠的自对准、高效流体传输和稳定数据传输能力，适应多种偏差。

Conclusion: 该连接器在多种应用中表现出高灵活性和低能耗，具有广泛适用性。

Abstract: This paper presents a multifunctional connector based on electro-permanent
magnet (EPM) technology, integrating self-alignment, mechanical coupling, fluid
transfer, and data communication within a compact SLA-3D printed structure.
Experimental results demonstrate reliable self-alignment, efficient fluid
transfer in single-loop and dual-channel modes, and robust data transmission
via integrated electronic control. The connector exhibits high flexibility in
accommodating axial, angular, and lateral misalignments while maintaining low
energy consumption. These features make it highly suitable for modular
robotics, electric vehicle charging, household robotic platforms, and aerospace
docking applications.

</details>


### [5] [Take That for Me: Multimodal Exophora Resolution with Interactive Questioning for Ambiguous Out-of-View Instructions](https://arxiv.org/abs/2508.16143)
*Akira Oyama,Shoichi Hasegawa,Akira Taniguchi,Yoshinobu Hagiwara,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: MIEL框架通过多模态交互解决机器人指令中的外指问题，结合声音定位、语义地图和GPT-4o提问，显著提升了用户可见和不可见时的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖视觉数据，无法解决用户或对象不可见时的外指问题。

Method: 结合声音定位、语义地图、视觉语言模型和GPT-4o交互提问。

Result: 用户可见时性能提升1.3倍，不可见时提升2.0倍。

Conclusion: MIEL在多模态交互中有效解决了外指问题，适用于真实场景。

Abstract: Daily life support robots must interpret ambiguous verbal instructions
involving demonstratives such as ``Bring me that cup,'' even when objects or
users are out of the robot's view. Existing approaches to exophora resolution
primarily rely on visual data and thus fail in real-world scenarios where the
object or user is not visible. We propose Multimodal Interactive Exophora
resolution with user Localization (MIEL), which is a multimodal exophora
resolution framework leveraging sound source localization (SSL), semantic
mapping, visual-language models (VLMs), and interactive questioning with
GPT-4o. Our approach first constructs a semantic map of the environment and
estimates candidate objects from a linguistic query with the user's skeletal
data. SSL is utilized to orient the robot toward users who are initially
outside its visual field, enabling accurate identification of user gestures and
pointing directions. When ambiguities remain, the robot proactively interacts
with the user, employing GPT-4o to formulate clarifying questions. Experiments
in a real-world environment showed results that were approximately 1.3 times
better when the user was visible to the robot and 2.0 times better when the
user was not visible to the robot, compared to the methods without SSL and
interactive questioning. The project website is
https://emergentsystemlabstudent.github.io/MIEL/.

</details>


### [6] [GPL-SLAM: A Laser SLAM Framework with Gaussian Process Based Extended Landmarks](https://arxiv.org/abs/2508.16459)
*Ali Emre Balcı,Erhan Ege Keyvan,Emre Özkan*

Main category: cs.RO

TL;DR: 提出了一种基于高斯过程（GP）的新型SLAM方法，通过GP轮廓表示环境中的对象，支持在线更新和语义信息提取。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法（如网格地图或点云配准）缺乏语义信息且内存效率低，需要一种更高效且支持语义理解的方法。

Method: 使用GP轮廓表示对象，通过递归方案在线更新，并在完全贝叶斯框架下联合推断机器人位姿和对象地图。

Result: 在合成和真实实验中验证了方法的准确性，能够提供对象数量、面积等语义信息，并支持安全导航。

Conclusion: 该方法在多样结构化环境中表现出色，为下游任务提供了有价值的形状置信边界。

Abstract: We present a novel Simultaneous Localization and Mapping (SLAM) method that
employs Gaussian Process (GP) based landmark (object) representations. Instead
of conventional grid maps or point cloud registration, we model the environment
on a per object basis using GP based contour representations. These contours
are updated online through a recursive scheme, enabling efficient memory usage.
The SLAM problem is formulated within a fully Bayesian framework, allowing
joint inference over the robot pose and object based map. This representation
provides semantic information such as the number of objects and their areas,
while also supporting probabilistic measurement to object associations.
Furthermore, the GP based contours yield confidence bounds on object shapes,
offering valuable information for downstream tasks like safe navigation and
exploration. We validate our method on synthetic and real world experiments,
and show that it delivers accurate localization and mapping performance across
diverse structured environments.

</details>


### [7] [Swarming Without an Anchor (SWA): Robot Swarms Adapt Better to Localization Dropouts Then a Single Robot](https://arxiv.org/abs/2508.16460)
*Jiri Horyna,Roland Jung,Stephan Weiss,Eliseo Ferrante,Martin Saska*

Main category: cs.RO

TL;DR: SWA方法通过融合分散状态估计、鲁棒相互感知和机载传感器数据，解决无人机群在定位失效时的状态估计问题，实现速度一致性和群体稳定性。


<details>
  <summary>Details</summary>
Motivation: 无人机群在定位失效时难以维持准确状态估计，影响群体协作和稳定性。

Method: 结合分散状态估计、鲁棒相互感知和机载传感器数据，利用相对信息估计无人机横向状态。

Result: 实现速度一致性，群体整体平移漂移外的干扰均被抑制，验证了方法的有效性。

Conclusion: SWA方法在定位不可靠或失效时仍能维持群体行为，提升了多无人机系统的可靠性和韧性。

Abstract: In this paper, we present the Swarming Without an Anchor (SWA) approach to
state estimation in swarms of Unmanned Aerial Vehicles (UAVs) experiencing
ego-localization dropout, where individual agents are laterally stabilized
using relative information only. We propose to fuse decentralized state
estimation with robust mutual perception and onboard sensor data to maintain
accurate state awareness despite intermittent localization failures. Thus, the
relative information used to estimate the lateral state of UAVs enables the
identification of the unambiguous state of UAVs with respect to the local
constellation. The resulting behavior reaches velocity consensus, as this task
can be referred to as the double integrator synchronization problem. All
disturbances and performance degradations except a uniform translation drift of
the swarm as a whole is attenuated which is enabling new opportunities in using
tight cooperation for increasing reliability and resilience of multi-UAV
systems. Simulations and real-world experiments validate the effectiveness of
our approach, demonstrating its capability to sustain cohesive swarm behavior
in challenging conditions of unreliable or unavailable primary localization.

</details>


### [8] [Terrain Classification for the Spot Quadrupedal Mobile Robot Using Only Proprioceptive Sensing](https://arxiv.org/abs/2508.16504)
*Sophie Villemure,Jefferson Silveira,Joshua A. Marshall*

Main category: cs.RO

TL;DR: 提出了一种用于波士顿动力Spot机器人的地形分类器，通过降维和分类技术识别地形，准确率达97%。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在复杂地形上易出现下沉和打滑问题，需要地形分类器辅助规划安全路径。

Method: 利用Spot机器人提供的100多个本体感知信号，结合降维和分类技术开发地形分类器。

Result: 分类器在实地测试中能准确识别三种地形，准确率约97%。

Conclusion: 该地形分类器能有效辅助四足机器人规划安全路径。

Abstract: Quadrupedal mobile robots can traverse a wider range of terrain types than
their wheeled counterparts but do not perform the same on all terrain types.
These robots are prone to undesirable behaviours like sinking and slipping on
challenging terrains. To combat this issue, we propose a terrain classifier
that provides information on terrain type that can be used in robotic systems
to create a traversability map to plan safer paths for the robot to navigate.
The work presented here is a terrain classifier developed for a Boston Dynamics
Spot robot. Spot provides over 100 measured proprioceptive signals describing
the motions of the robot and its four legs (e.g., foot penetration, forces,
joint angles, etc.). The developed terrain classifier combines dimensionality
reduction techniques to extract relevant information from the signals and then
applies a classification technique to differentiate terrain based on
traversability. In representative field testing, the resulting terrain
classifier was able to identify three different terrain types with an accuracy
of approximately 97%

</details>


### [9] [On Kinodynamic Global Planning in a Simplicial Complex Environment: A Mixed Integer Approach](https://arxiv.org/abs/2508.16511)
*Otobong Jerome,Alexandr Klimchik,Alexander Maloletov,Geesara Kulathunga*

Main category: cs.RO

TL;DR: 将汽车类车辆的动力学规划问题转化为优化任务，计算最小时间轨迹和速度剖面，同时满足边界条件。


<details>
  <summary>Details</summary>
Motivation: 解决汽车类车辆在复杂3D地形中的高效运动规划问题，避免局部极小值。

Method: 将问题建模为混合整数分数规划，通过变量转换和McCormick包络松弛为混合整数线性规划。

Result: 比MPPI和log-MPPI快104倍，且严格满足约束条件。

Conclusion: 该方法在复杂地形中高效且可靠，适用于汽车类车辆的动力学规划。

Abstract: This work casts the kinodynamic planning problem for car-like vehicles as an
optimization task to compute a minimum-time trajectory and its associated
velocity profile, subject to boundary conditions on velocity, acceleration, and
steering. The approach simultaneously optimizes both the spatial path and the
sequence of acceleration and steering controls, ensuring continuous motion from
a specified initial position and velocity to a target end position and
velocity.The method analyzes the admissible control space and terrain to avoid
local minima. The proposed method operates efficiently in simplicial complex
environments, a preferred terrain representation for capturing intricate 3D
landscapes. The problem is initially posed as a mixed-integer fractional
program with quadratic constraints, which is then reformulated into a
mixed-integer bilinear objective through a variable transformation and
subsequently relaxed to a mixed-integer linear program using McCormick
envelopes. Comparative simulations against planners such as MPPI and log-MPPI
demonstrate that the proposed approach generates solutions 104 times faster
while strictly adhering to the specified constraints

</details>


### [10] [Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments](https://arxiv.org/abs/2508.16515)
*Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira*

Main category: cs.RO

TL;DR: 论文测试了A*、RRT*和PSO三种路径规划算法在3D城市环境中的表现，发现A*在计算效率和路径质量上最优，PSO适合密集环境，RRT*则表现均衡。


<details>
  <summary>Details</summary>
Motivation: 无人机路径规划和避障是关键挑战，现有算法存在局限性，需测试不同算法的有效性。

Method: 在3D城市环境中设计三种实验，测试A*、RRT*和PSO在不同地图大小、高度和障碍物密度下的表现。

Result: A*在计算效率和路径质量上最优，PSO适合密集环境，RRT*表现均衡。

Conclusion: A*是首选算法，PSO和RRT*在特定场景下也有优势。

Abstract: The most crucial challenges for UAVs are planning paths and avoiding
obstacles in their way. In recent years, a wide variety of path-planning
algorithms have been developed. These algorithms have successfully solved
path-planning problems; however, they suffer from multiple challenges and
limitations. To test the effectiveness and efficiency of three widely used
algorithms, namely A*, RRT*, and Particle Swarm Optimization (PSO), this paper
conducts extensive experiments in 3D urban city environments cluttered with
obstacles. Three experiments were designed with two scenarios each to test the
aforementioned algorithms. These experiments consider different city map sizes,
different altitudes, and varying obstacle densities and sizes in the
environment. According to the experimental results, the A* algorithm
outperforms the others in both computation efficiency and path quality. PSO is
especially suitable for tight turns and dense environments, and RRT* offers a
balance and works well across all experiments due to its randomized approach to
finding solutions.

</details>


### [11] [Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems](https://arxiv.org/abs/2508.16574)
*Yizhi Wang,Degang Xu,Yongfang Xie,Shuzhong Tan,Xianan Zhou,Peng Chen*

Main category: cs.RO

TL;DR: 提出了一种用于四轮独立转向和驱动系统的分层决策框架，结合深度强化学习和模糊逻辑，提升导航性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决传统导航方法在复杂动态环境中性能不足的问题，同时确保物理可行性和机械安全性。

Method: 结合深度强化学习（高层导航）和模糊逻辑（低层控制），分别生成全局运动指令和强制执行运动学约束。

Result: 仿真和实际验证表明，该框架在训练效率、稳定性和安全性上优于传统方法。

Conclusion: 该框架为复杂场景下的四轮独立转向和驱动系统提供了可扩展且可靠的解决方案。

Abstract: This paper presents a hierarchical decision-making framework for autonomous
navigation in four-wheel independent steering and driving (4WISD) systems. The
proposed approach integrates deep reinforcement learning (DRL) for high-level
navigation with fuzzy logic for low-level control to ensure both task
performance and physical feasibility. The DRL agent generates global motion
commands, while the fuzzy logic controller enforces kinematic constraints to
prevent mechanical strain and wheel slippage. Simulation experiments
demonstrate that the proposed framework outperforms traditional navigation
methods, offering enhanced training efficiency and stability and mitigating
erratic behaviors compared to purely DRL-based solutions. Real-world
validations further confirm the framework's ability to navigate safely and
effectively in dynamic industrial settings. Overall, this work provides a
scalable and reliable solution for deploying 4WISD mobile robots in complex,
real-world scenarios.

</details>
