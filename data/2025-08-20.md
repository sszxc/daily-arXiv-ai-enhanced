<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Diff-MSM: Differentiable MusculoSkeletal Model for Simultaneous Identification of Human Muscle and Bone Parameters](https://arxiv.org/abs/2508.13303)
*Yingfan Zhou,Philip Sanderink,Sigurd Jager Lemming,Cheng Fang*

Main category: cs.RO

TL;DR: 提出了一种基于可微分肌肉骨骼模型（Diff-MSM）的方法，用于个性化肌肉和骨骼参数识别，无需直接测量关节扭矩。


<details>
  <summary>Details</summary>
Motivation: 高保真个性化肌肉骨骼模型对模拟人机交互系统至关重要，但现有方法难以直接测量内部生物力学变量。

Method: 使用可微分肌肉骨骼模型（Diff-MSM），通过自动微分技术从可测量的肌肉激活到运动结果进行端到端参数识别。

Result: 仿真结果表明，该方法在肌肉参数估计上显著优于现有基线方法，误差低至0.05%。

Conclusion: Diff-MSM不仅适用于肌肉骨骼建模，还在肌肉健康监测、康复和运动科学中有潜在应用。

Abstract: High-fidelity personalized human musculoskeletal models are crucial for
simulating realistic behavior of physically coupled human-robot interactive
systems and verifying their safety-critical applications in simulations before
actual deployment, such as human-robot co-transportation and rehabilitation
through robotic exoskeletons. Identifying subject-specific Hill-type muscle
model parameters and bone dynamic parameters is essential for a personalized
musculoskeletal model, but very challenging due to the difficulty of measuring
the internal biomechanical variables in vivo directly, especially the joint
torques. In this paper, we propose using Differentiable MusculoSkeletal Model
(Diff-MSM) to simultaneously identify its muscle and bone parameters with an
end-to-end automatic differentiation technique differentiating from the
measurable muscle activation, through the joint torque, to the resulting
observable motion without the need to measure the internal joint torques.
Through extensive comparative simulations, the results manifested that our
proposed method significantly outperformed the state-of-the-art baseline
methods, especially in terms of accurate estimation of the muscle parameters
(i.e., initial guess sampled from a normal distribution with the mean being the
ground truth and the standard deviation being 10% of the ground truth could end
up with an average of the percentage errors of the estimated values as low as
0.05%). In addition to human musculoskeletal modeling and simulation, the new
parameter identification technique with the Diff-MSM has great potential to
enable new applications in muscle health monitoring, rehabilitation, and sports
science.

</details>


### [2] [A Surveillance Based Interactive Robot](https://arxiv.org/abs/2508.13319)
*Kshitij Kavimandan,Pooja Mangal,Devanshi Mehta*

Main category: cs.RO

TL;DR: 论文介绍了一种基于树莓派的移动监控机器人，支持实时视频流和语音交互，使用YOLOv3进行物体检测，并依赖开源软件和现成硬件。


<details>
  <summary>Details</summary>
Motivation: 设计一个易于复现的移动监控机器人，支持实时视频流和语音交互，以提升监控和导航的智能化水平。

Method: 系统采用两个树莓派4单元，前端单元配备摄像头、麦克风和扬声器，中央单元负责视频流和感知任务。使用YOLOv3进行物体检测，Python库实现语音识别和多语言翻译，Kinect传感器提供视觉输入。

Result: 在室内测试中，机器人能够以交互式帧率检测物体，可靠识别语音命令，并自动执行动作。

Conclusion: 该设计依赖现成硬件和开源软件，易于复现，并讨论了未来扩展方向，如传感器融合和GPU加速。

Abstract: We build a mobile surveillance robot that streams video in real time and
responds to speech so a user can monitor and steer it from a phone or browser.
The system uses two Raspberry Pi 4 units: a front unit on a differential drive
base with camera, mic, and speaker, and a central unit that serves the live
feed and runs perception. Video is sent with FFmpeg. Objects in the scene are
detected using YOLOv3 to support navigation and event awareness. For voice
interaction, we use Python libraries for speech recognition, multilingual
translation, and text-to-speech, so the robot can take spoken commands and read
back responses in the requested language. A Kinect RGB-D sensor provides visual
input and obstacle cues. In indoor tests the robot detects common objects at
interactive frame rates on CPU, recognises commands reliably, and translates
them to actions without manual control. The design relies on off-the-shelf
hardware and open software, making it easy to reproduce. We discuss limits and
practical extensions, including sensor fusion with ultrasonic range data, GPU
acceleration, and adding face and text recognition.

</details>


### [3] [Incremental Generalized Hybrid A*](https://arxiv.org/abs/2508.13392)
*Sidharth Talia,Oren Salzman,Siddhartha Srinivasa*

Main category: cs.RO

TL;DR: IGHA*是一种动态组织顶点扩展的树搜索框架，优于传统的Hybrid A*，在复杂动力学下实现实时规划。


<details>
  <summary>Details</summary>
Motivation: 解决复杂动力学下实时规划的挑战，传统方法因网格分辨率选择困难导致效率低下。

Method: 提出Incremental Generalized Hybrid A* (IGHA*)，动态组织顶点扩展，避免刚性剪枝。

Result: IGHA*比优化版Hybrid A*减少6倍扩展次数，在仿真和实际车辆中实现实时性能。

Conclusion: IGHA*在复杂动力学下提供快速、鲁棒的规划，适用于自动驾驶和越野场景。

Abstract: We address the problem of efficiently organizing search over very large
trees, which arises in many applications ranging from autonomous driving to
aerial vehicles. Here, we are motivated by off-road autonomy, where real-time
planning is essential. Classical approaches use graphs of motion primitives and
exploit dominance to mitigate the curse of dimensionality and prune expansions
efficiently. However, for complex dynamics, repeatedly solving two-point
boundary-value problems makes graph construction too slow for fast kinodynamic
planning. Hybrid A* (HA*) addressed this challenge by searching over a tree of
motion primitives and introducing approximate pruning using a grid-based
dominance check. However, choosing the grid resolution is difficult: too coarse
risks failure, while too fine leads to excessive expansions and slow planning.
We propose Incremental Generalized Hybrid A* (IGHA*), an anytime tree-search
framework that dynamically organizes vertex expansions without rigid pruning.
IGHA* provably matches or outperforms HA*. For both on-road kinematic and
off-road kinodynamic planning queries for a car-like robot, variants of IGHA*
use 6x fewer expansions to the best solution compared to an optimized version
of HA*. In simulated off-road experiments in a high fidelity simulator, IGHA*
outperforms HA*M when both are used in the loop with a model predictive
controller. We demonstrate real-time performance both in simulation and on a
small-scale off-road vehicle, enabling fast, robust planning under complex
dynamics. Code: https://github.com/personalrobotics/IGHAStar

</details>


### [4] [Accelerating Signal-Temporal-Logic-Based Task and Motion Planning of Bipedal Navigation using Benders Decomposition](https://arxiv.org/abs/2508.13407)
*Jiming Ren,Xuan Lin,Roman Mineyev,Karen M. Feigh,Samuel Coogan,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于Benders分解的方法，用于解决信号时序逻辑约束下的任务和运动规划问题，显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 由于混合整数规划（MIP）在双足运动等应用中引入非凸约束时计算复杂度极高，需要一种更高效的方法。

Method: 采用Benders分解技术，将问题划分为主问题和子问题，主问题生成计划，子问题检查运动学和动力学可行性。

Result: 实验表明，该方法比传统算法更快地完成规划任务。

Conclusion: Benders分解是一种有效解决复杂任务和运动规划问题的方法。

Abstract: Task and motion planning under Signal Temporal Logic constraints is known to
be NP-hard. A common class of approaches formulates these hybrid problems,
which involve discrete task scheduling and continuous motion planning, as
mixed-integer programs (MIP). However, in applications for bipedal locomotion,
introduction of non-convex constraints such as kinematic reachability and
footstep rotation exacerbates the computational complexity of MIPs. In this
work, we present a method based on Benders Decomposition to address scenarios
where solving the entire monolithic optimization problem is prohibitively
intractable. Benders Decomposition proposes an iterative cutting-plane
technique that partitions the problem into a master problem to prototype a plan
that meets the task specification, and a series of subproblems for kinematics
and dynamics feasibility checks. Our experiments demonstrate that this method
achieves faster planning compared to alternative algorithms for solving the
resulting optimization program with nonlinear constraints.

</details>


### [5] [Switch4EAI: Leveraging Console Game Platform for Benchmarking Robotic Athletics](https://arxiv.org/abs/2508.13444)
*Tianyu Li,Jeonghwan Kim,Wontaek Kim,Donghoon Baek,Seungeun Rho,Sehoon Ha*

Main category: cs.RO

TL;DR: Switch4EAI利用任天堂Switch游戏《Just Dance》评估机器人全身控制策略，通过低成本、易部署的流程实现机器人动作与人类玩家的定量比较。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏标准化基准来评估机器人在现实环境中的运动性能，尤其是在与人类直接对比时。

Method: 利用运动感应游戏（如《Just Dance》）捕捉、重建并重定向游戏中的舞蹈动作，供机器人执行。

Result: 在Unitree G1人形机器人上验证了系统可行性，并建立了机器人性能的定量基准。

Conclusion: 商用游戏平台可作为物理基准测试工具，推动未来具身AI的基准测试研究。

Abstract: Recent advances in whole-body robot control have enabled humanoid and legged
robots to execute increasingly agile and coordinated movements. However,
standardized benchmarks for evaluating robotic athletic performance in
real-world settings and in direct comparison to humans remain scarce. We
present Switch4EAI(Switch-for-Embodied-AI), a low-cost and easily deployable
pipeline that leverages motion-sensing console games to evaluate whole-body
robot control policies. Using Just Dance on the Nintendo Switch as a
representative example, our system captures, reconstructs, and retargets
in-game choreography for robotic execution. We validate the system on a Unitree
G1 humanoid with an open-source whole-body controller, establishing a
quantitative baseline for the robot's performance against a human player. In
the paper, we discuss these results, which demonstrate the feasibility of using
commercial games platform as physically grounded benchmarks and motivate future
work to for benchmarking embodied AI.

</details>


### [6] [CAST: Counterfactual Labels Improve Instruction Following in Vision-Language-Action Models](https://arxiv.org/abs/2508.13446)
*Catherine Glossop,William Chen,Arjun Bhorkar,Dhruv Shah,Sergey Levine*

Main category: cs.RO

TL;DR: 论文提出了一种利用视觉语言模型生成反事实标签的方法，以增强机器人数据集的语言多样性，从而提升视觉-语言-动作模型在指令跟随任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型在细粒度指令跟随任务中表现不佳，主要原因是现有机器人数据集缺乏语义多样性和语言基础。

Method: 通过视觉语言模型生成反事实标签，增强数据集的多样性和语言细粒度，无需额外数据收集。

Result: 实验表明，该方法显著提升了模型在指令跟随任务中的表现，导航任务成功率提高了27%。

Conclusion: 反事实标签方法有效提升了视觉-语言-动作模型的指令跟随能力，且无需额外数据收集。

Abstract: Generalist robots should be able to understand and follow user instructions,
but current vision-language-action (VLA) models struggle with following
fine-grained commands despite providing a powerful architecture for mapping
open-vocabulary natural language instructions to robot actions. One cause for
this is a lack of semantic diversity and language grounding in existing robot
datasets and, specifically, a lack of fine-grained task diversity for similar
observations. To address this, we present a novel method to augment existing
robot datasets by leveraging vision language models to create counterfactual
labels. Our method improves the language-following capabilities of VLAs by
increasing the diversity and granularity of language grounding for robot
datasets by generating counterfactual language and actions. We evaluate the
resulting model's ability to follow language instructions, ranging from simple
object-centric commands to complex referential tasks, by conducting visual
language navigation experiments in 3 different indoor and outdoor environments.
Our experiments demonstrate that counterfactual relabeling, without any
additional data collection, significantly improves instruction-following in VLA
policies, making them competitive with state-of-the-art methods and increasing
success rate by 27% on navigation tasks.

</details>


### [7] [Modeling and Control of AWOISV: A Filtered Tube-Based MPC Approach for Simultaneous Tracking of Lateral Position and Heading Angle](https://arxiv.org/abs/2508.13457)
*Xu Yang,Jun Ni,Hengyang Feng,Feiyu Wang,Tiezhen Wang*

Main category: cs.RO

TL;DR: 论文提出了一种全轮全向独立转向车辆（AWOISV）的理论模型和控制策略，实现了高精度的位置和航向控制。


<details>
  <summary>Details</summary>
Motivation: 研究AWOISV的运动模式和控制方法，以实现其独特的机动能力（如偏航和对角运动）。

Method: 开发了广义动态模型，并提出了基于滤波管的线性时变MPC（FT-LTVMPC）策略。

Result: 仿真和硬件在环实验验证了FT-LTVMPC的高精度控制和实时性能。

Conclusion: FT-LTVMPC能有效控制AWOISV的位置和航向，具有鲁棒性和实时性。

Abstract: An all-wheel omni-directional independent steering vehicle (AWOISV) is a
specialized all-wheel independent steering vehicle with each wheel capable of
steering up to 90{\deg}, enabling unique maneuvers like yaw and diagonal
movement. This paper introduces a theoretical steering radius angle and
sideslip angle (\( \theta_R \)-\(\beta_R \)) representation, based on the
position of the instantaneous center of rotation relative to the wheel rotation
center, defining the motion modes and switching criteria for AWOISVs. A
generalized \( v\)-\(\beta\)-\(r \) dynamic model is developed with forward
velocity \(v\), sideslip angle \(\beta\), and yaw rate \(r\) as states, and
\(\theta_R\) and \(\beta_R\) as control inputs. This model decouples
longitudinal and lateral motions into forward and rotational motions, allowing
seamless transitions across all motion modes under specific conditions. A
filtered tube-based linear time-varying MPC (FT-LTVMPC) strategy is proposed,
achieving simultaneous tracking of lateral position and arbitrary heading
angles, with robustness to model inaccuracies and parameter uncertainties.
Co-simulation and hardware-in-loop (HIL) experiments confirm that FT-LTVMPC
enables high-precision control of both position and heading while ensuring
excellent real-time performance.

</details>


### [8] [Multi-Robot Navigation in Social Mini-Games: Definitions, Taxonomy, and Algorithms](https://arxiv.org/abs/2508.13459)
*Rohan Chandra,Shubham Singh,Abhishek Jha,Dannon Andrade,Hriday Sainathuni,Katia Sycara*

Main category: cs.RO

TL;DR: 论文探讨了自主车辆和服务机器人在受限和拥挤环境中的导航挑战，提出了“社交小游戏”（SMGs）的概念，并呼吁建立统一的分类和评估标准。


<details>
  <summary>Details</summary>
Motivation: 解决“最后一英里”挑战中机器人导航在复杂环境中的问题，尤其是与其他机器人和人类互动的场景。

Method: 通过调查和分类现有的SMG导航方法，提出统一的分类法和评估协议。

Result: 论文首次系统地整理了SMG导航方法，并提出了明确的分类标准。

Conclusion: 需要统一的分类和评估标准来推动SMG导航研究的进一步发展。

Abstract: The ``Last Mile Challenge'' has long been considered an important, yet
unsolved, challenge for autonomous vehicles, public service robots, and
delivery robots. A central issue in this challenge is the ability of robots to
navigate constrained and cluttered environments (e.g., doorways, hallways,
corridor intersections), often while competing for space with other robots and
humans. We refer to these environments as ``Social Mini-Games'' (SMGs). SMGs
are tightly coupled, high-agency interactions that arise within general
multi-robot navigation (MRN) scenarios. They are identified through certain
distinct characteristics and require specialized metrics to evaluate them.
Traditional navigation approaches designed for MRN do not perform well in SMGs,
which has led to focused research on dedicated SMG solvers (navigation methods
specialized to navigate in SMGs), which has flourished in recent years.
However, publications on SMG navigation research make different assumptions (on
centralized versus decentralized, observability, communication, cooperation,
etc.), and have different objective functions (safety versus liveness). These
assumptions and objectives are sometimes implicitly assumed or described
informally. This makes it difficult to establish appropriate baselines for
comparison in research papers, as well as making it difficult for practitioners
to find the papers relevant to their concrete application. Such ad-hoc
representation of the field also presents a barrier to new researchers wanting
to start research in this area. SMG navigation research requires its own
taxonomy, definitions, and evaluation protocols to guide effective research
moving forward. This survey is the first to catalog SMG solvers using a
well-defined and unified taxonomy and to classify existing methods accordingly.

</details>


### [9] [ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments](https://arxiv.org/abs/2508.13488)
*Jingwen Yu,Jiayi Yang,Anjun Hu,Jiankun Wang,Ping Tan,Hong Zhang*

Main category: cs.RO

TL;DR: ROVER是一种利用历史轨迹作为先验约束的闭环验证方法，用于在重复环境中避免误检测。


<details>
  <summary>Details</summary>
Motivation: 在重复环境中，基于外观的特征容易失效，导致闭环检测错误，而现有方法忽略了机器人的时空运动轨迹信息。

Method: 通过位姿图优化估计轨迹，并设计评分方案评估候选闭环是否符合轨迹先验。

Result: 实验证明ROVER在重复环境中有效，且集成到SLAM系统中表现出鲁棒性和高效性。

Conclusion: ROVER通过利用轨迹先验，显著提升了闭环验证的准确性。

Abstract: Loop closure detection is important for simultaneous localization and mapping
(SLAM), which associates current observations with historical keyframes,
achieving drift correction and global relocalization. However, a falsely
detected loop can be fatal, and this is especially difficult in repetitive
environments where appearance-based features fail due to the high similarity.
Therefore, verification of a loop closure is a critical step in avoiding false
positive detections. Existing works in loop closure verification predominantly
focus on learning invariant appearance features, neglecting the prior knowledge
of the robot's spatial-temporal motion cue, i.e., trajectory. In this letter,
we propose ROVER, a loop closure verification method that leverages the
historical trajectory as a prior constraint to reject false loops in
challenging repetitive environments. For each loop candidate, it is first used
to estimate the robot trajectory with pose-graph optimization. This trajectory
is then submitted to a scoring scheme that assesses its compliance with the
trajectory without the loop, which we refer to as the trajectory prior, to
determine if the loop candidate should be accepted. Benchmark comparisons and
real-world experiments demonstrate the effectiveness of the proposed method.
Furthermore, we integrate ROVER into state-of-the-art SLAM systems to verify
its robustness and efficiency. Our source code and self-collected dataset are
available at https://github.com/jarvisyjw/ROVER.

</details>


### [10] [Unified Hierarchical MPC in Task Executing for Modular Manipulators across Diverse Morphologies](https://arxiv.org/abs/2508.13513)
*Maolin Lei,Edoardo Romiti,Arturo Laurenzi,Cheng Zhou,Wanli Xing,Liang Lu,Nikos G. Tsagarakis*

Main category: cs.RO

TL;DR: 提出了一种统一的分层模型预测控制（H-MPC）方法，适用于不同形态的模块化机械臂，无需大量参数调整即可适应不同配置完成任务。


<details>
  <summary>Details</summary>
Motivation: 为了解决模块化机械臂在不同形态下的控制问题，避免复杂的参数调整，提高控制精度和可靠性。

Method: 将控制过程分为高层MPC和低层MPC：高层预测未来状态并提供轨迹信息，低层基于高层信息更新预测模型以细化控制动作。

Result: 通过分层结构整合了运动学约束，确保平滑的关节空间轨迹，并在实际场景中验证了拾取任务的有效性。

Conclusion: H-MPC方法在保持线性控制模型简单性的同时，提高了运动学表示的准确性，增强了整体控制性能。

Abstract: This work proposes a unified Hierarchical Model Predictive Control (H-MPC)
for modular manipulators across various morphologies, as the controller can
adapt to different configurations to execute the given task without extensive
parameter tuning in the controller. The H-MPC divides the control process into
two levels: a high-level MPC and a low-level MPC. The high-level MPC predicts
future states and provides trajectory information, while the low-level MPC
refines control actions by updating the predictive model based on this
high-level information. This hierarchical structure allows for the integration
of kinematic constraints and ensures smooth joint-space trajectories, even near
singular configurations. Moreover, the low-level MPC incorporates secondary
linearization by leveraging predictive information from the high-level MPC,
effectively capturing the second-order Taylor expansion information of the
kinematic model while still maintaining a linearized model formulation. This
approach not only preserves the simplicity of a linear control model but also
enhances the accuracy of the kinematic representation, thereby improving
overall control precision and reliability. To validate the effectiveness of the
control policy, we conduct extensive evaluations across different manipulator
morphologies and demonstrate the execution of pick-and-place tasks in
real-world scenarios.

</details>


### [11] [A Three-Level Whole-Body Disturbance Rejection Control Framework for Dynamic Motions in Legged Robots](https://arxiv.org/abs/2508.13531)
*Bolin Li,Gewei Zuo,Zhixiang Wang,Xiaotian Ke,Lijun Zhu,Han Ding*

Main category: cs.RO

TL;DR: 提出了一种增强腿式机器人稳定性和鲁棒性的控制框架，通过全状态反馈估计器补偿不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决腿式机器人在模型不确定性、外部干扰和故障情况下的稳定性问题。

Method: 1. 提出MH-ESO估计不确定性；2. 设计三层次T-WB-DRC框架；3. 仿真和实验验证。

Result: 仿真和实验表明T-WB-DRC在负载运输、抗干扰和容错方面表现优异。

Conclusion: T-WB-DRC显著提升了腿式机器人在复杂环境中的鲁棒性和稳定性。

Abstract: This paper presents a control framework designed to enhance the stability and
robustness of legged robots in the presence of uncertainties, including model
uncertainties, external disturbances, and faults. The framework enables the
full-state feedback estimator to estimate and compensate for uncertainties in
whole-body dynamics of the legged robots. First, we propose a novel moving
horizon extended state observer (MH-ESO) to estimate uncertainties and mitigate
noise in legged systems, which can be integrated into the framework for
disturbance compensation. Second, we introduce a three-level whole-body
disturbance rejection control framework (T-WB-DRC). Unlike the previous
two-level approach, this three-level framework considers both the plan based on
whole-body dynamics without uncertainties and the plan based on dynamics with
uncertainties, significantly improving payload transportation, external
disturbance rejection, and fault tolerance. Third, simulations of both humanoid
and quadruped robots in the Gazebo simulator demonstrate the effectiveness and
versatility of T-WB-DRC. Finally, extensive experimental trials on a quadruped
robot validate the robustness and stability of the system when using T-WB-DRC
under various disturbance conditions.

</details>


### [12] [MimicFunc: Imitating Tool Manipulation from a Single Human Video via Functional Correspondence](https://arxiv.org/abs/2508.13534)
*Chao Tang,Anxing Xiao,Yuhong Deng,Tianrun Hu,Wenlong Dong,Hanbo Zhang,David Hsu,Hong Zhang*

Main category: cs.RO

TL;DR: MimicFunc框架通过功能帧实现工具操作技能的泛化，从单个人类视频中学习并应用于新工具。


<details>
  <summary>Details</summary>
Motivation: 人类能轻松模仿工具操作并泛化到不同工具，而机器人难以实现类似能力，需解决功能级对应问题。

Method: 提出MimicFunc框架，利用功能帧（基于关键点的局部坐标系）建立功能对应关系。

Result: 实验显示，MimicFunc能有效从单个人类视频泛化到新工具操作，并用于训练视觉运动策略。

Conclusion: MimicFunc解决了工具操作技能泛化的关键挑战，为机器人学习提供了高效方法。

Abstract: Imitating tool manipulation from human videos offers an intuitive approach to
teaching robots, while also providing a promising and scalable alternative to
labor-intensive teleoperation data collection for visuomotor policy learning.
While humans can mimic tool manipulation behavior by observing others perform a
task just once and effortlessly transfer the skill to diverse tools for
functionally equivalent tasks, current robots struggle to achieve this level of
generalization. A key challenge lies in establishing function-level
correspondences, considering the significant geometric variations among
functionally similar tools, referred to as intra-function variations. To
address this challenge, we propose MimicFunc, a framework that establishes
functional correspondences with function frame, a function-centric local
coordinate frame constructed with keypoint-based abstraction, for imitating
tool manipulation skills. Experiments demonstrate that MimicFunc effectively
enables the robot to generalize the skill from a single RGB-D human video to
manipulating novel tools for functionally equivalent tasks. Furthermore,
leveraging MimicFunc's one-shot generalization capability, the generated
rollouts can be used to train visuomotor policies without requiring
labor-intensive teleoperation data collection for novel objects. Our code and
video are available at https://sites.google.com/view/mimicfunc.

</details>


### [13] [Assessing Pedestrian Behavior Around Autonomous Cleaning Robots in Public Spaces: Findings from a Field Observation](https://arxiv.org/abs/2508.13699)
*Maren Raab,Linda Miller,Zhe Zeng,Pascal Jansen,Martin Baumann,Johannes Kraus*

Main category: cs.RO

TL;DR: 研究探讨了机器人类型和移动模式对分心和未分心行人行为的影响，发现分心与否无显著差异，但机器人类型和移动模式显著影响行人的横向调整行为。


<details>
  <summary>Details</summary>
Motivation: 随着自主机器人在公共场所的普及，需要研究如何优化机器人的沟通策略以减少潜在冲突，但目前对行人在机器人存在下的行为研究有限。

Method: 在实地环境中，观察行人经过两种自主清洁机器人时的行为，记录并分析其移动行为。

Result: 分心与否对行人行为无显著影响，但机器人类型（较大清扫机器人）和移动模式（偏移矩形模式）显著增加横向调整行为。

Conclusion: 研究为公共场所中行人行为提供了初步见解，有助于人机交互领域的进一步发展。

Abstract: As autonomous robots become more common in public spaces, spontaneous
encounters with laypersons are more frequent. For this, robots need to be
equipped with communication strategies that enhance momentary transparency and
reduce the probability of critical situations. Adapting these robotic
strategies requires consideration of robot movements, environmental conditions,
and user characteristics and states. While numerous studies have investigated
the impact of distraction on pedestrians' movement behavior, limited research
has examined this behavior in the presence of autonomous robots. This research
addresses the impact of robot type and robot movement pattern on distracted and
undistracted pedestrians' movement behavior. In a field setting, unaware
pedestrians were videotaped while moving past two working, autonomous cleaning
robots. Out of N=498 observed pedestrians, approximately 8% were distracted by
smartphones. Distracted and undistracted pedestrians did not exhibit
significant differences in their movement behaviors around the robots. Instead,
both the larger sweeping robot and the offset rectangular movement pattern
significantly increased the number of lateral adaptations compared to the
smaller cleaning robot and the circular movement pattern. The offset
rectangular movement pattern also led to significantly more close lateral
adaptations. Depending on the robot type, the movement patterns led to
differences in the distances of lateral adaptations. The study provides initial
insights into pedestrian movement behavior around an autonomous cleaning robot
in public spaces, contributing to the growing field of HRI research.

</details>


### [14] [Blast Hole Seeking and Dipping -- The Navigation and Perception Framework in a Mine Site Inspection Robot](https://arxiv.org/abs/2508.13785)
*Liyang Liu,Ehsan Mihankhah,Nathan Wallace,Javier Martinez,Andrew J. Hill*

Main category: cs.RO

TL;DR: 论文提出了一种自主矿山检测机器人DIPPeR，用于爆破孔的内部检查和导航，通过LiDAR数据处理和目标检测实现精确的传感器定位。


<details>
  <summary>Details</summary>
Motivation: 传统人工爆破孔检查效率低且成本高，难以准确获取孔洞的几何和地质信息，因此开发了DIPPeR机器人以实现自动化检测。

Method: 利用LiDAR采集点云数据，通过3D锥体投影到虚拟深度图像实现2D分割，结合鲁棒检测模块精确定位孔中心，并动态调整投影参数以适应不同环境。

Result: 系统在高保真仿真环境和现场测试中均表现出色，实现了精确的爆破孔导航和传感器定位。

Conclusion: DIPPeR机器人通过自动化检测和导航技术，显著提升了爆破孔检查的效率和准确性，为矿山作业节省了成本。

Abstract: In open-pit mining, holes are drilled into the surface of the excavation site
and detonated with explosives to facilitate digging. These blast holes need to
be inspected internally for investigation of downhole material types and
properties. Knowing these properties can lead to significant savings in
material handling costs in downstream processes. Manual hole inspection is slow
and expensive, with major limitations in revealing the geometric and geological
properties of the holes and their contents. This has been the motivation for
the development of our autonomous mine-site inspection robot - "DIPPeR". In
this paper, the automation aspect of the project is explained. We present a
robust blast hole seeking and detection framework that enables target-based
navigation and accurate down-hole sensor positioning. The pipeline first
processes point-cloud data collected by the on-board LiDAR sensors, extracting
the cone-shaped volume of drill-waste above the ground. By projecting the 3D
cone points into a virtual depth image, segmentation is achieved in the 2D
domain, yielding a circular hole at the image centre and a collared cone face.
We then identify the hole centre using a robust detection module while
suppressing non-maximum candidates, ensuring precise sensor placement for
down-hole inspection and avoiding collisions with the cavity wall. To enable
autonomous hole-seeking, the pipeline automatically adjusts its projection
parameters during robot navigation to account for variations in point sparsity
and hole opening size, ensuring a consistent hole appearance in 2D images. This
allows continuous tracking of the target hole as the robot approaches the goal
point. We demonstrate the effectiveness of our navigation and perception system
in both high-fidelity simulation environments and on-site field tests. A
demonstration video is available at
"https://www.youtube.com/watch?v=fRNbcBcaSqE".

</details>


### [15] [Trajectory Tracking and Stabilization of Quadrotors Using Deep Koopman Model Predictive Control](https://arxiv.org/abs/2508.13795)
*Haitham El-Hussieny*

Main category: cs.RO

TL;DR: 提出了一种结合深度Koopman算子和模型预测控制（DK-MPC）的数据驱动控制框架，用于四旋翼系统，展示了更高的跟踪精度和更低的计算时间。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼非线性动力学问题，通过线性化模型实现高效控制。

Method: 使用深度Koopman算子训练飞行数据，构建高维潜在表示，结合MPC优化控制动作。

Result: 在轨迹跟踪和点稳定实验中，DK-MPC表现出优于传统非线性MPC的跟踪精度和计算效率。

Conclusion: Koopman学习方法在复杂四旋翼动力学中具有潜力，未来将扩展至更敏捷飞行场景并提升抗干扰能力。

Abstract: This paper presents a data-driven control framework for quadrotor systems
that integrates a deep Koopman operator with model predictive control (DK-MPC).
The deep Koopman operator is trained on sampled flight data to construct a
high-dimensional latent representation in which the nonlinear quadrotor
dynamics are approximated by linear models. This linearization enables the
application of MPC to efficiently optimize control actions over a finite
prediction horizon, ensuring accurate trajectory tracking and stabilization.
The proposed DK-MPC approach is validated through a series of
trajectory-following and point-stabilization numerical experiments, where it
demonstrates superior tracking accuracy and significantly lower computation
time compared to conventional nonlinear MPC. These results highlight the
potential of Koopman-based learning methods to handle complex quadrotor
dynamics while meeting the real-time requirements of embedded flight control.
Future work will focus on extending the framework to more agile flight
scenarios and improving robustness against external disturbances.

</details>


### [16] [Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided Decision Transformer](https://arxiv.org/abs/2508.13877)
*Rathnam Vidushika Rasanji,Jin Wei-Kocsis,Jiansong Zhang,Dongming Gan,Ragu Athinarayanan,Paul Asunda*

Main category: cs.RO

TL;DR: 提出了一种名为SGDT的新框架，结合神经符号机制与因果变换器，用于多机器人协作任务。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人操作中潜力巨大，但其数据密集性和对MDP假设的依赖限制了其在复杂动态和长期依赖场景中的应用。决策变换器（DTs）作为离线替代方案，但在多机器人操作中应用不足。

Method: SGDT框架通过神经符号规划器生成高级任务导向计划，指导目标条件决策变换器（GCDT）进行低级决策。

Result: SGDT在零样本和少样本任务场景中表现优异，首次探索了基于DT的多机器人操作技术。

Conclusion: SGDT通过分层架构实现了结构化、可解释和可泛化的决策，为复杂多机器人协作任务提供了新解决方案。

Abstract: Reinforcement learning (RL) has demonstrated great potential in robotic
operations. However, its data-intensive nature and reliance on the Markov
Decision Process (MDP) assumption limit its practical deployment in real-world
scenarios involving complex dynamics and long-term temporal dependencies, such
as multi-robot manipulation. Decision Transformers (DTs) have emerged as a
promising offline alternative by leveraging causal transformers for sequence
modeling in RL tasks. However, their applications to multi-robot manipulations
still remain underexplored. To address this gap, we propose a novel framework,
Symbolically-Guided Decision Transformer (SGDT), which integrates a
neuro-symbolic mechanism with a causal transformer to enable deployable
multi-robot collaboration. In the proposed SGDT framework, a neuro-symbolic
planner generates a high-level task-oriented plan composed of symbolic
subgoals. Guided by these subgoals, a goal-conditioned decision transformer
(GCDT) performs low-level sequential decision-making for multi-robot
manipulation. This hierarchical architecture enables structured, interpretable,
and generalizable decision making in complex multi-robot collaboration tasks.
We evaluate the performance of SGDT across a range of task scenarios, including
zero-shot and few-shot scenarios. To our knowledge, this is the first work to
explore DT-based technology for multi-robot manipulation.

</details>


### [17] [Driving Style Recognition Like an Expert Using Semantic Privileged Information from Large Language Models](https://arxiv.org/abs/2508.13881)
*Zhaokun Chen,Chaopeng Zhang,Xiaohan Li,Wenshuo Wang,Gentiane Venture,Junqiang Xi*

Main category: cs.RO

TL;DR: 提出了一种利用语义特权信息（SPI）提升驾驶风格识别准确性的新框架，结合LLM生成的自然语言描述，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖低级传感器特征，与人类专家的语义推理能力不匹配，导致分类与专家判断不一致。

Method: 通过DriBehavGPT生成驾驶行为描述，编码为机器学习兼容表示，并作为特权信息整合到SVM+中训练。

Result: 在真实驾驶场景中，F1分数提升7.6%（跟车）和7.9%（变道），且推理阶段仅需传感器数据。

Conclusion: SPI在训练中引入语义行为表示，显著提升识别准确性和可解释性，推动人本驾驶系统发展。

Abstract: Existing driving style recognition systems largely depend on low-level
sensor-derived features for training, neglecting the rich semantic reasoning
capability inherent to human experts. This discrepancy results in a fundamental
misalignment between algorithmic classifications and expert judgments. To
bridge this gap, we propose a novel framework that integrates Semantic
Privileged Information (SPI) derived from large language models (LLMs) to align
recognition outcomes with human-interpretable reasoning. First, we introduce
DriBehavGPT, an interactive LLM-based module that generates natural-language
descriptions of driving behaviors. These descriptions are then encoded into
machine learning-compatible representations via text embedding and
dimensionality reduction. Finally, we incorporate them as privileged
information into Support Vector Machine Plus (SVM+) for training, enabling the
model to approximate human-like interpretation patterns. Experiments across
diverse real-world driving scenarios demonstrate that our SPI-enhanced
framework outperforms conventional methods, achieving F1-score improvements of
7.6% (car-following) and 7.9% (lane-changing). Importantly, SPI is exclusively
used during training, while inference relies solely on sensor data, ensuring
computational efficiency without sacrificing performance. These results
highlight the pivotal role of semantic behavioral representations in improving
recognition accuracy while advancing interpretable, human-centric driving
systems.

</details>


### [18] [Multimodal Data Storage and Retrieval for Embodied AI: A Survey](https://arxiv.org/abs/2508.13901)
*Yihao Lu,Hao Tang*

Main category: cs.RO

TL;DR: 该论文系统评估了五种存储架构和五种检索范式在Embodied AI数据管理中的适用性，揭示了语义一致性与实时响应之间的冲突，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统数据管理系统难以处理Embodied AI生成的多模态数据流，需要探索更高效的存储和检索方法。

Method: 系统评估五种存储架构和五种检索范式，分析其核心需求满足情况。

Result: 发现语义一致性与实时响应的冲突，并识别了从物理基础到跨模态集成等多个关键瓶颈。

Conclusion: 提出未来研究议程，包括物理感知数据模型和自适应优化，为下一代自主系统提供数据管理框架。

Abstract: Embodied AI (EAI) agents continuously interact with the physical world,
generating vast, heterogeneous multimodal data streams that traditional
management systems are ill-equipped to handle. In this survey, we first
systematically evaluate five storage architectures (Graph Databases,
Multi-Model Databases, Data Lakes, Vector Databases, and Time-Series
Databases), focusing on their suitability for addressing EAI's core
requirements, including physical grounding, low-latency access, and dynamic
scalability. We then analyze five retrieval paradigms (Fusion Strategy-Based
Retrieval, Representation Alignment-Based Retrieval, Graph-Structure-Based
Retrieval, Generation Model-Based Retrieval, and Efficient Retrieval-Based
Optimization), revealing a fundamental tension between achieving long-term
semantic coherence and maintaining real-time responsiveness. Based on this
comprehensive analysis, we identify key bottlenecks, spanning from the
foundational Physical Grounding Gap to systemic challenges in cross-modal
integration, dynamic adaptation, and open-world generalization. Finally, we
outline a forward-looking research agenda encompassing physics-aware data
models, adaptive storage-retrieval co-optimization, and standardized
benchmarking, to guide future research toward principled data management
solutions for EAI. Our survey is based on a comprehensive review of more than
180 related studies, providing a rigorous roadmap for designing the robust,
high-performance data management frameworks essential for the next generation
of autonomous embodied systems.

</details>


### [19] [Augmenting cobots for sheet-metal SMEs with 3D object recognition and localisation](https://arxiv.org/abs/2508.13964)
*Martijn Cramer,Yanming Wu,David De Schepper,Eric Demeester*

Main category: cs.RO

TL;DR: COOCK+ ROBUST项目旨在通过整合3D物体识别和定位技术，将协作机器人转变为移动且可重构的生产助手，以应对小批量多样化生产的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于小批量多样化生产的需求，传统自动化解决方案难以满足，中小企业依赖重复性人工劳动，导致成本上升和技术工人潜力未充分发挥。

Method: 项目通过整合3D物体识别和定位技术，提升协作机器人系统的能力，并在工业环境中探索其机会与挑战。

Result: 文章概述了实现过程中的关键步骤，并通过ACRO研究单位与工业伙伴合作的实际案例展示了具体实施。

Conclusion: 增强协作机器人系统在工业环境中的应用潜力，但仍需解决相关挑战。

Abstract: Due to high-mix-low-volume production, sheet-metal workshops today are
challenged by small series and varying orders. As standard automation solutions
tend to fall short, SMEs resort to repetitive manual labour impacting
production costs and leading to tech-skilled workforces not being used to their
full potential. The COOCK+ ROBUST project aims to transform cobots into mobile
and reconfigurable production assistants by integrating existing technologies,
including 3D object recognition and localisation. This article explores both
the opportunities and challenges of enhancing cobotic systems with these
technologies in an industrial setting, outlining the key steps involved in the
process. Additionally, insights from a past project, carried out by the ACRO
research unit in collaboration with an industrial partner, serves as a concrete
implementation example throughout.

</details>


### [20] [Toward an Interaction-Centered Approach to Robot Trustworthiness](https://arxiv.org/abs/2508.13976)
*Carlo Mazzola,Hassan Ali,Kristína Malinovská,Igor Farkaš*

Main category: cs.RO

TL;DR: 论文提出了一种基于交互的框架，通过人类与机器人之间的相互理解来建立信任，强调人类意识和透明度的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人越来越多地融入人类环境，确保其可信度对于安全和有效的人机交互至关重要。

Method: 提出了一个基于交互的框架，包含人类意识和透明度两大支柱，以及四个关键组件。

Result: 通过整合这些组件，机器人可以更好地符合人类期望，同时让人类对其行为有理解和控制。

Conclusion: 该框架有助于缩小人类感知的信任与机器人实际能力之间的差距。

Abstract: As robots get more integrated into human environments, fostering
trustworthiness in embodied robotic agents becomes paramount for an effective
and safe human-robot interaction (HRI). To achieve that, HRI applications must
promote human trust that aligns with robot skills and avoid misplaced trust or
overtrust, which can pose safety risks and ethical concerns. To achieve that,
HRI applications must promote human trust that aligns with robot skills and
avoid misplaced trust or overtrust, which can pose safety risks and ethical
concerns. In this position paper, we outline an interaction-based framework for
building trust through mutual understanding between humans and robots. We
emphasize two main pillars: human awareness and transparency, referring to the
robot ability to interpret human actions accurately and to clearly communicate
its intentions and goals, respectively. By integrating these two pillars,
robots can behave in a manner that aligns with human expectations and needs
while providing their human partners with both comprehension and control over
their actions. We also introduce four components that we think are important
for bridging the gap between a human-perceived sense of trust and a robot true
capabilities.

</details>


### [21] [The Social Context of Human-Robot Interactions](https://arxiv.org/abs/2508.13982)
*Sydney Thompson,Kate Candon,Marynel Vázquez*

Main category: cs.RO

TL;DR: 论文总结了HRI领域中对‘社交情境’的不同定义，提出了一个概念模型，并讨论了其在机器人行为设计和评估中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于‘社交情境’在HRI研究中定义多样，导致沟通困难和研究成果难以比较，因此需要统一的概念框架。

Method: 通过文献综述总结现有定义，提出一个描述社交情境的概念模型，并将其应用于现有研究。

Result: 提出了一个社交情境的概念模型，帮助研究者规划交互、开发机器人行为模型及分析交互结果。

Conclusion: 讨论了未来在理解和建模社交情境方面的开放性问题，强调了统一框架的重要性。

Abstract: The Human-Robot Interaction (HRI) community often highlights the social
context of an interaction as a key consideration when designing, implementing,
and evaluating robot behavior. Unfortunately, researchers use the term "social
context" in varied ways. This can lead to miscommunication, making it
challenging to draw connections between related work on understanding and
modeling the social contexts of human-robot interactions. To address this gap,
we survey the HRI literature for existing definitions and uses of the term
"social context". Then, we propose a conceptual model for describing the social
context of a human-robot interaction. We apply this model to existing work, and
we discuss a range of attributes of social contexts that can help researchers
plan for interactions, develop behavior models for robots, and gain insights
after interactions have taken place. We conclude with a discussion of open
research questions in relation to understanding and modeling the social
contexts of human-robot interactions.

</details>


### [22] [Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation](https://arxiv.org/abs/2508.13998)
*Yifu Yuan,Haiqin Cui,Yaoting Huang,Yibin Chen,Fei Ni,Zibin Dong,Pengyi Li,Yan Zheng,Jianye Hao*

Main category: cs.RO

TL;DR: 论文提出了一种基于“指向”的统一中间表示方法，通过Embodied-R1模型和RFT训练范式，显著提升了具身AI的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决具身AI中的‘感知-行动差距’，即数据稀缺和具身异构性问题。

Method: 提出‘指向’作为中间表示，构建Embodied-Points-200K数据集，采用两阶段RFT训练Embodied-R1模型。

Result: 在11个基准测试中达到SOTA，零样本泛化能力显著提升（SIMPLEREnv 56.2%，XArm 87.5%）。

Conclusion: 指向表示结合RFT训练范式，为机器人感知-行动差距提供了有效且可泛化的解决方案。

Abstract: Generalization in embodied AI is hindered by the "seeing-to-doing gap," which
stems from data scarcity and embodiment heterogeneity. To address this, we
pioneer "pointing" as a unified, embodiment-agnostic intermediate
representation, defining four core embodied pointing abilities that bridge
high-level vision-language comprehension with low-level action primitives. We
introduce Embodied-R1, a 3B Vision-Language Model (VLM) specifically designed
for embodied reasoning and pointing. We use a wide range of embodied and
general visual reasoning datasets as sources to construct a large-scale
dataset, Embodied-Points-200K, which supports key embodied pointing
capabilities. We then train Embodied-R1 using a two-stage Reinforced
Fine-tuning (RFT) curriculum with a specialized multi-task reward design.
Embodied-R1 achieves state-of-the-art performance on 11 embodied spatial and
pointing benchmarks. Critically, it demonstrates robust zero-shot
generalization by achieving a 56.2% success rate in the SIMPLEREnv and 87.5%
across 8 real-world XArm tasks without any task-specific fine-tuning,
representing a 62% improvement over strong baselines. Furthermore, the model
exhibits high robustness against diverse visual disturbances. Our work shows
that a pointing-centric representation, combined with an RFT training paradigm,
offers an effective and generalizable pathway to closing the perception-action
gap in robotics.

</details>


### [23] [Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation](https://arxiv.org/abs/2508.14042)
*Zhuoling Li,Xiaoyang Wu,Zhenhua Xu,Hengshuang Zhao*

Main category: cs.RO

TL;DR: 论文提出了一种基于熵的理论框架和系统GEM，用于在少量演示下实现动态物体操作的强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提高制造业效率，减少对不同场景的专门工程需求，同时解决模仿学习中演示收集成本高的问题。

Method: 开发了基于熵的理论框架，并提出了GEM系统，通过优化模仿学习实现泛化。

Result: GEM在模拟和实际任务中表现出色，能适应多种环境、机器人、运动动力学和物体几何，实际部署成功率达97%。

Conclusion: GEM证明了在少量演示下实现强泛化能力的可行性，为动态物体操作提供了高效解决方案。

Abstract: Realizing generalizable dynamic object manipulation is important for
enhancing manufacturing efficiency, as it eliminates specialized engineering
for various scenarios. To this end, imitation learning emerges as a promising
paradigm, leveraging expert demonstrations to teach a policy manipulation
skills. Although the generalization of an imitation learning policy can be
improved by increasing demonstrations, demonstration collection is
labor-intensive. To address this problem, this paper investigates whether
strong generalization in dynamic object manipulation is achievable with only a
few demonstrations. Specifically, we develop an entropy-based theoretical
framework to quantify the optimization of imitation learning. Based on this
framework, we propose a system named Generalizable Entropy-based Manipulation
(GEM). Extensive experiments in simulated and real tasks demonstrate that GEM
can generalize across diverse environment backgrounds, robot embodiments,
motion dynamics, and object geometries. Notably, GEM has been deployed in a
real canteen for tableware collection. Without any in-scene demonstration, it
achieves a success rate of over 97% across more than 10,000 operations.

</details>
