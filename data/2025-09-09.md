<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 48]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory](https://arxiv.org/abs/2509.05314)
*Ying Li,Xiaobao Wei,Xiaowei Chi,Yuming Li,Zhongyu Zhao,Hao Wang,Ningning Ma,Ming Lu,Shanghang Zhang*

Main category: cs.RO

TL;DR: 本文提出ManipDreamer3D框架，旨在从输入图像和文本指令生成合理的3D感知机器人操作视频，解决数据稀缺及现有方法依赖2D轨迹导致3D空间模糊的问题。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺是机器人操作领域的主要挑战，现有扩散模型生成机器人操作视频的方法依赖2D轨迹，存在3D空间模糊问题。

Method: ManipDreamer3D首先从输入图像重建3D占用表示，然后计算优化的3D末端执行器轨迹（最小化路径长度并避免碰撞），接着采用潜在编辑技术从初始图像潜变量和优化的3D轨迹创建视频序列，以训练的轨迹到视频扩散模型生成机器人抓取放置视频。

Result: 该方法生成具有自主规划合理3D轨迹的机器人视频，显著降低人工干预需求，实验结果表明其视觉质量优于现有方法。

Conclusion: ManipDreamer3D通过结合3D轨迹规划、3D占用图重建和轨迹到视频扩散模型，有效解决了机器人操作视频生成中的3D空间模糊问题，生成质量更优且减少人工干预。

Abstract: Data scarcity continues to be a major challenge in the field of robotic
manipulation. Although diffusion models provide a promising solution for
generating robotic manipulation videos, existing methods largely depend on 2D
trajectories, which inherently face issues with 3D spatial ambiguity. In this
work, we present a novel framework named ManipDreamer3D for generating
plausible 3D-aware robotic manipulation videos from the input image and the
text instruction. Our method combines 3D trajectory planning with a
reconstructed 3D occupancy map created from a third-person perspective, along
with a novel trajectory-to-video diffusion model. Specifically, ManipDreamer3D
first reconstructs the 3D occupancy representation from the input image and
then computes an optimized 3D end-effector trajectory, minimizing path length
while avoiding collisions. Next, we employ a latent editing technique to create
video sequences from the initial image latent and the optimized 3D trajectory.
This process conditions our specially trained trajectory-to-video diffusion
model to produce robotic pick-and-place videos. Our method generates robotic
videos with autonomously planned plausible 3D trajectories, significantly
reducing human intervention requirements. Experimental results demonstrate
superior visual quality compared to existing methods.

</details>


### [2] [Evaluation of Large Language Models for Anomaly Detection in Autonomous Vehicles](https://arxiv.org/abs/2509.05315)
*Petros Loukas,David Bassir,Savvas Chatzichristofis,Angelos Amanatiadis*

Main category: cs.RO

TL;DR: 本文评估了大语言模型（LLMs）在自动驾驶真实边缘案例中的应用潜力，提出了结合开放词汇目标检测器、提示工程和LLM上下文推理的架构，并提供了定性比较结果与讨论。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在自动驾驶中的评估局限于合成数据集或无真实标签的人工驾驶数据集，缺乏对当前感知和规划算法在评估场景下表现的了解，尤其在真实边缘案例（自动驾驶已被证明会失败的场景）中的评估不足。

Method: 提出一种架构，包含开放词汇目标检测器，结合提示工程和大语言模型的上下文推理，并针对真实边缘案例评估了多个最先进模型。

Result: 对多个最先进模型在真实边缘案例中进行了评估，提供了定性比较结果。

Conclusion: 讨论了LLMs作为自动驾驶异常检测器的潜在应用发现。

Abstract: The rapid evolution of large language models (LLMs) has pushed their
boundaries to many applications in various domains. Recently, the research
community has started to evaluate their potential adoption in autonomous
vehicles and especially as complementary modules in the perception and planning
software stacks. However, their evaluation is limited in synthetic datasets or
manually driving datasets without the ground truth knowledge and more
precisely, how the current perception and planning algorithms would perform in
the cases under evaluation. For this reason, this work evaluates LLMs on
real-world edge cases where current autonomous vehicles have been proven to
fail. The proposed architecture consists of an open vocabulary object detector
coupled with prompt engineering and large language model contextual reasoning.
We evaluate several state-of-the-art models against real edge cases and provide
qualitative comparison results along with a discussion on the findings for the
potential application of LLMs as anomaly detectors in autonomous vehicles.

</details>


### [3] [Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks](https://arxiv.org/abs/2509.05338)
*Atsushi Masumori,Norihiro Maruyama,Itsuki Doi,johnsmith,Hiroki Sato,Takashi Ikegami*

Main category: cs.RO

TL;DR: Plantbot是一种混合生命体，通过大型语言模型（LLM）模块网络将活植物与移动机器人连接，各模块异步运行并通过自然语言通信，使生物与人工领域无缝交互，展现出作为具身自适应智能体的能力，为新型人工生命模型提供可能。


<details>
  <summary>Details</summary>
Motivation: 探索生物与人工系统间的新型交互方式，构建能自主响应环境条件的混合智能体，提出一种新的人工生命模型。

Method: 采用由负责传感、视觉、对话或行动的LLM模块组成的网络架构，各模块异步运行并通过自然语言通信，将多模态数据（土壤湿度、温度、视觉环境）转化为语言信息来协调系统行为，把植物状态转化为机器人动作，在感知-运动回路中建立主体性所需的规范性。

Result: Plantbot通过LLM介导的通信结合生物和机器人元素，表现为具身、自适应的智能体，能够自主响应环境条件。

Conclusion: 该方法表明，通过去中心化的LLM模块协调，能够实现生物与人工系统之间的新型交互，为新型人工生命模型提供了可能性。

Abstract: We introduce Plantbot, a hybrid lifeform that connects a living plant with a
mobile robot through a network of large language model (LLM) modules. Each
module - responsible for sensing, vision, dialogue, or action - operates
asynchronously and communicates via natural language, enabling seamless
interaction across biological and artificial domains. This architecture
leverages the capacity of LLMs to serve as hybrid interfaces, where natural
language functions as a universal protocol, translating multimodal data (soil
moisture, temperature, visual context) into linguistic messages that coordinate
system behaviors. The integrated network transforms plant states into robotic
actions, installing normativity essential for agency within the sensor-motor
loop. By combining biological and robotic elements through LLM-mediated
communication, Plantbot behaves as an embodied, adaptive agent capable of
responding autonomously to environmental conditions. This approach suggests
possibilities for a new model of artificial life, where decentralized, LLM
modules coordination enable novel interactions between biological and
artificial systems.

</details>


### [4] [INF-3DP: Implicit Neural Fields for Collision-Free Multi-Axis 3D Printing](https://arxiv.org/abs/2509.05345)
*Jiasheng Qu,Zhuo Huang,Dezhao Guo,Hailin Sun,Aoran Lyu,Chengkai Dai,Yeung Yam,Guoxin Fang*

Main category: cs.RO

TL;DR: 本文介绍了一个基于隐式神经场（INFs）的通用、可扩展的多轴3D打印计算框架，该框架统一了刀具路径生成和全局无碰撞运动规划的所有阶段。


<details>
  <summary>Details</summary>
Motivation: 现有基于显式表示的3D打印方法可能存在速度慢、路径到表面误差大等问题，需要一种能统一刀具路径生成和运动规划各阶段，并提升效率和精度的框架。

Method: 将输入模型表示为符号距离场，把制造目标直接编码到隐式引导场的优化中，通过隐式场插值生成外壳和填充路径，然后在连续四元数场上联合优化打印顺序和多轴运动，利用时变SDF构建演化的打印对象以支持可微的全局碰撞处理。

Result: 与基于显式表示的方法相比，INF-3DP实现了高达两个数量级的速度提升，并显著降低了路径点到表面的误差，在多种复杂模型上得到验证且通过机器人辅助多轴系统的物理制造实验证明了其效率。

Conclusion: 基于隐式神经场的INF-3DP框架有效统一了多轴3D打印的关键阶段，大幅提升了效率和精度，适用于复杂模型的制造。

Abstract: We introduce a general, scalable computational framework for multi-axis 3D
printing based on implicit neural fields (INFs) that unifies all stages of
toolpath generation and global collision-free motion planning. In our pipeline,
input models are represented as signed distance fields, with fabrication
objectives such as support-free printing, surface finish quality, and extrusion
control being directly encoded in the optimization of an implicit guidance
field. This unified approach enables toolpath optimization across both surface
and interior domains, allowing shell and infill paths to be generated via
implicit field interpolation. The printing sequence and multi-axis motion are
then jointly optimized over a continuous quaternion field. Our continuous
formulation constructs the evolving printing object as a time-varying SDF,
supporting differentiable global collision handling throughout INF-based motion
planning. Compared to explicit-representation-based methods, INF-3DP achieves
up to two orders of magnitude speedup and significantly reduces
waypoint-to-surface error. We validate our framework on diverse, complex models
and demonstrate its efficiency with physical fabrication experiments using a
robot-assisted multi-axis system.

</details>


### [5] [Human-LLM Synergy in Context-Aware Adaptive Architecture for Scalable Drone Swarm Operation](https://arxiv.org/abs/2509.05355)
*Ahmed R. Sadik,Muhammad Ashfaq,Niko Mäkitalo,Tommi Mikkonen*

Main category: cs.RO

TL;DR: 本文提出一种基于大型语言模型的自适应无人机集群架构，能根据任务复杂度、集群规模和通信稳定性等实时参数动态选择集中式、分层或合弄式最优架构，在可扩展性、能效和连通性方面优于传统静态模型，为现实世界灾害响应提供可扩展、自适应和弹性的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统固定架构难以应对动态不可预测环境，导致能源消耗和连通性效率低下，而灾害响应任务中无人机集群部署需要灵活、可扩展且稳健的协调系统。

Method: 利用大型语言模型，根据任务复杂度、集群规模、通信稳定性等实时任务参数动态选择集中式、分层或合弄式最优架构。

Result: 广泛仿真表明，该自适应架构在可扩展性、能源效率和连通性方面优于传统静态模型。

Conclusion: 该方法有潜力为现实世界灾害响应场景提供可扩展、自适应和弹性的解决方案。

Abstract: The deployment of autonomous drone swarms in disaster response missions
necessitates the development of flexible, scalable, and robust coordination
systems. Traditional fixed architectures struggle to cope with dynamic and
unpredictable environments, leading to inefficiencies in energy consumption and
connectivity. This paper addresses this gap by proposing an adaptive
architecture for drone swarms, leveraging a Large Language Model to dynamically
select the optimal architecture as centralized, hierarchical, or holonic based
on real time mission parameters such as task complexity, swarm size, and
communication stability. Our system addresses the challenges of scalability,
adaptability, and robustness,ensuring efficient energy consumption and
maintaining connectivity under varying conditions. Extensive simulations
demonstrate that our adaptive architecture outperforms traditional static
models in terms of scalability, energy efficiency, and connectivity. These
results highlight the potential of our approach to provide a scalable,
adaptable, and resilient solution for real world disaster response scenarios.

</details>


### [6] [Spiking Neural Networks for Continuous Control via End-to-End Model-Based Learning](https://arxiv.org/abs/2509.05356)
*Justus Huebotter,Pablo Lanillos,Marcel van Gerven,Serge Thill*

Main category: cs.RO

TL;DR: 本文展示全脉冲架构可端到端训练以控制多自由度机械臂在连续环境中运动，结合LIF动力学与代理梯度优化前向模型和策略网络，在2D平面抓取及6-DOF机械臂任务上实现稳定训练和精确扭矩控制，消融实验揭示初始化、可学习时间常数和正则化对训练动态的影响，指出循环脉冲网络对超参数敏感，需合理设计。


<details>
  <summary>Details</summary>
Motivation: 尽管脉冲神经网络（SNNs）在分类任务上取得进展，但其在连续运动控制中的应用仍有限。

Method: 提出预测控制框架，结合Leaky Integrate-and-Fire（LIF）动力学与代理梯度，联合优化用于动态预测的前向模型和用于目标导向动作的策略网络。

Result: 在平面2D抓取任务和模拟6-DOF Franka Emika Panda机械臂上评估，结果显示SNNs可实现稳定训练和精确扭矩控制，证明其在高维运动任务中的可行性；消融实验突出初始化、可学习时间常数和正则化在塑造训练动态中的作用。

Conclusion: 虽然能实现稳定有效的控制，但循环脉冲网络对超参数设置高度敏感，强调了原则性设计选择的重要性。

Abstract: Despite recent progress in training spiking neural networks (SNNs) for
classification, their application to continuous motor control remains limited.
Here, we demonstrate that fully spiking architectures can be trained end-to-end
to control robotic arms with multiple degrees of freedom in continuous
environments. Our predictive-control framework combines Leaky
Integrate-and-Fire dynamics with surrogate gradients, jointly optimizing a
forward model for dynamics prediction and a policy network for goal-directed
action. We evaluate this approach on both a planar 2D reaching task and a
simulated 6-DOF Franka Emika Panda robot. Results show that SNNs can achieve
stable training and accurate torque control, establishing their viability for
high-dimensional motor tasks. An extensive ablation study highlights the role
of initialization, learnable time constants, and regularization in shaping
training dynamics. We conclude that while stable and effective control can be
achieved, recurrent spiking networks remain highly sensitive to hyperparameter
settings, underscoring the importance of principled design choices.

</details>


### [7] [Long-Horizon Visual Imitation Learning via Plan and Code Reflection](https://arxiv.org/abs/2509.05368)
*Quan Chen,Chenrui Shi,Qi Chen,Yuwei Wu,Zhi Gao,Xintong Zhang,Rui Gao,Kun Wu,Yunde Jia*

Main category: cs.RO

TL;DR: 本文提出一种包含两个专用反射模块的智能体框架，以增强长程视觉模仿学习中的计划和代码生成，并引入LongVILBench基准进行评估，实验表明该框架性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 长程演示中复杂动作序列的学习对视觉模仿学习构成重大挑战，特别是在理解动作的时间关系和物体间的空间关系方面。

Method: 提出一种新的智能体框架，包含计划生成模块、计划反射模块、代码生成模块和代码反射模块。计划生成模块生成初始动作序列，计划反射模块验证其时间连贯性和与演示视频的空间对齐；代码生成模块将计划转换为可执行代码，代码反射模块验证并优化代码以确保正确性和与计划的一致性。

Result: 引入了LongVILBench基准，包含300个人类演示，动作序列最长达18步，强调多种任务类型的时间和空间复杂性。实验结果表明现有方法在该基准上表现不佳，而新框架为长程视觉模仿学习建立了强大的基线。

Conclusion: 所提出的包含两个反射模块的智能体框架能够检测和纠正计划生成与代码生成中的错误，提高了在具有复杂时间和空间依赖关系任务中的性能，为长程视觉模仿学习提供了有效解决方案。

Abstract: Learning from long-horizon demonstrations with complex action sequences
presents significant challenges for visual imitation learning, particularly in
understanding temporal relationships of actions and spatial relationships
between objects. In this paper, we propose a new agent framework that
incorporates two dedicated reflection modules to enhance both plan and code
generation. The plan generation module produces an initial action sequence,
which is then verified by the plan reflection module to ensure temporal
coherence and spatial alignment with the demonstration video. The code
generation module translates the plan into executable code, while the code
reflection module verifies and refines the generated code to ensure correctness
and consistency with the generated plan. These two reflection modules jointly
enable the agent to detect and correct errors in both the plan generation and
code generation, improving performance in tasks with intricate temporal and
spatial dependencies. To support systematic evaluation, we introduce
LongVILBench, a benchmark comprising 300 human demonstrations with action
sequences of up to 18 steps. LongVILBench emphasizes temporal and spatial
complexity across multiple task types. Experimental results demonstrate that
existing methods perform poorly on this benchmark, whereas our new framework
establishes a strong baseline for long-horizon visual imitation learning.

</details>


### [8] [Evaluating Magic Leap 2 Tool Tracking for AR Sensor Guidance in Industrial Inspections](https://arxiv.org/abs/2509.05391)
*Christian Masuhr,Julian Koch,Thorsten Schüppstuhl*

Main category: cs.RO

TL;DR: 本文通过系统评估Magic Leap 2（ML2）控制器的跟踪性能，填补了现代头戴式显示器（HMD）工具跟踪公共基准的空白，提供了定量基线和可转移的评估方法，为检查用例及类似工业AR引导任务的适用性评估奠定基础。


<details>
  <summary>Details</summary>
Motivation: 商业增强现实（AR）硬件的严格评估至关重要，但现代头戴式显示器（HMD）工具跟踪的公共基准有限。

Method: 使用符合EN ISO 9283标准的机械臂实现可重复运动，并以光学跟踪系统作为地面实况，评估协议在各种条件下（包括氢气泄漏检查用例的真实路径）评估静态和动态性能。

Result: 提供了ML2控制器准确性和重复性的定量基线，并提出了一种稳健、可转移的评估方法。

Conclusion: 研究结果为评估控制器在检查用例和类似工业基于传感器的AR引导任务中的适用性提供了基础。

Abstract: Rigorous evaluation of commercial Augmented Reality (AR) hardware is crucial,
yet public benchmarks for tool tracking on modern Head-Mounted Displays (HMDs)
are limited. This paper addresses this gap by systematically assessing the
Magic Leap 2 (ML2) controllers tracking performance. Using a robotic arm for
repeatable motion (EN ISO 9283) and an optical tracking system as ground truth,
our protocol evaluates static and dynamic performance under various conditions,
including realistic paths from a hydrogen leak inspection use case. The results
provide a quantitative baseline of the ML2 controller's accuracy and
repeatability and present a robust, transferable evaluation methodology. The
findings provide a basis to assess the controllers suitability for the
inspection use case and similar industrial sensor-based AR guidance tasks.

</details>


### [9] [RoboBallet: Planning for Multi-Robot Reaching with Graph Neural Networks and Reinforcement Learning](https://arxiv.org/abs/2509.05397)
*Matthew Lai,Keegan Go,Zhibin Li,Torsten Kroger,Stefan Schaal,Kelsey Allen,Jonathan Scholz*

Main category: cs.RO

TL;DR: 提出一种基于强化学习（RL）和图神经网络（GNN）的框架，用于多机器人在复杂环境中实现自动化任务分配、调度和运动规划，解决传统方法计算难题并具备零样本泛化能力，可应用于工作单元布局优化等场景。


<details>
  <summary>Details</summary>
Motivation: 现代机器人制造中，多机器人在共享、多障碍物工作空间需无碰撞协调完成任务，传统方法在实际规模下计算不可行，工业多臂系统依赖人工设计轨迹，过程劳动密集。

Method: 构建基于图神经网络（GNN）的策略，通过强化学习在程序生成的多样化环境（含不同障碍物布局、机器人配置和任务分布）中训练；采用场景图表示和图策略神经网络生成多机器人轨迹，联合解决任务分配、调度和运动规划子问题。

Result: 在模拟中训练的策略能零样本泛化到未见过的机器人位置、障碍物几何形状和任务姿态设置；解决方案的高速能力可用于工作单元布局优化，缩短求解时间，并为容错规划、基于在线感知的重规划等新能力打开大门。

Conclusion: 该强化学习框架实现了多机器人自动化任务与运动规划，具备速度、可扩展性和泛化能力，有效解决了传统方法的局限性，适用于动态任务场景。

Abstract: Modern robotic manufacturing requires collision-free coordination of multiple
robots to complete numerous tasks in shared, obstacle-rich workspaces. Although
individual tasks may be simple in isolation, automated joint task allocation,
scheduling, and motion planning under spatio-temporal constraints remain
computationally intractable for classical methods at real-world scales.
Existing multi-arm systems deployed in the industry rely on human intuition and
experience to design feasible trajectories manually in a labor-intensive
process. To address this challenge, we propose a reinforcement learning (RL)
framework to achieve automated task and motion planning, tested in an
obstacle-rich environment with eight robots performing 40 reaching tasks in a
shared workspace, where any robot can perform any task in any order. Our
approach builds on a graph neural network (GNN) policy trained via RL on
procedurally-generated environments with diverse obstacle layouts, robot
configurations, and task distributions. It employs a graph representation of
scenes and a graph policy neural network trained through reinforcement learning
to generate trajectories of multiple robots, jointly solving the sub-problems
of task allocation, scheduling, and motion planning. Trained on large randomly
generated task sets in simulation, our policy generalizes zero-shot to unseen
settings with varying robot placements, obstacle geometries, and task poses. We
further demonstrate that the high-speed capability of our solution enables its
use in workcell layout optimization, improving solution times. The speed and
scalability of our planner also open the door to new capabilities such as
fault-tolerant planning and online perception-based re-planning, where rapid
adaptation to dynamic task sets is required.

</details>


### [10] [HapMorph: A Pneumatic Framework for Multi-Dimensional Haptic Property Rendering](https://arxiv.org/abs/2509.05433)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: 本文介绍了HapMorph气动框架，通过拮抗式织物气动执行器（AFPAs）实现物体大小和刚度的连续同时调制，其原型可实现50-104mm尺寸变化、高达4.7N/mm刚度调制及21g可穿戴部件质量，人类感知研究显示用户能以89.4%准确率和6.7s平均响应时间区分9种离散状态，为下一代多维度触觉界面提供途径。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴触觉界面通常只能渲染几何特征或机械属性中的一种，难以同时调制多种物理属性，这是人机交互中的基本挑战。

Method: 提出HapMorph气动框架，利用拮抗式织物气动执行器（AFPAs），通过双腔压力调节实现大小和刚度属性的解耦控制，并构建了用于手部交互的原型。

Result: HapMorph原型实现50-104mm尺寸变化、高达4.7N/mm刚度调制，可穿戴部件质量仅21g；10名参与者的人类感知研究显示，用户能区分3个尺寸类别和3个刚度级别共9种离散状态，准确率89.4%，平均响应时间6.7s。

Conclusion: 拮抗气动原理为下一代触觉界面提供了途径，能够在实用的可穿戴约束下实现多维度渲染属性。

Abstract: Haptic interfaces that can simultaneously modulate multiple physical
properties remain a fundamental challenge in human-robot interaction. Existing
systems typically allow the rendering of either geometric features or
mechanical properties, but rarely both, within wearable form factors. Here, we
introduce HapMorph, a pneumatic framework that enables continuous, simultaneous
modulation of object size and stiffness through antagonistic fabric-based
pneumatic actuators (AFPAs). We implemented a HapMorph protoytpe designed for
hands interaction achieving size variation from 50 to 104 mm, stiffness
modulation up to 4.7 N/mm and mass of the wearable parts of just 21 g. Through
systematic characterization, we demonstrate decoupled control of size and
stiffness properties via dual-chamber pressure regulation. Human perception
studies with 10 participants reveal that users can distinguish nine discrete
states across three size categories and three stiffness levels with 89.4%
accuracy and 6.7 s average response time. We further demonstrate extended
architectures that combine AFPAs with complementary pneumatic structures to
enable shape or geometry morphing with concurrent stiffness control. Our
results establish antagonistic pneumatic principle as a pathway toward
next-generation haptic interfaces, capable of multi-dimensiona rendering
properties within practical wearable constraints.

</details>


### [11] [Learning Tool-Aware Adaptive Compliant Control for Autonomous Regolith Excavation](https://arxiv.org/abs/2509.05475)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 本文提出基于模型的强化学习框架，利用并行化仿真环境（含高保真粒子物理和程序生成技术）训练智能体，通过动态调整刚度和阻尼实现自适应挖掘策略，实验表明工具程序生成分布训练对泛化至关重要，视觉反馈可显著提升任务成功率，为未来太空任务自主系统开发提供验证方法。


<details>
  <summary>Details</summary>
Motivation: 自主月壤挖掘是地外资源原位利用及人类持续驻留的关键，但受颗粒介质复杂相互作用动力学及机器人需使用多样化工具的操作需求限制。

Method: 引入基于模型的强化学习框架，在并行化仿真环境中训练智能体；该环境利用高保真粒子物理和程序生成技术创建大量月球地形和挖掘工具几何形状分布；智能体通过操作空间控制在每个控制步骤动态调整自身刚度和阻尼，学习自适应交互策略。

Result: 实验证明，使用工具的程序生成分布进行训练对泛化能力至关重要，能促进复杂的工具感知行为发展；此外，为智能体增加视觉反馈可显著提高任务成功率。

Conclusion: 这些结果代表了一种经过验证的方法，可用于开发未来太空任务基础任务所需的鲁棒且多功能的自主系统。

Abstract: Autonomous regolith excavation is a cornerstone of in-situ resource
utilization for a sustained human presence beyond Earth. However, this task is
fundamentally hindered by the complex interaction dynamics of granular media
and the operational need for robots to use diverse tools. To address these
challenges, this work introduces a framework where a model-based reinforcement
learning agent learns within a parallelized simulation. This environment
leverages high-fidelity particle physics and procedural generation to create a
vast distribution of both lunar terrains and excavation tool geometries. To
master this diversity, the agent learns an adaptive interaction strategy by
dynamically modulating its own stiffness and damping at each control step
through operational space control. Our experiments demonstrate that training
with a procedural distribution of tools is critical for generalization and
enables the development of sophisticated tool-aware behavior. Furthermore, we
show that augmenting the agent with visual feedback significantly improves task
success. These results represent a validated methodology for developing the
robust and versatile autonomous systems required for the foundational tasks of
future space missions.

</details>


### [12] [Microrobot Vascular Parkour: Analytic Geometry-based Path Planning with Real-time Dynamic Obstacle Avoidance](https://arxiv.org/abs/2509.05500)
*Yanda Yang,Max Sokolich,Fatma Ceren Kirmizitas,Sambeeta Das,Andreas A. Malikopoulos*

Main category: cs.RO

TL;DR: 本文提出一种实时路径规划框架，结合解析几何全局规划器（AGP）与两种反应式局部逃逸控制器，以应对血管中自主微型机器人导航面临的密集移动障碍物挑战，在仿真和实验中表现良好，平均规划时间40ms/帧，推进了血管环境中微型机器人自主导航和靶向给药。


<details>
  <summary>Details</summary>
Motivation: 血管中的自主微型机器人可实现微创治疗，但导航面临密集移动障碍物的挑战。

Method: 提出一种实时路径规划框架，该框架耦合解析几何全局规划器（AGP）与两种反应式局部逃逸控制器（一种基于规则，一种基于强化学习），利用实时成像估计微型机器人、障碍物和目标的位置并计算无碰撞运动。

Result: 在仿真中，AGP比加权A*（WA*）、粒子群优化（PSO）和快速探索随机树（RRT）产生更短的路径和更快的规划速度，同时保持可行性和确定性；将AGP从2D扩展到3D且不失速度；在仿真和实验中，组合的全局规划器和局部控制器能可靠避开移动障碍物并到达目标，平均规划时间为40ms/帧，与25fps图像采集和实时闭环控制兼容。

Conclusion: 这些结果推进了血管环境中自主微型机器人导航和靶向药物递送的发展。

Abstract: Autonomous microrobots in blood vessels could enable minimally invasive
therapies, but navigation is challenged by dense, moving obstacles. We propose
a real-time path planning framework that couples an analytic geometry global
planner (AGP) with two reactive local escape controllers, one based on rules
and one based on reinforcement learning, to handle sudden moving obstacles.
Using real-time imaging, the system estimates the positions of the microrobot,
obstacles, and targets and computes collision-free motions. In simulation, AGP
yields shorter paths and faster planning than weighted A* (WA*), particle swarm
optimization (PSO), and rapidly exploring random trees (RRT), while maintaining
feasibility and determinism. We extend AGP from 2D to 3D without loss of speed.
In both simulations and experiments, the combined global planner and local
controllers reliably avoid moving obstacles and reach targets. The average
planning time is 40 ms per frame, compatible with 25 fps image acquisition and
real-time closed-loop control. These results advance autonomous microrobot
navigation and targeted drug delivery in vascular environments.

</details>


### [13] [TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs](https://arxiv.org/abs/2509.05547)
*Ziling Chen,Yeo Jung Yoon,Rolando Bautista-Montesano,Zhen Zhao,Ajay Mandlekar,John Liu*

Main category: cs.RO

TL;DR: TeleopLab是一个移动设备远程操作系统，允许学生控制机械臂和操作实验室设备，通过用户研究证明其能有效缩短任务完成时间、提升学生体验、降低工作负荷并提高可用性，为远程STEM学习提供可扩展且有效的平台。


<details>
  <summary>Details</summary>
Motivation: 远程教育中的实践学习（尤其是需要与真实设备交互的环境）面临成本高或操作不直观的问题。

Method: 设计了TeleopLab系统，包括机械臂、自适应 gripper、摄像头、多样化应用的实验室设备、智能手机用户界面和视频通话软件，并进行了用户研究，重点关注任务性能、学生对系统的看法、可用性和工作负荷评估。

Result: 用户熟悉系统后任务完成时间减少46.1%；学生使用系统后看法有改善；NASA TLX评估显示工作负荷为38.2（可管理），SUS评估可用性为73.8（积极）。

Conclusion: TeleopLab成功弥合了物理实验室与远程教育之间的差距，为远程STEM学习提供了可扩展且有效的平台。

Abstract: Teleoperation offers a promising solution for enabling hands-on learning in
remote education, particularly in environments requiring interaction with
real-world equipment. However, such remote experiences can be costly or
non-intuitive. To address these challenges, we present TeleopLab, a mobile
device teleoperation system that allows students to control a robotic arm and
operate lab equipment. TeleopLab comprises a robotic arm, an adaptive gripper,
cameras, lab equipment for a diverse range of applications, a user interface
accessible through smartphones, and video call software. We conducted a user
study, focusing on task performance, students' perspectives toward the system,
usability, and workload assessment. Our results demonstrate a 46.1% reduction
in task completion time as users gained familiarity with the system.
Quantitative feedback highlighted improvements in students' perspectives after
using the system, while NASA TLX and SUS assessments indicated a manageable
workload of 38.2 and a positive usability of 73.8. TeleopLab successfully
bridges the gap between physical labs and remote education, offering a scalable
and effective platform for remote STEM learning.

</details>


### [14] [Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids](https://arxiv.org/abs/2509.05581)
*Arturo Flores Alvarez,Fatemeh Zargarbashi,Havel Liu,Shiqi Wang,Liam Edwards,Jessica Anz,Alex Xu,Fan Shi,Stelian Coros,Dennis W. Hong*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习（RL）的运动系统，用于专为娱乐应用设计的人形机器人Cosmo。该系统通过应用对抗性运动先验（AMP）、定制的领域随机化技术和专门的奖励结构，解决了Cosmo因美学驱动设计导致的头部过重、感知有限和运动受限等挑战，实现了稳定的站立和行走行为，为平衡美学吸引力和功能性能的机器人提供了有前景的方向。


<details>
  <summary>Details</summary>
Motivation: 娱乐机器人因美学驱动的设计选择面临独特挑战，如Cosmo的头部过大（占总质量16%）、感知有限和运动受限，传统方法难以应对，需要新的运动系统来实现自然外观运动并保持物理稳定性。

Method: 应用对抗性运动先验（AMP）来使机器人学习自然运动并维持物理稳定性，同时开发定制的领域随机化技术和专门的奖励结构以确保安全的模拟到现实迁移，保护硬件组件。

Result: 实验表明，AMP在Cosmo极端的质量分布和运动约束下仍能生成稳定的站立和行走行为。

Conclusion: 研究结果为平衡美学吸引力和功能性能的机器人建立了有前景的方向，表明基于学习的方法能够有效适应美学驱动的设计约束。

Abstract: We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a
custom-built humanoid robot designed for entertainment applications. Unlike
traditional humanoids, entertainment robots present unique challenges due to
aesthetic-driven design choices. Cosmo embodies these with a disproportionately
large head (16% of total mass), limited sensing, and protective shells that
considerably restrict movement. To address these challenges, we apply
Adversarial Motion Priors (AMP) to enable the robot to learn natural-looking
movements while maintaining physical stability. We develop tailored domain
randomization techniques and specialized reward structures to ensure safe
sim-to-real, protecting valuable hardware components during deployment. Our
experiments demonstrate that AMP generates stable standing and walking
behaviors despite Cosmo's extreme mass distribution and movement constraints.
These results establish a promising direction for robots that balance aesthetic
appeal with functional performance, suggesting that learning-based methods can
effectively adapt to aesthetic-driven design constraints.

</details>


### [15] [MonoGlass3D: Monocular 3D Glass Detection with Plane Regression and Adaptive Feature Fusion](https://arxiv.org/abs/2509.05599)
*Kai Zhang,Guoyang Zhao,Jianxing Shi,Bonan Liu,Weiqing Qi,Jun Ma*

Main category: cs.RO

TL;DR: 本文介绍了一个新的玻璃数据集和MonoGlass3D方法，用于单目3D玻璃检测，通过自适应特征融合模块和平面回归管道结合几何和上下文线索，实验表明其在玻璃分割和深度估计上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 3D环境中玻璃的检测和定位对视觉感知系统构成重大挑战，因为玻璃的光学特性阻碍传统传感器准确区分玻璃表面，且缺乏专注于玻璃物体的真实世界数据集进一步阻碍了该领域的进展。

Method: 提出了一个具有精确3D标注的新玻璃数据集，基于此数据集提出MonoGlass3D方法，包括自适应特征融合模块以有效捕捉不同条件下的上下文信息，以及平面回归管道以整合玻璃表面的几何特性。

Result: 广泛实验表明，该方法在玻璃分割和单目玻璃深度估计方面优于最先进的方法。

Conclusion: 结合几何和上下文线索对于透明表面理解具有优势。

Abstract: Detecting and localizing glass in 3D environments poses significant
challenges for visual perception systems, as the optical properties of glass
often hinder conventional sensors from accurately distinguishing glass
surfaces. The lack of real-world datasets focused on glass objects further
impedes progress in this field. To address this issue, we introduce a new
dataset featuring a wide range of glass configurations with precise 3D
annotations, collected from distinct real-world scenarios. On the basis of this
dataset, we propose MonoGlass3D, a novel approach tailored for monocular 3D
glass detection across diverse environments. To overcome the challenges posed
by the ambiguous appearance and context diversity of glass, we propose an
adaptive feature fusion module that empowers the network to effectively capture
contextual information in varying conditions. Additionally, to exploit the
distinct planar geometry of glass surfaces, we present a plane regression
pipeline, which enables seamless integration of geometric properties within our
framework. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches in both glass segmentation and monocular glass
depth estimation. Our results highlight the advantages of combining geometric
and contextual cues for transparent surface understanding.

</details>


### [16] [Sharing but Not Caring: Similar Outcomes for Shared Control and Switching Control in Telepresence-Robot Navigation](https://arxiv.org/abs/2509.05672)
*Juho Kalliokoski,Evan G. Center,Steven M. LaValle,Timo Ojala,Basak Sakcak*

Main category: cs.RO

TL;DR: 研究开发并评估了一种共享控制方法用于远程呈现机器人导航，与控制切换方法相比，共享控制未降低导航效率，但也未显著减少任务负载，需进一步研究影响用户偏好和性能的因素。


<details>
  <summary>Details</summary>
Motivation: 远程呈现机器人的高效直观导航仍是挑战。

Method: 开发共享控制方法，机器人自主导航同时允许用户影响路径生成，并与控制切换（用户在直接和自动控制间切换）进行比较。

Result: 两项连续用户研究（最终样本n=20）表明，共享控制不会降低导航效率，但与控制切换相比，任务负载未显著减少。

Conclusion: 需进一步研究影响这些控制系统中用户偏好和性能的潜在因素。

Abstract: Telepresence robots enable users to interact with remote environments, but
efficient and intuitive navigation remains a challenge. In this work, we
developed and evaluated a shared control method, in which the robot navigates
autonomously while allowing users to affect the path generation to better suit
their needs. We compared this with control switching, where users toggle
between direct and automated control. We hypothesized that shared control would
maintain efficiency comparable to control switching while potentially reducing
user workload. The results of two consecutive user studies (each with final
sample of n=20) showed that shared control does not degrade navigation
efficiency, but did not show a significant reduction in task load compared to
control switching. Further research is needed to explore the underlying factors
that influence user preference and performance in these control systems.

</details>


### [17] [A*-PRM: A Dynamic Weight-Based Probabilistic Roadmap Algorithm](https://arxiv.org/abs/2509.05701)
*Siyuan Wang,Shuyi Zhang,Zhen Tian,Yuheng Yao,Gongsen Wang,Yu Zhao*

Main category: cs.RO

TL;DR: 本文提出一种混合路径规划算法A-star PRM，通过将A-star的曼哈顿距离启发式嵌入PRM的随机采样过程，实现路径质量与计算效率的平衡优化，实验证明其在路径长度、稳定性和计算效率方面具有综合优势，尤其在狭窄通道和动态障碍物场景中表现更佳。


<details>
  <summary>Details</summary>
Motivation: 解决机器人路径规划中提升自主导航系统环境适应性的基本挑战。

Method: 提出A-star PRM混合算法，采用分层采样策略和动态连接机制，将A-star的曼哈顿距离启发式嵌入PRM的随机采样过程。

Result: 在基准配置（1000个采样顶点）下，A-star PRM路径长度为1073.23±14.8米，比PRM短42.3%（p<0.01）；高密度采样（3000个顶点）时，路径长度减少0.94%（1036.61米 vs 1046.42米），计算时间增加量约为PRM的十分之一（71% vs 785%）。

Conclusion: A-star PRM在路径质量、稳定性和计算效率方面具有综合优势，与现有混合算法相比，在狭窄通道和动态障碍物场景中优势明显。

Abstract: Robot path planning is a fundamental challenge in enhancing the environmental
adaptability of autonomous navigation systems. This paper presents a hybrid
path planning algorithm, A-star PRM, which incorporates dynamic weights. By
embedding the Manhattan distance heuristic of the A-star algorithm into the
random sampling process of PRM, the algorithm achieves a balanced optimization
of path quality and computational efficiency. The approach uses a hierarchical
sampling strategy and a dynamic connection mechanism, greatly improving
adaptability to complex obstacle distributions. Experiments show that under a
baseline configuration with one thousand sampled vertices, the path length of
A-star PRM is 1073.23 plus or minus 14.8 meters and is 42.3 percent shorter
than that of PRM with p value less than 0.01. With high-density sampling using
three thousand vertices, the path length is reduced by 0.94 percent, 1036.61
meters compared with 1046.42 meters, while the increase in computational time
is cut to about one tenth of the PRM increase, 71 percent compared with 785
percent. These results confirm the comprehensive advantages of A-star PRM in
path quality, stability, and computational efficiency. Compared with existing
hybrid algorithms, the proposed method shows clear benefits, especially in
narrow channels and scenarios with dynamic obstacles.

</details>


### [18] [Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723)
*Liansheng Wang,Xinke Zhang,Chenhui Li,Dongjiao He,Yihan Pan,Jianjun Yi*

Main category: cs.RO

TL;DR: Super-LIO是一种鲁棒的激光雷达-惯性里程计系统，通过紧凑的八体素地图结构OctVox和启发式引导的KNN策略HKNN，在资源受限平台上实现了高性能和准确性，处理速度比SOTA快约73%且CPU资源消耗更少，开源且即插即用。


<details>
  <summary>Details</summary>
Motivation: 激光雷达-惯性里程计（LIO）是自主系统的基础技术，但由于计算和内存限制，在资源受限平台上的部署仍具有挑战性。

Method: 核心是紧凑的八体素地图结构OctVox，每个体素限制为八个融合子体素，实现严格的点密度控制和地图更新时的增量去噪；设计启发式引导的KNN策略（HKNN），利用空间局部性加速对应搜索。

Result: 在四个公开数据集和多个自收集数据集（共30多个序列）上进行了评估，在X86和ARM平台上的广泛测试证实，Super-LIO提供了卓越的效率和鲁棒性，同时保持了有竞争力的准确性，处理每帧的速度比SOTA快约73%，消耗更少的CPU资源。

Conclusion: Super-LIO是一种鲁棒的LIO系统，适用于空中机器人和移动自主系统等应用，完全开源且与多种激光雷达传感器和平台即插即用兼容。

Abstract: LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous
systems, yet its deployment on resource-constrained platforms remains
challenging due to computational and memory limitations. We propose Super-LIO,
a robust LIO system that demands both high performance and accuracy, ideal for
applications such as aerial robots and mobile autonomous systems. At the core
of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that
limits each voxel to eight fused subvoxels, enabling strict point density
control and incremental denoising during map updates. This design enables a
simple yet efficient and accurate map structure, which can be easily integrated
into existing LIO frameworks. Additionally, Super-LIO designs a
heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search
by leveraging spatial locality, further reducing runtime overhead. We evaluated
the proposed system using four publicly available datasets and several
self-collected datasets, totaling more than 30 sequences. Extensive testing on
both X86 and ARM platforms confirms that Super-LIO offers superior efficiency
and robustness, while maintaining competitive accuracy. Super-LIO processes
each frame approximately 73% faster than SOTA, while consuming less CPU
resources. The system is fully open-source and plug-and-play compatible with a
wide range of LiDAR sensors and platforms. The implementation is available at:
https://github.com/Liansheng-Wang/Super-LIO.git

</details>


### [19] [Scenario-based Decision-making Using Game Theory for Interactive Autonomous Driving: A Survey](https://arxiv.org/abs/2509.05777)
*Zhihao Lin,Zhen Tian*

Main category: cs.RO

TL;DR: This survey comprehensively evaluates game-based interactive driving methods by summarizing recent advancements, inherent roadway features in each scenario, critically assessing reviewed algorithms based on their adaptation of the standard game model and mechanism analysis, and discussing limitations and future research directions, addressing the lack of a systematic review comparing these approaches across scenarios.


<details>
  <summary>Details</summary>
Motivation: The motivation is that although game-based interactive driving simulations are versatile platforms for advancing decision-making algorithms, ensuring realism and robust performance amid dynamic and diverse scenarios is a challenge, and there is a lack of a systematic review comparing these approaches across different scenarios.

Method: The survey summarizes recent advancements and inherent roadway features in each scenario of game-based interactive driving methods, critically assesses the reviewed algorithms based on their adaptation of the standard game model and an analysis of their specific mechanisms to understand their impact on decision-making performance.

Result: The survey provides a comprehensive evaluation of game-based interactive driving methods, identifies the lack of a systematic review comparing these approaches across different scenarios, and discusses the limitations of current approaches and outlines promising directions for future research.

Conclusion: Game-based interactive driving simulations are important for advancing decision-making algorithms, but there are challenges in realism and performance. Recent integrated models outperform traditional methods in various scenarios. A systematic review was missing, so this survey evaluates these methods, assesses algorithms, and discusses limitations and future directions.

Abstract: Game-based interactive driving simulations have emerged as versatile
platforms for advancing decision-making algorithms in road transport mobility.
While these environments offer safe, scalable, and engaging settings for
testing driving strategies, ensuring both realism and robust performance amid
dynamic and diverse scenarios remains a significant challenge. Recently, the
integration of game-based techniques with advanced learning frameworks has
enabled the development of adaptive decision-making models that effectively
manage the complexities inherent in varied driving conditions. These models
outperform traditional simulation methods, especially when addressing
scenario-specific challenges, ranging from obstacle avoidance on highways and
precise maneuvering during on-ramp merging to navigation in roundabouts,
unsignalized intersections, and even the high-speed demands of autonomous
racing. Despite numerous innovations in game-based interactive driving, a
systematic review comparing these approaches across different scenarios is
still missing. This survey provides a comprehensive evaluation of game-based
interactive driving methods by summarizing recent advancements and inherent
roadway features in each scenario. Furthermore, the reviewed algorithms are
critically assessed based on their adaptation of the standard game model and an
analysis of their specific mechanisms to understand their impact on
decision-making performance. Finally, the survey discusses the limitations of
current approaches and outlines promising directions for future research.

</details>


### [20] [eKalibr-Inertial: Continuous-Time Spatiotemporal Calibration for Event-Based Visual-Inertial Systems](https://arxiv.org/abs/2509.05923)
*Shuolong Chen,Xingxing Li,Liu Yuan*

Main category: cs.RO

TL;DR: 本文提出eKalibr-Inertial，一种基于事件相机的视觉-惯性系统时空校准器，利用圆形网格板，通过严格高效的初始化和连续时间批量优化实现准确校准，并开源代码。


<details>
  <summary>Details</summary>
Motivation: 事件相机在运动估计等领域应用广泛，视觉-惯性系统因传感器互补性常被采用，但需准确的时空校准以实现最优融合。

Method: 基于eKalibr和eKalibr-Stereo的网格模式识别与跟踪方法，先进行严格高效的初始化以准确恢复估计器所有参数，随后通过连续时间批量优化优化初始参数。

Result: 大量真实世界实验表明，eKalibr-Inertial能实现基于事件的视觉-惯性时空校准的准确性。

Conclusion: eKalibr-Inertial是一种准确的事件相机视觉-惯性系统时空校准器，其开源实现有助于研究社区。

Abstract: The bioinspired event camera, distinguished by its exceptional temporal
resolution, high dynamic range, and low power consumption, has been extensively
studied in recent years for motion estimation, robotic perception, and object
detection. In ego-motion estimation, the visual-inertial setup is commonly
adopted due to complementary characteristics between sensors (e.g., scale
perception and low drift). For optimal event-based visual-inertial fusion,
accurate spatiotemporal (extrinsic and temporal) calibration is required. In
this work, we present eKalibr-Inertial, an accurate spatiotemporal calibrator
for event-based visual-inertial systems, utilizing the widely used circle grid
board. Building upon the grid pattern recognition and tracking methods in
eKalibr and eKalibr-Stereo, the proposed method starts with a rigorous and
efficient initialization, where all parameters in the estimator would be
accurately recovered. Subsequently, a continuous-time-based batch optimization
is conducted to refine the initialized parameters toward better states. The
results of extensive real-world experiments show that eKalibr-Inertial can
achieve accurate event-based visual-inertial spatiotemporal calibration. The
implementation of eKalibr-Inertial is open-sourced at
(https://github.com/Unsigned-Long/eKalibr) to benefit the research community.

</details>


### [21] [ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction](https://arxiv.org/abs/2509.06031)
*Junhui Huang,Yuhe Gong,Changsheng Li,Xingguang Duan,Luis Figueredo*

Main category: cs.RO

TL;DR: 提出ZLATTE，一种无学习的几何感知框架，用于人机交互中语言驱动的轨迹重塑。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于学习的方法在语言驱动轨迹重塑中的问题，提供更平滑、安全且可解释的轨迹修改。

Method: 利用视觉语言模型将物体注册为几何基元，通过大型语言模型将自然语言指令转化为明确的几何和运动学约束，集成到势场优化中以调整初始轨迹，并采用多智能体策略增强复杂或冲突命令下的鲁棒性。

Result: 仿真和真实世界实验表明，ZLATTE相比最先进的基线实现了更平滑、安全和可解释的轨迹修改。

Conclusion: ZLATTE是一种有效的无学习框架，在人机交互中语言驱动的轨迹重塑方面表现优于现有方法。

Abstract: We present ZLATTE, a geometry-aware, learning-free framework for
language-driven trajectory reshaping in human-robot interaction. Unlike prior
learning-based methods, ZLATTE leverages Vision-Language Models to register
objects as geometric primitives and employs a Large Language Model to translate
natural language instructions into explicit geometric and kinematic
constraints. These constraints are integrated into a potential field
optimization to adapt initial trajectories while preserving feasibility and
safety. A multi-agent strategy further enhances robustness under complex or
conflicting commands. Simulation and real-world experiments demonstrate that
ZLATTE achieves smoother, safer, and more interpretable trajectory
modifications compared to state-of-the-art baselines.

</details>


### [22] [Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness](https://arxiv.org/abs/2509.06048)
*Yi Dong,Yangjun Liu,Jinjun Duan,Yang Li,Zhendong Dai*

Main category: cs.RO

TL;DR: 本文提出一种机器人操作框架，包含感知模块、重定向规划器和打包规划器，可完成任意初始状态下成对鞋子的打包，通过语义关键点视觉模块、针对不同状态鞋子的基于基元的重定向方法及快速重定向方法，以及打包任务规划器，经实验验证了重定向方法的鲁棒性和打包策略的有效性，并为成对物体打包提供参考。


<details>
  <summary>Details</summary>
Motivation: 鞋类产品打包是涉及不规则形状和可变形物体的典型成对物品打包任务，现有研究未考虑鞋子不规则形状导致的不同初始状态及标准打包放置姿势。

Method: 提出包含感知模块、重定向规划器和打包规划器的机器人操作框架：1. 基于语义关键点的视觉模块，结合几何特征推断尺寸、状态、位姿和操作点；2. 针对单个可变形鞋子不同状态的基于基元的重定向方法，以及利用盒边接触和重力的顶部状态快速重定向方法；3. 基于感知模块和重定向方法的任意初始状态下鞋对打包任务规划器，提供最优打包策略。

Result: 通过现实世界实验验证了重定向方法对各种类型鞋子的鲁棒性和打包策略的有效性。

Conclusion: 本研究突出了语义关键点表示方法的潜力，为3D可变形物体的重定向和多物体操作引入了新视角，并为成对物体打包提供了参考。

Abstract: With the rapid development of the warehousing and logistics industries, the
packing of goods has gradually attracted the attention of academia and
industry. The packing of footwear products is a typical representative
paired-item packing task involving irregular shapes and deformable objects.
Although studies on shoe packing have been conducted, different initial states
due to the irregular shapes of shoes and standard packing placement poses have
not been considered. This study proposes a robotic manipulation framework,
including a perception module, reorientation planners, and a packing planner,
that can complete the packing of pairs of shoes in any initial state. First, to
adapt to the large intraclass variations due to the state, shape, and
deformation of the shoe, we propose a vision module based on semantic
keypoints, which can also infer more information such as size, state, pose, and
manipulation points by combining geometric features. Subsequently, we not only
proposed primitive-based reorientation methods for different states of a single
deformable shoe but also proposed a fast reorientation method for the top state
using box edge contact and gravity, which further improved the efficiency of
reorientation. Finally, based on the perception module and reorientation
methods, we propose a task planner for shoe pair packing in any initial state
to provide an optimal packing strategy. Real-world experiments were conducted
to verify the robustness of the reorientation methods and the effectiveness of
the packing strategy for various types of shoes. In this study, we highlight
the potential of semantic keypoint representation methods, introduce new
perspectives on the reorientation of 3D deformable objects and multi-object
manipulation, and provide a reference for paired object packing.

</details>


### [23] [Energy-Efficient Path Planning with Multi-Location Object Pickup for Mobile Robots on Uneven Terrain](https://arxiv.org/abs/2509.06061)
*Faiza Babakano,Ahmed Fahmin,Bojie Shen,Muhammad Aamir Cheema,Isma Farah Siddiqui*

Main category: cs.RO

TL;DR: 本文提出了物体拾取最小能量路径问题（OMEPP），旨在解决AMRs在从多个可能位置拾取物体并将其运送到目的地时的节能路径规划问题，提出了并发PCPD搜索方法，该方法比基线算法快1-2个数量级且接近最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注从源到目的地的节能路径计算，但忽略了机器人在途中需要拾取物体的实际场景，这种拾取动作会因有效载荷变化而显著影响能耗。

Method: 首先引入使用Z star算法的基线算法，该算法是A star的变体，用于迭代访问每个拾取点；为缓解计算成本高的问题，提出并发PCPD搜索，该搜索在所有拾取点同时管理多个Z star搜索，核心是Payload-Constrained Path Database（PCPD），它是Compressed Path Database（CPD）的扩展，纳入了有效载荷约束。

Result: 并发PCPD搜索虽然可能产生略次优的解决方案，但在真实世界数据集上的大量实验表明，它实现了接近最优的性能，同时比基线算法快1-2个数量级。

Conclusion: PCPD显著减少了搜索过程中的分支因子，提高了整体性能，并发PCPD搜索在解决OMEPP问题上表现出良好的效率和接近最优的性能。

Abstract: Autonomous Mobile Robots (AMRs) operate on battery power, making energy
efficiency a critical consideration, particularly in outdoor environments where
terrain variations affect energy consumption. While prior research has
primarily focused on computing energy-efficient paths from a source to a
destination, these approaches often overlook practical scenarios where a robot
needs to pick up an object en route - an action that can significantly impact
energy consumption due to changes in payload. This paper introduces the
Object-Pickup Minimum Energy Path Problem (OMEPP), which addresses
energy-efficient route planning for AMRs required to pick up an object from one
of many possible locations and deliver it to a destination. To address OMEPP,
we first introduce a baseline algorithm that employs the Z star algorithm, a
variant of A star tailored for energy-efficient routing, to iteratively visit
each pickup point. While this approach guarantees optimality, it suffers from
high computational cost due to repeated searches at each pickup location. To
mitigate this inefficiency, we propose a concurrent PCPD search that manages
multiple Z star searches simultaneously across all pickup points. Central to
our solution is the Payload-Constrained Path Database (PCPD), an extension of
the Compressed Path Database (CPD) that incorporates payload constraints. We
demonstrate that PCPD significantly reduces branching factors during search,
improving overall performance. Although the concurrent PCPD search may produce
slightly suboptimal solutions, extensive experiments on real-world datasets
show it achieves near-optimal performance while being one to two orders of
magnitude faster than the baseline algorithm.

</details>


### [24] [Hybrid A* Path Planning with Multi-Modal Motion Extension for Four-Wheel Steering Mobile Robots](https://arxiv.org/abs/2509.06115)
*Runjiao Bao,Lin Zhang,Tianwei Niu,Haoyu Yuan,Shoukun Wang*

Main category: cs.RO

TL;DR: 本文提出一种扩展的混合A*框架，通过四维状态空间整合空间状态和运动模式，设计多模态Reeds-Shepp曲线、增强启发函数及终端连接策略，以充分利用四轮独立转向（4WIS）机器人的多模态运动能力，提升复杂环境下的规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法通常假设单一运动学模型，无法充分利用4WIS平台的多模态能力，因此需要解决这一局限性。

Method: 提出扩展的混合A*框架，在四维状态空间（含空间状态和运动模式）中运行；设计针对各运动模式独特运动学约束的多模态Reeds-Shepp曲线；开发考虑模式切换成本的增强启发函数；引入具有智能模式选择的终端连接策略以确保不同转向模式间的平滑过渡。

Result: 该规划器能在单一路径中无缝整合多种运动模态，显著提高复杂环境下4WIS机器人的规划性能。

Conclusion: 所提规划器实现了多种运动模态在单一路径中的无缝集成，显著提升了4WIS机器人在复杂环境中的灵活性和适应性，规划性能得到明显改善。

Abstract: Four-wheel independent steering (4WIS) systems provide mobile robots with a
rich set of motion modes, such as Ackermann steering, lateral steering, and
parallel movement, offering superior maneuverability in constrained
environments. However, existing path planning methods generally assume a single
kinematic model and thus fail to fully exploit the multi-modal capabilities of
4WIS platforms. To address this limitation, we propose an extended Hybrid A*
framework that operates in a four-dimensional state space incorporating both
spatial states and motion modes. Within this framework, we design multi-modal
Reeds-Shepp curves tailored to the distinct kinematic constraints of each
motion mode, develop an enhanced heuristic function that accounts for
mode-switching costs, and introduce a terminal connection strategy with
intelligent mode selection to ensure smooth transitions between different
steering patterns. The proposed planner enables seamless integration of
multiple motion modalities within a single path, significantly improving
flexibility and adaptability in complex environments. Results demonstrate
significantly improved planning performance for 4WIS robots in complex
environments.

</details>


### [25] [A Hybrid TDMA/CSMA Protocol for Time-Sensitive Traffic in Robot Applications](https://arxiv.org/abs/2509.06119)
*Shiqi Xu,Lihao Zhang,Yuyang Du,Qun Yang,Soung Chang Liew*

Main category: cs.RO

TL;DR: 本文针对机器人通信中高流量下CSMA协议性能下降的问题，提出一种兼容IEEE 802.11的混合TDMA/CSMA协议，通过PTP同步、三会话超帧和信标-NAV保护等机制，在SDR平台和ROS仿真中实现了93%的截止期限错误减少和90%的轨迹误差降低，同时保持非关键流量吞吐量在±2%以内。


<details>
  <summary>Details</summary>
Motivation: 在制造业、医疗和自主系统等应用中，机器人通信需实时控制，关键任务流量有严格的QoS截止期限要求，而当前广泛使用的CSMA协议在高机器人流量负载下因竞争导致碰撞和延迟，严重影响关键数据包的准时到达。

Method: 提出一种兼容IEEE 802.11的混合TDMA/CSMA协议，该协议结合TDMA的确定性时隙调度和CSMA的异构流量适应性，通过亚微秒级PTP时隙同步、动态TDMA分配的三会话超帧以及信标-NAV保护机制实现关键通信会话的无碰撞和低延迟传输。

Result: 在实时SDR平台和ROS仿真中，与CSMA基线相比，该协议将截止期限错误减少93%，在高速机器人路径跟踪ROS仿真中，轨迹均方根误差降低高达90%，同时非关键流量吞吐量保持在±2%以内。

Conclusion: 所提出的混合TDMA/CSMA协议有效解决了高机器人流量下CSMA的性能问题，实现了无碰撞、低延迟的关键任务命令传输，并保持IEEE 802.11兼容性，显著提升了机器人通信的实时性和可靠性。

Abstract: Recent progress in robotics has underscored the demand for real-time control
in applications such as manufacturing, healthcare, and autonomous systems,
where the timely delivery of mission-critical commands under heterogeneous
robotic traffic is paramount for operational efficacy and safety. In these
scenarios, mission-critical traffic follows a strict deadline-constrained
communication pattern: commands must arrive within defined QoS deadlines,
otherwise late arrivals can degrade performance or destabilize control loops.In
this work, we demonstrate on a real-time SDR platform that CSMA, widely adopted
in robotic communications,suffers severe degradation under high robot traffic
loads, with contention-induced collisions and delays disrupting the on-time
arrival of mission-critical packets. To address this problem, we propose an
IEEE 802.11-compatible hybrid TDMA/CSMA protocol that combines TDMA's
deterministic slot scheduling with CSMA's adaptability for heterogeneous robot
traffic.The protocol achieves collision-free, low-latency mission-critical
command delivery and IEEE 802.11 compatibility through the synergistic
integration of sub-microsecond PTP-based slot synchronization-essential for
establishing precise timing for TDMA, a three-session superframe with dynamic
TDMA allocation for structured and adaptable traffic management,and beacon-NAV
protection to preemptively secure these critical communication sessions from
interference. Emulation experiments on real-time SDR testbed and Robot
Operating System (ROS) simulation show that the proposed protocol reduces
missed-deadline errors by 93% compared to the CSMA baseline. In high-speed
robot path-tracking ROS simulations, the protocol lowers Root Mean Square (RMS)
trajectory error by up to 90% compared with a CSMA baseline, all while
maintaining throughput for non-critical traffic within +-2%.

</details>


### [26] [Learning in ImaginationLand: Omnidirectional Policies through 3D Generative Models (OP-Gen)](https://arxiv.org/abs/2509.06191)
*Yifei Ren,Edward Johns*

Main category: cs.RO

TL;DR: 本文表明3D生成模型可通过单真实演示扩充数据集，使机器人能从远离演示的初始状态执行任务，减少策略学习所需演示次数，并在抓取、开抽屉、倒垃圾等任务中性能优于近期基线


<details>
  <summary>Details</summary>
Motivation: 利用3D生成模型从单真实演示扩充数据集，使机器人能在远离演示的初始状态下执行任务，减少策略学习所需的演示次数

Method: 使用3D生成模型扩充单真实演示的数据集，在该想象数据集中学习全向策略，并通过真实世界实验（如抓取物体、打开抽屉、将垃圾放入垃圾桶）研究各种设计选择对策略行为的影响

Result: 机器人能从与真实演示观察到的状态相差很远的初始状态（包括从物体相对于真实演示的相反侧开始）执行任务，且性能优于使用替代数据扩充方法的近期基线

Conclusion: 3D生成模型可有效扩充单演示数据集，学习到的全向策略能处理远离演示的初始状态，减少演示需求并优于基线方法

Abstract: Recent 3D generative models, which are capable of generating full object
shapes from just a few images, now open up new opportunities in robotics. In
this work, we show that 3D generative models can be used to augment a dataset
from a single real-world demonstration, after which an omnidirectional policy
can be learned within this imagined dataset. We found that this enables a robot
to perform a task when initialised from states very far from those observed
during the demonstration, including starting from the opposite side of the
object relative to the real-world demonstration, significantly reducing the
number of demonstrations required for policy learning. Through several
real-world experiments across tasks such as grasping objects, opening a drawer,
and placing trash into a bin, we study these omnidirectional policies by
investigating the effect of various design choices on policy behaviour, and we
show superior performance to recent baselines which use alternative methods for
data augmentation.

</details>


### [27] [Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control](https://arxiv.org/abs/2509.06201)
*Jun Yamada,Adithyavairavan Murali,Ajay Mandlekar,Clemens Eppner,Ingmar Posner,Balakumar Sundaralingam*

Main category: cs.RO

TL;DR: 本文提出Grasp-MPC，一种基于视觉的闭环6自由度抓取策略，旨在杂乱环境中对新物体实现稳健且反应性的抓取，其在模拟和真实环境中相比多种方法提升了抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 无结构化环境中多样化物体的抓取仍是重大挑战，开环抓取方法在杂乱环境中效果差，抓取预测误差和抓取时物体姿态变化是失败主因；闭环方法则在简化场景和有限物体集上存在，缺乏泛化能力。

Method: 提出Grasp-MPC，它结合了在包含200万条成功和失败抓取轨迹的大规模合成数据集上训练的价值函数，在MPC框架中部署该价值函数，并结合其他鼓励避碰和平滑执行的成本项。

Result: 在FetchBench和真实世界多样化环境中评估，Grasp-MPC在模拟中抓取成功率提升高达32.6%，在真实世界嘈杂条件下提升33.3%，优于开环、扩散策略、Transformer策略和IQL方法。

Conclusion: Grasp-MPC是一种有效且具有泛化能力的闭环6自由度视觉抓取策略，能在杂乱环境中对新物体实现稳健抓取，显著提升抓取成功率。

Abstract: Grasping of diverse objects in unstructured environments remains a
significant challenge. Open-loop grasping methods, effective in controlled
settings, struggle in cluttered environments. Grasp prediction errors and
object pose changes during grasping are the main causes of failure. In
contrast, closed-loop methods address these challenges in simplified settings
(e.g., single object on a table) on a limited set of objects, with no path to
generalization. We propose Grasp-MPC, a closed-loop 6-DoF vision-based grasping
policy designed for robust and reactive grasping of novel objects in cluttered
environments. Grasp-MPC incorporates a value function, trained on visual
observations from a large-scale synthetic dataset of 2 million grasp
trajectories that include successful and failed attempts. We deploy this
learned value function in an MPC framework in combination with other cost terms
that encourage collision avoidance and smooth execution. We evaluate Grasp-MPC
on FetchBench and real-world settings across diverse environments. Grasp-MPC
improves grasp success rates by up to 32.6% in simulation and 33.3% in
real-world noisy conditions, outperforming open-loop, diffusion policy,
transformer policy, and IQL approaches. Videos and more at
http://grasp-mpc.github.io.

</details>


### [28] [O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.06233)
*Tongxuan Tian,Xuhui Kang,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: 提出了一种新的单样本3D物体间交互性学习方法O³Afford，结合视觉基础模型的语义特征和点云几何理解，能有效泛化到新物体和类别，并与大语言模型集成以增强机器人操作中物体交互的理解和推理能力，实验证明其在准确性和泛化能力上显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注单物体交互性预测，忽略了现实世界中大多数交互涉及物体对关系，且在数据有限的情况下进行物体间交互性接地存在挑战。

Method: 受2D视觉基础模型少样本学习进展的启发，提出单样本3D物体间交互性学习方法，结合视觉基础模型的语义特征和点云表示以实现几何理解，并将3D交互性表示与大语言模型集成以生成任务特定约束函数。

Result: 在3D物体间交互性接地和机器人操作实验中，O³Afford在准确性和泛化能力方面显著优于现有基线。

Conclusion: 所提出的O³Afford方法有效解决了数据有限情况下物体间交互性接地问题，提升了机器人操作中对物体交互的理解和推理能力，具有良好的准确性和泛化性能。

Abstract: Grounding object affordance is fundamental to robotic manipulation as it
establishes the critical link between perception and action among interacting
objects. However, prior works predominantly focus on predicting single-object
affordance, overlooking the fact that most real-world interactions involve
relationships between pairs of objects. In this work, we address the challenge
of object-to-object affordance grounding under limited data contraints.
Inspired by recent advances in few-shot learning with 2D vision foundation
models, we propose a novel one-shot 3D object-to-object affordance learning
approach for robotic manipulation. Semantic features from vision foundation
models combined with point cloud representation for geometric understanding
enable our one-shot learning pipeline to generalize effectively to novel
objects and categories. We further integrate our 3D affordance representation
with large language models (LLMs) for robotics manipulation, significantly
enhancing LLMs' capability to comprehend and reason about object interactions
when generating task-specific constraint functions. Our experiments on 3D
object-to-object affordance grounding and robotic manipulation demonstrate that
our O$^3$Afford significantly outperforms existing baselines in terms of both
accuracy and generalization capability.

</details>


### [29] [DCReg: Decoupled Characterization for Efficient Degenerate LiDAR Registration](https://arxiv.org/abs/2509.06285)
*Xiangcheng Hu,Xieyuanli Chen,Mingkai Jia,Jin Wu,Ping Tan,Steven L. Waslander*

Main category: cs.RO

TL;DR: 本文介绍DCReg框架，通过Schur补分解检测病态条件、定量表征技术映射数学特征空间与物理运动方向、设计新型预条件器稳定病态方向，解决激光雷达点云配准在几何退化或狭窄环境中的病态问题，实验表明定位精度提升20%-50%，速度加快5-100倍。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能准确检测、解释和解决激光雷达点云配准在几何退化或狭窄环境中的病态条件，导致检测遗漏或解的损坏。

Method: DCReg框架包含三个创新：1. 采用Schur补分解Hessian矩阵实现可靠病态条件检测，将配准问题解耦为旋转和平移子空间；2. 在子空间中开发定量表征技术，建立数学特征空间与物理运动方向的显式映射；3. 设计新型预条件器，选择性稳定病态方向，通过预条件共轭梯度法实现高效鲁棒优化。

Result: DCReg在不同环境中比最先进方法的定位精度至少提高20%-50%，速度加快5-100倍。

Conclusion: DCReg通过系统性解决病态配准问题，有效提升了激光雷达点云配准的精度和效率。

Abstract: LiDAR point cloud registration is fundamental to robotic perception and
navigation. However, in geometrically degenerate or narrow environments,
registration problems become ill-conditioned, leading to unstable solutions and
degraded accuracy. While existing approaches attempt to handle these issues,
they fail to address the core challenge: accurately detection, interpret, and
resolve this ill-conditioning, leading to missed detections or corrupted
solutions. In this study, we introduce DCReg, a principled framework that
systematically addresses the ill-conditioned registration problems through
three integrated innovations. First, DCReg achieves reliable ill-conditioning
detection by employing a Schur complement decomposition to the hessian matrix.
This technique decouples the registration problem into clean rotational and
translational subspaces, eliminating coupling effects that mask degeneracy
patterns in conventional analyses. Second, within these cleanly subspaces, we
develop quantitative characterization techniques that establish explicit
mappings between mathematical eigenspaces and physical motion directions,
providing actionable insights about which specific motions lack constraints.
Finally, leveraging this clean subspace, we design a targeted mitigation
strategy: a novel preconditioner that selectively stabilizes only the
identified ill-conditioned directions while preserving all well-constrained
information in observable space. This enables efficient and robust optimization
via the Preconditioned Conjugate Gradient method with a single physical
interpretable parameter. Extensive experiments demonstrate DCReg achieves at
least 20% - 50% improvement in localization accuracy and 5-100 times speedup
over state-of-the-art methods across diverse environments. Our implementation
will be available at https://github.com/JokerJohn/DCReg.

</details>


### [30] [Learning to Walk with Less: a Dyna-Style Approach to Quadrupedal Locomotion](https://arxiv.org/abs/2509.06296)
*Francisco Affonso,Felipe Andrade G. Tommaselli,Juliano Negri,Vivian S. Medeiros,Mateus V. Gasparino,Girish Chowdhary,Marcelo Becker*

Main category: cs.RO

TL;DR: 本文提出一种基于模型的强化学习（MBRL）框架，通过在PPO控制器的标准轨迹末尾添加合成数据，遵循Dyna-Style范式，以提高四足机器人运动的样本效率。实验在Unitree Go1机器人仿真中验证，表明用合成步骤替代部分模拟步骤不仅能模拟扩展轨迹，还能提高策略回报并减少方差，且这种改进能在使用更少模拟步骤的情况下实现对多种运动指令的跟踪能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于RL的运动控制器存在数据效率低的问题，需要大量交互才能实现鲁棒性能，因此需要提高样本效率。

Method: 提出一种MBRL框架，训练一个预测模型与策略一起，生成短视域合成转换，并基于策略更新迭代的调度策略逐步整合；通过消融研究确定样本效率与轨迹长度的强相关性，指导实验设计；在仿真中用合成步骤替代部分模拟步骤。

Result: 在Unitree Go1机器人仿真中，用合成步骤替代部分模拟步骤不仅能模拟扩展轨迹，还能提高策略回报并减少方差，且能在使用更少模拟步骤的情况下跟踪多种运动指令。

Conclusion: 所提出的MBRL框架通过添加合成数据提高了四足机器人运动的样本效率，改善了策略性能，且该改进能迁移到跟踪多种运动指令的能力上。

Abstract: Traditional RL-based locomotion controllers often suffer from low data
efficiency, requiring extensive interaction to achieve robust performance. We
present a model-based reinforcement learning (MBRL) framework that improves
sample efficiency for quadrupedal locomotion by appending synthetic data to the
end of standard rollouts in PPO-based controllers, following the Dyna-Style
paradigm. A predictive model, trained alongside the policy, generates
short-horizon synthetic transitions that are gradually integrated using a
scheduling strategy based on the policy update iterations. Through an ablation
study, we identified a strong correlation between sample efficiency and rollout
length, which guided the design of our experiments. We validated our approach
in simulation on the Unitree Go1 robot and showed that replacing part of the
simulated steps with synthetic ones not only mimics extended rollouts but also
improves policy return and reduces variance. Finally, we demonstrate that this
improvement transfers to the ability to track a wide range of locomotion
commands using fewer simulated steps.

</details>


### [31] [Towards bridging the gap: Systematic sim-to-real transfer for diverse legged robots](https://arxiv.org/abs/2509.06342)
*Filip Bjelonic,Fabian Tischhauser,Marco Hutter*

Main category: cs.RO

TL;DR: 提出一种集成模拟到现实强化学习与永磁同步电机物理接地能量模型的框架，以实现腿式机器人的鲁棒运动和能量效率，无需动态参数随机化即可可靠策略迁移，提高了能量效率，降低了ANYmal的综合运输成本32%（值1.27）。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人需同时实现鲁棒运动和能量效率以在现实环境中实用，但模拟训练的控制器常无法可靠迁移，多数现有方法忽略特定执行器的能量损失或依赖复杂的手动调整奖励公式。

Method: 集成模拟到现实强化学习与永磁同步电机物理接地能量模型，需最小参数集捕捉模拟与现实差距，采用包含基于第一原理的能量损失公式的紧凑四项奖励，平衡电气和机械耗散，并通过自底向上的动态参数识别研究（涵盖执行器、全机器人空中轨迹和地面运动）进行评估验证。

Result: 在三个主要平台上测试并部署到十个额外机器人，无需动态参数随机化即可实现可靠策略迁移，比最先进方法提高能量效率，使ANYmal的综合运输成本降低32%（值1.27）。

Conclusion: 该框架有效解决了腿式机器人模拟到现实迁移及能量效率问题，具有良好的可靠性和性能提升，所有代码、模型和数据集将发布。

Abstract: Legged robots must achieve both robust locomotion and energy efficiency to be
practical in real-world environments. Yet controllers trained in simulation
often fail to transfer reliably, and most existing approaches neglect
actuator-specific energy losses or depend on complex, hand-tuned reward
formulations. We propose a framework that integrates sim-to-real reinforcement
learning with a physics-grounded energy model for permanent magnet synchronous
motors. The framework requires a minimal parameter set to capture the
simulation-to-reality gap and employs a compact four-term reward with a
first-principle-based energetic loss formulation that balances electrical and
mechanical dissipation. We evaluate and validate the approach through a
bottom-up dynamic parameter identification study, spanning actuators,
full-robot in-air trajectories and on-ground locomotion. The framework is
tested on three primary platforms and deployed on ten additional robots,
demonstrating reliable policy transfer without randomization of dynamic
parameters. Our method improves energetic efficiency over state-of-the-art
methods, achieving a 32 percent reduction in the full Cost of Transport of
ANYmal (value 1.27). All code, models, and datasets will be released.

</details>


### [32] [Adaptive Evolution Factor Risk Ellipse Framework for Reliable and Safe Autonomous Driving](https://arxiv.org/abs/2509.06375)
*Fujiang Yuan,Zhen Tian,Yangfan He,Guojian Zou,Chunhong Yuan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: 提出进化风险势场（ERPF），通过历史障碍物接近数据动态更新风险评估，结合风险椭圆和自适应进化因子，集成到模型预测控制（MPC）框架，实现复杂交互式驾驶场景下更平滑轨迹、更高平均速度和无碰撞导航。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的技术过于保守或计算密集，基于学习的方法需大量训练数据且可解释性和泛化性有限，简单策略如风险势场（RPF）静态且难以适应动态交通条件，为克服这些局限性而提出新方法。

Method: 提出ERPF，引入风险椭圆构造结合纵向范围和横向不确定性为统一时空碰撞包络，定义自适应进化因子指标（通过TTC和TWH的sigmoid归一化计算）实时调整椭圆轴尺寸，将该自适应风险指标集成到MPC框架。

Result: 综合对比实验表明ERPF-MPC方法始终实现更平滑轨迹、更高平均速度和无碰撞导航。

Conclusion: ERPF-MPC提供了一种稳健且自适应的解决方案，适用于复杂的交互式驾驶环境。

Abstract: In recent years, ensuring safety, efficiency, and comfort in interactive
autonomous driving has become a critical challenge. Traditional model-based
techniques, such as game-theoretic methods and robust control, are often overly
conservative or computationally intensive. Conversely, learning-based
approaches typically require extensive training data and frequently exhibit
limited interpretability and generalizability. Simpler strategies, such as Risk
Potential Fields (RPF), provide lightweight alternatives with minimal data
demands but are inherently static and struggle to adapt effectively to dynamic
traffic conditions. To overcome these limitations, we propose the Evolutionary
Risk Potential Field (ERPF), a novel approach that dynamically updates risk
assessments in dynamical scenarios based on historical obstacle proximity data.
We introduce a Risk-Ellipse construct that combines longitudinal reach and
lateral uncertainty into a unified spatial temporal collision envelope.
Additionally, we define an adaptive Evolution Factor metric, computed through
sigmoid normalization of Time to Collision (TTC) and Time-Window-of-Hazard
(TWH), which dynamically adjusts the dimensions of the ellipse axes in real
time. This adaptive risk metric is integrated seamlessly into a Model
Predictive Control (MPC) framework, enabling autonomous vehicles to proactively
address complex interactive driving scenarios in terms of uncertain driving of
surrounding vehicles. Comprehensive comparative experiments demonstrate that
our ERPF-MPC approach consistently achieves smoother trajectories, higher
average speeds, and collision-free navigation, offering a robust and adaptive
solution suitable for complex interactive driving environments.

</details>


### [33] [Safety Meets Speed: Accelerated Neural MPC with Safety Guarantees and No Retraining](https://arxiv.org/abs/2509.06404)
*Kaikai Wang,Tianxun Li,Liang Xu,Qinglei Hu,Keyou You*

Main category: cs.RO

TL;DR: 提出BAN-MPC框架，结合神经网络快速计算与MPC约束处理能力，通过CBF确保安全，离线学习的神经价值函数降低在线计算复杂度，神经灵敏度网络自适应调整价值函数，HIL实验显示比传统MPC快200倍，控制误差低于5%，适用于嵌入式系统。


<details>
  <summary>Details</summary>
Motivation: 传统MPC实时执行可能超出嵌入式计算预算，需要在保证安全的同时降低计算复杂度。

Method: 构建BAN-MPC框架，用CBF替代欧氏距离实现避障确保安全；将离线学习的神经价值函数集成到短时域MPC优化目标以降低在线计算复杂度；用第二个神经网络学习价值函数对系统参数的灵敏度，在模型参数变化时自适应调整神经价值函数，无需重新训练。

Result: 在Jetson Nano上的HIL实验表明，BAN-MPC比传统MPC快200倍，在模型参数变化15%以内时，控制误差低于5%，实现无碰撞导航。

Conclusion: BAN-MPC是一种有效的嵌入式MPC替代方案，能在保证安全和控制精度的同时显著降低计算成本，适用于模型参数变化的场景。

Abstract: While Model Predictive Control (MPC) enforces safety via constraints, its
real-time execution can exceed embedded compute budgets. We propose a
Barrier-integrated Adaptive Neural Model Predictive Control (BAN-MPC) framework
that synergizes neural networks' fast computation with MPC's
constraint-handling capability. To ensure strict safety, we replace traditional
Euclidean distance with Control Barrier Functions (CBFs) for collision
avoidance. We integrate an offline-learned neural value function into the
optimization objective of a Short-horizon MPC, substantially reducing online
computational complexity. Additionally, we use a second neural network to learn
the sensitivity of the value function to system parameters, and adaptively
adjust the neural value function based on this neural sensitivity when model
parameters change, eliminating the need for retraining and reducing offline
computation costs. The hardware in-the-loop (HIL) experiments on Jetson Nano
show that BAN-MPC solves 200 times faster than traditional MPC, enabling
collision-free navigation with control error below 5\% under model parameter
variations within 15\%, making it an effective embedded MPC alternative.

</details>


### [34] [Real-time Photorealistic Mapping for Situational Awareness in Robot Teleoperation](https://arxiv.org/abs/2509.06433)
*Ian Page,Pierre Susbielle,Olivier Aycard,Pierre-Brice Wieber*

Main category: cs.RO

TL;DR: 该研究提出一种基于GPU的模块化高效集成方案，将高斯溅射SLAM的最新进展与现有在线地图遥操作系统结合，通过无人机实世界实验验证，相比最先进的遥操作系统，显著提升了决策速度和环境交互准确性，增强了未知环境下的遥操作效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于在线地图的遥操作系统因计算成本高，难以实时生成视觉准确的3D地图，导致遥操作性能不佳，而未知环境中高效远程遥操作需快速构建场地布局理解，在线3D映射是解决该挑战的有效策略。

Method: 提出一种新颖、模块化且高效的基于GPU的集成方案，整合高斯溅射SLAM的最新进展与现有在线地图遥操作系统。

Result: 通过无人机实世界实验，与最先进的遥操作系统相比，该方案显著提高了决策速度和与环境交互的准确性，提升了遥操作效率。

Conclusion: 该系统通过无缝集成逼真地图生成与实时性能，增强了远程遥操作，实现了在不熟悉环境中的有效遥操作。

Abstract: Achieving efficient remote teleoperation is particularly challenging in
unknown environments, as the teleoperator must rapidly build an understanding
of the site's layout. Online 3D mapping is a proven strategy to tackle this
challenge, as it enables the teleoperator to progressively explore the site
from multiple perspectives. However, traditional online map-based teleoperation
systems struggle to generate visually accurate 3D maps in real-time due to the
high computational cost involved, leading to poor teleoperation performances.
In this work, we propose a solution to improve teleoperation efficiency in
unknown environments. Our approach proposes a novel, modular and efficient
GPU-based integration between recent advancement in gaussian splatting SLAM and
existing online map-based teleoperation systems. We compare the proposed
solution against state-of-the-art teleoperation systems and validate its
performances through real-world experiments using an aerial vehicle. The
results show significant improvements in decision-making speed and more
accurate interaction with the environment, leading to greater teleoperation
efficiency. In doing so, our system enhances remote teleoperation by seamlessly
integrating photorealistic mapping generation with real-time performances,
enabling effective teleoperation in unfamiliar environments.

</details>


### [35] [Interactive Shaping of Granular Media Using Reinforcement Learning](https://arxiv.org/abs/2509.06469)
*Benedikt Kreis,Malte Mosbach,Anny Ripke,Muhammad Ehsan Ullah,Sven Behnke,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出一种强化学习框架，使配备立方末端执行器和立体相机的机械臂能将颗粒介质塑形为目标结构，通过紧凑观测和简洁奖励公式解决高维配置空间问题，消融研究验证设计有效性，结果表明其在训练视觉策略及实际部署中优于两种基线方法


<details>
  <summary>Details</summary>
Motivation: 颗粒介质（如沙子）的自主操控在建筑、挖掘和增材制造等应用中至关重要，但因其高维配置空间和复杂动力学，传统基于规则的方法需大量工程努力，存在挑战

Method: 提出强化学习框架，采用配备立方末端执行器和立体相机的机械臂，通过紧凑观测和简洁奖励公式设计，结合消融研究验证设计选择

Result: 所提方法在训练操控颗粒介质的视觉策略及实际部署中有效，性能优于两种基线方法

Conclusion: 强化学习框架可有效解决颗粒介质塑形问题，紧凑观测和简洁奖励公式对处理大配置空间很重要，能实现视觉策略训练及实际应用

Abstract: Autonomous manipulation of granular media, such as sand, is crucial for
applications in construction, excavation, and additive manufacturing. However,
shaping granular materials presents unique challenges due to their
high-dimensional configuration space and complex dynamics, where traditional
rule-based approaches struggle without extensive engineering efforts.
Reinforcement learning (RL) offers a promising alternative by enabling agents
to learn adaptive manipulation strategies through trial and error. In this
work, we present an RL framework that enables a robotic arm with a cubic
end-effector and a stereo camera to shape granular media into desired target
structures. We show the importance of compact observations and concise reward
formulations for the large configuration space, validating our design choices
with an ablation study. Our results demonstrate the effectiveness of the
proposed approach for the training of visual policies that manipulate granular
media including their real-world deployment, outperforming two baseline
approaches.

</details>


### [36] [Event Driven CBBA with Reduced Communication](https://arxiv.org/abs/2509.06481)
*Vinita Sao,Tu Dac Ho,Sujoy Bhore,P. B. Sujit*

Main category: cs.RO

TL;DR: 本文提出一种基于事件驱动的通信机制（ED-CBBA），以解决共识束算法（CBBA）在多机器人任务分配中因持续通信导致的拥塞和丢包问题，同时保持收敛性和性能边界，通过蒙特卡洛模拟验证，消息传输减少高达52%


<details>
  <summary>Details</summary>
Motivation: 多机器人在多无人机监控、搜救等场景需同时完成多任务，但受限于通信范围，去中心化任务分配算法至关重要。现有CBBA虽有理论保证，但需持续通信，易导致拥塞和丢包，影响性能

Method: 引入事件驱动通信机制，在保持CBBA收敛性和性能边界的同时，解决通信挑战

Result: 通过蒙特卡洛模拟（在不同目标、智能体和束条件下）验证，所提ED-CBBA算法可减少消息传输高达52%，且解决方案质量与CBBA相当

Conclusion: 事件驱动通信机制有效解决了CBBA的通信问题，在保证性能的同时显著降低消息传输量

Abstract: In various scenarios such as multi-drone surveillance and search-and-rescue
operations, deploying multiple robots is essential to accomplish multiple tasks
at once. Due to the limited communication range of these vehicles, a
decentralised task allocation algorithm is crucial for effective task
distribution among robots. The consensus-based bundle algorithm (CBBA) has been
promising for multi-robot operation, offering theoretical guarantees. However,
CBBA demands continuous communication, leading to potential congestion and
packet loss that can hinder performance. In this study, we introduce an
event-driven communication mechanism designed to address these communication
challenges while maintaining the convergence and performance bounds of CBBA. We
demonstrate theoretically that the solution quality matches that of CBBA and
validate the approach with Monte-Carlo simulations across varying targets,
agents, and bundles. Results indicate that the proposed algorithm (ED-CBBA) can
reduce message transmissions by up to 52%.

</details>


### [37] [Co-Located VR with Hybrid SLAM-based HMD Tracking and Motion Capture Synchronization](https://arxiv.org/abs/2509.06582)
*Carlos A. Pinheiro de Sousa,Niklas Gröne,Mathias Günther,Oliver Deussen*

Main category: cs.RO

TL;DR: 本文介绍了一种多用户VR共定位框架，通过结合动作捕捉系统和基于SLAM的内向外跟踪，实现共享虚拟环境中用户与物理空间的同步，提供流畅、高帧率、低延迟性能，相比现有方案在空间精度、舒适度、可扩展性和鲁棒性上有提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖持续外部跟踪导致延迟和抖动，要么依赖一次性校准无法随时间纠正漂移，因此需要一种结合本地HMD SLAM跟踪响应性和外部源重对齐灵活性的方案。

Method: 结合动作捕捉系统与SLAM-based inside-out跟踪，在需要时将本地HMD SLAM跟踪与外部源重对齐，并支持跨设备实时姿态共享以确保用户间空间对齐一致。

Result: 评估表明该框架达到了自然多用户交互所需的空间精度，同时比现有共定位VR解决方案提供了更好的舒适度、可扩展性和鲁棒性。

Conclusion: 该多用户VR共定位框架通过创新的跟踪结合方式和姿态共享机制，有效解决了现有方案的延迟、漂移等问题，在多用户VR交互的关键性能指标上表现更优。

Abstract: We introduce a multi-user VR co-location framework that synchronizes users
within a shared virtual environment aligned to physical space. Our approach
combines a motion capture system with SLAM-based inside-out tracking to deliver
smooth, high-framerate, low-latency performance. Previous methods either rely
on continuous external tracking, which introduces latency and jitter, or on
one-time calibration, which cannot correct drift over time. In contrast, our
approach combines the responsiveness of local HMD SLAM tracking with the
flexibility to realign to an external source when needed. It also supports
real-time pose sharing across devices, ensuring consistent spatial alignment
and engagement between users. Our evaluation demonstrates that our framework
achieves the spatial accuracy required for natural multi-user interaction while
offering improved comfort, scalability, and robustness over existing co-located
VR solutions.

</details>


### [38] [A Robust Approach for LiDAR-Inertial Odometry Without Sensor-Specific Modeling](https://arxiv.org/abs/2509.06593)
*Meher V. R. Malladi,Tiziano Guadagnino,Luca Lobefaro,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 本文提出一种鲁棒的激光雷达-惯性里程计系统，无需依赖传感器特定建模，通过简化IMU集成运动模型和直接激光雷达扫描到地图配准，并引入新正则化方法提升性能，在多种传感器和平台数据集上验证了其在不同场景下的鲁棒性且配置一致，同时开源实现。


<details>
  <summary>Details</summary>
Motivation: 传感器基里程计方法需在不同传感器类型和目标领域（如城市驾驶场景的固态激光雷达、非结构化自然环境的手持旋转激光雷达）中保持鲁棒性，而现有激光雷达与IMU数据融合技术常依赖传感器特定建模。

Method: 提出一种无需传感器特定建模的鲁棒激光雷达-惯性里程计系统，采用简化的IMU集成运动模型，通过扫描到地图的方式直接配准激光雷达扫描，并对激光雷达配准施加新的正则化。

Result: 在涵盖多种常用机器人传感器和平台的多个数据集上进行了广泛实验，证明该方法在所有场景下使用完全相同的配置即可工作，展示了其鲁棒性。

Conclusion: 所提出的激光雷达-惯性里程计系统具有传感器无关性和场景鲁棒性，相同配置适用于不同传感器和环境，开源实现有助于社区进一步研究和应用于导航堆栈。

Abstract: Accurate odometry is a critical component in a robotic navigation stack, and
subsequent modules such as planning and control often rely on an estimate of
the robot's motion. Sensor-based odometry approaches should be robust across
sensor types and deployable in different target domains, from solid-state
LiDARs mounted on cars in urban-driving scenarios to spinning LiDARs on
handheld packages used in unstructured natural environments. In this paper, we
propose a robust LiDAR-inertial odometry system that does not rely on
sensor-specific modeling. Sensor fusion techniques for LiDAR and inertial
measurement unit (IMU) data typically integrate IMU data iteratively in a
Kalman filter or use pre-integration in a factor graph framework, combined with
LiDAR scan matching often exploiting some form of feature extraction. We
propose an alternative strategy that only requires a simplified motion model
for IMU integration and directly registers LiDAR scans in a scan-to-map
approach. Our approach allows us to impose a novel regularization on the LiDAR
registration, improving the overall odometry performance. We detail extensive
experiments on a number of datasets covering a wide array of commonly used
robotic sensors and platforms. We show that our approach works with the exact
same configuration in all these scenarios, demonstrating its robustness. We
have open-sourced our implementation so that the community can build further on
our work and use it in their navigation stacks.

</details>


### [39] [LiHRA: A LiDAR-Based HRI Dataset for Automated Risk Monitoring Methods](https://arxiv.org/abs/2509.06597)
*Frederik Plahl,Georgios Katranis,Ilshat Mamaev,Andrey Morozov*

Main category: cs.RO

TL;DR: 提出了LiHRA数据集，用于促进人机交互（HRI）场景下自动化、基于学习或经典的风险监测（RM）方法的开发，包含多模态数据，覆盖6种HRI场景，共4431个标记点云，还展示了一种基于上下文信息的RM方法。


<details>
  <summary>Details</summary>
Motivation: 随着工业环境中协作机器人的普及，对可靠安全系统的需求增加，但缺乏捕捉包括潜在危险事件在内的真实人机交互的高质量数据集，阻碍了相关发展。

Method: 提供综合的多模态数据集，结合3D LiDAR点云、人体关键点和机器人关节状态，覆盖六种代表性HRI场景（协作共存任务、物体交接、表面抛光等），每种场景有安全和危险版本，共4431个标记点云（10Hz记录），并引入利用机器人状态和动态模型量化风险水平的RM方法。

Result: LiHRA数据集为训练和基准测试经典及AI驱动的RM算法提供了丰富资源，所展示的RM方法能随时间量化各场景的风险水平。

Conclusion: LiHRA凭借高分辨率LiDAR数据、精确人体跟踪、机器人状态数据和真实碰撞事件，为未来人机工作空间实时RM和自适应安全策略研究提供了重要基础。

Abstract: We present LiHRA, a novel dataset designed to facilitate the development of
automated, learning-based, or classical risk monitoring (RM) methods for
Human-Robot Interaction (HRI) scenarios. The growing prevalence of
collaborative robots in industrial environments has increased the need for
reliable safety systems. However, the lack of high-quality datasets that
capture realistic human-robot interactions, including potentially dangerous
events, slows development. LiHRA addresses this challenge by providing a
comprehensive, multi-modal dataset combining 3D LiDAR point clouds, human body
keypoints, and robot joint states, capturing the complete spatial and dynamic
context of human-robot collaboration. This combination of modalities allows for
precise tracking of human movement, robot actions, and environmental
conditions, enabling accurate RM during collaborative tasks. The LiHRA dataset
covers six representative HRI scenarios involving collaborative and coexistent
tasks, object handovers, and surface polishing, with safe and hazardous
versions of each scenario. In total, the data set includes 4,431 labeled point
clouds recorded at 10 Hz, providing a rich resource for training and
benchmarking classical and AI-driven RM algorithms. Finally, to demonstrate
LiHRA's utility, we introduce an RM method that quantifies the risk level in
each scenario over time. This method leverages contextual information,
including robot states and the dynamic model of the robot. With its combination
of high-resolution LiDAR data, precise human tracking, robot state data, and
realistic collision events, LiHRA offers an essential foundation for future
research into real-time RM and adaptive safety strategies in human-robot
workspaces.

</details>


### [40] [T-araVLN: Translator for Agricultural Robotic Agents on Vision-and-Language Navigation](https://arxiv.org/abs/2509.06644)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 本文提出T-araVLN方法，通过指令翻译模块优化复杂指令，在A2A基准上提升农业机器人视觉语言导航性能，SR从0.47升至0.63，NE从2.91m降至2.28m，达领域最佳。


<details>
  <summary>Details</summary>
Motivation: 农业机器人依赖人工或固定轨道移动，现有AgriVLN方法难以理解复杂自然语言指令，需提升导航精度。

Method: 提出T-araVLN方法，包含Instruction Translator模块，将原始指令翻译为更精炼准确的版本，以优化视觉语言导航。

Result: 在A2A基准测试中，T-araVLN将成功率（SR）从0.47提高到0.63，导航误差（NE）从2.91米减少到2.28米，表现出最先进性能。

Conclusion: T-araVLN通过指令优化有效提升了农业机器人复杂指令理解能力，显著改善导航性能，为农业视觉语言导航领域提供新方案。

Abstract: Agricultural robotic agents have been becoming powerful helpers in a wide
range of agricultural tasks, nevertheless, still heavily rely on manual
operation or untransportable railway for movement. The AgriVLN method and the
A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the
agricultural domain, enabling agents navigate to the target position following
the natural language instructions. AgriVLN effectively understands the simple
instructions, however, often misunderstands the complicated instructions. To
bridge this gap, we propose the method of Translator for Agricultural Robotic
Agents on Vision-and-Language Navigation (T-araVLN), in which the Instruction
Translator module translates the original instruction to be both refined and
precise. Being evaluated on the A2A benchmark, our T-araVLN effectively
improves SR from 0.47 to 0.63 and reduces NE from 2.91m to 2.28m, demonstrating
the state-of-the-art performance in the agricultural domain. Code:
https://github.com/AlexTraveling/T-araVLN.

</details>


### [41] [An Adaptive Coverage Control Approach for Multiple Autonomous Off-road Vehicles in Dynamic Agricultural Fields](https://arxiv.org/abs/2509.06682)
*Sajad Ahmadi,Mohammadreza Davoodi,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 本文提出了一种适用于越野和无人地面车辆（UGVs）在动态农业环境中的自适应覆盖控制方法


<details>
  <summary>Details</summary>
Motivation: 传统覆盖控制方法常假设静态条件，不适用于存在移动机械和不平地形等障碍物的现实农业场景

Method: 整合无人机（UAVs）进行障碍物检测和地形评估，将环境建模为加权有向图，基于无人机观测持续更新边权重，并结合 Voronoi 分区、自适应边权重分配和基于成本的路径优化

Result: 仿真结果表明该方法在动态障碍物和泥泞地形下能有效改进路径规划、降低遍历成本并保持稳健覆盖

Conclusion: 所提出的实时路径规划框架对动态农业环境中UGVs的覆盖控制有效

Abstract: This paper presents an adaptive coverage control method for a fleet of
off-road and Unmanned Ground Vehicles (UGVs) operating in dynamic
(time-varying) agricultural environments. Traditional coverage control
approaches often assume static conditions, making them unsuitable for
real-world farming scenarios where obstacles, such as moving machinery and
uneven terrains, create continuous challenges. To address this, we propose a
real-time path planning framework that integrates Unmanned Aerial Vehicles
(UAVs) for obstacle detection and terrain assessment, allowing UGVs to
dynamically adjust their coverage paths. The environment is modeled as a
weighted directed graph, where the edge weights are continuously updated based
on the UAV observations to reflect obstacle motion and terrain variations. The
proposed approach incorporates Voronoi-based partitioning, adaptive edge weight
assignment, and cost-based path optimization to enhance navigation efficiency.
Simulation results demonstrate the effectiveness of the proposed method in
improving path planning, reducing traversal costs, and maintaining robust
coverage in the presence of dynamic obstacles and muddy terrains.

</details>


### [42] [Safe Robust Predictive Control-based Motion Planning of Automated Surface Vessels in Inland Waterways](https://arxiv.org/abs/2509.06687)
*Sajad Ahmadi,Hossein Nejatbakhsh Esfahani,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 本文提出一种结合鲁棒模型预测控制（RMPC）与控制障碍函数（CBFs）的自主水面舰艇（ASVs）运动规划方法，以应对内陆水道导航的挑战，确保避碰和鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 现有自主舰艇导航方法在内陆水道（如狭窄航道、高交通密度、水动力干扰）中缺乏足够的鲁棒性和精度。

Method: 采用鲁棒模型预测控制（RMPC）与控制障碍函数（CBFs）相结合的方法，将航道边界和障碍物作为安全约束纳入控制设计框架。

Result: 仿真结果表明，该方法能在真实条件下安全引导ASVs，相比现有技术具有更高的安全性和适应性。

Conclusion: 所提方法有效解决了ASVs在内陆复杂水道中的导航问题，提升了避碰能力和鲁棒性。

Abstract: Deploying self-navigating surface vessels in inland waterways offers a
sustainable alternative to reduce road traffic congestion and emissions.
However, navigating confined waterways presents unique challenges, including
narrow channels, higher traffic density, and hydrodynamic disturbances.
Existing methods for autonomous vessel navigation often lack the robustness or
precision required for such environments. This paper presents a new motion
planning approach for Automated Surface Vessels (ASVs) using Robust Model
Predictive Control (RMPC) combined with Control Barrier Functions (CBFs). By
incorporating channel borders and obstacles as safety constraints within the
control design framework, the proposed method ensures both collision avoidance
and robust navigation on complex waterways. Simulation results demonstrate the
efficacy of the proposed method in safely guiding ASVs under realistic
conditions, highlighting its improved safety and adaptability compared to the
state-of-the-art.

</details>


### [43] [Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots](https://arxiv.org/abs/2509.06768)
*Oluwadamilola Sotomi,Devika Kodi,Kiruthiga Chandra Shekar,Aliasghar Arab*

Main category: cs.RO

TL;DR: 提出了一种集成视觉语言模型和大型语言模型的多模态异常检测与缓解系统，能实时识别和报告危险情况与冲突，通过主动检测机制和自动化缓解行动使机器人感知、解释、报告并在可能时应对城市和环境异常，用户研究显示其异常检测准确率达91.2%且响应延迟低。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在动态环境中需识别和报告异常，体现主动缓解可提高安全性和操作连续性。

Method: 集成视觉语言模型和大型语言模型，将危险和冲突状态纳入机器人决策框架，每种异常类型触发特定缓解策略，并采用边缘AI架构。

Result: 用户研究（n=30）表明系统异常检测准确率为91.2%，响应延迟较低。

Conclusion: 该多模态异常检测与缓解系统有效，能实时识别和报告异常，主动缓解策略可提高机器人安全性和操作连续性。

Abstract: Autonomous robots operating in dynamic environments should identify and
report anomalies. Embodying proactive mitigation improves safety and
operational continuity. This paper presents a multimodal anomaly detection and
mitigation system that integrates vision-language models and large language
models to identify and report hazardous situations and conflicts in real-time.
The proposed system enables robots to perceive, interpret, report, and if
possible respond to urban and environmental anomalies through proactive
detection mechanisms and automated mitigation actions. A key contribution in
this paper is the integration of Hazardous and Conflict states into the robot's
decision-making framework, where each anomaly type can trigger specific
mitigation strategies. User studies (n = 30) demonstrated the effectiveness of
the system in anomaly detection with 91.2% prediction accuracy and relatively
low latency response times using edge-ai architecture.

</details>


### [44] [CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation](https://arxiv.org/abs/2509.06819)
*Daniel San José Pro,Oliver Hausdörfer,Ralf Römer,Maximilian Dösch,Martin Schuck,Angela P. Schöllig*

Main category: cs.RO

TL;DR: 本文提出CRISP，一种轻量级C++实现的ROS2兼容笛卡尔和关节空间柔顺控制器，旨在与基于学习的高级策略及遥操作无缝集成，适用于暴露关节扭矩接口的机械臂，通过Python和Gymnasium接口提供统一的数据记录与策略部署管道，已在Franka FR3硬件及Kuka IIWA14、Kinova Gen3仿真中验证，降低学习方法在ROS2机械臂上的应用门槛。


<details>
  <summary>Details</summary>
Motivation: 学习型控制器常生成低频或不连续的机器人状态变化，实现平滑参考跟踪需低级控制器将高级目标命令转换为关节扭矩，以在接触交互中实现柔顺行为。

Method: 提出CRISP，一种轻量级C++实现的ROS2控制标准兼容的笛卡尔和关节空间柔顺控制器，兼容任何暴露关节扭矩接口的机械臂，提供Python和Gymnasium接口实现硬件与仿真数据记录及高级学习策略部署的统一管道。

Result: 系统已在Franka Robotics FR3硬件上以及Kuka IIWA14和Kinova Gen3的仿真中得到验证。

Conclusion: CRISP设计用于快速集成、灵活部署和实时性能，提供数据收集和策略执行的统一管道，降低了在ROS2兼容机械臂上应用基于学习方法的障碍。

Abstract: Learning-based controllers, such as diffusion policies and vision-language
action models, often generate low-frequency or discontinuous robot state
changes. Achieving smooth reference tracking requires a low-level controller
that converts high-level targets commands into joint torques, enabling
compliant behavior during contact interactions. We present CRISP, a lightweight
C++ implementation of compliant Cartesian and joint-space controllers for the
ROS2 control standard, designed for seamless integration with high-level
learning-based policies as well as teleoperation. The controllers are
compatible with any manipulator that exposes a joint-torque interface. Through
our Python and Gymnasium interfaces, CRISP provides a unified pipeline for
recording data from hardware and simulation and deploying high-level
learning-based policies seamlessly, facilitating rapid experimentation. The
system has been validated on hardware with the Franka Robotics FR3 and in
simulation with the Kuka IIWA14 and Kinova Gen3. Designed for rapid
integration, flexible deployment, and real-time performance, our implementation
provides a unified pipeline for data collection and policy execution, lowering
the barrier to applying learning-based methods on ROS2-compatible manipulators.
Detailed documentation is available at the project website -
https://utiasDSL.github.io/crisp_controllers.

</details>


### [45] [Dynamic Modeling and Efficient Data-Driven Optimal Control for Micro Autonomous Surface Vehicles](https://arxiv.org/abs/2509.06882)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 本文提出了一种用于过驱动微型自主水面车辆（MicroASV）的物理驱动动力学模型和数据驱动最优控制框架，通过基于弱公式的在线模型学习方法持续优化模型，提升了轨迹跟踪精度和鲁棒性，尤其在未知负载和外部干扰下效果显著。


<details>
  <summary>Details</summary>
Motivation: 微型自主水面车辆（MicroASV）在受限或浅水区及群体机器人应用中潜力巨大，但在小尺度下实现精确鲁棒控制面临挑战，主要源于非线性水动力建模复杂、对自身运动效应及环境干扰（如波浪、受限空间边界效应）敏感性增加。

Method: 提出了过驱动MicroASV的物理驱动动力学模型，并引入数据驱动最优控制框架，该框架利用基于弱公式的在线模型学习方法，实时持续优化物理驱动模型，实现自适应控制以适应系统参数变化。

Result: 仿真结果表明，所提方法显著提高了轨迹跟踪精度和鲁棒性，即使在未知负载和外部干扰情况下亦然。

Conclusion: 研究结果突显了数据驱动在线学习最优控制在提升MicroASV性能方面的潜力，为更可靠、精确的自主水面车辆操作铺平了道路。

Abstract: Micro Autonomous Surface Vehicles (MicroASVs) offer significant potential for
operations in confined or shallow waters and swarm robotics applications.
However, achieving precise and robust control at such small scales remains
highly challenging, mainly due to the complexity of modeling nonlinear
hydrodynamic forces and the increased sensitivity to self-motion effects and
environmental disturbances, including waves and boundary effects in confined
spaces. This paper presents a physics-driven dynamics model for an
over-actuated MicroASV and introduces a data-driven optimal control framework
that leverages a weak formulation-based online model learning method. Our
approach continuously refines the physics-driven model in real time, enabling
adaptive control that adjusts to changing system parameters. Simulation results
demonstrate that the proposed method substantially enhances trajectory tracking
accuracy and robustness, even under unknown payloads and external disturbances.
These findings highlight the potential of data-driven online learning-based
optimal control to improve MicroASV performance, paving the way for more
reliable and precise autonomous surface vehicle operations.

</details>


### [46] [LLaDA-VLA: Vision Language Diffusion Action Models](https://arxiv.org/abs/2509.06932)
*Yuqing Wen,Hebei Li,Kefan Gu,Yucheng Zhao,Tiancai Wang,Xiaoyan Sun*

Main category: cs.RO

TL;DR: 本文提出首个基于预训练扩散型视觉语言模型（d-VLMs）的视觉-语言-扩散-动作模型LLaDA-VLA，用于机器人操作，通过局部特殊令牌分类和分层动作结构解码策略，在模拟和真实机器人上显著优于现有VLA模型。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视觉语言模型启发了机器人操作的视觉语言动作模型（VLA），而扩散模型在文本生成和多模态应用中表现出竞争力，但其在机器人策略学习中的应用尚未充分探索。

Method: 1. 局部特殊令牌分类策略：用特殊动作令牌分类替代全词汇分类，降低适配难度；2. 分层动作结构解码策略：考虑动作内部和跨动作的依赖关系，分层解码动作序列。

Result: LLaDA-VLA在模拟和真实世界机器人上均显著优于最先进的VLA模型。

Conclusion: 基于预训练d-VLMs构建的LLaDA-VLA通过关键设计有效适应机器人领域，在机器人操作任务上实现了性能提升。

Abstract: The rapid progress of auto-regressive vision-language models (VLMs) has
inspired growing interest in vision-language-action models (VLA) for robotic
manipulation. Recently, masked diffusion models, a paradigm distinct from
autoregressive models, have begun to demonstrate competitive performance in
text generation and multimodal applications, leading to the development of a
series of diffusion-based VLMs (d-VLMs). However, leveraging such models for
robot policy learning remains largely unexplored. In this work, we present
LLaDA-VLA, the first Vision-Language-Diffusion-Action model built upon
pretrained d-VLMs for robotic manipulation. To effectively adapt d-VLMs to
robotic domain, we introduce two key designs: (1) a localized special-token
classification strategy that replaces full-vocabulary classification with
special action token classification, reducing adaptation difficulty; (2) a
hierarchical action-structured decoding strategy that decodes action sequences
hierarchically considering the dependencies within and across actions.
Extensive experiments demonstrate that LLaDA-VLA significantly outperforms
state-of-the-art VLAs on both simulation and real-world robots.

</details>


### [47] [F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions](https://arxiv.org/abs/2509.06951)
*Qi Lv,Weijie Kong,Hao Li,Jia Zeng,Zherui Qiu,Delin Qu,Haoming Song,Qizhi Chen,Xiang Deng,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 本文介绍了F1，一个集成视觉预见性生成到决策流程的预训练VLA框架，通过混合Transformer架构和三阶段训练，在动态视觉环境中执行语言条件任务时，相比现有方法在任务成功率和泛化能力上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要采用反应式状态到动作的映射，在动态场景中常导致短视行为和较差的鲁棒性。

Method: F1采用混合Transformer架构，包含感知、预见性生成和控制的专用模块；核心是采用下一级预测机制合成目标条件视觉预见性作为显式规划目标，将动作生成重构为预见性引导的逆动力学问题；并在包含33万+轨迹的136个多样任务数据集上采用三阶段训练方法。

Result: 在现实世界任务和模拟基准上的广泛评估表明，F1持续优于现有方法，在任务成功率和泛化能力上均取得显著提升。

Conclusion: F1通过整合视觉预见性生成和专用架构及训练方法，有效解决了动态视觉环境中语言条件任务执行的挑战，展现出更强的性能和泛化能力。

Abstract: Executing language-conditioned tasks in dynamic visual environments remains a
central challenge in embodied AI. Existing Vision-Language-Action (VLA) models
predominantly adopt reactive state-to-action mappings, often leading to
short-sighted behaviors and poor robustness in dynamic scenes. In this paper,
we introduce F1, a pretrained VLA framework which integrates the visual
foresight generation into decision-making pipeline. F1 adopts a
Mixture-of-Transformer architecture with dedicated modules for perception,
foresight generation, and control, thereby bridging understanding, generation,
and actions. At its core, F1 employs a next-scale prediction mechanism to
synthesize goal-conditioned visual foresight as explicit planning targets. By
forecasting plausible future visual states, F1 reformulates action generation
as a foresight-guided inverse dynamics problem, enabling actions that
implicitly achieve visual goals. To endow F1 with robust and generalizable
capabilities, we propose a three-stage training recipe on an extensive dataset
comprising over 330k trajectories across 136 diverse tasks. This training
scheme enhances modular reasoning and equips the model with transferable visual
foresight, which is critical for complex and dynamic environments. Extensive
evaluations on real-world tasks and simulation benchmarks demonstrate F1
consistently outperforms existing approaches, achieving substantial gains in
both task success rate and generalization ability.

</details>


### [48] [Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments](https://arxiv.org/abs/2509.06953)
*Jiahui Yang,Jason Jingzhou Liu,Yulong Li,Youssef Khaky,Kenneth Shaw,Deepak Pathak*

Main category: cs.RO

TL;DR: 本文提出Deep Reactive Policy (DRP)，一种基于视觉-运动神经运动策略，用于在多样动态环境中生成反应式运动，直接处理点云感官输入，其核心是基于Transformer的神经运动策略IMPACT，通过预训练和微调提升静态避障，结合DCP-RMP增强动态避障，在模拟和现实环境中成功率优于传统和神经方法。


<details>
  <summary>Details</summary>
Motivation: 动态、部分可观测环境中生成无碰撞运动是机器人操纵器的基本挑战，传统运动规划器需完整环境知识且对动态场景太慢，神经运动策略虽能闭环运行但在复杂或动态环境中泛化能力差。

Method: 提出DRP，核心为IMPACT（基于Transformer的神经运动策略，在1000万生成的专家轨迹上预训练），通过迭代师生微调改善静态避障，推理时用DCP-RMP（局部反应式目标提议模块）增强动态避障。

Result: DRP在具有杂乱场景、动态移动障碍物和目标遮挡的挑战性任务中表现出强泛化能力，在模拟和现实世界环境中的成功率均优于先前的传统和神经方法。

Conclusion: DRP在多样动态环境中生成反应式运动方面效果显著，优于传统和神经方法，具有良好的泛化能力，在模拟和现实场景中成功率高。

Abstract: Generating collision-free motion in dynamic, partially observable
environments is a fundamental challenge for robotic manipulators. Classical
motion planners can compute globally optimal trajectories but require full
environment knowledge and are typically too slow for dynamic scenes. Neural
motion policies offer a promising alternative by operating in closed-loop
directly on raw sensory inputs but often struggle to generalize in complex or
dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural
motion policy designed for reactive motion generation in diverse dynamic
environments, operating directly on point cloud sensory input. At its core is
IMPACT, a transformer-based neural motion policy pretrained on 10 million
generated expert trajectories across diverse simulation scenarios. We further
improve IMPACT's static obstacle avoidance through iterative student-teacher
finetuning. We additionally enhance the policy's dynamic obstacle avoidance at
inference time using DCP-RMP, a locally reactive goal-proposal module. We
evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving
obstacles, and goal obstructions. DRP achieves strong generalization,
outperforming prior classical and neural methods in success rate across both
simulated and real-world settings. Video results and code available at
https://deep-reactive-policy.com

</details>
