<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 12]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Interprofessional and Agile Development of Mobirobot: A Socially Assistive Robot for Pediatric Therapy Across Clinical and Therapeutic Settings](https://arxiv.org/abs/2601.09838)
*Leonie Dyck,Aiko Galetzka,Maximilian Noller,Anna-Lena Rinke,Jutta Bormann,Jekaterina Miller,Michelle Hochbaum,Julia Siemann,Jördis Alboth,Andre Berwinkel,Johanna Luz,Britta Kley-Zobel,Marcine Cyrys,Nora Flöttmann,Ariane Vogeler,Mariia Melnikova,Ira-Katharina Petras,Michael Siniatchkin,Winfried Barthlen,Anna-Lisa Vollmer*

Main category: cs.RO

TL;DR: This paper presents Mobirobot, a socially assistive robot developed via human-centred, agile co-development with multidisciplinary teams and end users, aiming to support children's mobilisation post-trauma/fractures/depression through personalised exercises; deployment identified key design needs, leading to refinements, and a feasibility study is ongoing to assess acceptance, usability, and therapeutic benefit.


<details>
  <summary>Details</summary>
Motivation: To address the need for context-sensitive, co-designed socially assistive robots to enhance therapeutic engagement in paediatric clinical settings, specifically supporting children's mobilisation during recovery from trauma, fractures, or depressive disorders.

Method: An agile, human-centred development approach with iterative design, involving multidisciplinary clinical teams and end users in co-development, integrating early into real-world paediatric surgical/psychiatric settings; based on the NAO platform, with features like simple setup, adaptable exercise routines, interactive guidance, motivational dialogue, and a GUI for monitoring and no-code feedback.

Result: Deployment in hospitals identified key design requirements and usability constraints; stakeholder feedback led to refinements in interaction design, movement capabilities, and technical configuration; a feasibility study is underway assessing acceptance, usability, and perceived therapeutic benefit via questionnaires, observations, and interviews.

Conclusion: Mobirobot demonstrates the value of multiprofessional, stakeholder-led development for socially assistive systems in dynamic inpatient settings; early findings highlight importance of contextual integration, robustness, and minimal-intrusion design, with remaining challenges (sensor limitations, patient recruitment) but promising potential for further research and clinical application.

Abstract: Introduction: Socially assistive robots hold promise for enhancing therapeutic engagement in paediatric clinical settings. However, their successful implementation requires not only technical robustness but also context-sensitive, co-designed solutions. This paper presents Mobirobot, a socially assistive robot developed to support mobilisation in children recovering from trauma, fractures, or depressive disorders through personalised exercise programmes.
  Methods: An agile, human-centred development approach guided the iterative design of Mobirobot. Multidisciplinary clinical teams and end users were involved throughout the co-development process, which focused on early integration into real-world paediatric surgical and psychiatric settings. The robot, based on the NAO platform, features a simple setup, adaptable exercise routines with interactive guidance, motivational dialogue, and a graphical user interface (GUI) for monitoring and no-code system feedback.
  Results: Deployment in hospital environments enabled the identification of key design requirements and usability constraints. Stakeholder feedback led to refinements in interaction design, movement capabilities, and technical configuration. A feasibility study is currently underway to assess acceptance, usability, and perceived therapeutic benefit, with data collection including questionnaires, behavioural observations, and staff-patient interviews.
  Discussion: Mobirobot demonstrates how multiprofessional, stakeholder-led development can yield a socially assistive system suited for dynamic inpatient settings. Early-stage findings underscore the importance of contextual integration, robustness, and minimal-intrusion design. While challenges such as sensor limitations and patient recruitment remain, the platform offers a promising foundation for further research and clinical application.

</details>


### [2] [How Human Motion Prediction Quality Shapes Social Robot Navigation Performance in Constrained Spaces](https://arxiv.org/abs/2601.09856)
*Andrew Stratton,Phani Teja Singamaneni,Pranav Goyal,Rachid Alami,Christoforos Mavrogiannis*

Main category: cs.RO

TL;DR: 该研究聚焦动态和空间受限环境下的机器人导航，通过用户研究（N=80）系统探讨人类运动预测质量对机器人导航性能、人类生产力及印象的影响，涉及两个机器人平台和两个不同地区实验，发现平均位移误差不可靠、人类合作假设在受限环境失效、机器人导航效率提升常以人类效率和舒适度为代价。


<details>
  <summary>Details</summary>
Motivation: 为实现移动机器人在仓库、医院、工厂及家庭等场景中与人类更紧密集成，需赋予机器人人类运动模型，但人类行为随机性、用户偏好差异及数据稀缺使预测具挑战性，故研究人类运动预测质量对机器人导航等多方面的影响。

Method: 设计在受限工作空间中机器人与两名人类受试者互动的场景，在两个不同世界地区的实验点，使用两个不同机器人平台开展包含80名受试者的用户研究，系统调查人类运动预测质量的影响。

Result: 主要发现包括：1）广泛采用的平均位移误差不能可靠预测机器人导航性能和人类印象；2）在受限环境中，人类合作的常见假设不成立，用户常不回报机器人合作并导致性能下降；3）更高效的机器人导航往往以人类效率和舒适度为代价。

Conclusion: 研究揭示了人类运动预测质量对机器人导航及人机交互的关键影响，指出平均位移误差的局限性、人类合作假设在受限环境的失效及机器人效率与人类体验间的权衡关系，为优化人机协作导航系统提供了重要依据。

Abstract: Motivated by the vision of integrating mobile robots closer to humans in warehouses, hospitals, manufacturing plants, and the home, we focus on robot navigation in dynamic and spatially constrained environments. Ensuring human safety, comfort, and efficiency in such settings requires that robots are endowed with a model of how humans move around them. Human motion prediction around robots is especially challenging due to the stochasticity of human behavior, differences in user preferences, and data scarcity. In this work, we perform a methodical investigation of the effects of human motion prediction quality on robot navigation performance, as well as human productivity and impressions. We design a scenario involving robot navigation among two human subjects in a constrained workspace and instantiate it in a user study ($N=80$) involving two different robot platforms, conducted across two sites from different world regions. Key findings include evidence that: 1) the widely adopted average displacement error is not a reliable predictor of robot navigation performance and human impressions; 2) the common assumption of human cooperation breaks down in constrained environments, with users often not reciprocating robot cooperation, and causing performance degradations; 3) more efficient robot navigation often comes at the expense of human efficiency and comfort.

</details>


### [3] [SyncTwin: Fast Digital Twin Construction and Synchronization for Safe Robotic Grasping](https://arxiv.org/abs/2601.09920)
*Ruopeng Huang,Boyu Yang,Wenlong Gui,Jeremy Morgan,Erdem Biyik,Jiachen Li*

Main category: cs.RO

TL;DR: SyncTwin是一个数字孪生框架，通过快速3D场景重建和虚实同步，解决动态及视觉遮挡环境下机器人抓取的准确性与安全性问题。


<details>
  <summary>Details</summary>
Motivation: 动态及视觉遮挡条件下的准确安全抓取是现实世界机器人操作的核心挑战。

Method: 离线阶段利用VGGT从RGB图像快速重建物体级3D资产形成仿真几何库；执行阶段通过点云分割更新跟踪物体状态，经彩色ICP配准对齐实现数字孪生持续同步，使运动规划器在仿真中计算无碰撞且动态可行轨迹，通过虚实闭环安全执行。

Result: 在动态和遮挡场景实验中，SyncTwin提高了抓取精度和运动安全性。

Conclusion: 数字孪生同步对现实世界机器人执行具有有效性。

Abstract: Accurate and safe grasping under dynamic and visually occluded conditions remains a core challenge in real-world robotic manipulation. We present SyncTwin, a digital twin framework that unifies fast 3D scene reconstruction and real-to-sim synchronization for robust and safety-aware grasping in such environments. In the offline stage, we employ VGGT to rapidly reconstruct object-level 3D assets from RGB images, forming a reusable geometry library for simulation. During execution, SyncTwin continuously synchronizes the digital twin by tracking real-world object states via point cloud segmentation updates and aligning them through colored-ICP registration. The updated twin enables motion planners to compute collision-free and dynamically feasible trajectories in simulation, which are safely executed on the real robot through a closed real-to-sim-to-real loop. Experiments in dynamic and occluded scenes show that SyncTwin improves grasp accuracy and motion safety, demonstrating the effectiveness of digital-twin synchronization for real-world robotic execution.

</details>


### [4] [In-the-Wild Compliant Manipulation with UMI-FT](https://arxiv.org/abs/2601.09988)
*Hojung Choi,Yifan Hou,Chuer Pan,Seongheon Hong,Austin Patel,Xiaomeng Xu,Mark R. Cutkosky,Shuran Song*

Main category: cs.RO

TL;DR: This paper introduces UMI-FT, a handheld data-collection platform with finger-level F/T sensors, enabling multimodal data collection and training of an adaptive compliance policy for force-sensitive manipulation tasks, outperforming baselines in evaluations.


<details>
  <summary>Details</summary>
Motivation: Commercial F/T sensors are costly, bulky, and fragile, limiting large-scale force-aware policy learning for manipulation tasks requiring careful force modulation.

Method: Develop UMI-FT, a handheld platform with compact six-axis F/T sensors on each finger for finger-level wrench measurements alongside RGB, depth, and pose data; train an adaptive compliance policy predicting position targets, grasp force, and stiffness using multimodal data for execution on standard compliance controllers.

Result: Evaluations on three force-sensitive tasks (whiteboard wiping, skewering zucchini, lightbulb insertion) show UMI-FT enables policies that reliably regulate external contact and internal grasp forces, outperforming baselines lacking compliance or force sensing.

Conclusion: UMI-FT provides a scalable path to learning compliant manipulation from in-the-wild demonstrations, with open-sourced hardware and software to facilitate broader adoption.

Abstract: Many manipulation tasks require careful force modulation. With insufficient force the task may fail, while excessive force could cause damage. The high cost, bulky size and fragility of commercial force/torque (F/T) sensors have limited large-scale, force-aware policy learning. We introduce UMI-FT, a handheld data-collection platform that mounts compact, six-axis force/torque sensors on each finger, enabling finger-level wrench measurements alongside RGB, depth, and pose. Using the multimodal data collected from this device, we train an adaptive compliance policy that predicts position targets, grasp force, and stiffness for execution on standard compliance controllers. In evaluations on three contact-rich, force-sensitive tasks (whiteboard wiping, skewering zucchini, and lightbulb insertion), UMI-FT enables policies that reliably regulate external contact forces and internal grasp forces, outperforming baselines that lack compliance or force sensing. UMI-FT offers a scalable path to learning compliant manipulation from in-the-wild demonstrations. We open-source the hardware and software to facilitate broader adoption at:https://umi-ft.github.io/.

</details>


### [5] [CoCoPlan: Adaptive Coordination and Communication for Multi-robot Systems in Dynamic and Unknown Environments](https://arxiv.org/abs/2601.10116)
*Xintong Zhang,Junfeng Chen,Yuxiao Zhu,Bing Luo,Meng Guo*

Main category: cs.RO

TL;DR: Multi-robot systems often face limited communication, leading to suboptimal coordination. CoCoPlan, a unified framework co-optimizing task planning and intermittent communication, integrates branch-and-bound architecture, adaptive objective function, and communication event optimization module. It outperforms SOTA with 22.4% higher task completion rate, 58.6% lower communication overhead, and scalability for 100 robots in dynamic environments, validated in 2D office and 3D disaster-response scenarios.


<details>
  <summary>Details</summary>
Motivation: Existing multi-robot coordination methods fail to adapt effectively to dynamic spatio-temporal task distributions under limited communication, resulting in suboptimal coordination.

Method: CoCoPlan is a unified framework that co-optimizes collaborative task planning and team-wise intermittent communication, integrating: 1) branch-and-bound architecture encoding task assignments and communication events; 2) adaptive objective function balancing task efficiency and communication latency; 3) communication event optimization module determining when, where, and how to re-establish global connectivity.

Result: Extensive experiments show CoCoPlan outperforms state-of-the-art methods with 22.4% higher task completion rate, 58.6% reduced communication overhead, and scalability supporting up to 100 robots in dynamic environments. Hardware experiments include 2D office and 3D disaster-response scenarios.

Conclusion: CoCoPlan effectively addresses the gap of suboptimal coordination under limited communication by co-optimizing task planning and intermittent communication, achieving superior performance in task completion, communication efficiency, and scalability, validated in diverse hardware scenarios.

Abstract: Multi-robot systems can greatly enhance efficiency through coordination and collaboration, yet in practice, full-time communication is rarely available and interactions are constrained to close-range exchanges. Existing methods either maintain all-time connectivity, rely on fixed schedules, or adopt pairwise protocols, but none adapt effectively to dynamic spatio-temporal task distributions under limited communication, resulting in suboptimal coordination. To address this gap, we propose CoCoPlan, a unified framework that co-optimizes collaborative task planning and team-wise intermittent communication. Our approach integrates a branch-and-bound architecture that jointly encodes task assignments and communication events, an adaptive objective function that balances task efficiency against communication latency, and a communication event optimization module that strategically determines when, where and how the global connectivity should be re-established. Extensive experiments demonstrate that it outperforms state-of-the-art methods by achieving a 22.4% higher task completion rate, reducing communication overhead by 58.6%, and improving the scalability by supporting up to 100 robots in dynamic environments. Hardware experiments include the complex 2D office environment and large-scale 3D disaster-response scenario.

</details>


### [6] [Terrain-Adaptive Mobile 3D Printing with Hierarchical Control](https://arxiv.org/abs/2601.10208)
*Shuangshan Nors Li,J. Nathan Kutz*

Main category: cs.RO

TL;DR: 该论文提出一种集成AI驱动扰动预测、多模态传感器融合和分层硬件控制的闭环系统，以解决非结构化地形上移动3D打印中平台移动性与沉积精度的冲突，在户外实验中实现了亚厘米级打印精度并保持平台完全移动性。


<details>
  <summary>Details</summary>
Motivation: 解决非结构化地形上移动3D打印中平台移动性与沉积精度之间的冲突，现有龙门系统精度高但缺乏移动性，移动平台在不平地面难以维持打印质量。

Method: 构建了一个紧密集成AI驱动扰动预测、多模态传感器融合和分层硬件控制的闭环感知-学习-驱动系统。AI模块从IMU、视觉和深度传感器学习地形-扰动映射，实现主动补偿；该智能嵌入三层控制架构：路径规划、预测性底盘-机械臂协调和精密硬件执行。

Result: 通过在具有斜坡和表面不规则的地形上进行户外实验，实现了亚厘米级打印精度，同时保持平台完全移动性。

Conclusion: 这种AI与硬件的集成为此类非结构化环境中的自主建造奠定了实用基础。

Abstract: Mobile 3D printing on unstructured terrain remains challenging due to the conflict between platform mobility and deposition precision. Existing gantry-based systems achieve high accuracy but lack mobility, while mobile platforms struggle to maintain print quality on uneven ground. We present a framework that tightly integrates AI-driven disturbance prediction with multi-modal sensor fusion and hierarchical hardware control, forming a closed-loop perception-learning-actuation system. The AI module learns terrain-to-perturbation mappings from IMU, vision, and depth sensors, enabling proactive compensation rather than reactive correction. This intelligence is embedded into a three-layer control architecture: path planning, predictive chassis-manipulator coordination, and precision hardware execution. Through outdoor experiments on terrain with slopes and surface irregularities, we demonstrate sub-centimeter printing accuracy while maintaining full platform mobility. This AI-hardware integration establishes a practical foundation for autonomous construction in unstructured environments.

</details>


### [7] [A Unified Framework for Kinematic Simulation of Rigid Foldable Structures](https://arxiv.org/abs/2601.10225)
*Dongwook Kwak,Geonhee Cho,Jiook Chung,Jinkyu Yang*

Main category: cs.RO

TL;DR: An automated approach is presented to generate the Pfaffian constraint matrix for arbitrary rigid foldable structures (RFS), enabling unified kinematic analysis by constructing facet-hinge graphs, extracting minimum cycle bases, and assembling velocity-level constraint matrices via screw theory to compute and visualize deploy/fold motions, eliminating tedious constraint calculations.


<details>
  <summary>Details</summary>
Motivation: Origami-inspired rigid panel structures now include thick, kirigami, and multi-sheet types, requiring unified kinematic analysis, but a general method consolidating loop constraints has been lacking.

Method: An automated approach: from a minimally extended data schema, construct the facet-hinge graph, extract a minimum cycle basis capturing all constraints, and assemble a velocity-level constraint matrix via screw theory encoding coupled rotation and translation loop closure.

Result: The framework computes and visualizes deploy and fold motions across diverse RFS while eliminating tedious and error-prone constraint calculations.

Conclusion: The presented automated approach provides a general method for unified kinematic analysis of arbitrary RFS by generating Pfaffian constraint matrices, addressing the lack of consolidated loop constraint methods.

Abstract: Origami-inspired structures with rigid panels now span thick, kirigami, and multi-sheet realizations, making unified kinematic analysis essential. Yet a general method that consolidates their loop constraints has been lacking. We present an automated approach that generates the Pfaffian constraint matrix for arbitrary rigid foldable structures (RFS). From a minimally extended data schema, the tool constructs the facet-hinge graph, extracts a minimum cycle basis that captures all constraints, and assembles a velocity-level constraint matrix via screw theory that encodes coupled rotation and translation loop closure. The framework computes and visualizes deploy and fold motions across diverse RFS while eliminating tedious and error-prone constraint calculations.

</details>


### [8] [Proactive Local-Minima-Free Robot Navigation: Blending Motion Prediction with Safe Control](https://arxiv.org/abs/2601.10233)
*Yifan Xue,Ze Zhang,Knut Åkesson,Nadia Figueroa*

Main category: cs.RO

TL;DR: This work addresses safe and efficient mobile robot navigation in complex dynamic environments with concave moving obstacles by using Gaussian processes to learn barrier functions online from multimodal motion predictions of obstacles and feeding them into quadratic programs with modulated CBFs (MCBFs), with contributions including a prediction-to-barrier function online learning pipeline and an autonomous parameter tuning algorithm, and evaluations showing outperformance over baselines in simulations and real-world experiments.


<details>
  <summary>Details</summary>
Motivation: Reactive safe controllers like Control Barrier Functions (CBFs) design obstacle avoidance strategies based only on the current states of the obstacles, risking future collisions.

Method: Using Gaussian processes to learn barrier functions online from multimodal motion predictions of obstacles generated by neural networks trained with energy-based learning, then feeding the learned barrier functions into quadratic programs using modulated CBFs (MCBFs).

Result: The framework is evaluated in both simulations and real-world experiments, consistently outperforming baselines and demonstrating superior safety and efficiency in crowded dynamic environments.

Conclusion: The proposed framework achieves safe and efficient navigation in complex dynamic environments with concave moving obstacles through the developed prediction-to-barrier function online learning pipeline and autonomous parameter tuning algorithm for MCBFs.

Abstract: This work addresses the challenge of safe and efficient mobile robot navigation in complex dynamic environments with concave moving obstacles. Reactive safe controllers like Control Barrier Functions (CBFs) design obstacle avoidance strategies based only on the current states of the obstacles, risking future collisions. To alleviate this problem, we use Gaussian processes to learn barrier functions online from multimodal motion predictions of obstacles generated by neural networks trained with energy-based learning. The learned barrier functions are then fed into quadratic programs using modulated CBFs (MCBFs), a local-minimum-free version of CBFs, to achieve safe and efficient navigation. The proposed framework makes two key contributions. First, it develops a prediction-to-barrier function online learning pipeline. Second, it introduces an autonomous parameter tuning algorithm that adapts MCBFs to deforming, prediction-based barrier functions. The framework is evaluated in both simulations and real-world experiments, consistently outperforming baselines and demonstrating superior safety and efficiency in crowded dynamic environments.

</details>


### [9] [The impact of tactile sensor configurations on grasp learning efficiency -- a comparative evaluation in simulation](https://arxiv.org/abs/2601.10268)
*Eszter Birtalan,Miklós Koller*

Main category: cs.RO

TL;DR: 该论文通过模拟评估6种不同密度和布局的触觉传感器配置对强化学习的影响，确定一种在两种设置下均表现最佳的配置，旨在为包括假肢在内的机器人手设计提供参考。


<details>
  <summary>Details</summary>
Motivation: 目前已发表的机器人手设计中，触觉传感器在手部表面的密度和布局差异大，常占用大量空间，需评估其对强化学习的影响以优化设计。

Method: 使用两种设置的系统进行模拟，评估6种不同密度和布局的触觉传感器配置，结果不受特定物理模拟器、机器人手模型或机器学习算法的依赖。

Result: 结果显示了特定设置的效果以及6种传感器化模拟的通用影响，确定一种配置在两种设置下均持续产生最佳性能。

Conclusion: 这些结果可为未来包括假肢在内的机器人手设计研究提供帮助。

Abstract: Tactile sensors are breaking into the field of robotics to provide direct information related to contact surfaces, including contact events, slip events and even texture identification. These events are especially important for robotic hand designs, including prosthetics, as they can greatly improve grasp stability. Most presently published robotic hand designs, however, implement them in vastly different densities and layouts on the hand surface, often reserving the majority of the available space. We used simulations to evaluate 6 different tactile sensor configurations with different densities and layouts, based on their impact on reinforcement learning. Our two-setup system allows for robust results that are not dependent on the use of a given physics simulator, robotic hand model or machine learning algorithm. Our results show setup-specific, as well as generalized effects across the 6 sensorized simulations, and we identify one configuration as consistently yielding the best performance across both setups. These results could help future research aimed at robotic hand designs, including prostheses.

</details>


### [10] [CHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing](https://arxiv.org/abs/2601.10340)
*David Morilla-Cabello,Eduardo Montijano*

Main category: cs.RO

TL;DR: This paper proposes an integrated semantic-aware framework (CHORAL) for coordinating heterogeneous robot teams in complex environments, using metric-semantic maps from open-vocabulary vision models to enable capability-aware routing and task assignment, with experiments showing improved safety and efficiency.


<details>
  <summary>Details</summary>
Motivation: Addressing navigation challenges in monitoring large, unknown, complex environments with heterogeneous robots, where existing approaches lack integration of semantic scene understanding into routing, limiting adaptation and leveraging of robot strengths.

Method: 1. Build metric-semantic map via open-vocabulary vision models from reconnaissance flight; 2. Identify regions needing inspection and capability-aware paths for each robot; 3. Formulate heterogeneous vehicle routing to jointly assign tasks and compute trajectories.

Result: Experiments in simulation and real inspection with three robots demonstrate the approach enables safer and more efficient routes by accounting for navigation capabilities.

Conclusion: The proposed CHORAL framework effectively coordinates heterogeneous robots through semantic-aware routing and task assignment, improving mission performance; released as open source for reproducibility and deployment.

Abstract: Monitoring large, unknown, and complex environments with autonomous robots poses significant navigation challenges, where deploying teams of heterogeneous robots with complementary capabilities can substantially improve both mission performance and feasibility. However, effectively modeling how different robotic platforms interact with the environment requires rich, semantic scene understanding. Despite this, existing approaches often assume homogeneous robot teams or focus on discrete task compatibility rather than continuous routing. Consequently, scene understanding is not fully integrated into routing decisions, limiting their ability to adapt to the environment and to leverage each robot's strengths. In this paper, we propose an integrated semantic-aware framework for coordinating heterogeneous robots. Starting from a reconnaissance flight, we build a metric-semantic map using open-vocabulary vision models and use it to identify regions requiring closer inspection and capability-aware paths for each platform to reach them. These are then incorporated into a heterogeneous vehicle routing formulation that jointly assigns inspection tasks and computes robot trajectories. Experiments in simulation and in a real inspection mission with three robotic platforms demonstrate the effectiveness of our approach in planning safer and more efficient routes by explicitly accounting for each platform's navigation capabilities. We release our framework, CHORAL, as open source to support reproducibility and deployment of diverse robot teams.

</details>


### [11] [FastStair: Learning to Run Up Stairs with Humanoid Robots](https://arxiv.org/abs/2601.10365)
*Yan Liu,Tao Yu,Haolin Song,Hongbo Zhu,Nianzong Hu,Yuzhi Hao,Xiuyong Yao,Xizhe Zang,Hua Chen,Jie Zhao*

Main category: cs.RO

TL;DR: FastStair是一种结合模型规划与强化学习的多阶段框架，通过并行模型基足点规划器引导RL探索、预训练安全基础策略，再经LoRA整合速度专家策略，使Oli人形机器人实现稳定高速楼梯攀爬（最高1.65 m/s，33级螺旋楼梯12秒完成），获广州塔机器人登高赛冠军。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人楼梯攀爬中高敏捷性与严格稳定性的矛盾，现有模型无关强化学习（RL）因隐含稳定性奖励和任务特定奖励塑造易导致不安全行为，模型基足点规划器虽编码接触可行性和稳定性结构但约束过强导致运动保守、限制速度。

Method: 提出FastStair框架：1. 整合并行模型基足点规划器到RL训练循环，引导探索至动态可行接触并预训练安全基础策略；2. 微调基础策略为速度专用专家，通过低秩适应（LoRA）整合以实现全指令速度范围的平滑操作。

Result: 在Oli人形机器人上部署控制器，实现最高1.65 m/s的指令速度稳定楼梯攀爬，12秒内完成33级螺旋楼梯（每级台阶高17 cm），展示了在长楼梯上的鲁棒高速性能。

Conclusion: FastStair框架通过结合模型规划与强化学习的优势，有效解决了人形机器人楼梯攀爬的速度与稳定性问题，所提方法在广州塔机器人登高赛中获冠军。

Abstract: Running up stairs is effortless for humans but remains extremely challenging for humanoid robots due to the simultaneous requirements of high agility and strict stability. Model-free reinforcement learning (RL) can generate dynamic locomotion, yet implicit stability rewards and heavy reliance on task-specific reward shaping tend to result in unsafe behaviors, especially on stairs; conversely, model-based foothold planners encode contact feasibility and stability structure, but enforcing their hard constraints often induces conservative motion that limits speed. We present FastStair, a planner-guided, multi-stage learning framework that reconciles these complementary strengths to achieve fast and stable stair ascent. FastStair integrates a parallel model-based foothold planner into the RL training loop to bias exploration toward dynamically feasible contacts and to pretrain a safety-focused base policy. To mitigate planner-induced conservatism and the discrepancy between low- and high-speed action distributions, the base policy was fine-tuned into speed-specialized experts and then integrated via Low-Rank Adaptation (LoRA) to enable smooth operation across the full commanded-speed range. We deploy the resulting controller on the Oli humanoid robot, achieving stable stair ascent at commanded speeds up to 1.65 m/s and traversing a 33-step spiral staircase (17 cm rise per step) in 12 s, demonstrating robust high-speed performance on long staircases. Notably, the proposed approach served as the champion solution in the Canton Tower Robot Run Up Competition.

</details>


### [12] [Online identification of nonlinear time-varying systems with uncertain information](https://arxiv.org/abs/2601.10379)
*He Ren,Gaowei Yan,Hang Liu,Lifeng Cao,Zhijun Zhao,Gang Dang*

Main category: cs.RO

TL;DR: This paper proposes a novel Bayesian Regression-based Symbolic Learning (BRSL) framework to address the gap that existing techniques (Bayesian methods and symbolic identification methods) struggle to meet the requirements of digital twins (high predictive accuracy, strong interpretability, and online adaptive capability) simultaneously. The framework formulates online symbolic discovery as a unified probabilistic state-space model, incorporates sparse horseshoe priors for model selection as Bayesian inference, derives an online recursive algorithm with a forgetting factor and recursive conditions, provides convergence analysis, and validates effectiveness via case studies.


<details>
  <summary>Details</summary>
Motivation: Digital twins require virtual models with high predictive accuracy, strong interpretability, and online adaptive capability, but existing techniques (Bayesian methods excel in uncertainty quantification but lack interpretability; symbolic identification methods like SINDy are offline and batch-processing, making real-time updates challenging) cannot meet these demands simultaneously.

Method: Proposes a Bayesian Regression-based Symbolic Learning (BRSL) framework. It formulates online symbolic discovery as a unified probabilistic state-space model, incorporates sparse horseshoe priors to transform model selection into a Bayesian inference task for simultaneous system identification and uncertainty quantification. Derives an online recursive algorithm with a forgetting factor and establishes recursive conditions for posterior well-posedness (also as real-time data utility monitors). Provides rigorous convergence analysis of parameter estimates under persistent excitation.

Result: Case studies validate the effectiveness of the proposed BRSL framework in achieving interpretable, probabilistic prediction and online learning.

Conclusion: The BRSL framework bridges the semantic and computational gap between existing techniques, enabling digital twins' virtual models to meet the critical requirements of high predictive accuracy, strong interpretability, and online adaptive capability.

Abstract: Digital twins (DTs), serving as the core enablers for real-time monitoring and predictive maintenance of complex cyber-physical systems, impose critical requirements on their virtual models: high predictive accuracy, strong interpretability, and online adaptive capability. However, existing techniques struggle to meet these demands simultaneously: Bayesian methods excel in uncertainty quantification but lack model interpretability, while interpretable symbolic identification methods (e.g., SINDy) are constrained by their offline, batch-processing nature, which make real-time updates challenging. To bridge this semantic and computational gap, this paper proposes a novel Bayesian Regression-based Symbolic Learning (BRSL) framework. The framework formulates online symbolic discovery as a unified probabilistic state-space model. By incorporating sparse horseshoe priors, model selection is transformed into a Bayesian inference task, enabling simultaneous system identification and uncertainty quantification. Furthermore, we derive an online recursive algorithm with a forgetting factor and establish precise recursive conditions that guarantee the well-posedness of the posterior distribution. These conditions also function as real-time monitors for data utility, enhancing algorithmic robustness. Additionally, a rigorous convergence analysis is provided, demonstrating the convergence of parameter estimates under persistent excitation conditions. Case studies validate the effectiveness of the proposed framework in achieving interpretable, probabilistic prediction and online learning.

</details>
