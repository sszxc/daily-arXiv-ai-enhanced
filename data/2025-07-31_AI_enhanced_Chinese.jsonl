{"id": "2507.22188", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.22188", "abs": "https://arxiv.org/abs/2507.22188", "authors": ["Ethan DeVries", "Jack Ferlazzo", "Mustafa Ugur", "Laura H. Blumenschein"], "title": "Deployment of Objects with a Soft Everting Robot", "comment": "9 pages, 10 figures, This work has been submitted to the IEEE for\n  possible publication", "summary": "Soft everting robots present significant advantages over traditional rigid\nrobots, including enhanced dexterity, improved environmental interaction, and\nsafe navigation in unpredictable environments. While soft everting robots have\nbeen widely demonstrated for exploration type tasks, their potential to move\nand deploy payloads in such tasks has been less investigated, with previous\nwork focusing on sensors and tools for the robot. Leveraging the navigation\ncapabilities, and deployed body, of the soft everting robot to deliver payloads\nin hazardous areas, e.g. carrying a water bottle to a person stuck under\ndebris, would represent a significant capability in many applications. In this\nwork, we present an analysis of how soft everting robots can be used to deploy\nlarger, heavier payloads through the inside of the robot. We analyze both what\nobjects can be deployed and what terrain features they can be carried through.\nBuilding on existing models, we present methods to quantify the effects of\npayloads on robot growth and self-support, and develop a model to predict\npayload slip. We then experimentally quantify payload transport using soft\neverting robot with a variety of payload shapes, sizes, and weights and though\na series of tasks: steering, vertical transport, movement through holes, and\nmovement across gaps. Overall, the results show that we can transport payloads\nin a variety of shapes and up to 1.5kg in weight and that we can move through\ncircular apertures with as little as 0.01cm clearance around payloads, carry\nout discrete turns up to 135 degrees, and move across unsupported gaps of 1.15m\nin length.", "AI": {"tldr": "\u8f6f\u4f53\u7ffb\u8f6c\u673a\u5668\u4eba\u5728\u5371\u9669\u73af\u5883\u4e2d\u8fd0\u8f93\u6709\u6548\u8f7d\u8377\u7684\u80fd\u529b\u5206\u6790\uff0c\u5305\u62ec\u8d1f\u8f7d\u5bf9\u673a\u5668\u4eba\u6027\u80fd\u7684\u5f71\u54cd\u53ca\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u63a2\u7d22\u8f6f\u4f53\u7ffb\u8f6c\u673a\u5668\u4eba\u5728\u8fd0\u8f93\u8f83\u5927\u3001\u8f83\u91cd\u8d1f\u8f7d\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4ee5\u6269\u5c55\u5176\u5728\u5371\u9669\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u6a21\u578b\u5206\u6790\u8d1f\u8f7d\u5bf9\u673a\u5668\u4eba\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5305\u62ec\u4e0d\u540c\u5f62\u72b6\u3001\u5927\u5c0f\u548c\u91cd\u91cf\u7684\u8d1f\u8f7d\u8fd0\u8f93\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u673a\u5668\u4eba\u53ef\u8fd0\u8f93\u91cd\u8fbe1.5kg\u7684\u8d1f\u8f7d\uff0c\u5e76\u80fd\u901a\u8fc7\u72ed\u7a84\u7a7a\u95f4\u3001\u5b8c\u6210135\u5ea6\u8f6c\u5f2f\u548c\u8de8\u8d8a1.15m\u7684\u95f4\u9699\u3002", "conclusion": "\u8f6f\u4f53\u7ffb\u8f6c\u673a\u5668\u4eba\u5177\u5907\u5728\u590d\u6742\u73af\u5883\u4e2d\u8fd0\u8f93\u6709\u6548\u8f7d\u8377\u7684\u80fd\u529b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002"}}
{"id": "2507.22345", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22345", "abs": "https://arxiv.org/abs/2507.22345", "authors": ["Zhicheng Song", "Jinglan Xu", "Chunxin Zheng", "Yulin Li", "Zhihai Bi", "Jun Ma"], "title": "FLORES: A Reconfigured Wheel-Legged Robot for Enhanced Steering and Adaptability", "comment": null, "summary": "Wheel-legged robots integrate the agility of legs for navigating rough\nterrains while harnessing the efficiency of wheels for smooth surfaces.\nHowever, most existing designs do not fully capitalize on the benefits of both\nlegged and wheeled structures, which limits overall system flexibility and\nefficiency. We present FLORES (reconfigured wheel-legged robot for enhanced\nsteering and adaptability), a novel wheel-legged robot design featuring a\ndistinctive front-leg configuration that sets it beyond standard design\napproaches. Specifically, FLORES replaces the conventional hip-roll degree of\nfreedom (DoF) of the front leg with hip-yaw DoFs, and this allows for efficient\nmovement on flat surfaces while ensuring adaptability when navigating complex\nterrains. This innovative design facilitates seamless transitions between\ndifferent locomotion modes (i.e., legged locomotion and wheeled locomotion) and\noptimizes the performance across varied environments. To fully exploit FLORES's\nmechanical capabilities, we develop a tailored reinforcement learning (RL)\ncontroller that adapts the Hybrid Internal Model (HIM) with a customized reward\nstructure optimized for our unique mechanical configuration. This framework\nenables the generation of adaptive, multi-modal locomotion strategies that\nfacilitate smooth transitions between wheeled and legged movements.\nFurthermore, our distinctive joint design enables the robot to exhibit novel\nand highly efficient locomotion gaits that capitalize on the synergistic\nadvantages of both locomotion modes. Through comprehensive experiments, we\ndemonstrate FLORES's enhanced steering capabilities, improved navigation\nefficiency, and versatile locomotion across various terrains. The open-source\nproject can be found at\nhttps://github.com/ZhichengSong6/FLORES-A-Reconfigured-Wheel-Legged-Robot-for-Enhanced-Steering-and-Adaptability.git.", "AI": {"tldr": "FLORES\u662f\u4e00\u79cd\u65b0\u578b\u8f6e\u817f\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u72ec\u7279\u7684\u817f\u90e8\u8bbe\u8ba1\u548c\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\uff0c\u5b9e\u73b0\u4e86\u5728\u590d\u6742\u5730\u5f62\u4e2d\u7684\u9ad8\u6548\u5bfc\u822a\u548c\u591a\u6a21\u5f0f\u8fd0\u52a8\u3002", "motivation": "\u73b0\u6709\u8f6e\u817f\u673a\u5668\u4eba\u8bbe\u8ba1\u672a\u80fd\u5145\u5206\u53d1\u6325\u817f\u548c\u8f6e\u7684\u4f18\u52bf\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002", "method": "\u91c7\u7528\u72ec\u7279\u7684\u817f\u90e8\u8bbe\u8ba1\uff08\u9acb\u90e8\u504f\u822a\u81ea\u7531\u5ea6\u66ff\u4ee3\u4f20\u7edf\u9acb\u90e8\u6eda\u52a8\u81ea\u7531\u5ea6\uff09\uff0c\u5e76\u7ed3\u5408\u5b9a\u5236\u7684\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u3002", "result": "FLORES\u5c55\u793a\u4e86\u589e\u5f3a\u7684\u8f6c\u5411\u80fd\u529b\u3001\u5bfc\u822a\u6548\u7387\u548c\u8de8\u5730\u5f62\u9002\u5e94\u6027\u3002", "conclusion": "FLORES\u901a\u8fc7\u521b\u65b0\u8bbe\u8ba1\u548c\u63a7\u5236\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f6e\u817f\u673a\u5668\u4eba\u7684\u6027\u80fd\u3002"}}
{"id": "2507.22356", "categories": ["cs.RO", "J.2"], "pdf": "https://arxiv.org/pdf/2507.22356", "abs": "https://arxiv.org/abs/2507.22356", "authors": ["W. Jacob Wagner", "Ahmet Soylemezoglu", "Katherine Driggs-Campbell"], "title": "In-Situ Soil-Property Estimation and Bayesian Mapping with a Simulated Compact Track Loader", "comment": "29 pages, 12 figures, 5 algorithms, ISTVS 2025", "summary": "Existing earthmoving autonomy is largely confined to highly controlled and\nwell-characterized environments due to the complexity of vehicle-terrain\ninteraction dynamics and the partial observability of the terrain resulting\nfrom unknown and spatially varying soil conditions. In this chapter, a a\nsoil-property mapping system is proposed to extend the environmental state, in\norder to overcome these restrictions and facilitate development of more robust\nautonomous earthmoving. A GPU accelerated elevation mapping system is extended\nto incorporate a blind mapping component which traces the movement of the blade\nthrough the terrain to displace and erode intersected soil, enabling separately\ntracking undisturbed and disturbed soil. Each interaction is approximated as a\nflat blade moving through a locally homogeneous soil, enabling modeling of\ncutting forces using the fundamental equation of earthmoving (FEE). Building\nupon our prior work on in situ soil-property estimation, a method is devised to\nextract approximate geometric parameters of the model given the uneven terrain,\nand an improved physics infused neural network (PINN) model is developed to\npredict soil properties and uncertainties of these estimates. A simulation of a\ncompact track loader (CTL) with a blade attachment is used to collect data to\ntrain the PINN model. Post-training, the model is leveraged online by the\nmapping system to track soil property estimates spatially as separate layers in\nthe map, with updates being performed in a Bayesian manner. Initial experiments\nshow that the system accurately highlights regions requiring higher relative\ninteraction forces, indicating the promise of this approach in enabling\nsoil-aware planning for autonomous terrain shaping.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u571f\u58e4\u5c5e\u6027\u6620\u5c04\u7cfb\u7edf\uff0c\u901a\u8fc7GPU\u52a0\u901f\u548c\u76f2\u6620\u5c04\u7ec4\u4ef6\u6269\u5c55\u73af\u5883\u72b6\u6001\uff0c\u4ee5\u652f\u6301\u66f4\u9c81\u68d2\u7684\u81ea\u4e3b\u52a8\u571f\u4f5c\u4e1a\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u52a8\u571f\u6280\u672f\u53d7\u9650\u4e8e\u590d\u6742\u8f66\u8f86-\u5730\u5f62\u4ea4\u4e92\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u571f\u58e4\u6761\u4ef6\uff0c\u9700\u6269\u5c55\u73af\u5883\u72b6\u6001\u4ee5\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u7ed3\u5408\u76f2\u6620\u5c04\u7ec4\u4ef6\u8ffd\u8e2a\u94f2\u5200\u8fd0\u52a8\uff0c\u5229\u7528FEE\u5efa\u6a21\u5207\u5272\u529b\uff0c\u6539\u8fdbPINN\u6a21\u578b\u9884\u6d4b\u571f\u58e4\u5c5e\u6027\uff0c\u5e76\u901a\u8fc7\u8d1d\u53f6\u65af\u65b9\u6cd5\u5728\u7ebf\u66f4\u65b0\u5730\u56fe\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7cfb\u7edf\u80fd\u51c6\u786e\u8bc6\u522b\u9700\u8981\u66f4\u9ad8\u4ea4\u4e92\u529b\u7684\u533a\u57df\uff0c\u652f\u6301\u571f\u58e4\u611f\u77e5\u89c4\u5212\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u81ea\u4e3b\u52a8\u571f\u4f5c\u4e1a\u63d0\u4f9b\u4e86\u571f\u58e4\u5c5e\u6027\u611f\u77e5\u80fd\u529b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.22380", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22380", "abs": "https://arxiv.org/abs/2507.22380", "authors": ["Yifei Chen", "Yuzhe Zhang", "Giovanni D'urso", "Nicholas Lawrance", "Brendan Tidd"], "title": "Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations", "comment": "13 pages", "summary": "Recent developments in imitation learning have considerably advanced robotic\nmanipulation. However, current techniques in imitation learning can suffer from\npoor generalization, limiting performance even under relatively minor domain\nshifts. In this work, we aim to enhance the generalization capabilities of\ncomplex imitation learning algorithms to handle unpredictable changes from the\ntraining environments to deployment environments. To avoid confusion caused by\nobservations that are not relevant to the target task, we propose to explicitly\nlearn the causal relationship between observation components and expert\nactions, employing a framework similar to [6], where a causal structural\nfunction is learned by intervention on the imitation learning policy.\nDisentangling the feature representation from image input as in [6] is hard to\nsatisfy in complex imitation learning process in robotic manipulation, we\ntheoretically clarify that this requirement is not necessary in causal\nrelationship learning. Therefore, we propose a simple causal structure learning\nframework that can be easily embedded in recent imitation learning\narchitectures, such as the Action Chunking Transformer [31]. We demonstrate our\napproach using a simulation of the ALOHA [31] bimanual robot arms in Mujoco,\nand show that the method can considerably mitigate the generalization problem\nof existing complex imitation learning algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u6a21\u4eff\u5b66\u4e60\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u6a21\u4eff\u5b66\u4e60\u6280\u672f\u5728\u9762\u5bf9\u8bad\u7ec3\u73af\u5883\u4e0e\u90e8\u7f72\u73af\u5883\u7684\u5fae\u5c0f\u53d8\u5316\u65f6\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u663e\u5f0f\u5b66\u4e60\u89c2\u5bdf\u7ec4\u4ef6\u4e0e\u4e13\u5bb6\u52a8\u4f5c\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5d4c\u5165\u73b0\u6709\u6a21\u4eff\u5b66\u4e60\u67b6\u6784\u7684\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u5728ALOHA\u53cc\u624b\u673a\u5668\u4eba\u81c2\u7684\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u7f13\u89e3\u4e86\u73b0\u6709\u590d\u6742\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\u7684\u6cdb\u5316\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u590d\u6742\u7684\u7279\u5f81\u89e3\u8026\uff0c\u5373\u53ef\u6709\u6548\u63d0\u5347\u6a21\u4eff\u5b66\u4e60\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.22389", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.22389", "abs": "https://arxiv.org/abs/2507.22389", "authors": ["Kaustav Chakraborty", "Zeyuan Feng", "Sushant Veer", "Apoorva Sharma", "Wenhao Ding", "Sever Topan", "Boris Ivanovic", "Marco Pavone", "Somil Bansal"], "title": "Safety Evaluation of Motion Plans Using Trajectory Predictors as Forward Reachable Set Estimators", "comment": null, "summary": "The advent of end-to-end autonomy stacks - often lacking interpretable\nintermediate modules - has placed an increased burden on ensuring that the\nfinal output, i.e., the motion plan, is safe in order to validate the safety of\nthe entire stack. This requires a safety monitor that is both complete (able to\ndetect all unsafe plans) and sound (does not flag safe plans). In this work, we\npropose a principled safety monitor that leverages modern multi-modal\ntrajectory predictors to approximate forward reachable sets (FRS) of\nsurrounding agents. By formulating a convex program, we efficiently extract\nthese data-driven FRSs directly from the predicted state distributions,\nconditioned on scene context such as lane topology and agent history. To ensure\ncompleteness, we leverage conformal prediction to calibrate the FRS and\nguarantee coverage of ground-truth trajectories with high probability. To\npreserve soundness in out-of-distribution (OOD) scenarios or under predictor\nfailure, we introduce a Bayesian filter that dynamically adjusts the FRS\nconservativeness based on the predictor's observed performance. We then assess\nthe safety of the ego vehicle's motion plan by checking for intersections with\nthese calibrated FRSs, ensuring the plan remains collision-free under plausible\nfuture behaviors of others. Extensive experiments on the nuScenes dataset show\nour approach significantly improves soundness while maintaining completeness,\noffering a practical and reliable safety monitor for learned autonomy stacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u7684\u5b89\u5168\u76d1\u63a7\u5668\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u548c\u5171\u5f62\u9884\u6d4b\u786e\u4fdd\u8fd0\u52a8\u8ba1\u5212\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u6a21\u5757\uff0c\u9700\u786e\u4fdd\u8fd0\u52a8\u8ba1\u5212\u7684\u5b89\u5168\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e2\u5b8c\u6574\u53c8\u53ef\u9760\u7684\u5b89\u5168\u76d1\u63a7\u5668\u3002", "method": "\u5229\u7528\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u5668\u8fd1\u4f3c\u5468\u56f4\u667a\u80fd\u4f53\u7684\u524d\u5411\u53ef\u8fbe\u96c6\uff08FRS\uff09\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u63d0\u53d6\u6570\u636e\u9a71\u52a8\u7684FRS\uff0c\u5e76\u4f7f\u7528\u5171\u5f62\u9884\u6d4b\u548c\u8d1d\u53f6\u65af\u6ee4\u6ce2\u5668\u6821\u51c6FRS\u3002", "result": "\u5728nuScenes\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b8c\u6574\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b66\u4e60\u578b\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u9760\u7684\u5b89\u5168\u76d1\u63a7\u5668\u3002"}}
{"id": "2507.22429", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22429", "abs": "https://arxiv.org/abs/2507.22429", "authors": ["Erwin de Gelder", "Maren Buermann", "Olaf Op den Camp"], "title": "Comparing Normalizing Flows with Kernel Density Estimation in Estimating Risk of Automated Driving Systems", "comment": "Accepted for publication in proceedings of the 2025 IEEE\n  International Automated Vehicle Validation Conference", "summary": "The development of safety validation methods is essential for the safe\ndeployment and operation of Automated Driving Systems (ADSs). One of the goals\nof safety validation is to prospectively evaluate the risk of an ADS dealing\nwith real-world traffic. Scenario-based assessment is a widely-used approach,\nwhere test cases are derived from real-world driving data. To allow for a\nquantitative analysis of the system performance, the exposure of the scenarios\nmust be accurately estimated. The exposure of scenarios at parameter level is\nexpressed using a Probability Density Function (PDF). However, assumptions\nabout the PDF, such as parameter independence, can introduce errors, while\navoiding assumptions often leads to oversimplified models with limited\nparameters to mitigate the curse of dimensionality.\n  This paper considers the use of Normalizing Flows (NF) for estimating the PDF\nof the parameters. NF are a class of generative models that transform a simple\nbase distribution into a complex one using a sequence of invertible and\ndifferentiable mappings, enabling flexible, high-dimensional density estimation\nwithout restrictive assumptions on the PDF's shape. We demonstrate the\neffectiveness of NF in quantifying risk and risk uncertainty of an ADS,\ncomparing its performance with Kernel Density Estimation (KDE), a traditional\nmethod for non-parametric PDF estimation. While NF require more computational\nresources compared to KDE, NF is less sensitive to the curse of dimensionality.\nAs a result, NF can improve risk uncertainty estimation, offering a more\nprecise assessment of an ADS's safety.\n  This work illustrates the potential of NF in scenario-based safety. Future\nwork involves experimenting more with using NF for scenario generation and\noptimizing the NF architecture, transformation types, and training\nhyperparameters to further enhance their applicability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5f52\u4e00\u5316\u6d41\uff08NF\uff09\u4f30\u8ba1\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u573a\u666f\u53c2\u6570\u7684PDF\uff0c\u4ee5\u6539\u8fdb\u98ce\u9669\u8bc4\u4f30\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u76f8\u6bd4\u4f20\u7edfKDE\u65b9\u6cd5\uff0cNF\u5bf9\u7ef4\u5ea6\u707e\u96be\u66f4\u4e0d\u654f\u611f\u3002", "motivation": "\u4e3a\u5b89\u5168\u9a8c\u8bc1\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff0c\u9700\u8981\u51c6\u786e\u4f30\u8ba1\u573a\u666f\u53c2\u6570\u7684PDF\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u5047\u8bbe\u9650\u5236\u6216\u7ef4\u5ea6\u707e\u96be\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5f52\u4e00\u5316\u6d41\uff08NF\uff09\u6a21\u578b\uff0c\u901a\u8fc7\u53ef\u9006\u548c\u53ef\u5fae\u6620\u5c04\u4ece\u7b80\u5355\u5206\u5e03\u751f\u6210\u590d\u6742\u5206\u5e03\uff0c\u5b9e\u73b0\u9ad8\u7ef4\u5bc6\u5ea6\u4f30\u8ba1\u3002", "result": "NF\u5728\u98ce\u9669\u8bc4\u4f30\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e0a\u4f18\u4e8eKDE\uff0c\u5bf9\u7ef4\u5ea6\u707e\u96be\u66f4\u9c81\u68d2\uff0c\u4f46\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u66f4\u9ad8\u3002", "conclusion": "NF\u5728\u573a\u666f\u5b89\u5168\u9a8c\u8bc1\u4e2d\u6f5c\u529b\u663e\u8457\uff0c\u672a\u6765\u53ef\u4f18\u5316\u67b6\u6784\u548c\u8bad\u7ec3\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u5e94\u7528\u6027\u3002"}}
{"id": "2507.22433", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22433", "abs": "https://arxiv.org/abs/2507.22433", "authors": ["Olaf Op den Camp", "Erwin de Gelder"], "title": "Operationalization of Scenario-Based Safety Assessment of Automated Driving Systems", "comment": "Accepted for publication in proceedings of the 2025 IEEE\n  International Automated Vehicle Validation Conference", "summary": "Before introducing an Automated Driving System (ADS) on the road at scale,\nthe manufacturer must conduct some sort of safety assurance. To structure and\nharmonize the safety assurance process, the UNECE WP.29 Working Party on\nAutomated/Autonomous and Connected Vehicles (GRVA) is developing the New\nAssessment/Test Method (NATM) that indicates what steps need to be taken for\nsafety assessment of an ADS. In this paper, we will show how to practically\nconduct safety assessment making use of a scenario database, and what\nadditional steps must be taken to fully operationalize the NATM. In addition,\nwe will elaborate on how the use of scenario databases fits with methods\ndeveloped in the Horizon Europe projects that focus on safety assessment\nfollowing the NATM approach.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u573a\u666f\u6570\u636e\u5e93\u5b9e\u9645\u8fdb\u884c\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u7684\u5b89\u5168\u8bc4\u4f30\uff0c\u5e76\u8865\u5145\u4e86NATM\u7684\u5b8c\u6574\u64cd\u4f5c\u6b65\u9aa4\u3002", "motivation": "\u4e3a\u4e86\u5728\u5927\u89c4\u6a21\u90e8\u7f72ADS\u524d\u786e\u4fdd\u5176\u5b89\u5168\u6027\uff0c\u9700\u8981\u7ed3\u6784\u5316\u548c\u534f\u8c03\u5b89\u5168\u8bc4\u4f30\u6d41\u7a0b\u3002", "method": "\u4f7f\u7528\u573a\u666f\u6570\u636e\u5e93\u8fdb\u884c\u5b89\u5168\u8bc4\u4f30\uff0c\u5e76\u7ed3\u5408Horizon Europe\u9879\u76ee\u7684\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u5b9e\u9645\u8fdb\u884c\u5b89\u5168\u8bc4\u4f30\u7684\u65b9\u6cd5\uff0c\u5e76\u8865\u5145\u4e86NATM\u7684\u64cd\u4f5c\u6b65\u9aa4\u3002", "conclusion": "\u573a\u666f\u6570\u636e\u5e93\u4e0eNATM\u65b9\u6cd5\u7684\u7ed3\u5408\u4e3aADS\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.22473", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22473", "abs": "https://arxiv.org/abs/2507.22473", "authors": ["Yongjie Li", "Zhou Liu", "Wenshuai Yu", "Zhangji Lu", "Chenyang Wang", "Fei Yu", "Qingquan Li"], "title": "A Two-Stage Lightweight Framework for Efficient Land-Air Bimodal Robot Autonomous Navigation", "comment": "IROS2025", "summary": "Land-air bimodal robots (LABR) are gaining attention for autonomous\nnavigation, combining high mobility from aerial vehicles with long endurance\nfrom ground vehicles. However, existing LABR navigation methods are limited by\nsuboptimal trajectories from mapping-based approaches and the excessive\ncomputational demands of learning-based methods. To address this, we propose a\ntwo-stage lightweight framework that integrates global key points prediction\nwith local trajectory refinement to generate efficient and reachable\ntrajectories. In the first stage, the Global Key points Prediction Network\n(GKPN) was used to generate a hybrid land-air keypoint path. The GKPN includes\na Sobel Perception Network (SPN) for improved obstacle detection and a\nLightweight Attention Planning Network (LAPN) to improves predictive ability by\ncapturing contextual information. In the second stage, the global path is\nsegmented based on predicted key points and refined using a mapping-based\nplanner to create smooth, collision-free trajectories. Experiments conducted on\nour LABR platform show that our framework reduces network parameters by 14\\%\nand energy consumption during land-air transitions by 35\\% compared to existing\napproaches. The framework achieves real-time navigation without GPU\nacceleration and enables zero-shot transfer from simulation to reality during", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u7ed3\u5408\u5168\u5c40\u5173\u952e\u70b9\u9884\u6d4b\u4e0e\u5c40\u90e8\u8f68\u8ff9\u4f18\u5316\uff0c\u7528\u4e8e\u9646\u5730-\u7a7a\u4e2d\u53cc\u6a21\u6001\u673a\u5668\u4eba\u7684\u9ad8\u6548\u5bfc\u822a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8f68\u8ff9\u4f18\u5316\u548c\u8ba1\u7b97\u9700\u6c42\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5168\u5c40\u5173\u952e\u70b9\u9884\u6d4b\u7f51\u7edc\uff08GKPN\uff09\u751f\u6210\u8def\u5f84\uff0c\u5e76\u901a\u8fc7\u5c40\u90e8\u8f68\u8ff9\u4f18\u5316\u751f\u6210\u5e73\u6ed1\u3001\u65e0\u78b0\u649e\u7684\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6846\u67b6\u51cf\u5c11\u4e8614%\u7684\u7f51\u7edc\u53c2\u6570\u548c35%\u7684\u80fd\u8017\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u5bfc\u822a\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u65e0\u9700GPU\u52a0\u901f\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u5bfc\u822a\uff0c\u5e76\u652f\u6301\u4ece\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u3002"}}
{"id": "2507.22546", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22546", "abs": "https://arxiv.org/abs/2507.22546", "authors": ["Alex George", "Will Shepherd", "Simon Tait", "Lyudmila Mihaylova", "Sean R. Anderson"], "title": "Explainable Deep Anomaly Detection with Sequential Hypothesis Testing for Robotic Sewer Inspection", "comment": null, "summary": "Sewer pipe faults, such as leaks and blockages, can lead to severe\nconsequences including groundwater contamination, property damage, and service\ndisruption. Traditional inspection methods rely heavily on the manual review of\nCCTV footage collected by mobile robots, which is inefficient and susceptible\nto human error. To automate this process, we propose a novel system\nincorporating explainable deep learning anomaly detection combined with\nsequential probability ratio testing (SPRT). The anomaly detector processes\nsingle image frames, providing interpretable spatial localisation of anomalies,\nwhilst the SPRT introduces temporal evidence aggregation, enhancing robustness\nagainst noise over sequences of image frames. Experimental results demonstrate\nimproved anomaly detection performance, highlighting the benefits of the\ncombined spatiotemporal analysis system for reliable and robust sewer\ninspection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53ef\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\u5f02\u5e38\u68c0\u6d4b\u548c\u5e8f\u8d2f\u6982\u7387\u6bd4\u6d4b\u8bd5\uff08SPRT\uff09\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u4e0b\u6c34\u9053\u7ba1\u9053\u6545\u969c\u68c0\u6d4b\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u4e0b\u6c34\u9053\u7ba1\u9053\u6545\u969c\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u68c0\u67e5CCTV\u5f55\u50cf\uff0c\u6548\u7387\u4f4e\u4e14\u6613\u51fa\u9519\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u53ef\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\u5f02\u5e38\u68c0\u6d4b\uff08\u63d0\u4f9b\u7a7a\u95f4\u5b9a\u4f4d\uff09\u548cSPRT\uff08\u65f6\u95f4\u8bc1\u636e\u805a\u5408\uff09\uff0c\u589e\u5f3a\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u63d0\u9ad8\u4e86\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u4e14\u9c81\u68d2\u7684\u4e0b\u6c34\u9053\u68c0\u6d4b\u3002", "conclusion": "\u7ed3\u5408\u65f6\u7a7a\u5206\u6790\u7684\u7cfb\u7edf\u4e3a\u4e0b\u6c34\u9053\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.22653", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22653", "abs": "https://arxiv.org/abs/2507.22653", "authors": ["Weijie Xi", "Zhanxiang Cao", "Chenlin Ming", "Jianying Zheng", "Guyue Zhou"], "title": "UniLegs: Universal Multi-Legged Robot Control through Morphology-Agnostic Policy Distillation", "comment": "6 pages, 3 figures, IROS 2025", "summary": "Developing controllers that generalize across diverse robot morphologies\nremains a significant challenge in legged locomotion. Traditional approaches\neither create specialized controllers for each morphology or compromise\nperformance for generality. This paper introduces a two-stage teacher-student\nframework that bridges this gap through policy distillation. First, we train\nspecialized teacher policies optimized for individual morphologies, capturing\nthe unique optimal control strategies for each robot design. Then, we distill\nthis specialized expertise into a single Transformer-based student policy\ncapable of controlling robots with varying leg configurations. Our experiments\nacross five distinct legged morphologies demonstrate that our approach\npreserves morphology-specific optimal behaviors, with the Transformer\narchitecture achieving 94.47\\% of teacher performance on training morphologies\nand 72.64\\% on unseen robot designs. Comparative analysis reveals that\nTransformer-based architectures consistently outperform MLP baselines by\nleveraging attention mechanisms to effectively model joint relationships across\ndifferent kinematic structures. We validate our approach through successful\ndeployment on a physical quadruped robot, demonstrating the practical viability\nof our morphology-agnostic control framework. This work presents a scalable\nsolution for developing universal legged robot controllers that maintain\nnear-optimal performance while generalizing across diverse morphologies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6559\u5e08-\u5b66\u751f\u6846\u67b6\u7684\u4e24\u9636\u6bb5\u7b56\u7565\u84b8\u998f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f00\u53d1\u8de8\u5f62\u6001\u901a\u7528\u7684\u673a\u5668\u4eba\u63a7\u5236\u5668\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u817f\u90e8\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u65e0\u6cd5\u517c\u987e\u901a\u7528\u6027\u548c\u6027\u80fd\u7684\u95ee\u9898\u3002", "method": "\u5148\u8bad\u7ec3\u9488\u5bf9\u7279\u5b9a\u5f62\u6001\u7684\u6559\u5e08\u7b56\u7565\uff0c\u518d\u901a\u8fc7Transformer\u67b6\u6784\u7684\u5b66\u751f\u7b56\u7565\u84b8\u998f\u901a\u7528\u63a7\u5236\u5668\u3002", "result": "\u5728\u4e94\u79cd\u4e0d\u540c\u5f62\u6001\u4e0a\uff0c\u5b66\u751f\u7b56\u7565\u8fbe\u5230\u6559\u5e08\u6027\u80fd\u768494.47%\uff08\u8bad\u7ec3\u5f62\u6001\uff09\u548c72.64%\uff08\u672a\u89c1\u5f62\u6001\uff09\uff0c\u4f18\u4e8eMLP\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f00\u53d1\u901a\u7528\u4e14\u9ad8\u6027\u80fd\u7684\u817f\u90e8\u673a\u5668\u4eba\u63a7\u5236\u5668\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.22769", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.22769", "abs": "https://arxiv.org/abs/2507.22769", "authors": ["Satyesh Shanker Awasthi", "Mohammed Irshadh Ismaaeel Sathyamangalam Imran", "Stefano Arrigoni", "Francesco Braghin"], "title": "Bayesian Optimization applied for accelerated Virtual Validation of the Autonomous Driving Function", "comment": null, "summary": "Rigorous Verification and Validation (V&V) of Autonomous Driving Functions\n(ADFs) is paramount for ensuring the safety and public acceptance of Autonomous\nVehicles (AVs). Current validation relies heavily on simulation to achieve\nsufficient test coverage within the Operational Design Domain (ODD) of a\nvehicle, but exhaustively exploring the vast parameter space of possible\nscenarios is computationally expensive and time-consuming. This work introduces\na framework based on Bayesian Optimization (BO) to accelerate the discovery of\ncritical scenarios. We demonstrate the effectiveness of the framework on an\nModel Predictive Controller (MPC)-based motion planner, showing that it\nidentifies hazardous situations, such as off-road events, using orders of\nmagnitude fewer simulations than brute-force Design of Experiments (DoE)\nmethods. Furthermore, this study investigates the scalability of the framework\nin higher-dimensional parameter spaces and its ability to identify multiple,\ndistinct critical regions within the ODD of the motion planner used as the case\nstudy .", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u6846\u67b6\uff0c\u52a0\u901f\u53d1\u73b0\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\u7684\u5173\u952e\u573a\u666f\uff0c\u9a8c\u8bc1\u5176\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\u9a8c\u8bc1\u4f9d\u8d56\u4eff\u771f\uff0c\u4f46\u53c2\u6570\u7a7a\u95f4\u5e9e\u5927\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u66f4\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u9488\u5bf9\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u8fd0\u52a8\u89c4\u5212\u5668\uff0c\u52a0\u901f\u53d1\u73b0\u5371\u9669\u573a\u666f\u3002", "result": "\u6846\u67b6\u663e\u8457\u51cf\u5c11\u4eff\u771f\u6b21\u6570\uff0c\u8bc6\u522b\u51fa\u5371\u9669\u60c5\u51b5\uff08\u5982\u504f\u79bb\u9053\u8def\uff09\uff0c\u5e76\u5728\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u4e2d\u9a8c\u8bc1\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\uff0c\u9002\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\u9a8c\u8bc1\uff0c\u4f18\u4e8e\u4f20\u7edf\u5b9e\u9a8c\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
