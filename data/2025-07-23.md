<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Fast Task Planning with Neuro-Symbolic Relaxation](https://arxiv.org/abs/2507.15975)
*Qiwei Du,Bowen Li,Yi Du,Shaoshu Su,Taimeng Fu,Zitong Zhan,Zhipeng Zhao,Chen Wang*

Main category: cs.RO

TL;DR: 为解决现实任务规划中经典符号规划器的组合爆炸问题，提出NeSy松弛策略Flax，结合神经重要性预测与符号扩展，在合成和现实迷宫导航基准测试中，平均成功率提升20.82%，规划时间减少17.65%


<details>
  <summary>Details</summary>
Motivation: 现实任务规划需对具有复杂关系和属性的大量实体进行长程推理，导致经典符号规划器出现组合爆炸；现有神经符号集成方法可能遗漏关键实体，在不可解简化任务上浪费资源

Method: 首先学习图神经网络预测实体重要性以创建简化任务，用符号规划器求解；然后求解规则松弛任务获取快速粗略计划，将所有引用实体重新集成到简化任务中以恢复被忽略的关键元素；最后应用补充规则优化更新后的任务，保持其可靠且紧凑

Result: 在合成和现实迷宫导航基准测试（机器人必须穿越迷宫并与可移动物体交互）中，Flax相比最先进的神经符号基线，平均成功率提升20.82%，平均规划时间减少17.65%

Conclusion: Flax为复杂环境中快速、可扩展、长程任务规划提供了实用路径

Abstract: Real-world task planning requires long-horizon reasoning over large sets of
entities with complex relationships and attributes, leading to a combinatorial
explosion for classical symbolic planners. To prune the search space, recent
methods prioritize searching on a simplified task only containing a few
"important" entities predicted by a neural network. However, such a simple
neuro-symbolic (NeSy) integration risks omitting critical entities and wasting
resources on unsolvable simplified tasks. To enable Fast and reliable planning,
we introduce a NeSy relaxation strategy (Flax), combining neural importance
prediction with symbolic expansion. Specifically, we first learn a graph neural
network to predict entity importance to create a simplified task and solve it
with a symbolic planner. Then, we solve a rule-relaxed task to obtain a quick
rough plan, and reintegrate all referenced entities into the simplified task to
recover any overlooked but essential elements. Finally, we apply complementary
rules to refine the updated task, keeping it both reliable and compact.
Extensive experiments are conducted on both synthetic and real-world maze
navigation benchmarks where a robot must traverse through a maze and interact
with movable objects. The results show that Flax boosts the average success
rate by 20.82% and cuts mean wall-clock planning time by 17.65% compared with
the state-of-the-art NeSy baseline. We expect that Flax offers a practical path
toward fast, scalable, long-horizon task planning in complex environments.

</details>


### [2] [A Comprehensive Evaluation of LiDAR Odometry Techniques](https://arxiv.org/abs/2507.16000)
*Easton Potokar,Michael Kaess*

Main category: cs.RO

TL;DR: 本文总结了激光雷达里程计（LO）管道的各种技术，并在大量数据集上对这些LO组件进行了经验评估，最后为未来LO管道的设计提供了基于经验的建议以实现最准确和可靠的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管近年来有大量工作致力于寻找使用激光雷达传感器进行状态估计的最准确方法，但之前的工作中LO管道的各种构建块缺乏大量的消融研究比较。

Method: 总结LO管道的各种技术，并在跨越环境、激光雷达类型和车辆运动的大量数据集上对LO组件进行经验评估。

Result: 对LO组件进行了经验评估，并基于评估结果提出了未来LO管道设计的建议。

Conclusion: 通过对LO组件的广泛经验评估，为未来LO管道设计提供了基于实证的建议，以实现更准确可靠的性能。

Abstract: Light Detection and Ranging (LiDAR) sensors have become the sensor of choice
for many robotic state estimation tasks. Because of this, in recent years there
has been significant work done to fine the most accurate method to perform
state estimation using these sensors. In each of these prior works, an
explosion of possible technique combinations has occurred, with each work
comparing LiDAR Odometry (LO) "pipelines" to prior "pipelines". Unfortunately,
little work up to this point has performed the significant amount of ablation
studies comparing the various building-blocks of a LO pipeline. In this work,
we summarize the various techniques that go into defining a LO pipeline and
empirically evaluate these LO components on an expansive number of datasets
across environments, LiDAR types, and vehicle motions. Finally, we make
empirically-backed recommendations for the design of future LO pipelines to
provide the most accurate and reliable performance.

</details>


### [3] [Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation](https://arxiv.org/abs/2507.16034)
*Xuying Huang,Sicong Pan,Olga Zatsarynna,Juergen Gall,Maren Bennewitz*

Main category: cs.RO

TL;DR: 该研究聚焦移动机器人用户隐私问题，提出一种基于语义的超低分辨率导航方法，通过新型全联合学习方法（集成凝聚特征提取器和分割感知鉴别器）解决超低分语义分割难题，实现隐私保护与语义目标导航的协同优化，并在真实场景中提升了导航成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在移动机器人任务性能与隐私保护间存在权衡，隐私保护常限制任务执行效果，需联合解决两者目标。

Method: 提出一种新型全联合学习方法，集成凝聚特征提取器和分割感知鉴别器以解决超低分语义分割问题。

Result: 该方法在超低分语义分割任务上优于不同基线，且改进的分割结果提高了真实世界隐私受限场景下语义目标导航的成功率。

Conclusion: 所提方法有效实现了隐私保护与语义目标导航的协同优化，提升了相关任务性能。

Abstract: User privacy in mobile robotics has become a critical concern. Existing
methods typically prioritize either the performance of downstream robotic tasks
or privacy protection, with the latter often constraining the effectiveness of
task execution. To jointly address both objectives, we study semantic-based
robot navigation in an ultra-low-resolution setting to preserve visual privacy.
A key challenge in such scenarios is recovering semantic segmentation from
ultra-low-resolution RGB images. In this work, we introduce a novel fully
joint-learning method that integrates an agglomerative feature extractor and a
segmentation-aware discriminator to solve ultra-low-resolution semantic
segmentation, thereby enabling privacy-preserving, semantic object-goal
navigation. Our method outperforms different baselines on ultra-low-resolution
semantic segmentation and our improved segmentation results increase the
success rate of the semantic object-goal navigation in a real-world
privacy-constrained scenario.

</details>


### [4] [Therapist-Exoskeleton-Patient Interaction: An Immersive Gait Therapy](https://arxiv.org/abs/2507.16059)
*Emek Barış Küçüktabak,Matthew R. Short,Lorenzo Vianello,Daniel Ludvig,Levi Hargrove,Kevin Lynch,Jose Pons*

Main category: cs.RO

TL;DR: 本文提出了一种基于物理人机人交互（pHRHI）的新型步态康复范式，即治疗师和中风患者均穿戴下肢外骨骼并通过弹簧阻尼元件虚拟连接髋部和膝关节，实现双向交互，在8名慢性中风患者的研究中，pHRHI训练在关节活动范围、步态指标、肌肉激活和动机等方面优于传统治疗师引导的跑步机行走，显示出结合机器人精度和治疗师直觉以改善康复效果的潜力。


<details>
  <summary>Details</summary>
Motivation: 中风后患者常因下肢无力和关节控制丧失导致移动和平衡障碍，传统高强度治疗师主导的步态康复训练存在体力需求大、难以同时交互多个关节的问题，而现有机器人外骨骼控制策略往往限制治疗师参与和适应性。

Method: 提出基于物理人机人交互（pHRHI）的新型步态康复范式，治疗师和中风患者均穿戴下肢外骨骼，通过弹簧阻尼元件在髋部和膝关节处虚拟连接，实现双向交互，使治疗师能引导运动并接收触觉反馈，并在8名慢性中风患者中进行研究，对比pHRHI训练与传统治疗师引导的跑步机行走效果。

Result: 在8名慢性中风患者的研究中，pHRHI训练优于传统治疗师引导的跑步机行走，导致关节活动范围增加、步态指标改善、肌肉激活增强以及动机提升。

Conclusion: pHRHI具有结合机器人精度和治疗师直觉以改善康复效果的潜力。

Abstract: Following a stroke, individuals often experience mobility and balance
impairments due to lower-limb weakness and loss of independent joint control.
Gait recovery is a key goal of rehabilitation, traditionally achieved through
high-intensity therapist-led training. However, manual assistance can be
physically demanding and limits the therapist's ability to interact with
multiple joints simultaneously. Robotic exoskeletons offer multi-joint support,
reduce therapist strain, and provide objective feedback, but current control
strategies often limit therapist involvement and adaptability.
  We present a novel gait rehabilitation paradigm based on physical
Human-Robot-Human Interaction (pHRHI), where both the therapist and the
post-stroke individual wear lower-limb exoskeletons virtually connected at the
hips and knees via spring-damper elements. This enables bidirectional
interaction, allowing the therapist to guide movement and receive haptic
feedback. In a study with eight chronic stroke patients, pHRHI training
outperformed conventional therapist-guided treadmill walking, leading to
increased joint range of motion, step metrics, muscle activation, and
motivation. These results highlight pHRHI's potential to combine robotic
precision with therapist intuition for improved rehabilitation outcomes.

</details>


### [5] [Compositional Coordination for Multi-Robot Teams with Large Language Models](https://arxiv.org/abs/2507.16068)
*Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: 提出了LAN2CB框架，利用大语言模型将自然语言任务描述直接转换为多机器人系统的可执行Python代码，通过任务分解和代码生成两个关键组件，减少人工工程需求并支持跨任务类型的泛化。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人协调依赖特定任务和专家驱动的流程，人工将自然语言任务描述转化为数学公式、算法设计和可执行代码，存在劳动密集、非专家难以使用、对任务需求变化不灵活的问题。

Method: 提出LAN2CB框架，包含两个关键组件：（1）任务分解与任务表示，将任务解析为带依赖关系的任务图；（2）代码生成，利用任务图和结构化知识库生成可部署的机器人控制代码，并引入自然语言任务规范数据集。

Result: 仿真和真实环境实验结果表明，LAN2CB能从自然语言实现有效且灵活的多机器人协调，显著减少人工工程需求，同时支持跨任务类型的泛化。

Conclusion: LAN2CB框架利用大语言模型简化和泛化了多机器人协调流程，直接将自然语言任务描述转换为可执行代码，有效解决了传统流程的问题，具有良好的有效性和灵活性。

Abstract: Multi-robot coordination has traditionally relied on a task-specific and
expert-driven pipeline, where natural language mission descriptions are
manually translated by domain experts into mathematical formulation, algorithm
design, and executable code. This conventional process is labor-intensive,
inaccessible to non-experts, and inflexible to changes in mission requirements.
Here, we propose LAN2CB (Language to Collective Behavior), a novel framework
that leverages large language models (LLMs) to streamline and generalize the
multi-robot coordination pipeline. LAN2CB directly converts natural language
mission descriptions into executable Python code for multi-robot systems
through two key components: (1) Mission Decomposition for Task Representation,
which parses the mission into a task graph with dependencies, and (2) Code
Generation, which uses the task graph and a structured knowledge base to
generate deployable robot control code. We further introduce a dataset of
natural language mission specifications to support development and
benchmarking. Experimental results in both simulation and real-world settings
show that LAN2CB enables effective and flexible multi-robot coordination from
natural language, significantly reducing the need for manual engineering while
supporting generalization across mission types. Website:
https://sites.google.com/view/lan2cb.

</details>


### [6] [FTIN: Frequency-Time Integration Network for Inertial Odometry](https://arxiv.org/abs/2507.16120)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 本文提出一种融合频域和时域信息的新型网络架构，以解决现有惯性里程计方法依赖时域CNN难以捕捉IMU数据长期依赖关系的问题，实验表明该方法在多个公开数据集上有效，尤其在RoNIN数据集上较RoNIN ResNet绝对轨迹误差降低43.0%，相对轨迹误差降低13.1%。


<details>
  <summary>Details</summary>
Motivation: 现有惯性里程计方法主要依赖时域CNN，难以捕捉IMU数据的长期依赖关系，限制了定位精度的进一步提升。

Method: 提出融合频域和时域信息的新型网络架构，利用频域学习的全局视角和能量压缩特性建模长期依赖并减少IMU数据冗余，同时引入Scalar LSTM捕捉时域序列依赖，实现跨域信息融合为定位提供稳定可靠参考。

Result: 在多个公开数据集（如RIDI、RoNIN、OxIOD、RNIN、TLIO和IMUNet）上进行了实验评估，在RoNIN数据集上，与RoNIN ResNet相比，绝对轨迹误差降低43.0%，相对轨迹误差降低13.1%。

Conclusion: 所提出的频-时域融合策略是有效的。

Abstract: In recent years, machine learning has achieved significant advancements in
inertial odometry. However, most existing inertial odometry methods primarily
rely on CNNs in the time domain. These methods often struggle to capture
long-term dependency in inertial measurement unit data, thereby constraining
the potential for further improvements in localization accuracy. To address
these issues, we propose a novel network architecture that integrates both
frequency-domain and time-domain information. Specifically, we leverage the
global view and energy compaction properties of frequency-domain learning to
effectively model long-term dependency and reduce redundancy in IMU data.
Additionally, we introduce a Scalar LSTM to capture sequential dependencies in
the time domain, enabling cross-domain information fusion and providing a
stable and reliable reference for localization. Experimental evaluations on
multiple public datasets (e.g., RIDI, RoNIN, OxIOD, RNIN, TLIO, and IMUNet)
demonstrate the effectiveness of the proposed frequency-time domain fusion
strategy. Notably, on the RoNIN dataset, our method achieves a 43.0% reduction
in absolute trajectory error and a 13.1% reduction in relative trajectory error
compared to RoNIN ResNet.

</details>


### [7] [DWSFormer: A Lightweight Inertial Odometry Network for Complex Motion Modeling](https://arxiv.org/abs/2507.16121)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 本文提出一种轻量级惯性里程计框架，通过Star Operation方法将惯性数据投影到高维非线性特征空间，引入协同注意力机制及多尺度门控卷积单元，以解决复杂运动模式下的漂移误差问题，在六个惯性数据集上性能优于现有SOTA方法，在RoNIN数据集上ATE降低2.26% - 65.78%


<details>
  <summary>Details</summary>
Motivation: 现有惯性里程计方法在简单近线性运动轨迹重建中准确，但难以解决复杂运动模式（如转弯）导致的漂移误差，降低了定位精度并限制了其在现实场景中的适用性

Method: 1. 采用Star Operation方法将惯性数据投影到高维隐式非线性特征空间以提取复杂运动特征；2. 引入协同注意力机制联合建模通道和时间维度的全局运动动态；3. 设计多尺度门控卷积单元捕获运动过程中的细粒度动态变化

Result: 在六个广泛使用的惯性数据集上持续优于SOTA基线，在RoNIN数据集上ATE降低2.26% - 65.78%，建立了该领域新基准

Conclusion: 所提出的轻量级IO框架有效解决了复杂运动模式下的漂移误差问题，显著提升了定位精度，在多个数据集上表现优异，为惯性里程计的实际应用提供了新方案

Abstract: Inertial odometry (IO) directly estimates the position of a carrier from
inertial sensor measurements and serves as a core technology for the widespread
deployment of consumer grade localization systems. While existing IO methods
can accurately reconstruct simple and near linear motion trajectories, they
often fail to account for drift errors caused by complex motion patterns such
as turning. This limitation significantly degrades localization accuracy and
restricts the applicability of IO systems in real world scenarios. To address
these challenges, we propose a lightweight IO framework. Specifically, inertial
data is projected into a high dimensional implicit nonlinear feature space
using the Star Operation method, enabling the extraction of complex motion
features that are typically overlooked. We further introduce a collaborative
attention mechanism that jointly models global motion dynamics across both
channel and temporal dimensions. In addition, we design Multi Scale Gated
Convolution Units to capture fine grained dynamic variations throughout the
motion process, thereby enhancing the model's ability to learn rich and
expressive motion representations. Extensive experiments demonstrate that our
proposed method consistently outperforms SOTA baselines across six widely used
inertial datasets. Compared to baseline models on the RoNIN dataset, it
achieves reductions in ATE ranging from 2.26% to 65.78%, thereby establishing a
new benchmark in the field.

</details>


### [8] [Benchmarking LLM Privacy Recognition for Social Robot Decision Making](https://arxiv.org/abs/2507.16124)
*Dakota Sullivan,Shirley Zhang,Jennica Li,Heather Kirkorian,Bilge Mutlu,Kassem Fawaz*

Main category: cs.RO

TL;DR: 本文探讨家用社交机器人中LLM的隐私感知能力，通过Contextual Integrity框架设计隐私场景，调查用户隐私偏好（N=450）并与10个LLM的响应比较，发现人机一致性低，进而测试四种提示策略并讨论AI隐私意识对人机交互的影响


<details>
  <summary>Details</summary>
Motivation: LLM赋能的社交机器人需处理家庭环境中的敏感数据，存在实用性与隐私风险的矛盾，评估当前LLM管理敏感数据的能力至关重要

Method: 1. 基于Contextual Integrity设计隐私相关场景；2. 调查450名用户的隐私偏好及隐私导向对行为选择的影响；3. 向10个最先进LLM提供相同场景和问题；4. 实施四种额外提示策略并比较结果

Result: 用户与LLM在隐私场景中的一致性较低

Conclusion: 讨论了AI隐私意识在人机交互中的意义和潜力

Abstract: Social robots are embodied agents that interact with people while following
human communication norms. These robots interact using verbal and non-verbal
cues, and share the physical environments of people. While social robots have
previously utilized rule-based systems or probabilistic models for user
interaction, the rapid evolution of large language models (LLMs) presents new
opportunities to develop LLM-empowered social robots for enhanced human-robot
interaction. To fully realize these capabilities, however, robots need to
collect data such as audio, fine-grained images, video, and locations. As a
result, LLMs often process sensitive personal information, particularly within
home environments. Given the tension between utility and privacy risks,
evaluating how current LLMs manage sensitive data is critical. Specifically, we
aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the
context of household social robots. In this study, we present a set of
privacy-relevant scenarios crafted through the lens of Contextual Integrity
(CI). We first survey users' privacy preferences regarding in-home social robot
behaviors and then examine how their privacy orientation affects their choices
of these behaviors (N = 450). We then provide the same set of scenarios and
questions to state-of-the-art LLMs (N = 10) and find that the agreement between
humans and LLMs is low. To further investigate the capabilities of LLMs as a
potential privacy controller, we implement four additional prompting strategies
and compare their results. Finally, we discuss the implications and potential
of AI privacy awareness in human-robot interaction.

</details>


### [9] [Equivariant Goal Conditioned Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.16139)
*Arsh Tangri,Nichols Crawford Taylor,Haojie Huang,Robert Platt*

Main category: cs.RO

TL;DR: 本文提出等变对比强化学习（ECRL），通过利用目标条件操作任务中的固有对称性，引入旋转不变评论家表示和旋转等变演员，在基于状态和图像的模拟任务中持续优于强基线，并扩展到离线RL设置显示有效性。


<details>
  <summary>Details</summary>
Motivation: 对比强化学习（CRL）虽能从无标签交互中提取有用结构化表示，但在样本效率和空间泛化方面有提升空间，故需利用任务对称性进一步结构化潜在空间。

Method: 定义目标条件组不变MDP以描述旋转对称机器人操作任务，为CRL引入新颖的旋转不变评论家表示和旋转等变演员。

Result: 在一系列基于状态和图像的模拟任务中持续优于强基线，并成功扩展到离线RL设置，在多个任务中证明有效性。

Conclusion: ECRL通过等变约束结构化潜在空间，利用任务对称性提升了样本效率和空间泛化能力，在不同设置和任务中表现有效。

Abstract: Contrastive Reinforcement Learning (CRL) provides a promising framework for
extracting useful structured representations from unlabeled interactions. By
pulling together state-action pairs and their corresponding future states,
while pushing apart negative pairs, CRL enables learning nontrivial policies
without manually designed rewards. In this work, we propose Equivariant CRL
(ECRL), which further structures the latent space using equivariant
constraints. By leveraging inherent symmetries in goal-conditioned manipulation
tasks, our method improves both sample efficiency and spatial generalization.
Specifically, we formally define Goal-Conditioned Group-Invariant MDPs to
characterize rotation-symmetric robotic manipulation tasks, and build on this
by introducing a novel rotation-invariant critic representation paired with a
rotation-equivariant actor for Contrastive RL. Our approach consistently
outperforms strong baselines across a range of simulated tasks in both
state-based and image-based settings. Finally, we extend our method to the
offline RL setting, demonstrating its effectiveness across multiple tasks.

</details>


### [10] [Scanning Bot: Efficient Scan Planning using Panoramic Cameras](https://arxiv.org/abs/2507.16175)
*Euijeong Lee,Kyung Min Han,Young J. Kim*

Main category: cs.RO

TL;DR: 本文提出一种全自主扫描规划方法，用于全景RGB-D相机的环境扫描，解决手动选择视点和运输相机导致的耗时、繁琐及新手操作困难等问题，通过生成高效巡视计划确保无碰撞导航和足够视点重叠，在合成与真实环境实验中表现优于现有方法，真实环境平均扫描覆盖率达99%，总扫描时间比最先进规划器快3倍。


<details>
  <summary>Details</summary>
Motivation: 全景RGB-D相机虽能生成高质量3D场景重建，但手动选择视点和运输相机使3D模型生成耗时且繁琐，且因空间限制（如确保视点帧间足够特征重叠）对新手用户具有挑战性。

Method: 提出全自主扫描规划，生成高效环境扫描巡视计划，确保无碰撞导航和计划内视点间的足够重叠。

Result: 在合成和真实环境中进行的大量实验验证了该规划器相对于最先进视图规划器的性能，特别是在真实世界实验中，该方法的平均扫描覆盖率达99%，总扫描时间比最先进规划器快3倍。

Conclusion: 所提出的全自主扫描规划方法有效解决了全景RGB-D相机扫描中的问题，在扫描覆盖率和效率上均优于现有方法。

Abstract: Panoramic RGB-D cameras are known for their ability to produce high quality
3D scene reconstructions. However, operating these cameras involves manually
selecting viewpoints and physically transporting the camera, making the
generation of a 3D model time consuming and tedious. Additionally, the process
can be challenging for novice users due to spatial constraints, such as
ensuring sufficient feature overlap between viewpoint frames. To address these
challenges, we propose a fully autonomous scan planning that generates an
efficient tour plan for environment scanning, ensuring collision-free
navigation and adequate overlap between viewpoints within the plan. Extensive
experiments conducted in both synthetic and real-world environments validate
the performance of our planner against state-of-the-art view planners. In
particular, our method achieved an average scan coverage of 99 percent in the
real-world experiment, with our approach being up to 3 times faster than
state-of-the-art planners in total scan time.

</details>


### [11] [Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers](https://arxiv.org/abs/2507.16214)
*Batu Candan,Simone Servadio*

Main category: cs.RO

TL;DR: 本文提出了一个完整的管道，将先进的计算机视觉技术与自适应非线性滤波相结合，以解决针对翻滚废弃卫星（如欧空局的ENVISAT）的挑战性主动碎片清除（ADR）任务中的相对位姿估计问题。


<details>
  <summary>Details</summary>
Motivation: 为了实现针对翻滚废弃卫星（如欧空局的ENVISAT）的具有挑战性的主动碎片清除（ADR）任务，需要准确且稳健的相对位姿估计。

Method: 该工作提出了一个完整的管道，包括使用增强图像预处理的卷积神经网络（CNN）从追踪器图像中检测结构标记（角点），通过相机建模将其2D坐标转换为3D测量值，并在无迹卡尔曼滤波器（UKF）框架内融合这些测量值以估计完整的相对位姿。UKF中采用了双重自适应策略：动态调整测量噪声协方差以补偿CNN测量不确定性的变化，以及利用测量残差分析自适应调整过程噪声协方差以在线考虑未建模的动力学或机动。

Result: 通过使用逼真的ENVISAT模型进行高保真模拟，在各种条件下（包括测量中断）将估计值与地面实况进行比较，评估了所提出的自适应集成系统的性能。

Conclusion: 这种综合方法为稳健的机载相对导航提供了增强的解决方案，显著提升了ADR任务期间安全接近操作所需的能力。

Abstract: Accurate and robust relative pose estimation is crucial for enabling
challenging Active Debris Removal (ADR) missions targeting tumbling derelict
satellites such as ESA's ENVISAT. This work presents a complete pipeline
integrating advanced computer vision techniques with adaptive nonlinear
filtering to address this challenge. A Convolutional Neural Network (CNN),
enhanced with image preprocessing, detects structural markers (corners) from
chaser imagery, whose 2D coordinates are converted to 3D measurements using
camera modeling. These measurements are fused within an Unscented Kalman Filter
(UKF) framework, selected for its ability to handle nonlinear relative
dynamics, to estimate the full relative pose. Key contributions include the
integrated system architecture and a dual adaptive strategy within the UKF:
dynamic tuning of the measurement noise covariance compensates for varying CNN
measurement uncertainty, while adaptive tuning of the process noise covariance,
utilizing measurement residual analysis, accounts for unmodeled dynamics or
maneuvers online. This dual adaptation enhances robustness against both
measurement imperfections and dynamic model uncertainties. The performance of
the proposed adaptive integrated system is evaluated through high-fidelity
simulations using a realistic ENVISAT model, comparing estimates against ground
truth under various conditions, including measurement outages. This
comprehensive approach offers an enhanced solution for robust onboard relative
navigation, significantly advancing the capabilities required for safe
proximity operations during ADR missions.

</details>


### [12] [GFM-Planner: Perception-Aware Trajectory Planning with Geometric Feature Metric](https://arxiv.org/abs/2507.16233)
*Yue Lin,Xiaoxuan Zhang,Yang Liu,Dong Wang,Huchuan Lu*

Main category: cs.RO

TL;DR: 提出GFM-Planner框架，通过几何特征度量(GFM)引导机器人避开退化区域，提升LiDAR定位精度


<details>
  <summary>Details</summary>
Motivation: 自主机器人依赖特征丰富环境进行精确定位，需解决如何引导机器人避开退化区域以提升定位精度的问题

Method: 1. 从LiDAR定位问题推导出几何特征度量(GFM)；2. 设计2D网格基度量编码图(MEM)存储GFM值；3. 提出常数时间解码算法从MEM检索任意位姿的GFM值；4. 开发感知感知轨迹规划算法引导机器人选择特征丰富区域轨迹

Result: 仿真和真实世界实验表明，该方法能使机器人主动选择轨迹，显著提升LiDAR定位精度

Conclusion: GFM-Planner框架可有效引导机器人通过特征丰富区域，从而增强LiDAR定位能力

Abstract: Like humans who rely on landmarks for orientation, autonomous robots depend
on feature-rich environments for accurate localization. In this paper, we
propose the GFM-Planner, a perception-aware trajectory planning framework based
on the geometric feature metric, which enhances LiDAR localization accuracy by
guiding the robot to avoid degraded areas. First, we derive the Geometric
Feature Metric (GFM) from the fundamental LiDAR localization problem. Next, we
design a 2D grid-based Metric Encoding Map (MEM) to efficiently store GFM
values across the environment. A constant-time decoding algorithm is further
proposed to retrieve GFM values for arbitrary poses from the MEM. Finally, we
develop a perception-aware trajectory planning algorithm that improves LiDAR
localization capabilities by guiding the robot in selecting trajectories
through feature-rich areas. Both simulation and real-world experiments
demonstrate that our approach enables the robot to actively select trajectories
that significantly enhance LiDAR localization accuracy.

</details>


### [13] [Trajectory Planning of a Curtain Wall Installation Robot Based on Biomimetic Mechanisms](https://arxiv.org/abs/2507.16305)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文提出一种受人类上肢举重运动力学启发的生物启发轨迹规划框架，以解决建筑机器人能耗问题，通过整合人类力施加模式和能耗模式，利用粒子群优化算法实现基于类人运动特征的机械臂轨迹规划动态负载分配，并在幕墙安装任务中验证，能耗降低48.4%。


<details>
  <summary>Details</summary>
Motivation: 建筑机器人能耗问题限制其应用，需优化能耗。

Method: 收集哑铃弯举时的运动轨迹和肌电信号，构建整合人类力施加与能耗模式的拟人轨迹规划，利用粒子群优化算法实现基于类人运动特征的机械臂轨迹规划动态负载分配，并应用于幕墙安装任务。

Result: 仿真结果显示能耗降低48.4%。

Conclusion: 该方法为幕墙安装机器人在实际搬运任务中的能耗优化提供了新见解和理论支持。

Abstract: As the robotics market rapidly evolves, energy consumption has become a
critical issue, particularly restricting the application of construction
robots. To tackle this challenge, our study innovatively draws inspiration from
the mechanics of human upper limb movements during weight lifting, proposing a
bio-inspired trajectory planning framework that incorporates human energy
conversion principles. By collecting motion trajectories and electromyography
(EMG) signals during dumbbell curls, we construct an anthropomorphic trajectory
planning that integrates human force exertion patterns and energy consumption
patterns. Utilizing the Particle Swarm Optimization (PSO) algorithm, we achieve
dynamic load distribution for robotic arm trajectory planning based on
human-like movement features. In practical application, these bio-inspired
movement characteristics are applied to curtain wall installation tasks,
validating the correctness and superiority of our trajectory planning method.
Simulation results demonstrate a 48.4% reduction in energy consumption through
intelligent conversion between kinetic and potential energy. This approach
provides new insights and theoretical support for optimizing energy use in
curtain wall installation robots during actual handling tasks.

</details>


### [14] [Design and Dimensional Optimization of Legged Structures for Construction Robots](https://arxiv.org/abs/2507.16328)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文受自然界蚂蚁启发，提出针对建筑场景的腿部构型设计与优化方法，通过运动学建模、多维工作空间分析、平均可操作性概念及虚拟原型仿真，获得综合运动性能最佳的腿部节段比例，为腿式建筑机器人在复杂地形实现自主移动提供结构设计基础。


<details>
  <summary>Details</summary>
Motivation: 轮式和履带式机器人在复杂非结构化建筑环境中地形适应性和灵活性存在显著局限，难以满足自主作业需求。

Method: 1. 分析腿部在摆动和支撑阶段的全操作运动性能；2. 基于运动学建模和多维工作空间分析，引入“改进工作空间”概念，用图形法优化摆动阶段腿部尺寸；3. 基于速度雅可比矩阵引入“平均可操作性”新概念，通过数值解法获得最大化可操作性的腿部节段比例；4. 在ADAMS中进行虚拟原型仿真，探索机器人身体最佳灵活性与腿部节段比例的关系。

Result: 获得了综合运动性能最佳的腿部节段比例。

Conclusion: 本研究提出首个针对建筑环境的腿部运动性能多维定量评估框架，为腿式建筑机器人在复杂地形实现自主移动提供了结构设计基础。

Abstract: Faced with complex and unstructured construction environments, wheeled and
tracked robots exhibit significant limitations in terrain adaptability and
flexibility, making it difficult to meet the requirements of autonomous
operation. Inspired by ants in nature, this paper proposes a leg configuration
design and optimization method tailored for construction scenarios, aiming to
enhance the autonomous mobility of construction robots. This paper analyzes the
full operational motion performance of the leg during both swing and stance
phases. First, based on kinematic modeling and multi-dimensional workspace
analysis, the concept of an "improved workspace" is introduced, and graphical
methods are used to optimize the leg dimensions during the swing phase.
Furthermore, a new concept of "average manipulability" is introduced based on
the velocity Jacobian matrix, and numerical solutions are applied to obtain the
leg segment ratio that maximizes manipulability. To overcome the difficulties
associated with traditional analytical methods, virtual prototype simulations
are conducted in ADAMS to explore the relationship between the robot body's
optimal flexibility and leg segment proportions. In summary, the leg segment
proportions with the best comprehensive motion performance are obtained. This
study presents the first multi-dimensional quantitative evaluation framework
for leg motion performance tailored for construction environments, providing a
structural design foundation for legged construction robots to achieve
autonomous mobility in complex terrains.

</details>


### [15] [Topology Optimization of Leg Structures for Construction Robots Based on Variable Density Method](https://arxiv.org/abs/2507.16335)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文聚焦建筑机器人腿部结构优化，提出基于SIMP变密度法的拓扑优化策略及结构再设计方法，经ANSYS有限元分析验证，股骨质量减少19.45%，腿部总质量减少7.92%，且仍满足结构性能要求，为轻量化建筑机器人设计提供理论和技术支持。


<details>
  <summary>Details</summary>
Motivation: 复杂地形建筑环境中，机器人需同时具备高负载能力和移动灵活性，腿部作为关键承重部件，其结构优化尤为重要。

Method: 采用基于SIMP变密度法的拓扑优化策略及结构再设计方法，通过ANSYS进行有限元分析，先对初始设计进行静力学和模态分析评估合理性，再对占腿部重量最大比例的股骨部分应用拓扑优化，经迭代计算后对股骨进行二次结构重构，最后对重构后的腿部进行静力学和模态分析。

Result: 优化后，股骨质量减少19.45%，腿部总质量减少7.92%，且优化后的腿部仍满足结构性能要求。

Conclusion: 该研究为轻量化建筑机器人设计提供了有力的理论和技术支持，为其在复杂建筑环境中的高效运行奠定了基础。

Abstract: In complex terrain construction environments, there are high demands for
robots to achieve both high payload capacity and mobility flexibility. As the
key load-bearing component, the optimization of robotic leg structures is of
particular importance. Therefore, this study focuses on the optimization of leg
structures for construction robots, proposing a topology optimization strategy
based on the SIMP (Solid Isotropic Microstructures with Penalization) variable
density method along with a structural re-design approach. The design
performance is comprehensively validated through finite element analysis using
ANSYS. First, static and modal analyses are conducted to evaluate the
rationality of the initial design. Then, topology optimization using the
SIMP-based variable density method is applied to the femur section, which
accounts for the largest proportion of the leg's weight. Based on iterative
calculations, the femur undergoes secondary structural reconstruction. After
optimization, the mass of the femur is reduced by 19.45\%, and the overall leg
mass decreases by 7.92\%, achieving the goal of lightweight design. Finally,
static and modal analyses are conducted on the reconstructed leg. The results
demonstrate that the optimized leg still meets structural performance
requirements, validating the feasibility of lightweight design. This research
provides robust theoretical and technical support for lightweight construction
robot design and lays a foundation for their efficient operation in complex
construction environments.

</details>


### [16] [Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane](https://arxiv.org/abs/2507.16369)
*Thanh D V Nguyen,Vincent Bonnet,Pierre Fernbach,David Daney,Florent Lamiraux*

Main category: cs.RO

TL;DR: 提出一种新的实用方法，利用单平面、嵌入式力传感器和导纳控制器，通过IROC算法生成31个最优校准姿态，在TALOS人形机器人上验证，相比制造商模型平均RMS误差降低2.3倍，实现无需人工干预的全身运动学校准


<details>
  <summary>Details</summary>
Motivation: 全身几何校准耗时且实验负担重，虽对精确控制和仿真重要但常被人形机器人领域忽视

Method: 利用单平面、嵌入式力传感器和导纳控制器，提出IROC算法生成最小化最优校准姿态集，通过可行候选姿态池构建归一化加权信息矩阵确定最优姿态

Result: 在TALOS机器人上用31个3点接触桌面的最优姿态校准全身运动学链，交叉验证中平均RMS误差较制造商模型降低2.3倍

Conclusion: 提出的单平面校准方法和IROC算法有效，能在减少实验负担的情况下提升人形机器人全身运动学精度

Abstract: Whole-body geometric calibration of humanoid robots using classical robot
calibration methods is a timeconsuming and experimentally burdensome task.
However, despite its significance for accurate control and simulation, it is
often overlooked in the humanoid robotics community. To address this issue, we
propose a novel practical method that utilizes a single plane, embedded force
sensors, and an admittance controller to calibrate the whole-body kinematics of
humanoids without requiring manual intervention. Given the complexity of
humanoid robots, it is crucial to generate and determine a minimal set of
optimal calibration postures. To do so, we propose a new algorithm called IROC
(Information Ranking algorithm for selecting Optimal Calibration postures).
IROC requires a pool of feasible candidate postures to build a normalized
weighted information matrix for each posture. Then, contrary to other
algorithms from the literature, IROC will determine the minimal number of
optimal postures that are to be played onto a robot for its calibration. Both
IROC and the single-plane calibration method were experimentally validated on a
TALOS humanoid robot. The total whole-body kinematics chain was calibrated
using solely 31 optimal postures with 3-point contacts on a table by the robot
gripper. In a cross-validation experiment, the average root-mean-square (RMS)
error was reduced by a factor of 2.3 compared to the manufacturer's model.

</details>


### [17] [Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance](https://arxiv.org/abs/2507.16382)
*Chenhao Yao,Zike Yuan,Xiaoxu Liu,Chi Zhu*

Main category: cs.RO

TL;DR: 本文提出一种新框架，利用大语言模型(LLMs)基于任务优先级和智能体可观测信息生成奖励函数，并通过更先进的评估指标动态在线调整，使多智能体系统(MAS)在动态环境中高效实现编队控制与避障，仿真和现实实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习(MARL)在多智能体系统(MAS)中效果显著，但在编队控制与避障(FCCA)复杂目标下，设计能促使策略网络快速收敛到最优解的有效奖励函数面临挑战。

Method: 引入新框架，让大语言模型(LLMs)基于任务优先级和各智能体可观测信息生成奖励函数，并采用更先进的评估指标而非奖励本身，根据评估结果动态在线调整奖励函数。

Result: 该机制使多智能体系统(MAS)能在动态环境中同时实现编队控制和避障，效率提升，达到优异性能所需迭代次数减少，仿真和现实环境下的实证研究验证了所提方法的实用性和有效性。

Conclusion: 所提出的框架通过LLMs生成并动态调整奖励函数，有效解决了FCCA任务中奖励函数设计难题，提升了MAS在动态环境中的性能和效率。

Abstract: Multi-Agent Systems (MAS) excel at accomplishing complex objectives through
the collaborative efforts of individual agents. Among the methodologies
employed in MAS, Multi-Agent Reinforcement Learning (MARL) stands out as one of
the most efficacious algorithms. However, when confronted with the complex
objective of Formation Control with Collision Avoidance (FCCA): designing an
effective reward function that facilitates swift convergence of the policy
network to an optimal solution. In this paper, we introduce a novel framework
that aims to overcome this challenge. By giving large language models (LLMs) on
the prioritization of tasks and the observable information available to each
agent, our framework generates reward functions that can be dynamically
adjusted online based on evaluation outcomes by employing more advanced
evaluation metrics rather than the rewards themselves. This mechanism enables
the MAS to simultaneously achieve formation control and obstacle avoidance in
dynamic environments with enhanced efficiency, requiring fewer iterations to
reach superior performance levels. Our empirical studies, conducted in both
simulation and real-world settings, validate the practicality and effectiveness
of our proposed approach.

</details>


### [18] [AI or Human? Understanding Perceptions of Embodied Robots with LLMs](https://arxiv.org/abs/2507.16398)
*Lavinia Hriscu,Alberto Sanfeliu,Anais Garrell*

Main category: cs.RO

TL;DR: 本研究在机器人平台上进行图灵测试，以探究参与者对具身机器人智能的感知，结果表明参与者无法可靠区分AI与人类操作的机器人，且分析了影响感知的关键因素，为未来交互机器人设计及AI智能评估提供见解。


<details>
  <summary>Details</summary>
Motivation: 尽管图灵测试被提出用于评估系统智能，但其在人机交互领域的相关性和应用仍未被充分探索，因此本研究旨在探究具身机器人的智能感知。

Method: 在机器人平台上进行图灵测试，34名参与者需在信息检索和包裹交接两项交互任务中区分AI和人类操作的机器人，这些任务在静态和动态条件下评估机器人的感知与导航能力。

Result: 参与者无法可靠地区分AI和人类控制的机器人，其区分能力未超过随机水平，且分析参与者反应揭示了影响具身机器人系统中人工与人类智能感知的关键因素。

Conclusion: 研究结果为未来交互机器人设计提供了见解，并有助于推动AI驱动系统智能评估的相关讨论。

Abstract: The pursuit of artificial intelligence has long been associated to the the
challenge of effectively measuring intelligence. Even if the Turing Test was
introduced as a means of assessing a system intelligence, its relevance and
application within the field of human-robot interaction remain largely
underexplored. This study investigates the perception of intelligence in
embodied robots by performing a Turing Test within a robotic platform. A total
of 34 participants were tasked with distinguishing between AI- and
human-operated robots while engaging in two interactive tasks: an information
retrieval and a package handover. These tasks assessed the robot perception and
navigation abilities under both static and dynamic conditions. Results indicate
that participants were unable to reliably differentiate between AI- and
human-controlled robots beyond chance levels. Furthermore, analysis of
participant responses reveals key factors influencing the perception of
artificial versus human intelligence in embodied robotic systems. These
findings provide insights into the design of future interactive robots and
contribute to the ongoing discourse on intelligence assessment in AI-driven
systems.

</details>


### [19] [Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones](https://arxiv.org/abs/2507.16458)
*Yang Xu,Jesús Bautista,José Hinojosa,Héctor García de Marina*

Main category: cs.RO

TL;DR: 本文提出一种无需速度控制即可实现固定翼无人机编队飞行的算法，通过在引导向量场上叠加振荡行为，利用新型共识算法和分布式闭环调整振荡幅度，实现路径平均速度协调，经理论分析、数值模拟和实际飞行验证有效。


<details>
  <summary>Details</summary>
Motivation: 固定翼无人机编队飞行中，速度协调因速度严格受限且多设计为标称空速飞行而困难，故需无需速度控制的编队算法。

Method: 引导无人机沿特定路径（如平行直线）飞行，在引导向量场上叠加振荡行为以控制路径平均速度；无人机通过无向连通图与邻居通信，分布式闭环调整振荡幅度，引入基于非负非对称饱和函数的新型共识算法。

Result: 算法经严格理论分析、数值模拟及实际编队飞行验证有效。

Conclusion: 所提算法无需速度控制，通过振荡行为和新型共识算法实现固定翼无人机编队飞行，具有理论和实践有效性。

Abstract: The autonomous formation flight of fixed-wing drones is hard when the
coordination requires the actuation over their speeds since they are critically
bounded and aircraft are mostly designed to fly at a nominal airspeed. This
paper proposes an algorithm to achieve formation flights of fixed-wing drones
without requiring any actuation over their speed. In particular, we guide all
the drones to travel over specific paths, e.g., parallel straight lines, and we
superpose an oscillatory behavior onto the guiding vector field that drives the
drones to the paths. This oscillation enables control over the average velocity
along the path, thereby facilitating inter-drone coordination. Each drone
adjusts its oscillation amplitude distributively in a closed-loop manner by
communicating with neighboring agents in an undirected and connected graph. A
novel consensus algorithm is introduced, leveraging a non-negative, asymmetric
saturation function. This unconventional saturation is justified since negative
amplitudes do not make drones travel backward or have a negative velocity along
the path. Rigorous theoretical analysis of the algorithm is complemented by
validation through numerical simulations and a real-world formation flight.

</details>


### [20] [Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots](https://arxiv.org/abs/2507.16480)
*Sabrina Livanec,Laura Londoño,Michael Gorki,Adrian Röfer,Abhinav Valada,Andrea Kiesel*

Main category: cs.RO

TL;DR: 本研究旨在解决参与者评估不同机器人行为与人类需求结合的研究空白，通过在线实验（112名参与者，含实验组和对照组）发现人机协作类型影响评估，反社会机器人行为评分最低，与老年人协作引发更敏感评价，有物品交接场景更积极，认知-情感映射（CAM）反思未显著影响整体评分但对特定组合评估更明显，强调亲社会设计及反思方法对用户中心和社会责任机器人系统的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前关于参与者如何评估不同机器人行为与多样化人类需求结合的研究稀缺，可能因参与者对先进家用机器人的真实世界经验有限，故需填补此空白并使用能让参与者评估机器人行为及支持有意义反思的方法。

Method: 在在线研究中，112名参与者（来自实验组和对照组）评估了28种人机协作类型中的7个视频；实验组在提供评分前先完成了关于人机协作的认知-情感映射（CAM）练习。

Result: CAM反思未显著影响整体评分，但对某些机器人行为和人类状况的组合导致更明显的评估；人机协作类型影响评估，反社会机器人行为始终评分最低，与老年人协作引发更敏感评价，涉及物品交接的场景比无交接的更积极。

Conclusion: 人类特征和交互范式均影响协作机器人的感知可接受性，强调亲社会设计的重要性；同时突出反思方法（如CAM）引出细微反馈的潜力，支持为多样化人群定制用户中心和社会责任的机器人系统。

Abstract: The development of assistive robots for social collaboration raises critical
questions about responsible and inclusive design, especially when interacting
with individuals from protected groups such as those with disabilities or
advanced age. Currently, research is scarce on how participants assess varying
robot behaviors in combination with diverse human needs, likely since
participants have limited real-world experience with advanced domestic robots.
In the current study, we aim to address this gap while using methods that
enable participants to assess robot behavior, as well as methods that support
meaningful reflection despite limited experience. In an online study, 112
participants (from both experimental and control groups) evaluated 7 videos
from a total of 28 variations of human-robot collaboration types. The
experimental group first completed a cognitive-affective mapping (CAM) exercise
on human-robot collaboration before providing their ratings. Although CAM
reflection did not significantly affect overall ratings, it led to more
pronounced assessments for certain combinations of robot behavior and human
condition. Most importantly, the type of human-robot collaboration influences
the assessment. Antisocial robot behavior was consistently rated as the lowest,
while collaboration with aged individuals elicited more sensitive evaluations.
Scenarios involving object handovers were viewed more positively than those
without them. These findings suggest that both human characteristics and
interaction paradigms influence the perceived acceptability of collaborative
robots, underscoring the importance of prosocial design. They also highlight
the potential of reflective methods, such as CAM, to elicit nuanced feedback,
supporting the development of user-centered and socially responsible robotic
systems tailored to diverse populations.

</details>


### [21] [Guided Reinforcement Learning for Omnidirectional 3D Jumping in Quadruped Robots](https://arxiv.org/abs/2507.16481)
*Riccardo Bussola,Michele Focchi,Giulio Turrisi,Claudio Semini,Luigi Palopoli*

Main category: cs.RO

TL;DR: 本文提出一种新的引导强化学习方法，结合贝塞尔曲线和匀加速直线运动（UARM）模型，以解决四足机器人跳跃控制中的优化方法耗时、传统端到端强化学习样本效率低和运动可预测性差的问题，实验结果证明该方法优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 四足机器人跳跃在许多操作场景中至关重要，但现有优化方法耗时且需大量机器人和地形参数知识，在现实场景中鲁棒性不足；传统端到端强化学习样本复杂度高，需大量仿真训练，且最终运动的可预测性差，难以保证安全性。

Method: 提出一种新的引导强化学习方法，利用物理直觉，将贝塞尔曲线与匀加速直线运动（UARM）模型相结合，实现高效且可解释的跳跃。

Result: 通过大量仿真和实验结果，清晰证明了所提方法相比现有替代方案具有优势。

Conclusion: 所提出的结合贝塞尔曲线和UARM模型的引导强化学习方法能够有效克服四足机器人跳跃控制中的现有局限性，提升效率和可解释性。

Abstract: Jumping poses a significant challenge for quadruped robots, despite being
crucial for many operational scenarios. While optimisation methods exist for
controlling such motions, they are often time-consuming and demand extensive
knowledge of robot and terrain parameters, making them less robust in
real-world scenarios. Reinforcement learning (RL) is emerging as a viable
alternative, yet conventional end-to-end approaches lack efficiency in terms of
sample complexity, requiring extensive training in simulations, and
predictability of the final motion, which makes it difficult to certify the
safety of the final motion. To overcome these limitations, this paper
introduces a novel guided reinforcement learning approach that leverages
physical intuition for efficient and explainable jumping, by combining B\'ezier
curves with a Uniformly Accelerated Rectilinear Motion (UARM) model. Extensive
simulation and experimental results clearly demonstrate the advantages of our
approach over existing alternatives.

</details>


### [22] [A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System](https://arxiv.org/abs/2507.16621)
*Lorenzo Gentilini,Pierpaolo Serio,Valentina Donzella,Lorenzo Pollini*

Main category: cs.RO

TL;DR: 本文提出一种基于目标的外参标定系统，用于多激光雷达和多相机传感器套件，通过自定义ChArUco板和非线性优化方法实现有限先验知识下的激光雷达与相机交叉标定，在仓库实际数据测试中证明了有效性和可行性。


<details>
  <summary>Details</summary>
Motivation: 外参标定是自动驾驶的基石，其精度对感知 pipeline 至关重要，而现代传感器系统采集的环境数据类型多样，导致数据对齐难度增加。

Method: 提出基于目标的外参标定系统，使用自定义ChArUco板和定制的非线性优化方法，实现多激光雷达和多相机传感器套件在有限先验知识下的交叉标定。

Result: 在仓库采集的真实世界数据上测试，结果证明了所提方法的有效性，突出了为各类传感器定制独特 pipeline 的可行性。

Conclusion: 所提出的基于目标的外参标定系统适用于多激光雷达和多相机传感器套件，能有效实现交叉标定，具有实际应用价值。

Abstract: Extrinsic Calibration represents the cornerstone of autonomous driving. Its
accuracy plays a crucial role in the perception pipeline, as any errors can
have implications for the safety of the vehicle. Modern sensor systems collect
different types of data from the environment, making it harder to align the
data. To this end, we propose a target-based extrinsic calibration system
tailored for a multi-LiDAR and multi-camera sensor suite. This system enables
cross-calibration between LiDARs and cameras with limited prior knowledge using
a custom ChArUco board and a tailored nonlinear optimization method. We test
the system with real-world data gathered in a warehouse. Results demonstrated
the effectiveness of the proposed method, highlighting the feasibility of a
unique pipeline tailored for various types of sensors.

</details>


### [23] [Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control](https://arxiv.org/abs/2507.16645)
*Zongzheng Zhang,Jiawen Yang,Ziqiao Peng,Meng Yang,Jianzhu Ma,Lin Cheng,Huazhe Xu,Hang Zhao,Hao Zhao*

Main category: cs.RO

TL;DR: 该论文提出一种混合驱动方法，结合刚性驱动和肌腱驱动机制，并引入自建模网络和神经网络，实现从语音输入生成多种情感表情的紧凑型多功能硬件平台。


<details>
  <summary>Details</summary>
Motivation: 以往电子动画脸因硬件和软件限制难以有效表达情感，硬件上刚性驱动机制精确但设计受限，肌腱驱动机制空间效率高但控制难。

Method: 硬件采用混合驱动方法，眼和嘴用刚性机制控制精确运动，鼻子和脸颊用字符串驱动传递微妙微表情；算法引入自建模网络映射电机动作到面部地标，通过梯度反向传播自动建立不同面部表情混合形状系数与相应电机控制信号的关系，训练神经网络将语音输入映射到相应混合形状控制。

Result: 能够从任何给定句子生成快乐、恐惧、厌恶和愤怒等不同情感表情，每种表情都有细微的、特定于情感的控制信号，这是早期系统未展示的功能。

Conclusion: 构建了一个紧凑且多功能的硬件平台，能表达广泛的情感，并发布了硬件设计和代码。

Abstract: Previous animatronic faces struggle to express emotions effectively due to
hardware and software limitations. On the hardware side, earlier approaches
either use rigid-driven mechanisms, which provide precise control but are
difficult to design within constrained spaces, or tendon-driven mechanisms,
which are more space-efficient but challenging to control. In contrast, we
propose a hybrid actuation approach that combines the best of both worlds. The
eyes and mouth-key areas for emotional expression-are controlled using rigid
mechanisms for precise movement, while the nose and cheek, which convey subtle
facial microexpressions, are driven by strings. This design allows us to build
a compact yet versatile hardware platform capable of expressing a wide range of
emotions. On the algorithmic side, our method introduces a self-modeling
network that maps motor actions to facial landmarks, allowing us to
automatically establish the relationship between blendshape coefficients for
different facial expressions and the corresponding motor control signals
through gradient backpropagation. We then train a neural network to map speech
input to corresponding blendshape controls. With our method, we can generate
distinct emotional expressions such as happiness, fear, disgust, and anger,
from any given sentence, each with nuanced, emotion-specific control signals-a
feature that has not been demonstrated in earlier systems. We release the
hardware design and code at https://github.com/ZZongzheng0918/Morpheus-Hardware
and https://github.com/ZZongzheng0918/Morpheus-Software.

</details>


### [24] [Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory](https://arxiv.org/abs/2507.16713)
*Guowei Lan,Kaixian Qu,René Zurbrügg,Changan Chen,Christopher E. Mower,Haitham Bou-Ammar,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出ExpTeach框架，通过构建自生成的真实世界经验记忆来将视觉语言模型（VLMs）与物理机器人对接，实现自主规划、验证结果、反思失败并适应行为，结合检索增强生成（RAG）和按需图像标注模块，提升机器人任务成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决将原本基于互联网数据训练的VLMs应用于多样化真实世界机器人时的对接挑战。

Method: ExpTeach框架包含：VLM自主规划动作、验证结果、反思失败并闭环适应机器人行为；将自生成经验总结为长期记忆，通过RAG检索知识指导未来任务；配备按需图像标注模块增强VLMs的空间理解。

Result: 反思使四项挑战性机器人任务成功率从36%提升至84%，出现智能物体交互（含创造性工具使用）；在12个真实场景（含8个未见场景）中，长期记忆对接使单次尝试成功率从22%提升至80%。

Conclusion: ExpTeach通过自生成经验记忆和反思机制有效提升了VLMs在真实机器人上的对接效果和泛化能力，验证了其有效性和通用性。

Abstract: Vision-language models (VLMs) have been widely adopted in robotics to enable
autonomous planning. However, grounding VLMs, originally trained on internet
data, to diverse real-world robots remains a challenge. This paper presents
ExpTeach, a framework that grounds VLMs to physical robots by building a
self-generated memory of real-world experiences. In ExpTeach, the VLM
autonomously plans actions, verifies outcomes, reflects on failures, and adapts
robot behaviors in a closed loop. The self-generated experiences during this
process are then summarized into a long-term memory, enabling retrieval of
learned knowledge to guide future tasks via retrieval-augmented generation
(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with
an on-demand image annotation module. In experiments, we show that reflection
improves success rates from 36% to 84% on four challenging robotic tasks and
observe the emergence of intelligent object interactions, including creative
tool use. Across extensive tests on 12 real-world scenarios (including eight
unseen ones), we find that grounding with long-term memory boosts single-trial
success rates from 22% to 80%, demonstrating the effectiveness and
generalizability of ExpTeach.

</details>
