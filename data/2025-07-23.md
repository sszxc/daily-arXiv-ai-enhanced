<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Fast Task Planning with Neuro-Symbolic Relaxation](https://arxiv.org/abs/2507.15975)
*Qiwei Du,Bowen Li,Yi Du,Shaoshu Su,Taimeng Fu,Zitong Zhan,Zhipeng Zhao,Chen Wang*

Main category: cs.RO

TL;DR: Flax是一种神经符号松弛策略，结合神经重要性预测与符号扩展，显著提升任务规划的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统符号规划器在复杂环境中因组合爆炸导致的效率低下问题，同时避免简单神经符号方法可能忽略关键实体的风险。

Method: 使用图神经网络预测实体重要性生成简化任务，通过符号规划器求解；再通过规则松弛任务快速生成粗略计划，并重新整合被忽略的实体；最后应用补充规则优化任务。

Result: 在合成和真实迷宫导航基准测试中，Flax将平均成功率提升20.82%，规划时间减少17.65%。

Conclusion: Flax为复杂环境中的快速、可扩展、长视野任务规划提供了实用路径。

Abstract: Real-world task planning requires long-horizon reasoning over large sets of
entities with complex relationships and attributes, leading to a combinatorial
explosion for classical symbolic planners. To prune the search space, recent
methods prioritize searching on a simplified task only containing a few
"important" entities predicted by a neural network. However, such a simple
neuro-symbolic (NeSy) integration risks omitting critical entities and wasting
resources on unsolvable simplified tasks. To enable Fast and reliable planning,
we introduce a NeSy relaxation strategy (Flax), combining neural importance
prediction with symbolic expansion. Specifically, we first learn a graph neural
network to predict entity importance to create a simplified task and solve it
with a symbolic planner. Then, we solve a rule-relaxed task to obtain a quick
rough plan, and reintegrate all referenced entities into the simplified task to
recover any overlooked but essential elements. Finally, we apply complementary
rules to refine the updated task, keeping it both reliable and compact.
Extensive experiments are conducted on both synthetic and real-world maze
navigation benchmarks where a robot must traverse through a maze and interact
with movable objects. The results show that Flax boosts the average success
rate by 20.82% and cuts mean wall-clock planning time by 17.65% compared with
the state-of-the-art NeSy baseline. We expect that Flax offers a practical path
toward fast, scalable, long-horizon task planning in complex environments.

</details>


### [2] [A Comprehensive Evaluation of LiDAR Odometry Techniques](https://arxiv.org/abs/2507.16000)
*Easton Potokar,Michael Kaess*

Main category: cs.RO

TL;DR: 本文总结了LiDAR里程计（LO）管道的各种技术，并通过大量数据集评估了这些组件，最终提出了设计未来LO管道的建议。


<details>
  <summary>Details</summary>
Motivation: 由于LiDAR传感器在机器人状态估计任务中的广泛应用，但缺乏对LO管道各构建块的系统比较，本文旨在填补这一空白。

Method: 总结了LO管道的各种技术，并在多种数据集、LiDAR类型和车辆运动下进行了实证评估。

Result: 通过实证评估，提出了设计未来LO管道的建议，以提高准确性和可靠性。

Conclusion: 本文为未来LO管道的设计提供了实证支持的建议，有助于提升性能和可靠性。

Abstract: Light Detection and Ranging (LiDAR) sensors have become the sensor of choice
for many robotic state estimation tasks. Because of this, in recent years there
has been significant work done to fine the most accurate method to perform
state estimation using these sensors. In each of these prior works, an
explosion of possible technique combinations has occurred, with each work
comparing LiDAR Odometry (LO) "pipelines" to prior "pipelines". Unfortunately,
little work up to this point has performed the significant amount of ablation
studies comparing the various building-blocks of a LO pipeline. In this work,
we summarize the various techniques that go into defining a LO pipeline and
empirically evaluate these LO components on an expansive number of datasets
across environments, LiDAR types, and vehicle motions. Finally, we make
empirically-backed recommendations for the design of future LO pipelines to
provide the most accurate and reliable performance.

</details>


### [3] [Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation](https://arxiv.org/abs/2507.16034)
*Xuying Huang,Sicong Pan,Olga Zatsarynna,Juergen Gall,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出了一种联合学习方法，用于超低分辨率语义分割，以在保护隐私的同时提升机器人导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人中用户隐私保护与任务性能之间的权衡问题。

Method: 结合聚合特征提取器和分割感知判别器，实现超低分辨率语义分割。

Result: 在超低分辨率语义分割和隐私约束的导航任务中优于基线方法。

Conclusion: 该方法在保护隐私的同时有效提升了机器人导航的成功率。

Abstract: User privacy in mobile robotics has become a critical concern. Existing
methods typically prioritize either the performance of downstream robotic tasks
or privacy protection, with the latter often constraining the effectiveness of
task execution. To jointly address both objectives, we study semantic-based
robot navigation in an ultra-low-resolution setting to preserve visual privacy.
A key challenge in such scenarios is recovering semantic segmentation from
ultra-low-resolution RGB images. In this work, we introduce a novel fully
joint-learning method that integrates an agglomerative feature extractor and a
segmentation-aware discriminator to solve ultra-low-resolution semantic
segmentation, thereby enabling privacy-preserving, semantic object-goal
navigation. Our method outperforms different baselines on ultra-low-resolution
semantic segmentation and our improved segmentation results increase the
success rate of the semantic object-goal navigation in a real-world
privacy-constrained scenario.

</details>


### [4] [Therapist-Exoskeleton-Patient Interaction: An Immersive Gait Therapy](https://arxiv.org/abs/2507.16059)
*Emek Barış Küçüktabak,Matthew R. Short,Lorenzo Vianello,Daniel Ludvig,Levi Hargrove,Kevin Lynch,Jose Pons*

Main category: cs.RO

TL;DR: 提出了一种基于物理人-机器人-人交互（pHRHI）的新型步态康复范式，通过虚拟连接的髋膝弹簧阻尼元件实现治疗师和患者之间的双向交互，显著提升了康复效果。


<details>
  <summary>Details</summary>
Motivation: 传统康复方法中治疗师手动辅助强度大且难以同时控制多个关节，而现有机器人外骨骼控制策略限制了治疗师的参与和适应性。pHRHI旨在结合机器人精确性和治疗师直觉，提升康复效果。

Method: 治疗师和患者均穿戴下肢外骨骼，通过虚拟连接的髋膝弹簧阻尼元件实现双向交互，治疗师可引导运动并接收触觉反馈。

Result: 在八名慢性中风患者的研究中，pHRHI训练在关节活动范围、步态指标、肌肉激活和患者动机方面优于传统治疗师引导的跑步机步行。

Conclusion: pHRHI结合了机器人精确性和治疗师直觉，显著提升了康复效果，展示了其在步态康复中的潜力。

Abstract: Following a stroke, individuals often experience mobility and balance
impairments due to lower-limb weakness and loss of independent joint control.
Gait recovery is a key goal of rehabilitation, traditionally achieved through
high-intensity therapist-led training. However, manual assistance can be
physically demanding and limits the therapist's ability to interact with
multiple joints simultaneously. Robotic exoskeletons offer multi-joint support,
reduce therapist strain, and provide objective feedback, but current control
strategies often limit therapist involvement and adaptability.
  We present a novel gait rehabilitation paradigm based on physical
Human-Robot-Human Interaction (pHRHI), where both the therapist and the
post-stroke individual wear lower-limb exoskeletons virtually connected at the
hips and knees via spring-damper elements. This enables bidirectional
interaction, allowing the therapist to guide movement and receive haptic
feedback. In a study with eight chronic stroke patients, pHRHI training
outperformed conventional therapist-guided treadmill walking, leading to
increased joint range of motion, step metrics, muscle activation, and
motivation. These results highlight pHRHI's potential to combine robotic
precision with therapist intuition for improved rehabilitation outcomes.

</details>


### [5] [Compositional Coordination for Multi-Robot Teams with Large Language Models](https://arxiv.org/abs/2507.16068)
*Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: LAN2CB框架利用大语言模型（LLMs）将自然语言任务描述直接转换为多机器人系统的可执行Python代码，简化了传统专家驱动的多机器人协调流程。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人协调流程依赖专家手动翻译任务描述，耗时且不灵活，LAN2CB旨在解决这一问题。

Method: 通过任务分解和代码生成两个关键组件，将自然语言转换为任务图并生成可执行代码。

Result: 实验证明LAN2CB能有效实现多机器人协调，减少人工干预并支持任务泛化。

Conclusion: LAN2CB为多机器人协调提供了一种灵活且通用的解决方案。

Abstract: Multi-robot coordination has traditionally relied on a task-specific and
expert-driven pipeline, where natural language mission descriptions are
manually translated by domain experts into mathematical formulation, algorithm
design, and executable code. This conventional process is labor-intensive,
inaccessible to non-experts, and inflexible to changes in mission requirements.
Here, we propose LAN2CB (Language to Collective Behavior), a novel framework
that leverages large language models (LLMs) to streamline and generalize the
multi-robot coordination pipeline. LAN2CB directly converts natural language
mission descriptions into executable Python code for multi-robot systems
through two key components: (1) Mission Decomposition for Task Representation,
which parses the mission into a task graph with dependencies, and (2) Code
Generation, which uses the task graph and a structured knowledge base to
generate deployable robot control code. We further introduce a dataset of
natural language mission specifications to support development and
benchmarking. Experimental results in both simulation and real-world settings
show that LAN2CB enables effective and flexible multi-robot coordination from
natural language, significantly reducing the need for manual engineering while
supporting generalization across mission types. Website:
https://sites.google.com/view/lan2cb.

</details>


### [6] [FTIN: Frequency-Time Integration Network for Inertial Odometry](https://arxiv.org/abs/2507.16120)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种结合频域和时域信息的新型网络架构，显著提升了惯性里程计的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有惯性里程计方法主要依赖时域CNN，难以捕捉长期依赖关系，限制了定位精度的进一步提升。

Method: 通过频域学习的全局视角和能量压缩特性建模长期依赖，同时引入Scalar LSTM捕捉时域序列依赖，实现跨域信息融合。

Result: 在多个公开数据集上验证了方法的有效性，尤其在RoNIN数据集上绝对轨迹误差降低43.0%，相对轨迹误差降低13.1%。

Conclusion: 频域与时域融合策略显著提升了惯性里程计的定位精度，为未来研究提供了新思路。

Abstract: In recent years, machine learning has achieved significant advancements in
inertial odometry. However, most existing inertial odometry methods primarily
rely on CNNs in the time domain. These methods often struggle to capture
long-term dependency in inertial measurement unit data, thereby constraining
the potential for further improvements in localization accuracy. To address
these issues, we propose a novel network architecture that integrates both
frequency-domain and time-domain information. Specifically, we leverage the
global view and energy compaction properties of frequency-domain learning to
effectively model long-term dependency and reduce redundancy in IMU data.
Additionally, we introduce a Scalar LSTM to capture sequential dependencies in
the time domain, enabling cross-domain information fusion and providing a
stable and reliable reference for localization. Experimental evaluations on
multiple public datasets (e.g., RIDI, RoNIN, OxIOD, RNIN, TLIO, and IMUNet)
demonstrate the effectiveness of the proposed frequency-time domain fusion
strategy. Notably, on the RoNIN dataset, our method achieves a 43.0% reduction
in absolute trajectory error and a 13.1% reduction in relative trajectory error
compared to RoNIN ResNet.

</details>


### [7] [DWSFormer: A Lightweight Inertial Odometry Network for Complex Motion Modeling](https://arxiv.org/abs/2507.16121)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种轻量级惯性里程计框架，通过高维非线性特征空间和协作注意力机制，显著提升了复杂运动模式下的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有惯性里程计方法在复杂运动（如转弯）时存在漂移误差，限制了实际应用。

Method: 使用Star Operation方法将惯性数据投影到高维特征空间，引入协作注意力机制和多尺度门控卷积单元。

Result: 在六个惯性数据集上优于SOTA基线，RoNIN数据集上ATE降低2.26%至65.78%。

Conclusion: 该方法在惯性里程计领域设立了新基准，提升了复杂运动下的定位性能。

Abstract: Inertial odometry (IO) directly estimates the position of a carrier from
inertial sensor measurements and serves as a core technology for the widespread
deployment of consumer grade localization systems. While existing IO methods
can accurately reconstruct simple and near linear motion trajectories, they
often fail to account for drift errors caused by complex motion patterns such
as turning. This limitation significantly degrades localization accuracy and
restricts the applicability of IO systems in real world scenarios. To address
these challenges, we propose a lightweight IO framework. Specifically, inertial
data is projected into a high dimensional implicit nonlinear feature space
using the Star Operation method, enabling the extraction of complex motion
features that are typically overlooked. We further introduce a collaborative
attention mechanism that jointly models global motion dynamics across both
channel and temporal dimensions. In addition, we design Multi Scale Gated
Convolution Units to capture fine grained dynamic variations throughout the
motion process, thereby enhancing the model's ability to learn rich and
expressive motion representations. Extensive experiments demonstrate that our
proposed method consistently outperforms SOTA baselines across six widely used
inertial datasets. Compared to baseline models on the RoNIN dataset, it
achieves reductions in ATE ranging from 2.26% to 65.78%, thereby establishing a
new benchmark in the field.

</details>


### [8] [Benchmarking LLM Privacy Recognition for Social Robot Decision Making](https://arxiv.org/abs/2507.16124)
*Dakota Sullivan,Shirley Zhang,Jennica Li,Heather Kirkorian,Bilge Mutlu,Kassem Fawaz*

Main category: cs.RO

TL;DR: 研究探讨了大型语言模型（LLMs）在家庭社交机器人中的隐私意识，发现人类与LLMs在隐私偏好上的一致性较低，并测试了不同提示策略的效果。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在社交机器人中的应用增加，处理敏感数据的隐私风险成为关键问题，需评估LLMs的隐私意识。

Method: 通过情境完整性（CI）框架设计隐私相关场景，调查用户偏好（N=450），并测试LLMs（N=10）的反应，比较人类与LLMs的一致性。

Result: 人类与LLMs在隐私偏好上的一致性较低，不同提示策略对LLMs的隐私意识表现有显著影响。

Conclusion: LLMs在隐私控制方面潜力有限，需进一步研究AI隐私意识以优化人机交互。

Abstract: Social robots are embodied agents that interact with people while following
human communication norms. These robots interact using verbal and non-verbal
cues, and share the physical environments of people. While social robots have
previously utilized rule-based systems or probabilistic models for user
interaction, the rapid evolution of large language models (LLMs) presents new
opportunities to develop LLM-empowered social robots for enhanced human-robot
interaction. To fully realize these capabilities, however, robots need to
collect data such as audio, fine-grained images, video, and locations. As a
result, LLMs often process sensitive personal information, particularly within
home environments. Given the tension between utility and privacy risks,
evaluating how current LLMs manage sensitive data is critical. Specifically, we
aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the
context of household social robots. In this study, we present a set of
privacy-relevant scenarios crafted through the lens of Contextual Integrity
(CI). We first survey users' privacy preferences regarding in-home social robot
behaviors and then examine how their privacy orientation affects their choices
of these behaviors (N = 450). We then provide the same set of scenarios and
questions to state-of-the-art LLMs (N = 10) and find that the agreement between
humans and LLMs is low. To further investigate the capabilities of LLMs as a
potential privacy controller, we implement four additional prompting strategies
and compare their results. Finally, we discuss the implications and potential
of AI privacy awareness in human-robot interaction.

</details>


### [9] [Equivariant Goal Conditioned Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.16139)
*Arsh Tangri,Nichols Crawford Taylor,Haojie Huang,Robert Platt*

Main category: cs.RO

TL;DR: ECRL通过引入等变约束和对称性，提升了对比强化学习的样本效率和空间泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统CRL缺乏对任务对称性的利用，限制了学习效率和泛化能力。

Method: 提出Goal-Conditioned Group-Invariant MDPs和旋转不变性critic与旋转等变性actor结合的ECRL框架。

Result: 在模拟任务中优于基线方法，并扩展到离线RL场景。

Conclusion: ECRL通过结构化潜在空间，显著提升了对比强化学习的性能。

Abstract: Contrastive Reinforcement Learning (CRL) provides a promising framework for
extracting useful structured representations from unlabeled interactions. By
pulling together state-action pairs and their corresponding future states,
while pushing apart negative pairs, CRL enables learning nontrivial policies
without manually designed rewards. In this work, we propose Equivariant CRL
(ECRL), which further structures the latent space using equivariant
constraints. By leveraging inherent symmetries in goal-conditioned manipulation
tasks, our method improves both sample efficiency and spatial generalization.
Specifically, we formally define Goal-Conditioned Group-Invariant MDPs to
characterize rotation-symmetric robotic manipulation tasks, and build on this
by introducing a novel rotation-invariant critic representation paired with a
rotation-equivariant actor for Contrastive RL. Our approach consistently
outperforms strong baselines across a range of simulated tasks in both
state-based and image-based settings. Finally, we extend our method to the
offline RL setting, demonstrating its effectiveness across multiple tasks.

</details>


### [10] [Scanning Bot: Efficient Scan Planning using Panoramic Cameras](https://arxiv.org/abs/2507.16175)
*Euijeong Lee,Kyung Min Han,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一种全自动扫描规划方法，用于高效生成环境扫描路径，解决手动操作耗时和空间约束问题。


<details>
  <summary>Details</summary>
Motivation: 解决全景RGB-D相机手动操作耗时、繁琐及空间约束对新手用户的挑战。

Method: 提出全自动扫描规划，生成高效扫描路径，确保无碰撞导航和足够视角重叠。

Result: 在真实实验中平均扫描覆盖率达99%，扫描时间比现有方法快3倍。

Conclusion: 该方法显著提升了扫描效率和覆盖范围，适用于实际应用。

Abstract: Panoramic RGB-D cameras are known for their ability to produce high quality
3D scene reconstructions. However, operating these cameras involves manually
selecting viewpoints and physically transporting the camera, making the
generation of a 3D model time consuming and tedious. Additionally, the process
can be challenging for novice users due to spatial constraints, such as
ensuring sufficient feature overlap between viewpoint frames. To address these
challenges, we propose a fully autonomous scan planning that generates an
efficient tour plan for environment scanning, ensuring collision-free
navigation and adequate overlap between viewpoints within the plan. Extensive
experiments conducted in both synthetic and real-world environments validate
the performance of our planner against state-of-the-art view planners. In
particular, our method achieved an average scan coverage of 99 percent in the
real-world experiment, with our approach being up to 3 times faster than
state-of-the-art planners in total scan time.

</details>


### [11] [Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers](https://arxiv.org/abs/2507.16214)
*Batu Candan,Simone Servadio*

Main category: cs.RO

TL;DR: 提出了一种结合CNN和UKF的自适应集成系统，用于估计翻滚卫星的相对姿态，提高了ADR任务中的导航鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 精确且鲁棒的相对姿态估计对于ADR任务（如处理ENVISAT等翻滚卫星）至关重要。

Method: 集成CNN（用于检测结构标记）和UKF（用于非线性动态估计），并采用双自适应策略调整噪声协方差。

Result: 通过高保真仿真验证，系统在测量中断等条件下仍能保持高精度。

Conclusion: 该系统显著提升了ADR任务中安全接近操作的导航能力。

Abstract: Accurate and robust relative pose estimation is crucial for enabling
challenging Active Debris Removal (ADR) missions targeting tumbling derelict
satellites such as ESA's ENVISAT. This work presents a complete pipeline
integrating advanced computer vision techniques with adaptive nonlinear
filtering to address this challenge. A Convolutional Neural Network (CNN),
enhanced with image preprocessing, detects structural markers (corners) from
chaser imagery, whose 2D coordinates are converted to 3D measurements using
camera modeling. These measurements are fused within an Unscented Kalman Filter
(UKF) framework, selected for its ability to handle nonlinear relative
dynamics, to estimate the full relative pose. Key contributions include the
integrated system architecture and a dual adaptive strategy within the UKF:
dynamic tuning of the measurement noise covariance compensates for varying CNN
measurement uncertainty, while adaptive tuning of the process noise covariance,
utilizing measurement residual analysis, accounts for unmodeled dynamics or
maneuvers online. This dual adaptation enhances robustness against both
measurement imperfections and dynamic model uncertainties. The performance of
the proposed adaptive integrated system is evaluated through high-fidelity
simulations using a realistic ENVISAT model, comparing estimates against ground
truth under various conditions, including measurement outages. This
comprehensive approach offers an enhanced solution for robust onboard relative
navigation, significantly advancing the capabilities required for safe
proximity operations during ADR missions.

</details>


### [12] [GFM-Planner: Perception-Aware Trajectory Planning with Geometric Feature Metric](https://arxiv.org/abs/2507.16233)
*Yue Lin,Xiaoxuan Zhang,Yang Liu,Dong Wang,Huchuan Lu*

Main category: cs.RO

TL;DR: GFM-Planner通过几何特征度量提升LiDAR定位精度，引导机器人避开退化区域。


<details>
  <summary>Details</summary>
Motivation: 机器人依赖特征丰富的环境进行定位，类似人类依赖地标。

Method: 提出GFM度量，设计MEM存储GFM值，开发感知感知轨迹规划算法。

Result: 仿真和实验证明，GFM-Planner显著提升LiDAR定位精度。

Conclusion: GFM-Planner有效提升机器人在复杂环境中的定位能力。

Abstract: Like humans who rely on landmarks for orientation, autonomous robots depend
on feature-rich environments for accurate localization. In this paper, we
propose the GFM-Planner, a perception-aware trajectory planning framework based
on the geometric feature metric, which enhances LiDAR localization accuracy by
guiding the robot to avoid degraded areas. First, we derive the Geometric
Feature Metric (GFM) from the fundamental LiDAR localization problem. Next, we
design a 2D grid-based Metric Encoding Map (MEM) to efficiently store GFM
values across the environment. A constant-time decoding algorithm is further
proposed to retrieve GFM values for arbitrary poses from the MEM. Finally, we
develop a perception-aware trajectory planning algorithm that improves LiDAR
localization capabilities by guiding the robot in selecting trajectories
through feature-rich areas. Both simulation and real-world experiments
demonstrate that our approach enables the robot to actively select trajectories
that significantly enhance LiDAR localization accuracy.

</details>


### [13] [Trajectory Planning of a Curtain Wall Installation Robot Based on Biomimetic Mechanisms](https://arxiv.org/abs/2507.16305)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 论文提出了一种受人类上肢运动启发的轨迹规划框架，通过模仿人类举重时的能量转换原理，显著降低了建筑机器人的能耗。


<details>
  <summary>Details</summary>
Motivation: 机器人市场快速发展，能耗问题成为制约建筑机器人应用的关键因素。

Method: 收集人类举重时的运动轨迹和肌电信号，构建拟人化轨迹规划，并利用粒子群优化算法实现动态负载分配。

Result: 在实际应用中，该方法使能耗降低了48.4%。

Conclusion: 该方法为幕墙安装机器人的能耗优化提供了新思路和理论支持。

Abstract: As the robotics market rapidly evolves, energy consumption has become a
critical issue, particularly restricting the application of construction
robots. To tackle this challenge, our study innovatively draws inspiration from
the mechanics of human upper limb movements during weight lifting, proposing a
bio-inspired trajectory planning framework that incorporates human energy
conversion principles. By collecting motion trajectories and electromyography
(EMG) signals during dumbbell curls, we construct an anthropomorphic trajectory
planning that integrates human force exertion patterns and energy consumption
patterns. Utilizing the Particle Swarm Optimization (PSO) algorithm, we achieve
dynamic load distribution for robotic arm trajectory planning based on
human-like movement features. In practical application, these bio-inspired
movement characteristics are applied to curtain wall installation tasks,
validating the correctness and superiority of our trajectory planning method.
Simulation results demonstrate a 48.4% reduction in energy consumption through
intelligent conversion between kinetic and potential energy. This approach
provides new insights and theoretical support for optimizing energy use in
curtain wall installation robots during actual handling tasks.

</details>


### [14] [Design and Dimensional Optimization of Legged Structures for Construction Robots](https://arxiv.org/abs/2507.16328)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 提出了一种针对建筑场景的腿部配置设计和优化方法，以提高建筑机器人的自主移动能力。


<details>
  <summary>Details</summary>
Motivation: 轮式和履带式机器人在复杂和非结构化建筑环境中适应性差，难以满足自主操作需求。

Method: 通过运动学建模和多维工作空间分析，引入“改进工作空间”概念，并基于速度雅可比矩阵提出“平均可操作性”概念，结合虚拟原型仿真优化腿部尺寸和比例。

Result: 获得了具有最佳综合运动性能的腿部比例。

Conclusion: 研究为腿式建筑机器人在复杂地形中实现自主移动提供了结构设计基础。

Abstract: Faced with complex and unstructured construction environments, wheeled and
tracked robots exhibit significant limitations in terrain adaptability and
flexibility, making it difficult to meet the requirements of autonomous
operation. Inspired by ants in nature, this paper proposes a leg configuration
design and optimization method tailored for construction scenarios, aiming to
enhance the autonomous mobility of construction robots. This paper analyzes the
full operational motion performance of the leg during both swing and stance
phases. First, based on kinematic modeling and multi-dimensional workspace
analysis, the concept of an "improved workspace" is introduced, and graphical
methods are used to optimize the leg dimensions during the swing phase.
Furthermore, a new concept of "average manipulability" is introduced based on
the velocity Jacobian matrix, and numerical solutions are applied to obtain the
leg segment ratio that maximizes manipulability. To overcome the difficulties
associated with traditional analytical methods, virtual prototype simulations
are conducted in ADAMS to explore the relationship between the robot body's
optimal flexibility and leg segment proportions. In summary, the leg segment
proportions with the best comprehensive motion performance are obtained. This
study presents the first multi-dimensional quantitative evaluation framework
for leg motion performance tailored for construction environments, providing a
structural design foundation for legged construction robots to achieve
autonomous mobility in complex terrains.

</details>


### [15] [Topology Optimization of Leg Structures for Construction Robots Based on Variable Density Method](https://arxiv.org/abs/2507.16335)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 论文提出了一种基于SIMP方法的机器人腿部结构拓扑优化策略，通过有限元分析验证，实现了轻量化设计。


<details>
  <summary>Details</summary>
Motivation: 复杂地形施工对机器人高负载和灵活移动性有高要求，腿部结构优化是关键。

Method: 采用SIMP变量密度法进行拓扑优化，结合结构重构，通过ANSYS进行静态和模态分析。

Result: 优化后腿部质量减少7.92%，股骨质量减少19.45%，性能仍满足要求。

Conclusion: 研究为轻量化施工机器人设计提供了理论和技术支持，适用于复杂施工环境。

Abstract: In complex terrain construction environments, there are high demands for
robots to achieve both high payload capacity and mobility flexibility. As the
key load-bearing component, the optimization of robotic leg structures is of
particular importance. Therefore, this study focuses on the optimization of leg
structures for construction robots, proposing a topology optimization strategy
based on the SIMP (Solid Isotropic Microstructures with Penalization) variable
density method along with a structural re-design approach. The design
performance is comprehensively validated through finite element analysis using
ANSYS. First, static and modal analyses are conducted to evaluate the
rationality of the initial design. Then, topology optimization using the
SIMP-based variable density method is applied to the femur section, which
accounts for the largest proportion of the leg's weight. Based on iterative
calculations, the femur undergoes secondary structural reconstruction. After
optimization, the mass of the femur is reduced by 19.45\%, and the overall leg
mass decreases by 7.92\%, achieving the goal of lightweight design. Finally,
static and modal analyses are conducted on the reconstructed leg. The results
demonstrate that the optimized leg still meets structural performance
requirements, validating the feasibility of lightweight design. This research
provides robust theoretical and technical support for lightweight construction
robot design and lays a foundation for their efficient operation in complex
construction environments.

</details>


### [16] [Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane](https://arxiv.org/abs/2507.16369)
*Thanh D V Nguyen,Vincent Bonnet,Pierre Fernbach,David Daney,Florent Lamiraux*

Main category: cs.RO

TL;DR: 提出了一种利用单平面、嵌入式力传感器和导纳控制器的全几何校准方法，无需人工干预，并通过IROC算法选择最优校准姿势。


<details>
  <summary>Details</summary>
Motivation: 人形机器人的全身几何校准通常耗时且实验负担重，但对其精确控制和仿真至关重要。

Method: 使用单平面、嵌入式力传感器和导纳控制器，结合IROC算法选择最优校准姿势。

Result: 在TALOS人形机器人上验证，仅需31个最优姿势，RMS误差降低2.3倍。

Conclusion: 该方法高效且显著提升了校准精度。

Abstract: Whole-body geometric calibration of humanoid robots using classical robot
calibration methods is a timeconsuming and experimentally burdensome task.
However, despite its significance for accurate control and simulation, it is
often overlooked in the humanoid robotics community. To address this issue, we
propose a novel practical method that utilizes a single plane, embedded force
sensors, and an admittance controller to calibrate the whole-body kinematics of
humanoids without requiring manual intervention. Given the complexity of
humanoid robots, it is crucial to generate and determine a minimal set of
optimal calibration postures. To do so, we propose a new algorithm called IROC
(Information Ranking algorithm for selecting Optimal Calibration postures).
IROC requires a pool of feasible candidate postures to build a normalized
weighted information matrix for each posture. Then, contrary to other
algorithms from the literature, IROC will determine the minimal number of
optimal postures that are to be played onto a robot for its calibration. Both
IROC and the single-plane calibration method were experimentally validated on a
TALOS humanoid robot. The total whole-body kinematics chain was calibrated
using solely 31 optimal postures with 3-point contacts on a table by the robot
gripper. In a cross-validation experiment, the average root-mean-square (RMS)
error was reduced by a factor of 2.3 compared to the manufacturer's model.

</details>


### [17] [Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance](https://arxiv.org/abs/2507.16382)
*Chenhao Yao,Zike Yuan,Xiaoxu Liu,Chi Zhu*

Main category: cs.RO

TL;DR: 提出了一种基于大语言模型（LLMs）的动态奖励函数生成框架，用于多智能体强化学习（MARL）中的编队控制与避障任务，提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统（MAS）在编队控制与避障（FCCA）任务中设计有效奖励函数的挑战。

Method: 利用LLMs动态生成奖励函数，并通过高级评估指标在线调整。

Result: 在仿真和实际环境中验证了框架的高效性和实用性。

Conclusion: 该框架显著提升了MAS在动态环境中的编队控制和避障能力。

Abstract: Multi-Agent Systems (MAS) excel at accomplishing complex objectives through
the collaborative efforts of individual agents. Among the methodologies
employed in MAS, Multi-Agent Reinforcement Learning (MARL) stands out as one of
the most efficacious algorithms. However, when confronted with the complex
objective of Formation Control with Collision Avoidance (FCCA): designing an
effective reward function that facilitates swift convergence of the policy
network to an optimal solution. In this paper, we introduce a novel framework
that aims to overcome this challenge. By giving large language models (LLMs) on
the prioritization of tasks and the observable information available to each
agent, our framework generates reward functions that can be dynamically
adjusted online based on evaluation outcomes by employing more advanced
evaluation metrics rather than the rewards themselves. This mechanism enables
the MAS to simultaneously achieve formation control and obstacle avoidance in
dynamic environments with enhanced efficiency, requiring fewer iterations to
reach superior performance levels. Our empirical studies, conducted in both
simulation and real-world settings, validate the practicality and effectiveness
of our proposed approach.

</details>


### [18] [AI or Human? Understanding Perceptions of Embodied Robots with LLMs](https://arxiv.org/abs/2507.16398)
*Lavinia Hriscu,Alberto Sanfeliu,Anais Garrell*

Main category: cs.RO

TL;DR: 研究通过图灵测试评估了人类对机器人智能的感知，发现参与者无法可靠区分AI和人类控制的机器人。


<details>
  <summary>Details</summary>
Motivation: 探索图灵测试在人机交互中的应用，评估人类对机器人智能的感知。

Method: 34名参与者通过信息检索和包裹交接任务，区分AI和人类控制的机器人。

Result: 参与者无法可靠区分AI和人类控制的机器人，揭示了影响智能感知的关键因素。

Conclusion: 研究为未来交互机器人设计提供了见解，并推动了AI智能评估的讨论。

Abstract: The pursuit of artificial intelligence has long been associated to the the
challenge of effectively measuring intelligence. Even if the Turing Test was
introduced as a means of assessing a system intelligence, its relevance and
application within the field of human-robot interaction remain largely
underexplored. This study investigates the perception of intelligence in
embodied robots by performing a Turing Test within a robotic platform. A total
of 34 participants were tasked with distinguishing between AI- and
human-operated robots while engaging in two interactive tasks: an information
retrieval and a package handover. These tasks assessed the robot perception and
navigation abilities under both static and dynamic conditions. Results indicate
that participants were unable to reliably differentiate between AI- and
human-controlled robots beyond chance levels. Furthermore, analysis of
participant responses reveals key factors influencing the perception of
artificial versus human intelligence in embodied robotic systems. These
findings provide insights into the design of future interactive robots and
contribute to the ongoing discourse on intelligence assessment in AI-driven
systems.

</details>


### [19] [Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones](https://arxiv.org/abs/2507.16458)
*Yang Xu,Jesús Bautista,José Hinojosa,Héctor García de Marina*

Main category: cs.RO

TL;DR: 提出一种无需调整速度的固定翼无人机编队飞行算法，通过振荡行为实现协调。


<details>
  <summary>Details</summary>
Motivation: 固定翼无人机速度受限，传统编队飞行需速度调整，难以实现。

Method: 引导无人机沿特定路径飞行，叠加振荡行为控制平均速度，分布式调整振幅。

Result: 理论分析、数值模拟和实际飞行验证了算法的有效性。

Conclusion: 算法成功实现固定翼无人机编队飞行，无需速度调整。

Abstract: The autonomous formation flight of fixed-wing drones is hard when the
coordination requires the actuation over their speeds since they are critically
bounded and aircraft are mostly designed to fly at a nominal airspeed. This
paper proposes an algorithm to achieve formation flights of fixed-wing drones
without requiring any actuation over their speed. In particular, we guide all
the drones to travel over specific paths, e.g., parallel straight lines, and we
superpose an oscillatory behavior onto the guiding vector field that drives the
drones to the paths. This oscillation enables control over the average velocity
along the path, thereby facilitating inter-drone coordination. Each drone
adjusts its oscillation amplitude distributively in a closed-loop manner by
communicating with neighboring agents in an undirected and connected graph. A
novel consensus algorithm is introduced, leveraging a non-negative, asymmetric
saturation function. This unconventional saturation is justified since negative
amplitudes do not make drones travel backward or have a negative velocity along
the path. Rigorous theoretical analysis of the algorithm is complemented by
validation through numerical simulations and a real-world formation flight.

</details>


### [20] [Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots](https://arxiv.org/abs/2507.16480)
*Sabrina Livanec,Laura Londoño,Michael Gorki,Adrian Röfer,Abhinav Valada,Andrea Kiesel*

Main category: cs.RO

TL;DR: 研究探讨了辅助机器人在社会协作中的设计问题，重点关注与弱势群体互动时的行为评估，发现人类特征和交互范式影响机器人的可接受性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏关于机器人行为与多样化人类需求结合的研究，尤其是参与者对高级家用机器人的实际经验有限。

Method: 通过在线研究，112名参与者评估了28种人机协作视频，实验组在评估前完成认知情感映射（CAM）练习。

Result: CAM未显著影响整体评分，但对某些机器人行为与人类条件的组合评估更明显。反社会机器人行为评分最低，与老年人协作更敏感，物体交接场景更受欢迎。

Conclusion: 人类特征和交互范式影响机器人可接受性，强调亲社会设计的重要性，CAM等反思方法有助于获取细致反馈，支持开发用户中心和社会责任的机器人系统。

Abstract: The development of assistive robots for social collaboration raises critical
questions about responsible and inclusive design, especially when interacting
with individuals from protected groups such as those with disabilities or
advanced age. Currently, research is scarce on how participants assess varying
robot behaviors in combination with diverse human needs, likely since
participants have limited real-world experience with advanced domestic robots.
In the current study, we aim to address this gap while using methods that
enable participants to assess robot behavior, as well as methods that support
meaningful reflection despite limited experience. In an online study, 112
participants (from both experimental and control groups) evaluated 7 videos
from a total of 28 variations of human-robot collaboration types. The
experimental group first completed a cognitive-affective mapping (CAM) exercise
on human-robot collaboration before providing their ratings. Although CAM
reflection did not significantly affect overall ratings, it led to more
pronounced assessments for certain combinations of robot behavior and human
condition. Most importantly, the type of human-robot collaboration influences
the assessment. Antisocial robot behavior was consistently rated as the lowest,
while collaboration with aged individuals elicited more sensitive evaluations.
Scenarios involving object handovers were viewed more positively than those
without them. These findings suggest that both human characteristics and
interaction paradigms influence the perceived acceptability of collaborative
robots, underscoring the importance of prosocial design. They also highlight
the potential of reflective methods, such as CAM, to elicit nuanced feedback,
supporting the development of user-centered and socially responsible robotic
systems tailored to diverse populations.

</details>


### [21] [Guided Reinforcement Learning for Omnidirectional 3D Jumping in Quadruped Robots](https://arxiv.org/abs/2507.16481)
*Riccardo Bussola,Michele Focchi,Giulio Turrisi,Claudio Semini,Luigi Palopoli*

Main category: cs.RO

TL;DR: 提出了一种结合Bézier曲线和UARM模型的强化学习方法，用于四足机器人高效且可解释的跳跃控制。


<details>
  <summary>Details</summary>
Motivation: 四足机器人的跳跃控制面临优化方法耗时且依赖参数知识的问题，传统强化学习方法样本效率低且难以保证安全性。

Method: 结合Bézier曲线和UARM模型，提出了一种引导式强化学习方法。

Result: 仿真和实验结果表明该方法优于现有方法。

Conclusion: 该方法在效率和可解释性上具有优势，适用于实际场景。

Abstract: Jumping poses a significant challenge for quadruped robots, despite being
crucial for many operational scenarios. While optimisation methods exist for
controlling such motions, they are often time-consuming and demand extensive
knowledge of robot and terrain parameters, making them less robust in
real-world scenarios. Reinforcement learning (RL) is emerging as a viable
alternative, yet conventional end-to-end approaches lack efficiency in terms of
sample complexity, requiring extensive training in simulations, and
predictability of the final motion, which makes it difficult to certify the
safety of the final motion. To overcome these limitations, this paper
introduces a novel guided reinforcement learning approach that leverages
physical intuition for efficient and explainable jumping, by combining B\'ezier
curves with a Uniformly Accelerated Rectilinear Motion (UARM) model. Extensive
simulation and experimental results clearly demonstrate the advantages of our
approach over existing alternatives.

</details>


### [22] [A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System](https://arxiv.org/abs/2507.16621)
*Lorenzo Gentilini,Pierpaolo Serio,Valentina Donzella,Lorenzo Pollini*

Main category: cs.RO

TL;DR: 提出了一种基于目标的多LiDAR和多摄像头传感器套件的外在校准系统，使用自定义ChArUco板和优化的非线性方法进行跨传感器校准。


<details>
  <summary>Details</summary>
Motivation: 外在校准是自动驾驶感知的关键，误差会影响车辆安全，而现代传感器系统收集的数据类型多样，增加了数据对齐的难度。

Method: 使用自定义ChArUco板和定制的非线性优化方法，实现LiDAR和摄像头之间的跨校准，无需过多先验知识。

Result: 在仓库中采集的真实数据测试表明，该方法有效，验证了适用于多种传感器的统一管道的可行性。

Conclusion: 提出的系统能够高效完成多传感器外在校准，为自动驾驶感知提供了可靠支持。

Abstract: Extrinsic Calibration represents the cornerstone of autonomous driving. Its
accuracy plays a crucial role in the perception pipeline, as any errors can
have implications for the safety of the vehicle. Modern sensor systems collect
different types of data from the environment, making it harder to align the
data. To this end, we propose a target-based extrinsic calibration system
tailored for a multi-LiDAR and multi-camera sensor suite. This system enables
cross-calibration between LiDARs and cameras with limited prior knowledge using
a custom ChArUco board and a tailored nonlinear optimization method. We test
the system with real-world data gathered in a warehouse. Results demonstrated
the effectiveness of the proposed method, highlighting the feasibility of a
unique pipeline tailored for various types of sensors.

</details>


### [23] [Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control](https://arxiv.org/abs/2507.16645)
*Zongzheng Zhang,Jiawen Yang,Ziqiao Peng,Meng Yang,Jianzhu Ma,Lin Cheng,Huazhe Xu,Hang Zhao,Hao Zhao*

Main category: cs.RO

TL;DR: 提出了一种混合驱动方法，结合刚性和肌腱驱动机制，用于更有效的情感表达。


<details>
  <summary>Details</summary>
Motivation: 解决传统动画面部硬件和软件在情感表达上的局限性。

Method: 使用混合驱动机制，结合刚性驱动和肌腱驱动，并引入自建模网络映射动作到面部特征。

Result: 能够生成多种情感表达，如快乐、恐惧、厌恶和愤怒。

Conclusion: 该方法在紧凑硬件平台上实现了广泛的情感表达，并开源了设计和代码。

Abstract: Previous animatronic faces struggle to express emotions effectively due to
hardware and software limitations. On the hardware side, earlier approaches
either use rigid-driven mechanisms, which provide precise control but are
difficult to design within constrained spaces, or tendon-driven mechanisms,
which are more space-efficient but challenging to control. In contrast, we
propose a hybrid actuation approach that combines the best of both worlds. The
eyes and mouth-key areas for emotional expression-are controlled using rigid
mechanisms for precise movement, while the nose and cheek, which convey subtle
facial microexpressions, are driven by strings. This design allows us to build
a compact yet versatile hardware platform capable of expressing a wide range of
emotions. On the algorithmic side, our method introduces a self-modeling
network that maps motor actions to facial landmarks, allowing us to
automatically establish the relationship between blendshape coefficients for
different facial expressions and the corresponding motor control signals
through gradient backpropagation. We then train a neural network to map speech
input to corresponding blendshape controls. With our method, we can generate
distinct emotional expressions such as happiness, fear, disgust, and anger,
from any given sentence, each with nuanced, emotion-specific control signals-a
feature that has not been demonstrated in earlier systems. We release the
hardware design and code at https://github.com/ZZongzheng0918/Morpheus-Hardware
and https://github.com/ZZongzheng0918/Morpheus-Software.

</details>


### [24] [Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory](https://arxiv.org/abs/2507.16713)
*Guowei Lan,Kaixian Qu,René Zurbrügg,Changan Chen,Christopher E. Mower,Haitham Bou-Ammar,Marco Hutter*

Main category: cs.RO

TL;DR: ExpTeach框架通过自生成经验记忆，将视觉语言模型（VLMs）应用于机器人任务，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决VLMs在多样化机器人任务中的实际落地问题。

Method: 通过闭环自主规划、验证、反思和适应，构建长期记忆库，并结合检索增强生成（RAG）和图像标注模块。

Result: 任务成功率从36%提升至84%，单次任务成功率从22%提升至80%。

Conclusion: ExpTeach有效提升了VLMs在机器人任务中的适应性和泛化能力。

Abstract: Vision-language models (VLMs) have been widely adopted in robotics to enable
autonomous planning. However, grounding VLMs, originally trained on internet
data, to diverse real-world robots remains a challenge. This paper presents
ExpTeach, a framework that grounds VLMs to physical robots by building a
self-generated memory of real-world experiences. In ExpTeach, the VLM
autonomously plans actions, verifies outcomes, reflects on failures, and adapts
robot behaviors in a closed loop. The self-generated experiences during this
process are then summarized into a long-term memory, enabling retrieval of
learned knowledge to guide future tasks via retrieval-augmented generation
(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with
an on-demand image annotation module. In experiments, we show that reflection
improves success rates from 36% to 84% on four challenging robotic tasks and
observe the emergence of intelligent object interactions, including creative
tool use. Across extensive tests on 12 real-world scenarios (including eight
unseen ones), we find that grounding with long-term memory boosts single-trial
success rates from 22% to 80%, demonstrating the effectiveness and
generalizability of ExpTeach.

</details>
