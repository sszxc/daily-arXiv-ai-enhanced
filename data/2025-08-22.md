<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 14]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot](https://arxiv.org/abs/2508.14994)
*Murilo Vinicius da Silva,Matheus Hipolito Carvalho,Juliano Negri,Thiago Segreto,Gustavo J. G. Lahr,Ricardo V. Godoy,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出一种基于视觉的直观远程控制方法，通过映射人类手臂动作到四足机器人机械臂，提高操作安全性和易用性。


<details>
  <summary>Details</summary>
Motivation: 在危险和远程环境中，四足机器人机械臂的远程操作缺乏集成的障碍检测和直观控制方法，增加了碰撞风险，且传统操作方式复杂且认知负荷高。

Method: 利用外部摄像头和基于机器学习的姿态估计模型检测操作者手腕位置，实时映射到机械臂指令，并结合轨迹规划器确保安全操作。

Result: 在真实机器人上验证了系统的实时控制性能，展示了鲁棒性和安全性。

Conclusion: 该方法为高风险工业应用提供了一种成本效益高、安全、精确且易于使用的远程控制解决方案。

Abstract: In hazardous and remote environments, robotic systems perform critical tasks
demanding improved safety and efficiency. Among these, quadruped robots with
manipulator arms offer mobility and versatility for complex operations.
However, teleoperating quadruped robots is challenging due to the lack of
integrated obstacle detection and intuitive control methods for the robotic
arm, increasing collision risks in confined or dynamically changing workspaces.
Teleoperation via joysticks or pads can be non-intuitive and demands a high
level of expertise due to its complexity, culminating in a high cognitive load
on the operator. To address this challenge, a teleoperation approach that
directly maps human arm movements to the robotic manipulator offers a simpler
and more accessible solution. This work proposes an intuitive remote control by
leveraging a vision-based pose estimation pipeline that utilizes an external
camera with a machine learning-based model to detect the operator's wrist
position. The system maps these wrist movements into robotic arm commands to
control the robot's arm in real-time. A trajectory planner ensures safe
teleoperation by detecting and preventing collisions with both obstacles and
the robotic arm itself. The system was validated on the real robot,
demonstrating robust performance in real-time control. This teleoperation
approach provides a cost-effective solution for industrial applications where
safety, precision, and ease of use are paramount, ensuring reliable and
intuitive robotic control in high-risk environments.

</details>


### [2] [GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping](https://arxiv.org/abs/2508.15002)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种合成大规模、多样化且物理可行的抓取方法，通过改进的能量公式和优化方法，显著提升了抓取多样性和稳定性，并发布了一个新的大规模抓取数据集。


<details>
  <summary>Details</summary>
Motivation: 现有抓取数据生成方法通常局限于简单的强力抓取，缺乏多样性，限制了多指灵巧手的潜力。

Method: 引入了一种基于二次规划（QP）的严格可微分能量公式，并提出了一种改进的优化方法（MALA*），动态拒绝梯度步骤以提高性能。

Result: 显著提升了抓取多样性和稳定性，并生成了一个包含5,700个物体、五种不同夹持器和三种抓取类型的大规模数据集。

Conclusion: 该方法为灵巧手的抓取任务提供了更丰富的数据支持，推动了抓取预测模型和操纵策略的发展。

Abstract: Dexterous robotic hands enable versatile interactions due to the flexibility
and adaptability of multi-fingered designs, allowing for a wide range of
task-specific grasp configurations in diverse environments. However, to fully
exploit the capabilities of dexterous hands, access to diverse and high-quality
grasp data is essential -- whether for developing grasp prediction models from
point clouds, training manipulation policies, or supporting high-level task
planning with broader action options. Existing approaches for dataset
generation typically rely on sampling-based algorithms or simplified
force-closure analysis, which tend to converge to power grasps and often
exhibit limited diversity. In this work, we propose a method to synthesize
large-scale, diverse, and physically feasible grasps that extend beyond simple
power grasps to include refined manipulations, such as pinches and tri-finger
precision grasps. We introduce a rigorous, differentiable energy formulation of
force closure, implicitly defined through a Quadratic Program (QP).
Additionally, we present an adjusted optimization method (MALA*) that improves
performance by dynamically rejecting gradient steps based on the distribution
of energy values across all samples. We extensively evaluate our approach and
demonstrate significant improvements in both grasp diversity and the stability
of final grasp predictions. Finally, we provide a new, large-scale grasp
dataset for 5,700 objects from DexGraspNet, comprising five different grippers
and three distinct grasp types.
  Dataset and Code:https://graspqp.github.io/

</details>


### [3] [In-Context Iterative Policy Improvement for Dynamic Manipulation](https://arxiv.org/abs/2508.15021)
*Mark Van der Merwe,Devesh Jha*

Main category: cs.RO

TL;DR: 论文探讨了利用预训练语言模型的上下文学习能力进行动态操控任务，展示了在低数据量情况下的优越性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索大型语言模型（LLMs）在动态操控任务中的上下文学习能力，解决高维度、复杂动态和部分可观测性等挑战。

Method: 采用迭代方法，通过上下文学习预测基于先前交互的参数化策略调整。

Result: 在仿真和物理机器人任务中，上下文学习方法在低数据量情况下优于其他方法。

Conclusion: 结论表明，上下文学习在动态操控任务中具有潜力，尤其是在数据稀缺的情况下。

Abstract: Attention-based architectures trained on internet-scale language data have
demonstrated state of the art reasoning ability for various language-based
tasks, such as logic problems and textual reasoning. Additionally, these Large
Language Models (LLMs) have exhibited the ability to perform few-shot
prediction via in-context learning, in which input-output examples provided in
the prompt are generalized to new inputs. This ability furthermore extends
beyond standard language tasks, enabling few-shot learning for general
patterns. In this work, we consider the application of in-context learning with
pre-trained language models for dynamic manipulation. Dynamic manipulation
introduces several crucial challenges, including increased dimensionality,
complex dynamics, and partial observability. To address this, we take an
iterative approach, and formulate our in-context learning problem to predict
adjustments to a parametric policy based on previous interactions. We show
across several tasks in simulation and on a physical robot that utilizing
in-context learning outperforms alternative methods in the low data regime.
Video summary of this work and experiments can be found
https://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn.

</details>


### [4] [Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring](https://arxiv.org/abs/2508.15038)
*Makram Chahine,William Yang,Alaa Maalouf,Justin Siriska,Ninad Jadhav,Daniel Vogt,Stephanie Gil,Robert Wood,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的去中心化多无人机系统，用于野生动物监测，具有可扩展性、低带宽需求和最小传感器配置。


<details>
  <summary>Details</summary>
Motivation: 现有机器人解决方案多从群体角度出发或依赖人工操作，难以满足大规模野生动物监测的需求。

Method: 开发了新型视觉协调和跟踪算法，适用于动态、非结构化环境，无需集中通信或控制。

Result: 通过实地实验验证了系统在不同环境条件下的可靠部署。

Conclusion: 该系统为野生动物监测提供了一种高效、可扩展的解决方案。

Abstract: Wildlife field operations demand efficient parallel deployment methods to
identify and interact with specific individuals, enabling simultaneous
collective behavioral analysis, and health and safety interventions. Previous
robotics solutions approach the problem from the herd perspective, or are
manually operated and limited in scale. We propose a decentralized vision-based
multi-quadrotor system for wildlife monitoring that is scalable, low-bandwidth,
and sensor-minimal (single onboard RGB camera). Our approach enables robust
identification and tracking of large species in their natural habitat. We
develop novel vision-based coordination and tracking algorithms designed for
dynamic, unstructured environments without reliance on centralized
communication or control. We validate our system through real-world
experiments, demonstrating reliable deployment in diverse field conditions.

</details>


### [5] [Hardware Implementation of a Zero-Prior-Knowledge Approach to Lifelong Learning in Kinematic Control of Tendon-Driven Quadrupeds](https://arxiv.org/abs/2508.15160)
*Hesam Azadjou,Suraj Chakravarthi Raja,Ali Marjaninejad,Francisco J. Valero-Cuevas*

Main category: cs.RO

TL;DR: G2P算法通过仿生学习快速控制肌腱驱动四足机器人，实现自适应周期性运动。


<details>
  <summary>Details</summary>
Motivation: 机器人需在不完全了解身体结构和环境的情况下快速学习控制并适应变化。

Method: 采用G2P算法，结合5分钟通用运动探索和15次20秒的细化训练。

Result: 系统在几分钟内学会控制冗余肌腱驱动四足机器人，实现功能性运动。

Conclusion: 该方法为机器人动态适应新环境提供了新途径。

Abstract: Like mammals, robots must rapidly learn to control their bodies and interact
with their environment despite incomplete knowledge of their body structure and
surroundings. They must also adapt to continuous changes in both. This work
presents a bio-inspired learning algorithm, General-to-Particular (G2P),
applied to a tendon-driven quadruped robotic system developed and fabricated
in-house. Our quadruped robot undergoes an initial five-minute phase of
generalized motor babbling, followed by 15 refinement trials (each lasting 20
seconds) to achieve specific cyclical movements. This process mirrors the
exploration-exploitation paradigm observed in mammals. With each refinement,
the robot progressively improves upon its initial "good enough" solution. Our
results serve as a proof-of-concept, demonstrating the hardware-in-the-loop
system's ability to learn the control of a tendon-driven quadruped with
redundancies in just a few minutes to achieve functional and adaptive cyclical
non-convex movements. By advancing autonomous control in robotic locomotion,
our approach paves the way for robots capable of dynamically adjusting to new
environments, ensuring sustained adaptability and performance.

</details>


### [6] [Survey of Vision-Language-Action Models for Embodied Manipulation](https://arxiv.org/abs/2508.15201)
*Haoran Li,Yuhui Chen,Wenbo Cui,Weiheng Liu,Kai Liu,Mingcai Zhou,Zhengtao Zhang,Dongbin Zhao*

Main category: cs.RO

TL;DR: 本文综述了视觉-语言-动作（VLA）模型在具身智能系统中的发展、研究现状及未来方向。


<details>
  <summary>Details</summary>
Motivation: 具身智能系统通过环境交互提升智能体能力，VLA模型作为通用机器人控制框架，进一步推动了这一领域的发展。

Method: 综述了VLA模型的架构发展，并从模型结构、训练数据、预训练方法、后训练方法和模型评估五个维度分析了当前研究。

Result: 总结了VLA模型在开发和实际部署中的关键挑战。

Conclusion: 提出了未来研究的潜在方向。

Abstract: Embodied intelligence systems, which enhance agent capabilities through
continuous environment interactions, have garnered significant attention from
both academia and industry. Vision-Language-Action models, inspired by
advancements in large foundation models, serve as universal robotic control
frameworks that substantially improve agent-environment interaction
capabilities in embodied intelligence systems. This expansion has broadened
application scenarios for embodied AI robots. This survey comprehensively
reviews VLA models for embodied manipulation. Firstly, it chronicles the
developmental trajectory of VLA architectures. Subsequently, we conduct a
detailed analysis of current research across 5 critical dimensions: VLA model
structures, training datasets, pre-training methods, post-training methods, and
model evaluation. Finally, we synthesize key challenges in VLA development and
real-world deployment, while outlining promising future research directions.

</details>


### [7] [Mag-Match: Magnetic Vector Field Features for Map Matching and Registration](https://arxiv.org/abs/2508.15300)
*William McDonald,Cedric Le Gentil,Jennifer Wakulicz,Teresa Vidal-Calleja*

Main category: cs.RO

TL;DR: Mag-Match是一种利用3D磁场特征进行地图匹配和注册的新方法，适用于恶劣环境。


<details>
  <summary>Details</summary>
Motivation: 传统方法在烟雾或灰尘等恶劣条件下表现不佳，而磁力计能提供稳定且独特的特征。

Method: 基于磁场高阶导数的特征描述符，结合物理信息高斯过程进行高效推理。

Result: 在仿真和实际实验中，Mag-Match表现优于基于SIFT的方法，无需初始重力对齐。

Conclusion: Mag-Match为恶劣环境下的地图匹配和注册提供了可靠解决方案。

Abstract: Map matching and registration are essential tasks in robotics for
localisation and integration of multi-session or multi-robot data. Traditional
methods rely on cameras or LiDARs to capture visual or geometric information
but struggle in challenging conditions like smoke or dust. Magnetometers, on
the other hand, detect magnetic fields, revealing features invisible to other
sensors and remaining robust in such environments. In this paper, we introduce
Mag-Match, a novel method for extracting and describing features in 3D magnetic
vector field maps to register different maps of the same area. Our feature
descriptor, based on higher-order derivatives of magnetic field maps, is
invariant to global orientation, eliminating the need for gravity-aligned
mapping. To obtain these higher-order derivatives map-wide given point-wise
magnetometer data, we leverage a physics-informed Gaussian Process to perform
efficient and recursive probabilistic inference of both the magnetic field and
its derivatives. We evaluate Mag-Match in simulated and real-world experiments
against a SIFT-based approach, demonstrating accurate map-to-map, robot-to-map,
and robot-to-robot transformations - even without initial gravitational
alignment.

</details>


### [8] [Sensing, Social, and Motion Intelligence in Embodied Navigation: A Comprehensive Survey](https://arxiv.org/abs/2508.15354)
*Chaoran Xiong,Yulong Huang,Fangwen Yu,Changhao Chen,Yue Wang,Songpengchen Xia,Ling Pei*

Main category: cs.RO

TL;DR: 该论文提出了一种名为TOFRA的五阶段框架，用于系统化地研究具身导航（EN），并综述了当前技术、平台和评估指标，同时指出了未来的研究挑战。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法依赖显式定位和预定义地图，而具身导航通过感知、社交和运动智能实现更复杂的任务，因此需要一种系统化的框架来总结和推动该领域的发展。

Method: 论文提出了TOFRA框架，包括Transition、Observation、Fusion、Reward-policy construction和Action五个阶段，用于分析和综述当前技术。

Result: 论文综述了具身导航的现状，包括相关平台和评估指标，并指出了未来的研究挑战。

Conclusion: TOFRA框架为具身导航领域提供了系统化的研究工具，未来研究可以在此基础上进一步探索开放性问题。

Abstract: Embodied navigation (EN) advances traditional navigation by enabling robots
to perform complex egocentric tasks through sensing, social, and motion
intelligence. In contrast to classic methodologies that rely on explicit
localization and pre-defined maps, EN leverages egocentric perception and
human-like interaction strategies. This survey introduces a comprehensive EN
formulation structured into five stages: Transition, Observation, Fusion,
Reward-policy construction, and Action (TOFRA). The TOFRA framework serves to
synthesize the current state of the art, provide a critical review of relevant
platforms and evaluation metrics, and identify critical open research
challenges. A list of studies is available at
https://github.com/Franky-X/Awesome-Embodied-Navigation.

</details>


### [9] [Lang2Lift: A Framework for Language-Guided Pallet Detection and Pose Estimation Integrated in Autonomous Outdoor Forklift Operation](https://arxiv.org/abs/2508.15427)
*Huy Hoang Nguyen,Johannes Huemer,Markus Murschitz,Tobias Glueck,Minh Nhat Vu,Andreas Kugi*

Main category: cs.RO

TL;DR: Lang2Lift框架利用基础模型实现自然语言引导的托盘检测与6D姿态估计，解决物流和建筑行业中托盘自动化搬运的挑战。


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺、安全隐患以及手动定位和检索托盘的效率低下。

Method: 结合Florence-2、SAM-2和FoundationPose，实现语言引导的分割与姿态估计，并集成运动规划模块。

Result: 在真实测试数据集上达到0.76 mIoU的分割精度，系统鲁棒性得到验证。

Conclusion: Lang2Lift在物流和建筑环境中具有实际部署的可行性。

Abstract: The logistics and construction industries face persistent challenges in
automating pallet handling, especially in outdoor environments with variable
payloads, inconsistencies in pallet quality and dimensions, and unstructured
surroundings. In this paper, we tackle automation of a critical step in pallet
transport: the pallet pick-up operation. Our work is motivated by labor
shortages, safety concerns, and inefficiencies in manually locating and
retrieving pallets under such conditions. We present Lang2Lift, a framework
that leverages foundation models for natural language-guided pallet detection
and 6D pose estimation, enabling operators to specify targets through intuitive
commands such as "pick up the steel beam pallet near the crane." The perception
pipeline integrates Florence-2 and SAM-2 for language-grounded segmentation
with FoundationPose for robust pose estimation in cluttered, multi-pallet
outdoor scenes under variable lighting. The resulting poses feed into a motion
planning module for fully autonomous forklift operation. We validate Lang2Lift
on the ADAPT autonomous forklift platform, achieving 0.76 mIoU pallet
segmentation accuracy on a real-world test dataset. Timing and error analysis
demonstrate the system's robustness and confirm its feasibility for deployment
in operational logistics and construction environments. Video demonstrations
are available at https://eric-nguyen1402.github.io/lang2lift.github.io/

</details>


### [10] [LLM-Driven Self-Refinement for Embodied Drone Task Planning](https://arxiv.org/abs/2508.15501)
*Deyu Zhang,Xicheng Zhang,Jiahao Li,Tingting Long,Xunhua Dai,Yongjian Fu,Jinrui Zhang,Ju Ren,Yaoxue Zhang*

Main category: cs.RO

TL;DR: SRDrone是一种用于工业级无人机的自我精炼任务规划系统，通过连续状态评估和行为树修改模型，显著提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖单帧最终状态评估，难以适应连续动态的无人机操作，SRDrone旨在解决这一问题。

Method: 采用连续状态评估方法和分层行为树修改模型，结合多级分析和约束策略空间。

Result: 实验显示SRDrone比基线方法成功率提高44.87%，实际部署后达到96.25%的成功率。

Conclusion: SRDrone成功将大型语言模型的推理能力与无人机的物理执行约束结合，提升了任务规划的适应性。

Abstract: We introduce SRDrone, a novel system designed for self-refinement task
planning in industrial-grade embodied drones. SRDrone incorporates two key
technical contributions: First, it employs a continuous state evaluation
methodology to robustly and accurately determine task outcomes and provide
explanatory feedback. This approach supersedes conventional reliance on
single-frame final-state assessment for continuous, dynamic drone operations.
Second, SRDrone implements a hierarchical Behavior Tree (BT) modification
model. This model integrates multi-level BT plan analysis with a constrained
strategy space to enable structured reflective learning from experience.
Experimental results demonstrate that SRDrone achieves a 44.87% improvement in
Success Rate (SR) over baseline methods. Furthermore, real-world deployment
utilizing an experience base optimized through iterative self-refinement
attains a 96.25% SR. By embedding adaptive task refinement capabilities within
an industrial-grade BT planning framework, SRDrone effectively integrates the
general reasoning intelligence of Large Language Models (LLMs) with the
stringent physical execution constraints inherent to embodied drones. Code is
available at https://github.com/ZXiiiC/SRDrone.

</details>


### [11] [Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation](https://arxiv.org/abs/2508.15663)
*Nikita Kachaev,Andrei Spiridonov,Andrey Gorodetsky,Kirill Muravyev,Nikita Oskolkov,Aditya Narendra,Vlad Shakhuro,Dmitry Makarov,Aleksandr I. Panov,Polina Fedotova,Alexey K. Kovalev*

Main category: cs.RO

TL;DR: Kitchen-R是一个新的基准测试，用于统一评估任务规划和低级控制在模拟厨房环境中的表现，填补了机器人研究中语言指令与物理执行之间的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在高层次语言指令跟随和低级机器人控制之间存在脱节，无法全面评估任务规划和物理执行集成的系统。

Method: Kitchen-R基于Isaac Sim模拟器构建，包含500多个复杂语言指令，提供任务规划和低级控制的基线方法，支持三种评估模式。

Result: Kitchen-R为语言引导的机器人代理提供了更全面和现实的基准测试框架。

Conclusion: Kitchen-R填补了具身AI研究中的关键空白，推动了更全面的系统评估。

Abstract: Benchmarks are crucial for evaluating progress in robotics and embodied AI.
However, a significant gap exists between benchmarks designed for high-level
language instruction following, which often assume perfect low-level execution,
and those for low-level robot control, which rely on simple, one-step commands.
This disconnect prevents a comprehensive evaluation of integrated systems where
both task planning and physical execution are critical. To address this, we
propose Kitchen-R, a novel benchmark that unifies the evaluation of task
planning and low-level control within a simulated kitchen environment. Built as
a digital twin using the Isaac Sim simulator and featuring more than 500
complex language instructions, Kitchen-R supports a mobile manipulator robot.
We provide baseline methods for our benchmark, including a task-planning
strategy based on a vision-language model and a low-level control policy based
on diffusion policy. We also provide a trajectory collection system. Our
benchmark offers a flexible framework for three evaluation modes: independent
assessment of the planning module, independent assessment of the control
policy, and, crucially, an integrated evaluation of the whole system. Kitchen-R
bridges a key gap in embodied AI research, enabling more holistic and realistic
benchmarking of language-guided robotic agents.

</details>


### [12] [Exploiting Policy Idling for Dexterous Manipulation](https://arxiv.org/abs/2508.15669)
*Annie S. Chen,Philemon Brakel,Antonia Bronars,Annie Xie,Sandy Huang,Oliver Groth,Maria Bauza,Markus Wulfmeier,Nicolas Heess,Dushyant Rao*

Main category: cs.RO

TL;DR: 论文提出了一种名为Pause-Induced Perturbations (PIP)的方法，通过在检测到的空闲状态施加扰动，提升策略的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 学习到的策略在复杂操作任务中容易出现空闲行为，影响可靠性和鲁棒性。现有方法如数据过滤或控制频率调整可能带来负面影响。

Method: 提出PIP方法，在检测到的空闲状态施加扰动，帮助策略逃离局部最优。

Result: 在模拟双臂任务中显著提升性能，并在真实世界插入任务中实现15-35%的绝对成功率提升。

Conclusion: PIP是一种简单有效的方法，无需额外监督或训练即可显著提升策略性能。

Abstract: Learning-based methods for dexterous manipulation have made notable progress
in recent years. However, learned policies often still lack reliability and
exhibit limited robustness to important factors of variation. One failure
pattern that can be observed across many settings is that policies idle, i.e.
they cease to move beyond a small region of states when they reach certain
states. This policy idling is often a reflection of the training data. For
instance, it can occur when the data contains small actions in areas where the
robot needs to perform high-precision motions, e.g., when preparing to grasp an
object or object insertion. Prior works have tried to mitigate this phenomenon
e.g. by filtering the training data or modifying the control frequency.
However, these approaches can negatively impact policy performance in other
ways. As an alternative, we investigate how to leverage the detectability of
idling behavior to inform exploration and policy improvement. Our approach,
Pause-Induced Perturbations (PIP), applies perturbations at detected idling
states, thus helping it to escape problematic basins of attraction. On a range
of challenging simulated dual-arm tasks, we find that this simple approach can
already noticeably improve test-time performance, with no additional
supervision or training. Furthermore, since the robot tends to idle at critical
points in a movement, we also find that learning from the resulting episodes
leads to better iterative policy improvement compared to prior approaches. Our
perturbation strategy also leads to a 15-35% improvement in absolute success
rate on a real-world insertion task that requires complex multi-finger
manipulation.

</details>


### [13] [Understanding and Utilizing Dynamic Coupling in Free-Floating Space Manipulators for On-Orbit Servicing](https://arxiv.org/abs/2508.15732)
*Gargi Das,Daegyun Choi,Donghoon Kim*

Main category: cs.RO

TL;DR: 提出了一种动态耦合感知的轨迹优化算法，用于自由浮动空间机械臂系统（SMSs），通过利用动态耦合改进轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 动态耦合在影响系统行为中起关键作用，以往研究多关注最小化耦合，而忽略了其潜在优势。本文研究如何利用动态耦合改进轨迹规划。

Method: 采用动态耦合矩阵的奇异值分解（SVD）识别主导耦合行为的分量，并制定定量指标表征耦合强度和方向性，将其纳入轨迹优化框架。

Result: 仿真结果表明，在轨迹规划中显式考虑动态耦合可以实现更高效的操作。

Conclusion: 该研究为自由浮动SMSs的控制提供了新方向，表明利用动态耦合可以优化轨迹规划。

Abstract: This study proposes a dynamic coupling-informed trajectory optimization
algorithm for free-floating space manipulator systems (SMSs). Dynamic coupling
between the base and the manipulator arms plays a critical role in influencing
the system's behavior. While prior research has predominantly focused on
minimizing this coupling, often overlooking its potential advantages, this work
investigates how dynamic coupling can instead be leveraged to improve
trajectory planning. Singular value decomposition (SVD) of the dynamic coupling
matrix is employed to identify the dominant components governing coupling
behavior. A quantitative metric is then formulated to characterize the strength
and directionality of the coupling and is incorporated into a trajectory
optimization framework. To assess the feasibility of the optimized trajectory,
a sliding mode control-based tracking controller is designed to generate the
required joint torque inputs. Simulation results demonstrate that explicitly
accounting for dynamic coupling in trajectory planning enables more informed
and potentially more efficient operation, offering new directions for the
control of free-floating SMSs.

</details>


### [14] [Neural Robot Dynamics](https://arxiv.org/abs/2508.15755)
*Jie Xu,Eric Heiden,Iretiayo Akinola,Dieter Fox,Miles Macklin,Yashraj Narang*

Main category: cs.RO

TL;DR: NeRD（神经机器人动力学）是一种通用的神经模拟器，用于预测刚体机器人在接触约束下的未来状态，具有稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现代机器人模拟因高自由度和复杂机制而困难，现有神经模拟器缺乏泛化能力。

Method: 提出NeRD，替代传统模拟器的低层动力学和接触求解器，采用机器人中心和空间不变的表示。

Result: NeRD在千步模拟中稳定准确，能泛化到新任务和环境，支持从真实数据微调。

Conclusion: NeRD为机器人模拟提供了高效、通用的解决方案，缩小了模拟与现实的差距。

Abstract: Accurate and efficient simulation of modern robots remains challenging due to
their high degrees of freedom and intricate mechanisms. Neural simulators have
emerged as a promising alternative to traditional analytical simulators,
capable of efficiently predicting complex dynamics and adapting to real-world
data; however, existing neural simulators typically require
application-specific training and fail to generalize to novel tasks and/or
environments, primarily due to inadequate representations of the global state.
In this work, we address the problem of learning generalizable neural
simulators for robots that are structured as articulated rigid bodies. We
propose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models
for predicting future states for articulated rigid bodies under contact
constraints. NeRD uniquely replaces the low-level dynamics and contact solvers
in an analytical simulator and employs a robot-centric and spatially-invariant
simulation state representation. We integrate the learned NeRD models as an
interchangeable backend solver within a state-of-the-art robotics simulator. We
conduct extensive experiments to show that the NeRD simulators are stable and
accurate over a thousand simulation steps; generalize across tasks and
environment configurations; enable policy learning exclusively in a neural
engine; and, unlike most classical simulators, can be fine-tuned from
real-world data to bridge the gap between simulation and reality.

</details>
