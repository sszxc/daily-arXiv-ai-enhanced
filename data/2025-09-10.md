<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [First Plan Then Evaluate: Use a Vectorized Motion Planner for Grasping](https://arxiv.org/abs/2509.07162)
*Martin Matak,Mohanraj Devendran Ashanti,Karl Van Wyk,Tucker Hermans*

Main category: cs.RO

TL;DR: 提出一种并行规划轨迹至生成抓取目标集的框架，利用向量化运动规划器高效规划，评估器估计轨迹抓取成功可能性，机器人执行最可能成功的轨迹，在不同对象、生成器、运动规划器及真实新环境中优于传统生成器-评估器-规划器框架


<details>
  <summary>Details</summary>
Motivation: 传统生成器-评估器-规划器框架中，执行低排名抓取成功率低且多次轨迹优化耗时，放宽运动规划精度阈值虽易计算轨迹但降低抓取成功可能性估计准确性，陷入耗时或估计差的两难困境

Method: 提出并行规划轨迹至生成抓取目标集的框架，使用向量化运动规划器高效规划至不同目标的轨迹，评估器估计所得轨迹的抓取成功可能性，机器人执行最可能成功的轨迹

Result: 实验表明该方法在不同对象、生成器、运动规划器上均优于传统框架，并成功泛化到真实世界的新环境，包括不同货架和桌子高度

Conclusion: 所提框架通过并行规划轨迹并选择最可能成功的轨迹执行，解决了传统框架的耗时与成功率估计差的问题，提升了机器人抓取性能

Abstract: Autonomous multi-finger grasping is a fundamental capability in robotic
manipulation. Optimization-based approaches show strong performance, but tend
to be sensitive to initialization and are potentially time-consuming. As an
alternative, the generator-evaluator-planner framework has been proposed. A
generator generates grasp candidates, an evaluator ranks the proposed grasps,
and a motion planner plans a trajectory to the highest-ranked grasp. If the
planner doesn't find a trajectory, a new trajectory optimization is started
with the next-best grasp as the target and so on. However, executing
lower-ranked grasps means a lower chance of grasp success, and multiple
trajectory optimizations are time-consuming. Alternatively, relaxing the
threshold for motion planning accuracy allows for easier computation of a
successful trajectory but implies lower accuracy in estimating grasp success
likelihood. It's a lose-lose proposition: either spend more time finding a
successful trajectory or have a worse estimate of grasp success. We propose a
framework that plans trajectories to a set of generated grasp targets in
parallel, the evaluator estimates the grasp success likelihood of the resulting
trajectories, and the robot executes the trajectory most likely to succeed. To
plan trajectories to different targets efficiently, we propose the use of a
vectorized motion planner. Our experiments show our approach improves over the
traditional generator-evaluator-planner framework across different objects,
generators, and motion planners, and successfully generalizes to novel
environments in the real world, including different shelves and table heights.
Project website https://sites.google.com/view/fpte

</details>


### [2] [Quantum Machine Learning and Grover's Algorithm for Quantum Optimization of Robotic Manipulators](https://arxiv.org/abs/2509.07216)
*Hassen Nigatu,Shi Gaokun,Li Jituo,Wang Jin,Lu Guodong,Howard Li*

Main category: cs.RO

TL;DR: 本文提出一种量子原生框架，将量子机器学习与Grover算法结合，以高效解决高自由度机器人的运动学优化问题，在增加问题维度时较经典优化器实现显著加速（最高93倍），为量子计算与机器人学问题搭建了基础桥梁。


<details>
  <summary>Details</summary>
Motivation: 经典方法在搜索高自由度机器人操作器复杂、高维配置空间时面临计算挑战。

Method: 引入量子原生框架，集成量子机器学习与Grover算法；训练参数化量子电路近似正向运动学模型，构建识别最优配置的预言机；Grover算法利用该预言机实现搜索复杂度的二次降低。

Result: 在1-DoF、2-DoF和双臂操作器任务上进行了演示，随着问题维度增加，该方法较Nelder-Mead等经典优化器实现显著加速，最高达93倍。

Conclusion: 这项工作建立了用于机器人运动学优化的基础量子原生框架，有效连接了量子计算与机器人学问题。

Abstract: Optimizing high-degree of freedom robotic manipulators requires searching
complex, high-dimensional configuration spaces, a task that is computationally
challenging for classical methods. This paper introduces a quantum native
framework that integrates quantum machine learning with Grover's algorithm to
solve kinematic optimization problems efficiently. A parameterized quantum
circuit is trained to approximate the forward kinematics model, which then
constructs an oracle to identify optimal configurations. Grover's algorithm
leverages this oracle to provide a quadratic reduction in search complexity.
Demonstrated on 1-DoF, 2-DoF, and dual-arm manipulator tasks, the method
achieves significant speedups-up to 93x over classical optimizers like Nelder
Mead as problem dimensionality increases. This work establishes a foundational,
quantum-native framework for robot kinematic optimization, effectively bridging
quantum computing and robotics problems.

</details>


### [3] [Safe Gap-based Planning in Dynamic Settings](https://arxiv.org/abs/2509.07239)
*Max Asselmeier,Abdel Zaro,Dhruv Ahuja,Ye Zhao,Patricio A. Vela*

Main category: cs.RO

TL;DR: 本文将基于感知的间隙局部规划器扩展到动态环境，提出Dynamic Gap规划器，通过跟踪间隙动态、传播未来间隙及利用追踪制导理论生成无碰撞轨迹，并在基准测试和真实实验中表现优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有动态环境中基于感知的局部规划器常依赖涌现或经验鲁棒性进行避障，缺乏对动态障碍物的形式化分析。

Method: 该规划器通过以下步骤处理动态障碍物：首先跟踪称为间隙的自由空间极地区域并估计其动态以了解局部环境随时间的演变；然后在规划时通过新颖的间隙传播算法将间隙传播到未来，以了解哪些区域可通行；最后利用追踪制导理论生成在理想条件下可证明无碰撞的局部轨迹。此外，在无间隙情况下执行以障碍物为中心的非间隙处理，以增强整体规划框架的鲁棒性。

Result: 在动态环境中，一系列基于间隙的规划器与一系列经典和学习的运动规划器进行基准测试，Dynamic Gap在所有环境中均优于所有其他基线。此外，在TurtleBot2平台上进行了多个真实世界实验，验证了避障行为。

Conclusion: Dynamic Gap规划器通过明确处理动态障碍物的步骤，在动态环境中表现出优于其他规划器的性能，并在真实实验中有效验证了其避障能力。

Abstract: This chapter extends the family of perception-informed gap-based local
planners to dynamic environments. Existing perception-informed local planners
that operate in dynamic environments often rely on emergent or empirical
robustness for collision avoidance as opposed to performing formal analysis of
dynamic obstacles. This proposed planner, dynamic gap, explicitly addresses
dynamic obstacles through several steps in the planning pipeline. First, polar
regions of free space known as gaps are tracked and their dynamics are
estimated in order to understand how the local environment evolves over time.
Then, at planning time, gaps are propagated into the future through novel gap
propagation algorithms to understand what regions are feasible for passage.
Lastly, pursuit guidance theory is leveraged to generate local trajectories
that are provably collision-free under ideal conditions. Additionally,
obstacle-centric ungap processing is performed in situations where no gaps
exist to robustify the overall planning framework. A set of gap-based planners
are benchmarked against a series of classical and learned motion planners in
dynamic environments, and dynamic gap is shown to outperform all other
baselines in all environments. Furthermore, dynamic gap is deployed on a
TurtleBot2 platform in several real-world experiments to validate collision
avoidance behaviors.

</details>


### [4] [Performance Characterization of a Point-Cloud-Based Path Planner in Off-Road Terrain](https://arxiv.org/abs/2509.07321)
*Casey D. Majhor,Jeremy P. Bos*

Main category: cs.RO

TL;DR: 本文对基于点云的自主越野导航栈MUONS进行了综合评估，通过3万次模拟规划导航试验和实地测试验证性能，发现初始规划阶段的Bi-RRT扩展半径与规划时间和路径长度性能相关性最强，且调谐参数变化的比例变异与实地测试性能相关性良好，支持蒙特卡洛模拟用于性能评估和参数调谐。


<details>
  <summary>Details</summary>
Motivation: 评估基于点云的自主越野导航栈MUONS的性能。

Method: 通过3万次模拟规划导航试验（考虑三种运动学挑战地形地图和七种路径规划参数的二十种组合）和实地测试，结合统计和相关性分析。

Result: 模拟中配备MUONS的AGV成功率达0.98，实地无故障；初始规划阶段的Bi-RRT扩展半径与规划时间和路径长度性能相关性最强；调谐参数变化的比例变异与实地测试性能相关性良好。

Conclusion: 支持使用蒙特卡洛模拟用于性能评估和参数调谐。

Abstract: We present a comprehensive evaluation of a point-cloud-based navigation
stack, MUONS, for autonomous off-road navigation. Performance is characterized
by analyzing the results of 30,000 planning and navigation trials in simulation
and validated through field testing. Our simulation campaign considers three
kinematically challenging terrain maps and twenty combinations of seven
path-planning parameters. In simulation, our MUONS-equipped AGV achieved a 0.98
success rate and experienced no failures in the field. By statistical and
correlation analysis we determined that the Bi-RRT expansion radius used in the
initial planning stages is most correlated with performance in terms of
planning time and traversed path length. Finally, we observed that the
proportional variation due to changes in the tuning parameters is remarkably
well correlated to performance in field testing. This finding supports the use
of Monte-Carlo simulation campaigns for performance assessment and parameter
tuning.

</details>


### [5] [Aerial-ground Cross-modal Localization: Dataset, Ground-truth, and Benchmark](https://arxiv.org/abs/2509.07362)
*Yandi Yang,Jianping Li,Youqi Liao,Yuhao Li,Yizhe Zhang,Zhen Dong,Bisheng Yang,Naser El-Sheimy*

Main category: cs.RO

TL;DR: 针对城市环境视觉定位的局限，本文引入一个新的大规模数据集，整合移动测绘系统的地面图像与武汉、香港和旧金山的机载激光扫描（ALS）点云。


<details>
  <summary>Details</summary>
Motivation: 城市环境中视觉里程计受无纹理表面、严重视点变化和长期漂移限制，而ALS数据的可用性为视觉定位提供新途径，但因缺乏平台多样化数据集、大规模城市环境可靠真值生成方法及跨平台图像到点云（I2P）算法验证不足，其潜力未被充分挖掘。

Method: 引入整合移动测绘系统地面图像与武汉、香港、旧金山ALS点云的新大规模数据集。

Result: 未提及具体结果。

Conclusion: 未提及具体结论。

Abstract: Accurate visual localization in dense urban environments poses a fundamental
task in photogrammetry, geospatial information science, and robotics. While
imagery is a low-cost and widely accessible sensing modality, its effectiveness
on visual odometry is often limited by textureless surfaces, severe viewpoint
changes, and long-term drift. The growing public availability of airborne laser
scanning (ALS) data opens new avenues for scalable and precise visual
localization by leveraging ALS as a prior map. However, the potential of
ALS-based localization remains underexplored due to three key limitations: (1)
the lack of platform-diverse datasets, (2) the absence of reliable ground-truth
generation methods applicable to large-scale urban environments, and (3)
limited validation of existing Image-to-Point Cloud (I2P) algorithms under
aerial-ground cross-platform settings. To overcome these challenges, we
introduce a new large-scale dataset that integrates ground-level imagery from
mobile mapping systems with ALS point clouds collected in Wuhan, Hong Kong, and
San Francisco.

</details>


### [6] [TransMPC: Transformer-based Explicit MPC with Variable Prediction Horizon](https://arxiv.org/abs/2509.07381)
*Sichao Wu,Jiang Wu,Xingyu Cao,Fawang Zhang,Guangyuan Yu,Junjie Zhao,Yue Qu,Fei Ma,Jingliang Duan*

Main category: cs.RO

TL;DR: 该论文提出TransMPC，一种基于Transformer的显式MPC算法，能为复杂动态系统实时生成高精度控制序列，通过编码器-仅Transformer架构和直接策略优化框架，解决传统MPC计算复杂、现有显式MPC精度受限问题，并在仿真和实车实验中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统在线MPC计算复杂度高限制实际部署，现有显式MPC依赖简化系统动力学和代价函数，导致复杂系统精度受限，故提出TransMPC以解决这些问题。

Method: 将MPC策略构建为编码器-仅Transformer，利用双向自注意力，在单次前向传播中同时推断整个控制序列；引入直接策略优化框架，交替采样与学习阶段，通过自动微分直接优化真实有限 horizon 代价，结合随机 horizon 采样和回放缓冲区提供独立同分布训练样本。

Result: 通过大量仿真和真实世界车辆控制实验，验证了TransMPC在求解精度、对不同horizon的适应性及计算效率方面的有效性。

Conclusion: TransMPC是一种新颖的基于Transformer的显式MPC算法，能够为复杂动态系统实时生成高精度控制序列，具有良好的性能和应用前景。

Abstract: Traditional online Model Predictive Control (MPC) methods often suffer from
excessive computational complexity, limiting their practical deployment.
Explicit MPC mitigates online computational load by pre-computing control
policies offline; however, existing explicit MPC methods typically rely on
simplified system dynamics and cost functions, restricting their accuracy for
complex systems. This paper proposes TransMPC, a novel Transformer-based
explicit MPC algorithm capable of generating highly accurate control sequences
in real-time for complex dynamic systems. Specifically, we formulate the MPC
policy as an encoder-only Transformer leveraging bidirectional self-attention,
enabling simultaneous inference of entire control sequences in a single forward
pass. This design inherently accommodates variable prediction horizons while
ensuring low inference latency. Furthermore, we introduce a direct policy
optimization framework that alternates between sampling and learning phases.
Unlike imitation-based approaches dependent on precomputed optimal
trajectories, TransMPC directly optimizes the true finite-horizon cost via
automatic differentiation. Random horizon sampling combined with a replay
buffer provides independent and identically distributed (i.i.d.) training
samples, ensuring robust generalization across varying states and horizon
lengths. Extensive simulations and real-world vehicle control experiments
validate the effectiveness of TransMPC in terms of solution accuracy,
adaptability to varying horizons, and computational efficiency.

</details>


### [7] [Attention and Risk-Aware Decision Framework for Safe Autonomous Driving](https://arxiv.org/abs/2509.07412)
*Zhen Tian,Fujiang Yuan,Yangfan He,Qinghao Li,Changlin Chen,Huilin Chen,Tianxiang Xu,Jianyu Duan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: 本文提出一种改进的PPO算法，通过引入风险感知机制、风险注意力决策网络、平衡奖励函数和安全辅助机制，解决现有PPO在自动驾驶中训练效果差、效率低及碰撞问题，在物理引擎仿真中表现优于基准算法。


<details>
  <summary>Details</summary>
Motivation: 现有基于模型的自动驾驶方法难以应对不可预见事件，而PPO等基于学习的方法存在训练效果差、长序列训练效率低及易导致碰撞等问题，需对此改进。

Method: 引入风险感知机制突出潜在碰撞区域，平衡奖励函数根据周围车辆数量调整奖励，风险注意力网络增强对输入图像高风险区域的通道和空间注意力，安全辅助机制监督并防止换道和车道保持时的碰撞风险动作。

Result: 在物理引擎的多测试交通流场景中，所提算法在避碰方面优于基准算法，实现更高的峰值奖励，训练时间更短，在风险区域的驾驶时间更短。

Conclusion: 改进的PPO算法通过多种机制提升了自动驾驶的训练效果、效率及安全性，仿真结果验证其有效性。

Abstract: Autonomous driving has attracted great interest due to its potential
capability in full-unsupervised driving. Model-based and learning-based methods
are widely used in autonomous driving. Model-based methods rely on pre-defined
models of the environment and may struggle with unforeseen events. Proximal
policy optimization (PPO), an advanced learning-based method, can adapt to the
above limits by learning from interactions with the environment. However,
existing PPO faces challenges with poor training results, and low training
efficiency in long sequences. Moreover, the poor training results are
equivalent to collisions in driving tasks. To solve these issues, this paper
develops an improved PPO by introducing the risk-aware mechanism, a
risk-attention decision network, a balanced reward function, and a
safety-assisted mechanism. The risk-aware mechanism focuses on highlighting
areas with potential collisions, facilitating safe-driving learning of the PPO.
The balanced reward function adjusts rewards based on the number of surrounding
vehicles, promoting efficient exploration of the control strategy during
training. Additionally, the risk-attention network enhances the PPO to hold
channel and spatial attention for the high-risk areas of input images.
Moreover, the safety-assisted mechanism supervises and prevents the actions
with risks of collisions during the lane keeping and lane changing. Simulation
results on a physical engine demonstrate that the proposed algorithm
outperforms benchmark algorithms in collision avoidance, achieving higher peak
reward with less training time, and shorter driving time remaining on the risky
areas among multiple testing traffic flow scenarios.

</details>


### [8] [Robust Docking Maneuvers for Autonomous Trolley Collection: An Optimization-Based Visual Servoing Scheme](https://arxiv.org/abs/2509.07413)
*Yuhan Pang,Bingyi Xia,Zhe Zhang,Zhirui Sun,Peijia Xie,Bike Zhu,Wenjun Xu,Jiankun Wang*

Main category: cs.RO

TL;DR: 本文提出一种基于优化的视觉伺服方案，结合主动红外标记以实现鲁棒特征提取，通过建模非完整运动学和可见性约束，并增加扰动抑制观测器，解决服务机器人在多种环境下对接手推车时的高精度要求、环境干扰和机器人固有约束问题，实验表明系统具有鲁棒性和高对接精度。


<details>
  <summary>Details</summary>
Motivation: 服务机器人在公共空间（如机场、仓库）自主收集和重新分配手推车可提高效率、降低成本，但基于Leader-Follower编队的多手推车收集运输系统中，移动基座的可靠对接操作对将手推车对齐成有序队列至关重要。然而，开发基于视觉的机器人对接系统面临高精度要求、环境干扰和机器人固有约束等重大挑战。

Method: 提出一种基于优化的视觉伺服方案，该方案结合主动红外标记以在不同光照条件下实现鲁棒特征提取。此框架在混合视觉伺服问题中明确建模非完整运动学和可见性约束，并增加扰动抑制观测器以确保精确稳定的对接。

Result: 在不同环境下的实验结果表明该系统具有鲁棒性，定量评估证实其具有高对接精度。

Conclusion: 所提出的优化视觉伺服方案有效解决了服务机器人手推车对接面临的挑战，实现了鲁棒且高精度的对接。

Abstract: Service robots have demonstrated significant potential for autonomous trolley
collection and redistribution in public spaces like airports or warehouses to
improve efficiency and reduce cost. Usually, a fully autonomous system for the
collection and transportation of multiple trolleys is based on a
Leader-Follower formation of mobile manipulators, where reliable docking
maneuvers of the mobile base are essential to align trolleys into organized
queues. However, developing a vision-based robotic docking system faces
significant challenges: high precision requirements, environmental
disturbances, and inherent robot constraints. To address these challenges, we
propose an optimization-based Visual Servoing scheme that incorporates active
infrared markers for robust feature extraction across diverse lighting
conditions. This framework explicitly models nonholonomic kinematics and
visibility constraints within the Hybrid Visual Servoing problem, augmented
with an observer for disturbance rejection to ensure precise and stable
docking. Experimental results across diverse environments demonstrate the
robustness of this system, with quantitative evaluations confirming high
docking accuracy.

</details>


### [9] [Timing the Message: Language-Based Notifications for Time-Critical Assistive Settings](https://arxiv.org/abs/2509.07438)
*Ya-Chuan Hsu,Jonathan DeCastro,Andrew Silva,Guy Rosman*

Main category: cs.RO

TL;DR: This paper studies the trade-off between timeliness and informativeness in time-critical human-AI assistance by using an augmented-state Markov Decision Process framework combining reinforcement learning and a generated offline taxonomy dataset, improving success rates by over 40% compared to methods ignoring time delays.


<details>
  <summary>Details</summary>
Motivation: Current language-based assistive systems in time-critical settings (e.g., assistive driving) prioritize content generation but overlook critical timing factors (verbal conveyance duration, human comprehension delays, follow-through duration), leading to potential delays affecting outcomes.

Method: Framing the challenge as a sequential decision-making problem using an augmented-state Markov Decision Process, designing a framework combining reinforcement learning and a generated offline taxonomy dataset to balance timeliness and informativeness with a scalable taxonomy dataset generation pipeline.

Result: Empirical evaluation with synthetic humans shows the framework improves success rates by over 40% compared to methods ignoring time delays, effectively balancing timeliness and informativeness, and exposes the trade-off between these two factors.

Conclusion: The framework effectively balances timeliness and informativeness in time-critical human-AI assistance, improves success rates, and opens new directions for optimizing communication in such settings by addressing the overlooked trade-off.

Abstract: In time-critical settings such as assistive driving, assistants often rely on
alerts or haptic signals to prompt rapid human attention, but these cues
usually leave humans to interpret situations and decide responses
independently, introducing potential delays or ambiguity in meaning.
Language-based assistive systems can instead provide instructions backed by
context, offering more informative guidance. However, current approaches (e.g.,
social assistive robots) largely prioritize content generation while
overlooking critical timing factors such as verbal conveyance duration, human
comprehension delays, and subsequent follow-through duration. These timing
considerations are crucial in time-critical settings, where even minor delays
can substantially affect outcomes. We aim to study this inherent trade-off
between timeliness and informativeness by framing the challenge as a sequential
decision-making problem using an augmented-state Markov Decision Process. We
design a framework combining reinforcement learning and a generated offline
taxonomy dataset, where we balance the trade-off while enabling a scalable
taxonomy dataset generation pipeline. Empirical evaluation with synthetic
humans shows our framework improves success rates by over 40% compared to
methods that ignore time delays, while effectively balancing timeliness and
informativeness. It also exposes an often-overlooked trade-off between these
two factors, opening new directions for optimizing communication in
time-critical human-AI assistance.

</details>


### [10] [Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions](https://arxiv.org/abs/2509.07445)
*Harrison Field,Max Yang,Yijiong Lin,Efi Psomopoulou,David Barton,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 本文提出Text2Touch，将大语言模型（LLMs）生成的奖励函数应用于多轴手部物体旋转任务，结合基于视觉的触觉传感，通过提示工程和模拟到现实蒸馏，在真实灵巧机器人手上实现了优于人工设计基线的性能，加速了触觉灵巧技能的开发。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的奖励设计研究未考虑触觉传感，而触觉对类人灵巧操作至关重要，需解决多轴手部物体旋转中触觉传感与LLM奖励结合的问题。

Method: 1. 提出Text2Touch方法，利用LLM生成奖励函数；2. 采用提示工程策略处理超过70个环境变量；3. 通过模拟到现实蒸馏实现策略向真实四指灵巧机器人手的迁移。

Result: Text2Touch显著优于人工设计基线，旋转速度更快、稳定性更高，且奖励函数长度和复杂度降低一个数量级。

Conclusion: LLM设计的奖励函数可显著减少从概念到可部署触觉灵巧技能的时间，支持更快速、可扩展的多模态机器人学习。

Abstract: Large language models (LLMs) are beginning to automate reward design for
dexterous manipulation. However, no prior work has considered tactile sensing,
which is known to be critical for human-like dexterity. We present Text2Touch,
bringing LLM-crafted rewards to the challenging task of multi-axis in-hand
object rotation with real-world vision based tactile sensing in palm-up and
palm-down configurations. Our prompt engineering strategy scales to over 70
environment variables, and sim-to-real distillation enables successful policy
transfer to a tactile-enabled fully actuated four-fingered dexterous robot
hand. Text2Touch significantly outperforms a carefully tuned human-engineered
baseline, demonstrating superior rotation speed and stability while relying on
reward functions that are an order of magnitude shorter and simpler. These
results illustrate how LLM-designed rewards can significantly reduce the time
from concept to deployable dexterous tactile skills, supporting more rapid and
scalable multimodal robot learning. Project website:
https://hpfield.github.io/text2touch-website

</details>


### [11] [DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis](https://arxiv.org/abs/2509.07463)
*Sven Kirchner,Nils Purschke,Ross Greer,Alois C. Knoll*

Main category: cs.RO

TL;DR: DepthVision是一个多模态场景理解框架，通过结合稀疏LiDAR点云和真实RGB数据解决视觉输入退化问题，无需微调下游视觉语言模型，在微光条件下性能优于仅用RGB的基线模型


<details>
  <summary>Details</summary>
Motivation: 解决机器人在视觉输入退化或不足时的可靠操作挑战

Method: 使用条件生成对抗网络（GAN）结合精炼网络从稀疏LiDAR点云合成RGB图像，再通过亮度感知模态适配（LAMA）根据环境光照动态融合合成视图与真实RGB数据

Result: 在真实和模拟数据集上评估，特别是安全关键任务，在低光条件下性能提升，相比RGB-only基线有显著增益，同时保持与冻结视觉语言模型的兼容性

Conclusion: LiDAR引导的RGB合成在实现现实环境中稳健机器人操作方面具有潜力

Abstract: Ensuring reliable robot operation when visual input is degraded or
insufficient remains a central challenge in robotics. This letter introduces
DepthVision, a framework for multimodal scene understanding designed to address
this problem. Unlike existing Vision-Language Models (VLMs), which use only
camera-based visual input alongside language, DepthVision synthesizes RGB
images from sparse LiDAR point clouds using a conditional generative
adversarial network (GAN) with an integrated refiner network. These synthetic
views are then combined with real RGB data using a Luminance-Aware Modality
Adaptation (LAMA), which blends the two types of data dynamically based on
ambient lighting conditions. This approach compensates for sensor degradation,
such as darkness or motion blur, without requiring any fine-tuning of
downstream vision-language models. We evaluate DepthVision on real and
simulated datasets across various models and tasks, with particular attention
to safety-critical tasks. The results demonstrate that our approach improves
performance in low-light conditions, achieving substantial gains over RGB-only
baselines while preserving compatibility with frozen VLMs. This work highlights
the potential of LiDAR-guided RGB synthesis for achieving robust robot
operation in real-world environments.

</details>


### [12] [Safe and Non-Conservative Contingency Planning for Autonomous Vehicles via Online Learning-Based Reachable Set Barriers](https://arxiv.org/abs/2509.07464)
*Rui Yang,Lei Zheng,Shuzhi Sam Ge,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出一种实时应急轨迹优化框架，通过事件触发的在线学习量化多模态人类驾驶车辆（HV）不确定性并增量细化前向可达集（FRS），利用基于FRS的障碍约束确保安全性，结合共识交替方向乘子法（ADMM）高效求解，在高速公路和城市场景的高保真模拟及真实世界实验中，在保证不确定性下安全的同时显著提升驾驶效率和乘客舒适度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需在动态不确定环境中平衡安全性和驾驶效率，而周围人类驾驶车辆（HV）的不可预测性及感知不准确加剧了这一挑战，过度保守的规划器会降低驾驶效率，确定性方法面对突发意外机动时可能出现严重问题和失效风险。

Method: 提出实时应急轨迹优化框架，采用事件触发的HV控制意图集在线学习，动态量化多模态HV不确定性并增量细化前向可达集（FRS），通过基于FRS的障碍约束强制不变安全性（不依赖HV准确轨迹预测），将这些约束嵌入应急轨迹优化并通过共识交替方向乘子法（ADMM）高效求解。

Result: 在高速公路和城市场景的高保真模拟以及一系列真实世界实验中，该系统在不确定性下保持安全性的同时，显著提高了驾驶效率和乘客舒适度。

Conclusion: 该实时应急轨迹优化框架能够持续适应HV行为的不确定性，在不依赖过度保守的情况下保持可行性和安全性，有效平衡了自动驾驶的安全性与驾驶效率。

Abstract: Autonomous vehicles must navigate dynamically uncertain environments while
balancing the safety and driving efficiency. This challenge is exacerbated by
the unpredictable nature of surrounding human-driven vehicles (HVs) and
perception inaccuracies, which require planners to adapt to evolving
uncertainties while maintaining safe trajectories. Overly conservative planners
degrade driving efficiency, while deterministic approaches may encounter
serious issues and risks of failure when faced with sudden and unexpected
maneuvers. To address these issues, we propose a real-time contingency
trajectory optimization framework in this paper. By employing event-triggered
online learning of HV control-intent sets, our method dynamically quantifies
multi-modal HV uncertainties and refines the forward reachable set (FRS)
incrementally. Crucially, we enforce invariant safety through FRS-based barrier
constraints that ensure safety without reliance on accurate trajectory
prediction of HVs. These constraints are embedded in contingency trajectory
optimization and solved efficiently through consensus alternative direction
method of multipliers (ADMM). The system continuously adapts to the
uncertainties in HV behaviors, preserving feasibility and safety without
resorting to excessive conservatism. High-fidelity simulations on highway and
urban scenarios, as well as a series of real-world experiments demonstrate
significant improvements in driving efficiency and passenger comfort while
maintaining safety under uncertainty. The project page is available at
https://pathetiue.github.io/frscp.github.io/.

</details>


### [13] [Flexible Morphing Aerial Robot with Inflatable Structure for Perching-based Human-Robot Interaction](https://arxiv.org/abs/2509.07496)
*Ayano Miyamichi,Moju Zhao,Kazuki Sugihara,Junichiro Sugihara,Masanori Konishi,Kunio Kojima,Kei Okada,Masayuki Inaba*

Main category: cs.RO

TL;DR: 本文旨在开发一种能够在人体上栖息并具有高灵活性和抓取能力的可变形空中机器人，通过混合形变结构结合单侧柔性臂和气动充气执行器，解决飞行和栖息稳定性挑战，并首次实现空中机器人与人体交互栖息。


<details>
  <summary>Details</summary>
Motivation: 自然界中的鸟类栖息不仅是为了休息，还用于与人类互动（如与驯鹰人的关系）。近年来，研究人员开发出具有栖息能力的空中机器人以节省能源，可变形结构在栖息效率和配置紧凑性方面显示出显著优势。然而，由于难以控制柔性臂，确保可变形空中机器人的飞行稳定性仍然具有挑战性。此外，用于人类交互的栖息需要高柔顺性和安全性。

Method: 提出一种混合形变结构，结合单侧柔性臂和气动充气执行器，使机器人手臂在飞行时保持刚性，栖息时变软以实现更有效的抓取；开发气动控制系统，优化压力调节，同时整合减震和可调抓取力；关注单侧柔性臂的结构特性，确定标准四旋翼建模和控制在飞行稳定性方面保持有效的充分条件。

Result: 开发的原型展示了在人体上进行柔顺栖息操作的可行性，以及即使在飞行中因推力降低导致手臂变形后也能稳健恢复。

Conclusion: 据作者所知，这项工作首次实现了能够在人体上栖息以进行交互的空中机器人。

Abstract: Birds in nature perform perching not only for rest but also for interaction
with human such as the relationship with falconers. Recently, researchers
achieve perching-capable aerial robots as a way to save energy, and deformable
structure demonstrate significant advantages in efficiency of perching and
compactness of configuration. However, ensuring flight stability remains
challenging for deformable aerial robots due to the difficulty of controlling
flexible arms. Furthermore, perching for human interaction requires high
compliance along with safety. Thus, this study aims to develop a deformable
aerial robot capable of perching on humans with high flexibility and grasping
ability. To overcome the challenges of stability of both flight and perching,
we propose a hybrid morphing structure that combines a unilateral flexible arm
and a pneumatic inflatable actuators. This design allows the robot's arms to
remain rigid during flight and soft while perching for more effective grasping.
We also develop a pneumatic control system that optimizes pressure regulation
while integrating shock absorption and adjustable grasping forces, enhancing
interaction capabilities and energy efficiency. Besides, we focus on the
structural characteristics of the unilateral flexible arm and identify
sufficient conditions under which standard quadrotor modeling and control
remain effective in terms of flight stability. Finally, the developed prototype
demonstrates the feasibility of compliant perching maneuvers on humans, as well
as the robust recovery even after arm deformation caused by thrust reductions
during flight. To the best of our knowledge, this work is the first to achieve
an aerial robot capable of perching on humans for interaction.

</details>


### [14] [OmniMap: A General Mapping Framework Integrating Optics, Geometry, and Semantics](https://arxiv.org/abs/2509.07500)
*Yinan Deng,Yufeng Yue,Jianyu Dou,Jingyu Zhao,Jiahui Wang,Yujie Tang,Yi Yang,Mengyin Fu*

Main category: cs.RO

TL;DR: OmniMap是首个在线映射框架，同时捕获光学、几何和语义场景属性，保持实时性能和模型紧凑性，在渲染保真度、几何精度和零样本语义分割方面优于现有方法，并支持多种下游应用。


<details>
  <summary>Details</summary>
Motivation: 现有方法在机器人系统3D环境感知中仅部分满足对照片级真实外观（光学）、精确布局形状（几何）和开放词汇场景理解（语义）的需求，存在光学模糊、几何不规则和语义模糊问题。

Method: OmniMap采用紧密耦合的3DGS-Voxel混合表示，结合细粒度建模与结构稳定性；在实现层面引入创新：自适应相机建模（运动模糊和曝光补偿）、带法向约束的混合增量表示、用于鲁棒实例级理解的概率融合。

Result: 广泛实验表明，OmniMap在不同场景中，在渲染保真度、几何精度和零样本语义分割方面优于最先进方法。

Conclusion: OmniMap作为首个同时捕获光学、几何和语义场景属性的在线映射框架，具有实时性和模型紧凑性，性能优越且通用性强，支持多域场景问答、交互式编辑、感知引导操作和地图辅助导航等多种下游应用。

Abstract: Robotic systems demand accurate and comprehensive 3D environment perception,
requiring simultaneous capture of photo-realistic appearance (optical), precise
layout shape (geometric), and open-vocabulary scene understanding (semantic).
Existing methods typically achieve only partial fulfillment of these
requirements while exhibiting optical blurring, geometric irregularities, and
semantic ambiguities. To address these challenges, we propose OmniMap. Overall,
OmniMap represents the first online mapping framework that simultaneously
captures optical, geometric, and semantic scene attributes while maintaining
real-time performance and model compactness. At the architectural level,
OmniMap employs a tightly coupled 3DGS-Voxel hybrid representation that
combines fine-grained modeling with structural stability. At the implementation
level, OmniMap identifies key challenges across different modalities and
introduces several innovations: adaptive camera modeling for motion blur and
exposure compensation, hybrid incremental representation with normal
constraints, and probabilistic fusion for robust instance-level understanding.
Extensive experiments show OmniMap's superior performance in rendering
fidelity, geometric accuracy, and zero-shot semantic segmentation compared to
state-of-the-art methods across diverse scenes. The framework's versatility is
further evidenced through a variety of downstream applications, including
multi-domain scene Q&A, interactive editing, perception-guided manipulation,
and map-assisted navigation.

</details>


### [15] [Improving Machine Learning-Based Robot Self-Collision Checking with Input Positional Encoding](https://arxiv.org/abs/2509.07542)
*Bartlomiej Kulecki,Dominik Belter*

Main category: cs.RO

TL;DR: 本文研究将计算机图形学中广泛使用的位置编码技术集成到二进制分类模型的输入向量中，用于自碰撞检测，结果表明该技术能提高分类精度，且基于机器学习的轻量级多层感知器（MLPs）在低维特征空间中比传统几何方法更快


<details>
  <summary>Details</summary>
Motivation: 传统自碰撞检测方法（如三角形相交测试、BVH）依赖几何方法，速度较慢，需要更快速的替代方案

Method: 将位置编码技术集成到二进制分类模型的输入向量中，使用轻量级多层感知器（MLPs）在低维特征空间中进行碰撞检测

Result: 集成位置编码能通过使模型更好地捕捉高频变化，增强分类精度，从而更详细、精确地表示复杂碰撞模式；基于MLPs的方法比传统几何方法更快

Conclusion: 基于机器学习的技术（如轻量级MLPs）结合位置编码为自碰撞检测提供了一种更快且精度更高的替代方案

Abstract: This manuscript investigates the integration of positional encoding -- a
technique widely used in computer graphics -- into the input vector of a binary
classification model for self-collision detection. The results demonstrate the
benefits of incorporating positional encoding, which enhances classification
accuracy by enabling the model to better capture high-frequency variations,
leading to a more detailed and precise representation of complex collision
patterns. The manuscript shows that machine learning-based techniques, such as
lightweight multilayer perceptrons (MLPs) operating in a low-dimensional
feature space, offer a faster alternative for collision checking than
traditional methods that rely on geometric approaches, such as
triangle-to-triangle intersection tests and Bounding Volume Hierarchies (BVH)
for mesh-based models.

</details>


### [16] [Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?](https://arxiv.org/abs/2509.07593)
*Gavin Tao,Yinuo Wang,Jinzhao Zhou*

Main category: cs.RO

TL;DR: 本文提出基于SSD-Mamba2的视觉驱动跨模态RL框架，解决运动控制中感知-动作策略在计算内存权衡方面的问题，通过选择性状态空间骨干网络实现低延迟、低内存使用，在多种运动控制场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有运动控制器要么是盲目的（仅本体感受），要么依赖计算内存权衡不佳的融合骨干网络，循环控制器存在长程信用分配问题，基于Transformer的融合在标记长度上有二次成本，限制了时间和空间上下文。

Method: 构建基于SSD-Mamba2的视觉驱动跨模态RL框架，SSD-Mamba2是应用状态空间对偶性（SSD）的选择性状态空间骨干网络，能实现循环和卷积扫描，具有硬件感知流处理和近线性扩展。将本体感受状态和外感受观察编码为紧凑标记，通过堆叠SSD-Mamba2层融合。采用课程学习随机化地形和外观，逐渐增加场景复杂度，使用紧凑的以状态为中心的奖励平衡任务进度、能源效率和安全性。

Result: 在多种运动控制场景中，该方法在回报、安全性（碰撞和跌倒）和样本效率方面始终超过强大的最先进基线，同时在相同计算预算下收敛更快。

Conclusion: SSD-Mamba2为可扩展、有远见且高效的端到端运动控制提供了实用的融合骨干网络。

Abstract: End-to-end reinforcement learning for motion control promises unified
perception-action policies that scale across embodiments and tasks, yet most
deployed controllers are either blind (proprioception-only) or rely on fusion
backbones with unfavorable compute-memory trade-offs. Recurrent controllers
struggle with long-horizon credit assignment, and Transformer-based fusion
incurs quadratic cost in token length, limiting temporal and spatial context.
We present a vision-driven cross-modal RL framework built on SSD-Mamba2, a
selective state-space backbone that applies state-space duality (SSD) to enable
both recurrent and convolutional scanning with hardware-aware streaming and
near-linear scaling. Proprioceptive states and exteroceptive observations
(e.g., depth tokens) are encoded into compact tokens and fused by stacked
SSD-Mamba2 layers. The selective state-space updates retain long-range
dependencies with markedly lower latency and memory use than quadratic
self-attention, enabling longer look-ahead, higher token resolution, and stable
training under limited compute. Policies are trained end-to-end under curricula
that randomize terrain and appearance and progressively increase scene
complexity. A compact, state-centric reward balances task progress, energy
efficiency, and safety. Across diverse motion-control scenarios, our approach
consistently surpasses strong state-of-the-art baselines in return, safety
(collisions and falls), and sample efficiency, while converging faster at the
same compute budget. These results suggest that SSD-Mamba2 provides a practical
fusion backbone for scalable, foresightful, and efficient end-to-end motion
control.

</details>


### [17] [Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network](https://arxiv.org/abs/2509.07646)
*Yanlong Peng,Zhigang Wang,Ziwen He,Pengxu Chang,Chuangchuang Zhou,Yu Yan,Ming Chen*

Main category: cs.RO

TL;DR: 本文介绍了RobKiNet，一种运动学知情神经网络，用于在配置空间的多约束下对连续可行集（CFS）进行端到端采样，并建立了其优化期望模型。与传统采样和基于学习的方法相比，RobKiNet的运动学知识注入通过确保稳定准确的梯度优化提高了训练效率，在2-DOF空间的可视化和定量分析验证了其理论效率，在9-DOF自主移动机械手（AMMR）上的应用展示了优越的全身和解耦控制，在电池拆卸任务中表现出色，训练速度比深度强化学习快74.29倍，采样精度高达99.25%，在实际场景中的任务完成率达到97.33%。


<details>
  <summary>Details</summary>
Motivation: 在机器人任务和运动规划（TAMP）中，在机器人配置空间内采样以满足任务级全局约束并提高后续运动规划效率至关重要。由于多级约束下关节配置采样的复杂性，传统方法通常效率低下。

Method: 本文介绍了RobKiNet的原理，即一种运动学知情神经网络，用于在配置空间的多约束下对连续可行集（CFS）进行端到端采样，并建立了其优化期望模型。

Result: 与传统采样和基于学习的方法相比，RobKiNet的运动学知识注入通过确保稳定准确的梯度优化提高了训练效率。在2-DOF空间的可视化和定量分析验证了其理论效率，而其在9-DOF自主移动机械手（AMMR）上的应用展示了优越的全身和解耦控制，在电池拆卸任务中表现出色。RobKiNet优于深度强化学习，训练速度快74.29倍，采样精度高达99.25%，在实际场景中的任务完成率达到97.33%。

Conclusion: RobKiNet通过运动学知识注入，在机器人配置空间采样中提高了训练效率和采样精度，在实际机器人任务中表现出色，优于传统和其他学习方法。

Abstract: In robots task and motion planning (TAMP), it is crucial to sample within the
robot's configuration space to meet task-level global constraints and enhance
the efficiency of subsequent motion planning. Due to the complexity of joint
configuration sampling under multi-level constraints, traditional methods often
lack efficiency. This paper introduces the principle of RobKiNet, a
kinematics-informed neural network, for end-to-end sampling within the
Continuous Feasible Set (CFS) under multiple constraints in configuration
space, establishing its Optimization Expectation Model. Comparisons with
traditional sampling and learning-based approaches reveal that RobKiNet's
kinematic knowledge infusion enhances training efficiency by ensuring stable
and accurate gradient optimization.Visualizations and quantitative analyses in
a 2-DOF space validate its theoretical efficiency, while its application on a
9-DOF autonomous mobile manipulator robot(AMMR) demonstrates superior
whole-body and decoupled control, excelling in battery disassembly tasks.
RobKiNet outperforms deep reinforcement learning with a training speed 74.29
times faster and a sampling accuracy of up to 99.25%, achieving a 97.33% task
completion rate in real-world scenarios.

</details>


### [18] [Collaborative Exploration with a Marsupial Ground-Aerial Robot Team through Task-Driven Map Compression](https://arxiv.org/abs/2509.07655)
*Angelos Zacharia,Mihir Dharmadhikari,Kostas Alexis*

Main category: cs.RO

TL;DR: 本文提出了一种适用于有袋类地面-空中机器人团队的协作探索框架，通过图基路径规划算法及任务驱动的地图压缩策略，提升未知环境探索效率并减少数据传输。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在通信受限的密闭和大规模场景中高效探索未知环境面临挑战。

Method: 采用图基路径规划算法引导探索，在预期收益显著超过地面机器人的区域部署空中机器人；引入带宽高效的任务驱动地图压缩策略，使各机器人能重建特定分辨率的体积地图并保留探索关键细节。

Result: 仿真和真实世界实验验证了所提方法能有效提高探索效率，同时显著减少数据传输。

Conclusion: 所提出的协作探索框架及地图压缩策略对提升机器人团队在未知环境中的探索效率和降低通信开销有效。

Abstract: Efficient exploration of unknown environments is crucial for autonomous
robots, especially in confined and large-scale scenarios with limited
communication. To address this challenge, we propose a collaborative
exploration framework for a marsupial ground-aerial robot team that leverages
the complementary capabilities of both platforms. The framework employs a
graph-based path planning algorithm to guide exploration and deploy the aerial
robot in areas where its expected gain significantly exceeds that of the ground
robot, such as large open spaces or regions inaccessible to the ground
platform, thereby maximizing coverage and efficiency. To facilitate large-scale
spatial information sharing, we introduce a bandwidth-efficient, task-driven
map compression strategy. This method enables each robot to reconstruct
resolution-specific volumetric maps while preserving exploration-critical
details, even at high compression rates. By selectively compressing and sharing
key data, communication overhead is minimized, ensuring effective map
integration for collaborative path planning. Simulation and real-world
experiments validate the proposed approach, demonstrating its effectiveness in
improving exploration efficiency while significantly reducing data
transmission.

</details>


### [19] [Temporal Counterfactual Explanations of Behaviour Tree Decisions](https://arxiv.org/abs/2509.07674)
*Tamlin Love,Antonio Andriella,Guillem Alenyà*

Main category: cs.RO

TL;DR: 本文提出一种新方法，能从行为树自动构建因果模型并生成多样化反事实解释，以回答机器人决策的“为什么”问题，提升系统透明度与可信度。


<details>
  <summary>Details</summary>
Motivation: 现有行为树可解释性方法无法生成因果、反事实解释，无法详细说明机器人决策和行为的原因。

Method: 首先从行为树结构及领域知识（状态和单个节点）自动构建因果模型，然后查询和搜索该模型以找到多样化反事实解释。

Result: 该方法能正确解释多种行为树结构和状态的行为，可回答广泛的因果查询。

Conclusion: 该方法是迈向更透明、可理解且最终值得信赖的机器人系统的一步。

Abstract: Explainability is a critical tool in helping stakeholders understand robots.
In particular, the ability for robots to explain why they have made a
particular decision or behaved in a certain way is useful in this regard.
Behaviour trees are a popular framework for controlling the decision-making of
robots and other software systems, and thus a natural question to ask is
whether or not a system driven by a behaviour tree is capable of answering
"why" questions. While explainability for behaviour trees has seen some prior
attention, no existing methods are capable of generating causal, counterfactual
explanations which detail the reasons for robot decisions and behaviour.
Therefore, in this work, we introduce a novel approach which automatically
generates counterfactual explanations in response to contrastive "why"
questions. Our method achieves this by first automatically building a causal
model from the structure of the behaviour tree as well as domain knowledge
about the state and individual behaviour tree nodes. The resultant causal model
is then queried and searched to find a set of diverse counterfactual
explanations. We demonstrate that our approach is able to correctly explain the
behaviour of a wide range of behaviour tree structures and states. By being
able to answer a wide range of causal queries, our approach represents a step
towards more transparent, understandable and ultimately trustworthy robotic
systems.

</details>


### [20] [Robust Radar SLAM for Vehicle Parking Applications](https://arxiv.org/abs/2509.07683)
*Luis Diener,Jens Kalkkuhl,Markus Enzweiler*

Main category: cs.RO

TL;DR: 本文提出一种基于雷达的SLAM方法用于自动泊车中的 ego-motion 估计，以解决传统IMU和轮编码器方法需校准、成本高且耗时的问题，通过融合特征位置和多普勒速度，支持多雷达及信息基特征剪枝策略，实验表明其定位精度高且鲁棒性优于现有方法，满足自动泊车需求。


<details>
  <summary>Details</summary>
Motivation: 自动泊车中，因空间狭小和障碍物近，厘米级精度至关重要；传统使用IMU和轮编码器的方法需校准，成本高且耗时，故需新方法克服这些问题。

Method: 提出基于雷达的SLAM方法，采用以机器人为中心的公式，融合特征位置和多普勒速度以实现鲁棒的数据关联和滤波器收敛，包括多普勒增强的雷达SLAM方法、多雷达支持及信息基特征剪枝策略。

Result: 实验表明该方法实现了高精度定位，且鲁棒性优于现有方法，满足自动泊车的需求。

Conclusion: 所提出的雷达基SLAM方法在自动泊车ego-motion估计中有效，具备高精度和高鲁棒性，解决了传统方法的校准问题，适用于自动泊车场景。

Abstract: We address ego-motion estimation for automated parking, where
centimeter-level accuracy is crucial due to tight spaces and nearby obstacles.
Traditional methods using inertial-measurement units and wheel encoders require
calibration, making them costly and time-consuming. To overcome this, we
propose a radar-based simultaneous localization and mapping (SLAM) approach
that leverages the robustness of radar to adverse weather and support for
online calibration. Our robocentric formulation fuses feature positions and
Doppler velocities for robust data association and filter convergence. Key
contributions include a Doppler-augmented radar SLAM method, multi-radar
support and an information-based feature-pruning strategy. Experiments
demonstrate high-accuracy localization and improved robustness over
state-of-the-art methods, meeting the demands of automated parking.

</details>


### [21] [Fault Tolerant Control of a Quadcopter using Reinforcement Learning](https://arxiv.org/abs/2509.07707)
*Muzaffar Habib,Adnan Maqsood,Adnan Fayyaz ud Din*

Main category: cs.RO

TL;DR: 本研究提出一种基于强化学习（RL）的新型控制框架，旨在增强四旋翼无人机的安全性和鲁棒性，特别关注其在飞行中单个螺旋桨故障时的恢复能力。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼无人机在实际应用中保持期望高度以确保硬件和有效载荷安全的鲁棒控制策略这一关键需求。

Method: 研究了两种RL方法——动态规划（DP，基于模型，有收敛保证但计算量大）和深度确定性策略梯度（DDPG，无模型，计算快速但受解持续时间限制），并对现有算法进行修改，以适应大型连续状态和动作域，并在飞行中螺旋桨故障后达到期望状态。

Result: 在MATLAB环境中针对各种初始条件进行了广泛仿真，验证了所提控制框架的鲁棒性，且对两种RL算法在故障航空系统中的应用潜力进行了比较分析。

Conclusion: 所提出的基于RL的控制框架对任务关键型四旋翼无人机应用具有可行性。

Abstract: This study presents a novel reinforcement learning (RL)-based control
framework aimed at enhancing the safety and robustness of the quadcopter, with
a specific focus on resilience to in-flight one propeller failure. Addressing
the critical need of a robust control strategy for maintaining a desired
altitude for the quadcopter to safe the hardware and the payload in physical
applications. The proposed framework investigates two RL methodologies Dynamic
Programming (DP) and Deep Deterministic Policy Gradient (DDPG), to overcome the
challenges posed by the rotor failure mechanism of the quadcopter. DP, a
model-based approach, is leveraged for its convergence guarantees, despite high
computational demands, whereas DDPG, a model-free technique, facilitates rapid
computation but with constraints on solution duration. The research challenge
arises from training RL algorithms on large dimensions and action domains. With
modifications to the existing DP and DDPG algorithms, the controllers were
trained not only to cater for large continuous state and action domain and also
achieve a desired state after an inflight propeller failure. To verify the
robustness of the proposed control framework, extensive simulations were
conducted in a MATLAB environment across various initial conditions and
underscoring its viability for mission-critical quadcopter applications. A
comparative analysis was performed between both RL algorithms and their
potential for applications in faulty aerial systems.

</details>


### [22] [Unlocking Stopped-Rotor Flight: Development and Validation of SPERO, a Novel UAV Platform](https://arxiv.org/abs/2509.07812)
*Kristan Hilby,Ian Hunter*

Main category: cs.RO

TL;DR: 本文提出了一种名为SPERO的停转旋翼无人机，通过多种创新设计（包括可翻转锁定机翼、主动压力中心机构等）和控制框架，解决了停转旋翼飞行器在飞行模式间的气动和稳定性冲突，实现了垂直起降与前飞之间稳定的双向过渡。


<details>
  <summary>Details</summary>
Motivation: 停转旋翼飞行器被认为是理想的垂直起降（VTOL）飞行器，适用于农业监测、搜救、最后一公里配送等需要在两种飞行模式上花费相等时间的任务，但由于飞行模式间的气动和稳定性冲突，其实际应用一直不可行。

Method: 设计了SPERO停转旋翼无人机，具有可翻转锁定机翼、主动压力中心机构、推力矢量平衡装置、五旋翼架构，以及协调几何和控制器重构的十一状态机飞行控制器，并建立了可推广的停转旋翼无人机设计和控制框架。

Result: 克服了停转旋翼飞行中长期存在的挑战，实现了垂直起降与前飞之间首次稳定的双向过渡。

Conclusion: SPERO的创新设计和控制框架解决了停转旋翼飞行器的关键问题，为其实际应用奠定了基础。

Abstract: Stop-rotor aircraft have long been proposed as the ideal vertical takeoff and
landing (VTOL) aircraft for missions with equal time spent in both flight
regimes, such as agricultural monitoring, search and rescue, and last-mile
delivery. Featuring a central lifting surface that rotates in VTOL to generate
vertical thrust and locks in forward flight to generate passive lift, the
stop-rotor offers the potential for high efficiency across both modes. However,
practical implementation has remained infeasible due to aerodynamic and
stability conflicts between flight modes. In this work, we present SPERO
(Stopped-Penta Rotor), a stop-rotor uncrewed aerial vehicle (UAV) featuring a
flipping and latching wing, an active center of pressure mechanism, thrust
vectored counterbalances, a five-rotor architecture, and an eleven-state
machine flight controller coordinating geometric and controller
reconfiguration. Furthermore, SPERO establishes a generalizable design and
control framework for stopped-rotor UAVs. Together, these innovations overcome
longstanding challenges in stop-rotor flight and enable the first stable,
bidirectional transition between VTOL and forward flight.

</details>


### [23] [Programmable Locking Cells (PLC) for Modular Robots with High Stiffness Tunability and Morphological Adaptability](https://arxiv.org/abs/2509.07916)
*Jianshu Zhou,Wei Chen,Junda Huang,Boyuan Liang,Yunhui Liu,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 本文提出可编程锁定单元（PLC），一种模块化、肌腱驱动单元，通过机械互锁关节实现离散刚度调制，可组装成具有空间可编程刚度的可重构机器人结构，并通过两个功能原型验证了其设计有效性。


<details>
  <summary>Details</summary>
Motivation: 现有可变刚度解决方案依赖复杂驱动方案、持续输入功率或整体式设计，限制了模块化和可扩展性，而机器人系统在非结构化环境中需要在柔顺和刚性状态间切换以执行多种任务。

Method: 提出可编程锁定单元（PLC），一种模块化、肌腱驱动单元，通过电缆张力驱动的机械互锁关节实现离散刚度调制，每个单元通过结构接合在柔顺和刚性状态间转换，多个PLC单元可组装成具有空间可编程刚度的可重构机器人结构。

Result: PLC单元组装系统每单元刚度变化高达950%，刚性状态下承受高负载时不易损坏；通过两个功能原型验证了设计：（1）可变刚度抓手，能自适应抓取、牢固握持和在手操作；（2）由串联PLC单元组成的管道穿越机器人，在受限环境中实现形状适应性和刚度控制。

Conclusion: PLC是一种可扩展、以结构为中心的可编程刚度和运动机制，使机器人系统具有可重构形态和任务自适应交互能力。

Abstract: Robotic systems operating in unstructured environments require the ability to
switch between compliant and rigid states to perform diverse tasks such as
adaptive grasping, high-force manipulation, shape holding, and navigation in
constrained spaces, among others. However, many existing variable stiffness
solutions rely on complex actuation schemes, continuous input power, or
monolithic designs, limiting their modularity and scalability. This paper
presents the Programmable Locking Cell (PLC)-a modular, tendon-driven unit that
achieves discrete stiffness modulation through mechanically interlocked joints
actuated by cable tension. Each unit transitions between compliant and firm
states via structural engagement, and the assembled system exhibits high
stiffness variation-up to 950% per unit-without susceptibility to damage under
high payload in the firm state. Multiple PLC units can be assembled into
reconfigurable robotic structures with spatially programmable stiffness. We
validate the design through two functional prototypes: (1) a variable-stiffness
gripper capable of adaptive grasping, firm holding, and in-hand manipulation;
and (2) a pipe-traversing robot composed of serial PLC units that achieves
shape adaptability and stiffness control in confined environments. These
results demonstrate the PLC as a scalable, structure-centric mechanism for
programmable stiffness and motion, enabling robotic systems with reconfigurable
morphology and task-adaptive interaction.

</details>


### [24] [RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction](https://arxiv.org/abs/2509.07953)
*Zheyuan Hu,Robyn Wu,Naveen Enock,Jasmine Li,Riya Kadakia,Zackory Erickson,Aviral Kumar*

Main category: cs.RO

TL;DR: 现有机器人模仿学习在接触丰富、可变形物体和长周期任务中表现不佳，原因是基于人类遥操作的数据收集效率低。本文提出RaC方法，在模仿学习预训练后通过人类介入轨迹微调策略，包括回退到熟悉状态和提供纠正段，以提升效率和鲁棒性，在三个真实双手机器人任务和一个模拟装配任务中用10倍少的数据收集时间和样本超越SOTA，且性能随恢复操作数量线性扩展。


<details>
  <summary>Details</summary>
Motivation: 现有基于人类遥操作的“专家”数据收集程序效率低下，导致机器人在接触丰富、可变形物体和长周期任务中的性能远低于完美执行水平，即使有数千次专家演示也难以改善。

Method: 提出RaC方法，在模仿学习预训练后，通过人类介入轨迹微调机器人策略。具体是在策略部署时，人类操作员在即将发生故障时介入，先将机器人回退到熟悉的分布内状态，再提供完成当前子任务的纠正段。

Result: 在三个真实世界双手机器人控制任务（挂衬衫、密封容器盖、外卖盒包装）和一个模拟装配任务中，RaC使用10倍更少的数据收集时间和样本，性能优于先前的最先进技术；且训练后的RaC策略性能随其展示的恢复操作数量线性扩展。

Conclusion: RaC通过在模仿学习预训练后引入人类介入轨迹的微调阶段，扩展了机器人的技能库，使其具备重试和适应行为，这对提高长周期任务的效率和鲁棒性至关重要。

Abstract: Modern paradigms for robot imitation train expressive policy architectures on
large amounts of human demonstration data. Yet performance on contact-rich,
deformable-object, and long-horizon tasks plateau far below perfect execution,
even with thousands of expert demonstrations. This is due to the inefficiency
of existing ``expert'' data collection procedures based on human teleoperation.
To address this issue, we introduce RaC, a new phase of training on
human-in-the-loop rollouts after imitation learning pre-training. In RaC, we
fine-tune a robotic policy on human intervention trajectories that illustrate
recovery and correction behaviors. Specifically, during a policy rollout, human
operators intervene when failure appears imminent, first rewinding the robot
back to a familiar, in-distribution state and then providing a corrective
segment that completes the current sub-task. Training on this data composition
expands the robotic skill repertoire to include retry and adaptation behaviors,
which we show are crucial for boosting both efficiency and robustness on
long-horizon tasks. Across three real-world bimanual control tasks: shirt
hanging, airtight container lid sealing, takeout box packing, and a simulated
assembly task, RaC outperforms the prior state-of-the-art using 10$\times$ less
data collection time and samples. We also show that RaC enables test-time
scaling: the performance of the trained RaC policy scales linearly in the
number of recovery maneuvers it exhibits. Videos of the learned policy are
available at https://rac-scaling-robot.github.io/.

</details>


### [25] [Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation](https://arxiv.org/abs/2509.07957)
*Shunlei Li,Longsen Gao,Jiuwen Cao,Yingbai Hu*

Main category: cs.RO

TL;DR: 本文提出GF-VLA框架，通过从RGB-D人类演示中提取任务相关线索并构建时序场景图，结合语言条件Transformer生成层次化行为树和可解释运动原语，实现双臂机器人在不同物体、空间布局和操作器配置下的任务级推理与执行，在四项积木装配基准测试中取得高成功率。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖低级轨迹复制，难以在不同物体、空间布局和操作器配置间泛化，因此需要一种能从人类视频演示中实现任务级推理与执行的框架。

Method: 1. 采用信息论方法提取任务相关线索，突出关键手-物和物-物交互；2. 将线索构建为时序场景图，结合语言条件Transformer生成层次化行为树和可解释笛卡尔运动原语；3. 提出跨臂分配策略，自主确定 gripper 分配，无需显式几何建模。

Result: 在四项双臂积木装配基准测试中，场景图准确率超95%，子任务分割率达93%；语言-动作规划器生成的策略在抓取可靠性（94%）、放置精度（89%）和总体任务成功率（90%）方面表现良好，在堆叠、字母形成和几何重构任务中具有强泛化性和鲁棒性。

Conclusion: GF-VLA框架通过结构化场景表示和语言-动作规划，实现了双臂机器人在多样化空间和语义变化下的强泛化性和鲁棒性任务执行，为从人类演示中获取灵巧机器人技能提供了有效解决方案。

Abstract: Acquiring dexterous robotic skills from human video demonstrations remains a
significant challenge, largely due to conventional reliance on low-level
trajectory replication, which often fails to generalize across varying objects,
spatial layouts, and manipulator configurations. To address this limitation, we
introduce Graph-Fused Vision-Language-Action (GF-VLA), a unified framework that
enables dual-arm robotic systems to perform task-level reasoning and execution
directly from RGB-D human demonstrations. GF-VLA employs an
information-theoretic approach to extract task-relevant cues, selectively
highlighting critical hand-object and object-object interactions. These cues
are structured into temporally ordered scene graphs, which are subsequently
integrated with a language-conditioned transformer to produce hierarchical
behavior trees and interpretable Cartesian motion primitives. To enhance
efficiency in bimanual execution, we propose a cross-arm allocation strategy
that autonomously determines gripper assignment without requiring explicit
geometric modeling. We validate GF-VLA on four dual-arm block assembly
benchmarks involving symbolic structure construction and spatial
generalization. Empirical results demonstrate that the proposed representation
achieves over 95% graph accuracy and 93% subtask segmentation, enabling the
language-action planner to generate robust, interpretable task policies. When
deployed on a dual-arm robot, these policies attain 94% grasp reliability, 89%
placement accuracy, and 90% overall task success across stacking,
letter-formation, and geometric reconfiguration tasks, evidencing strong
generalization and robustness under diverse spatial and semantic variations.

</details>


### [26] [TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models](https://arxiv.org/abs/2509.07962)
*Zongzheng Zhang,Haobo Xu,Zhuo Yang,Chenghao Yue,Zehao Lin,Huan-ang Gao,Ziwei Wang,Hao Zhao*

Main category: cs.RO

TL;DR: 本文探索了扭矩感知VLA模型，通过系统研究将扭矩信号整合到现有VLA架构的设计空间，提出并评估了多种策略，发现解码器中引入扭矩适配器优于编码器，且将扭矩预测为辅助输出可进一步提升性能，实验验证了这些发现。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言-动作（VLA）模型缺乏整合如扭矩等细微物理反馈的能力，而许多机器人操作任务需要感知和响应力信号以评估任务是否成功完成并实现闭环控制。

Method: 系统研究将扭矩信号整合到现有VLA架构的设计空间，识别并评估了多种策略，包括在解码器中引入扭矩适配器，以及受自动驾驶中联合预测和规划范式启发，将扭矩预测为辅助输出。

Result: 解码器中引入扭矩适配器的策略始终优于在编码器中插入的策略，将扭矩预测为辅助输出的策略进一步提升了性能，该策略促使模型构建具有物理基础的交互动力学内部表示，在接触丰富的操作基准测试中通过了广泛的定量和定性实验验证。

Conclusion: 通过将扭矩信号整合到VLA架构中，特别是在解码器中引入扭矩适配器和将扭矩预测为辅助输出的策略，能够有效提升模型在接触丰富的机器人操作任务中的性能，验证了构建具有物理基础的内部表示对提升VLA模型能力的有效性。

Abstract: Many robotic manipulation tasks require sensing and responding to force
signals such as torque to assess whether the task has been successfully
completed and to enable closed-loop control. However, current
Vision-Language-Action (VLA) models lack the ability to integrate such subtle
physical feedback. In this work, we explore Torque-aware VLA models, aiming to
bridge this gap by systematically studying the design space for incorporating
torque signals into existing VLA architectures. We identify and evaluate
several strategies, leading to three key findings. First, introducing torque
adapters into the decoder consistently outperforms inserting them into the
encoder.Third, inspired by joint prediction and planning paradigms in
autonomous driving, we propose predicting torque as an auxiliary output, which
further improves performance. This strategy encourages the model to build a
physically grounded internal representation of interaction dynamics. Extensive
quantitative and qualitative experiments across contact-rich manipulation
benchmarks validate our findings.

</details>
